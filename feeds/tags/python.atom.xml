<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jason Antman's Blog - python</title><link href="https://blog.jasonantman.com/" rel="alternate"></link><link href="https://blog.jasonantman.com/feeds/tags/python.atom.xml" rel="self"></link><id>https://blog.jasonantman.com/</id><updated>2018-11-01T18:07:00-04:00</updated><entry><title>Open Source WiFi Site Survey Heatmap Tool</title><link href="https://blog.jasonantman.com/2018/11/open-source-wifi-site-survey-tool/" rel="alternate"></link><published>2018-11-01T18:07:00-04:00</published><updated>2018-11-01T18:07:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-11-01:/2018/11/open-source-wifi-site-survey-tool/</id><summary type="html">&lt;p&gt;A bit about a Python project I wrote to plot floorplan heatmaps of wireless site&amp;nbsp;surveys.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week I finally bought myself a new wireless access point (&lt;span class="caps"&gt;AP&lt;/span&gt;) to replace my current ones, a pair of older Ubiquiti models that have been continually in service without issue for &lt;a href="https://twitter.com/j_antman/status/1029135879695228929"&gt;nine years&lt;/a&gt; and five years, respectively. I bought another Ubiquiti, of course, but wanted to be a bit more methodical and scientific in figuring out the best placement of it in my&amp;nbsp;house.&lt;/p&gt;
&lt;p&gt;Years ago when part of my job was supporting an extremely large wireless network, we used some expensive proprietary Windows software (I&amp;#8217;m pretty sure it was &lt;a href="https://www.ekahau.com/products/ekahau-site-survey/overview/"&gt;Ekahau Site Survey&lt;/a&gt;) for performing site surveys to
determine &lt;span class="caps"&gt;AP&lt;/span&gt; location. Essentially you temporarily rig up a running &lt;span class="caps"&gt;AP&lt;/span&gt; where you propose locating one, load a floorplan of the building into the site survey software, and then walk around the area tapping on the floorplan at your current location. At each tap, the software performs some measurements through the &lt;span class="caps"&gt;AP&lt;/span&gt; (I don&amp;#8217;t remember what the specific software we used did, but generally it&amp;#8217;s some bandwidth measurement like &lt;a href="https://software.es.net/iperf/"&gt;iperf&lt;/a&gt;) and ends up plotting a (predictive, interpolated) heatmap of signal strength or data transfer speeds over the&amp;nbsp;floorplan.&lt;/p&gt;
&lt;p&gt;I wanted to do something similar for my new &lt;span class="caps"&gt;AP&lt;/span&gt;, but was rather surprised that I couldn&amp;#8217;t find any existing F/&lt;span class="caps"&gt;OSS&lt;/span&gt; solution; only a handful of proprietary options costing anywhere from &amp;#8220;more than I&amp;#8217;d pay for a one-time thing&amp;#8221; to astronomical prices, and none of them clearly with Linux support. The closest I was able to find - and I&amp;#8217;m very thankful that I found it - was a &lt;a href="https://github.com/beaugunderson/wifi-heatmap"&gt;GitHub repository from Beau Gunderson&lt;/a&gt; that plots a heatmap superimposed on a floorplan using a &lt;span class="caps"&gt;CSV&lt;/span&gt; file of WiFi signal strength measurements. This was enough to get me started on a similar project to automate the&amp;nbsp;process.&lt;/p&gt;
&lt;p&gt;Over a couple of afternoons I came up with a really rough tool, &lt;a href="https://github.com/jantman/python-wifi-survey-heatmap"&gt;python-wifi-survey-heatmap&lt;/a&gt; to handle this. The full documentation is in the &lt;a href="https://github.com/jantman/python-wifi-survey-heatmap/blob/master/README.rst"&gt;&lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt;, but the gist is that it&amp;#8217;s a Python &lt;span class="caps"&gt;GUI&lt;/span&gt; (wxPython) and &lt;span class="caps"&gt;CLI&lt;/span&gt; application that automates the process. It&amp;#8217;s currently Linux-only because it uses &lt;code&gt;iwlib&lt;/code&gt; (wireless_tools) to pull wireless information and perform scans, but that could be fixed by adding collector classes for other OSes. In short you run an iperf3 server somewhere on your &lt;span class="caps"&gt;LAN&lt;/span&gt;, connect to the &lt;span class="caps"&gt;SSID&lt;/span&gt; you want to test, fire up the &lt;span class="caps"&gt;GUI&lt;/span&gt; passing it the path to an image to use as the floorplan background and the &lt;span class="caps"&gt;IP&lt;/span&gt; or hostname of the iperf3 server, and then walk around clicking the floorplan at your current location. For each click the application will draw a yellow circle and then change it to green when measurement is complete, about a minute&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;For each measurement point (location on the floorplan), the application&amp;nbsp;captures:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Current wireless statistics including quality, signal strength, and noise level (like &lt;code&gt;iwconfig&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;A current scan (like &lt;code&gt;iwlist scan&lt;/code&gt;) of all visible networks and their signal&amp;nbsp;strength/quality.&lt;/li&gt;
&lt;li&gt;Three 10-second iperf3 measurements to the iperf&amp;nbsp;server:&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;TCP&lt;/span&gt; upload (client/application to&amp;nbsp;server)&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;TCP&lt;/span&gt; download (server to&amp;nbsp;client)&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;UDP&lt;/span&gt;&amp;nbsp;upload&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After each measurement is complete all data is saved to a &lt;span class="caps"&gt;JSON&lt;/span&gt; file in the current directory, and the gui application can optionally load an existing &lt;span class="caps"&gt;JSON&lt;/span&gt; output file to continue a previous survey. None of this uses any sort of shell/subprocess/exec hackery; we interface with iwconfig and iwlist information via the python &lt;a href="https://pypi.org/project/iwlib/"&gt;iwlib&lt;/a&gt; package, a cffi Python wrapper around wireless_tools&amp;#8217; iwlib, and with iperf3 via the &lt;a href="https://pypi.org/project/iperf3/"&gt;iperf3&lt;/a&gt; package, a cdll wrapper around&amp;nbsp;libiperf.&lt;/p&gt;
&lt;p&gt;Once you&amp;#8217;ve completed capturing data for your site survey, the &lt;code&gt;wifi-heatmap&lt;/code&gt; &lt;span class="caps"&gt;CLI&lt;/span&gt; entrypoint processes the data and generates some heatmaps as well as channel utilization graphs like&amp;nbsp;these:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/channels24_WAP1.png"&gt;&lt;img alt="example 2.4 GHz channel usage" src="/GFX/channels24_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/channels5_WAP1.png"&gt;&lt;img alt="example 5 GHz channel usage" src="/GFX/channels5_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/jitter_WAP1.png"&gt;&lt;img alt="example jitter heatmap" src="/GFX/jitter_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/quality_WAP1.png"&gt;&lt;img alt="example quality heatmap" src="/GFX/quality_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/rssi_WAP1.png"&gt;&lt;img alt="example rssi heatmap" src="/GFX/rssi_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/tcp_download_Mbps_WAP1.png"&gt;&lt;img alt="example tcp download heatmap" src="/GFX/tcp_download_Mbps_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/tcp_upload_Mbps_WAP1.png"&gt;&lt;img alt="example tcp upload heatmap" src="/GFX/tcp_upload_Mbps_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/udp_Mbps_WAP1.png"&gt;&lt;img alt="example udp upload heatmap" src="/GFX/udp_Mbps_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All of the code and some initial documentation is available at &lt;a href="https://github.com/jantman/python-wifi-survey-heatmap"&gt;https://github.com/jantman/python-wifi-survey-heatmap&lt;/a&gt;. It&amp;#8217;s very alpha and rough around the edges, and I doubt I&amp;#8217;ll be actively developing or supporting it once I&amp;#8217;m done installing my new &lt;span class="caps"&gt;AP&lt;/span&gt;, but I very much hope that it might be of use to someone else and maybe someone will even improve it a&amp;nbsp;bit.&lt;/p&gt;</content><category term="wifi"></category><category term="survey"></category><category term="wireless"></category><category term="heatmap"></category><category term="python"></category></entry><entry><title>Better Logging for AppDaemon Apps</title><link href="https://blog.jasonantman.com/2018/07/better-logging-for-appdaemon-apps/" rel="alternate"></link><published>2018-07-15T07:38:00-04:00</published><updated>2018-07-15T07:38:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-07-15:/2018/07/better-logging-for-appdaemon-apps/</id><summary type="html">&lt;p&gt;A small Python class I wrote to give AppDaemon apps more Pythonic&amp;nbsp;logging.&lt;/p&gt;</summary><content type="html">&lt;p&gt;As I briefly mentioned in my last post, &lt;a href="/2018/07/ip-camera-home-security-and-automation-update/"&gt;&lt;span class="caps"&gt;IP&lt;/span&gt; Camera, Home Security and Automation Update&lt;/a&gt;, I&amp;#8217;ve begun using the &lt;a href="https://www.home-assistant.io/"&gt;HomeAssistant&lt;/a&gt; project for home automation and also to act as the brain for my &lt;span class="caps"&gt;DIY&lt;/span&gt; alarm system. The logic behind some of this is somewhat complex, so rather than try to use HomeAssistant&amp;#8217;s &lt;span class="caps"&gt;YAML&lt;/span&gt;-based automation configuration for all of it, I&amp;#8217;ve implemented the alarm logic using AppDaemon. &lt;a href="http://appdaemon.readthedocs.io/en/latest/"&gt;AppDaemon&lt;/a&gt; is a Python daemon that integrates with HomeAssistant&amp;#8217;s &lt;span class="caps"&gt;API&lt;/span&gt; and message/event bus, and allows standalone Python classes (&amp;#8220;apps&amp;#8221;) to operate like HomeAssistant automations - be triggered by events or state change, access internal state and attributes, call services, and control anything that HomeAssistant can control. For someone with at least a basic working knowledge of Python, this makes it much easier to write complex conditional logic than attempting to use&amp;nbsp;&lt;span class="caps"&gt;YAML&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;However, when I wrote my first AppDaemon app, I was quite frustrated by the built-in logging system. The &lt;a href="http://appdaemon.readthedocs.io/en/latest/APPGUIDE.html#writing-to-logfiles"&gt;documentation&lt;/a&gt; explains that AppDaemon uses two log files by default, &amp;#8220;general&amp;#8221; and &amp;#8220;error&amp;#8221;, and that each AppDaemon app (subclass of &lt;code&gt;appdaemon.plugins.hass.hassapi.Hass&lt;/code&gt;) can log to them using &lt;code&gt;self.log()&lt;/code&gt; and &lt;code&gt;self.error()&lt;/code&gt; convenience methods. So far this sounds fine. However, looking at the &lt;span class="caps"&gt;API&lt;/span&gt; documentation for these &lt;a href="http://appdaemon.readthedocs.io/en/latest/APIREFERENCE.html#log"&gt;log()&lt;/a&gt; and &lt;a href="http://appdaemon.readthedocs.io/en/latest/APIREFERENCE.html#error"&gt;error()&lt;/a&gt; methods, it becomes apparent that the only arguments they take are a string &lt;code&gt;message&lt;/code&gt; and a log level that defaults to &lt;code&gt;INFO&lt;/code&gt;. Unlike the ubiquitous logging methods of the &lt;a href="https://docs.python.org/3/library/logging.html#logger-objects"&gt;Python standard library&lt;/a&gt;, they don&amp;#8217;t accept a message with percent-formatting placeholders and a list of arguments, meaning that the message string needs to be formatted in the logging call&amp;nbsp;itself.&lt;/p&gt;
&lt;p&gt;Another annoyance is the fixed logging format that includes only the timestamp, log level, app name, and message; when I&amp;#8217;m developing and debugging code I often find it useful to include at least the source module and line number in the log message. At first I tried to alter the logging formatter in use by AppDaemon, but that gave some strange results because it turns out that AppDaemon doesn&amp;#8217;t actually use a logging format, but rather in the &lt;a href="https://github.com/home-assistant/appdaemon/blob/e04820aafafe840fb4be7a8bef1996b70e62506f/appdaemon/utils.py#L143-L160"&gt;appdaemon.utils.log()&lt;/a&gt; function interpolates the timestamp, level and app name directly into the message and passes that to&amp;nbsp;logging.&lt;/p&gt;
&lt;p&gt;Furthermore, and even more bothersome during development, there&amp;#8217;s no way to enable debug-level logging on a per-app basis. Logging level is controlled by a command line flag (&lt;code&gt;-D&lt;/code&gt;) to &lt;code&gt;appdaemon&lt;/code&gt; itself, which means that debug logging is all-or-nothing for both AppDaemon itself and all apps. I found a &lt;a href="https://community.home-assistant.io/t/appdaemon-debug-mode/9703"&gt;forum thread&lt;/a&gt; complaining about this and also a &lt;a href="https://github.com/home-assistant/appdaemon/issues/45"&gt;closed GitHub issue&lt;/a&gt; looking for a better&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;So, I came up with my own solution to this in the form of my &lt;a href="https://github.com/jantman/home-automation-configs/blob/9c196f1e552fc9fbdfe15f2e27a7275bca24f167/appdaemon/apps/sane_app_logging.py"&gt;sane_app_logging.py&lt;/a&gt; module and the &lt;a href="https://github.com/jantman/home-automation-configs/blob/9c196f1e552fc9fbdfe15f2e27a7275bca24f167/appdaemon/apps/sane_app_logging.py"&gt;SaneAppLogging&lt;/a&gt; mixin class in it. All I need to do is add &lt;code&gt;SaneAppLogging&lt;/code&gt; to the list of classes my app inherits from and add a call to &lt;code&gt;self._setup_logging(self.__class__.__name__, False)&lt;/code&gt; at the beginning of the &lt;code&gt;initialize()&lt;/code&gt; method. What this gets me&amp;nbsp;is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;self._log.(debug|info|warning|error|critical|log)&lt;/code&gt; methods that pass directly through to the standard library logging methods, including args and kwargs (and therefore support for log messages with percent-formatting of&amp;nbsp;args).&lt;/li&gt;
&lt;li&gt;Log message formatting for all of AppDaemon that includes the filename, line number and function name (&lt;code&gt;"[%(levelname)s %(filename)s:%(lineno)s - %(name)s.%(funcName)s() ] %(message)s"&lt;/code&gt;). A large portion of the code in my &lt;code&gt;sane_app_logging.py&lt;/code&gt; module is dedicated to finding the proper stack frame so that source location is correct even with the wrapper in&amp;nbsp;place.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Runtime&lt;/em&gt; toggling of &amp;#8220;debug-as-info&amp;#8221; logging. To get around AppDaemon&amp;#8217;s global log levels and the requirement of enabling debugging at AppDaemon start and for all running code, apps using &lt;code&gt;SaneAppLogging&lt;/code&gt; listen for a &lt;code&gt;LOGWRAPPER_SET_DEBUG&lt;/code&gt; event from HomeAssistant. When received this event toggles a specific app class to log all &lt;code&gt;.debug()&lt;/code&gt; messages at &lt;span class="caps"&gt;INFO&lt;/span&gt; level instead, allowing me to selectively turn on and off debug logging on a single app at&amp;nbsp;runtime.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The event payloads for debug-as-info toggling are quite simple, a dictionary with two keys: &lt;code&gt;app_class&lt;/code&gt; and &lt;code&gt;debug_value&lt;/code&gt;. &lt;code&gt;app_class&lt;/code&gt; should be set to the name of the class (App) we want to change, and &lt;code&gt;debug_value&lt;/code&gt; a boolean. When True, any messages logged via &lt;code&gt;self._log.debug()&lt;/code&gt; will &lt;a href="https://github.com/jantman/home-automation-configs/blob/9c196f1e552fc9fbdfe15f2e27a7275bca24f167/appdaemon/apps/sane_app_logging.py#L100-L102"&gt;actually be logged&lt;/a&gt; via &lt;code&gt;self._log.info()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So far this seems to be working quite well for me, and allowing me to have a much better experience with developing, debugging and testing AppDaemon apps. Perhaps it will be useful to someone else as&amp;nbsp;well.&lt;/p&gt;</content><category term="AppDaemon"></category><category term="HomeAssistant"></category><category term="automation"></category><category term="python"></category><category term="logging"></category></entry><entry><title>Python script to check xfinity data usage</title><link href="https://blog.jasonantman.com/2017/04/python-script-to-check-xfinity-data-usage/" rel="alternate"></link><published>2017-04-17T16:11:00-04:00</published><updated>2017-04-17T16:11:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2017-04-17:/2017/04/python-script-to-check-xfinity-data-usage/</id><summary type="html">&lt;p&gt;Python/selenium script to check your Xfinity data&amp;nbsp;usage&lt;/p&gt;</summary><content type="html">&lt;p&gt;Yesterday I got one of those invasive, abusive, utterly awful (and idiotic) &lt;a href="https://www.techdirt.com/articles/20161123/10554936126/comcast-takes-heat-injecting-messages-into-internet-traffic.shtml"&gt;injected popups from Xfinity&lt;/a&gt; that I&amp;#8217;m at 75% of my monthly bandwidth allocation. Nevermind the fact that I have a bunch of automated scripts running on my computer and injected &lt;span class="caps"&gt;HTML&lt;/span&gt; might never be seen by a human, or that I work from home and every once in a while I&amp;#8217;ll find myself pulling and pushing multi-&lt;span class="caps"&gt;GB&lt;/span&gt; Docker images, which completely kills my &lt;span class="caps"&gt;1TB&lt;/span&gt; bandwidth limit. But it&amp;#8217;s only half way through the month and, frankly, I&amp;#8217;m pretty mystified how I could have used so much data this quickly. I went to Xfinity&amp;#8217;s site to check my usage meter - after rummaging around in my password manager to find my credentials - and realized that while it shows a graph of the past three months and a progress bar for the current month, it doesn&amp;#8217;t show me any detailed (i.e. daily or hourly) data that would help me figure out the&amp;nbsp;cause.&lt;/p&gt;
&lt;p&gt;So, I wrote a little &lt;a href="https://github.com/jantman/xfinity-usage"&gt;script&lt;/a&gt; using Python and Selenium to log in to their My Account site and screen-scrape the &lt;a href="http://www.xfinity.com/usagemeter"&gt;usage meter&lt;/a&gt;. Why Comcast would require me to log in to view my usage when I&amp;#8217;m accessing their site from the &lt;span class="caps"&gt;IP&lt;/span&gt; address &lt;em&gt;they&lt;/em&gt; gave me, on &lt;em&gt;their&lt;/em&gt; network, I have no idea&amp;#8230; unless it&amp;#8217;s to provide a disincentive for customers to be aware of their usage. But I wrote the script, and it seems to be working. For the time being, I&amp;#8217;m both pushing the results into Graphite so I can see usage over time, and sending myself a daily email so I can keep on top of&amp;nbsp;usage.&lt;/p&gt;
&lt;p&gt;Apparently Comcast used to have &lt;a href="http://usmapp-qa.comcast.net/"&gt;a desktop app&lt;/a&gt; to track usage but it&amp;#8217;s since been completely shut down, along with the &lt;span class="caps"&gt;API&lt;/span&gt; that backed it (which an enterprising fellow reverse-engineered in &lt;a href="https://github.com/WTFox/comcastUsage"&gt;this script&lt;/a&gt;). I can only assume this is another indication that, though the bandwidth cap was introduced citing &amp;#8220;network performance&amp;#8221;, they really don&amp;#8217;t want people lowering network load (and avoiding&amp;nbsp;fees).&lt;/p&gt;
&lt;p&gt;I don&amp;#8217;t remember anything about screen-scraping in the Xfinity terms of service - and if they&amp;#8217;re f-ing injecting elements into &lt;em&gt;my&lt;/em&gt; web traffic, I sure as hell hope they don&amp;#8217;t complain about me checking my own usage - but use this at your own risk. Also be aware that it&amp;#8217;s screen-scraping, so it may well break with a site redesign or element &lt;span class="caps"&gt;ID&lt;/span&gt;&amp;nbsp;changes.&lt;/p&gt;
&lt;p&gt;If anyone would find this useful, please see &lt;a href="https://github.com/jantman/xfinity-usage"&gt;https://github.com/jantman/xfinity-usage&lt;/a&gt;.&lt;/p&gt;</content><category term="comcast"></category><category term="xfinity"></category><category term="data"></category><category term="usage"></category><category term="bandwidth"></category><category term="cap"></category><category term="python"></category><category term="selenium"></category></entry><entry><title>Tooling for AWS - webhooks to SQS via API Gateway and Lambda</title><link href="https://blog.jasonantman.com/2016/08/tooling-for-aws-webhooks-to-sqs-via-api-gateway-and-lambda/" rel="alternate"></link><published>2016-08-06T21:38:00-04:00</published><updated>2016-08-06T21:38:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2016-08-06:/2016/08/tooling-for-aws-webhooks-to-sqs-via-api-gateway-and-lambda/</id><summary type="html">&lt;p&gt;Project I created that uses Python and Terraform to setup an &lt;span class="caps"&gt;AWS&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; Gateway instance to receive webhooks, and enqueue their content in &lt;span class="caps"&gt;SQS&lt;/span&gt; queues via&amp;nbsp;Lambda.&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few weeks ago at work, I was party to two discussions about possible tooling needs, both very low-priority. One was the possible need to sync MarkDown documentation
from GitHub repositories to&amp;#8230; another thing that can hold docs. The other was relating to the new Version 2 Docker Registry, &lt;a href="https://github.com/docker/distribution"&gt;distribution&lt;/a&gt;.
We have some Jenkins jobs that dynamically populate dropdown fields for build parameters with Docker image names and tags, using the &lt;a href="https://wiki.jenkins-ci.org/display/JENKINS/Active+Choices+Plugin"&gt;Active Choices Plugin&lt;/a&gt;.
Right now we&amp;#8217;re directly querying the Docker Registry &lt;span class="caps"&gt;API&lt;/span&gt; from Groovy, every time the Build With Parameters page is loaded. With the original version 1 Docker Registry,
images were often missing from the results (eek!) but the performance was good. With the switch to the v2 Registry, it takes almost two minutes to load the page.
While brainstorming solutions, we decided that caching the list of images and tags in the Registry was the solution. For bonus points, it would also be nice to
be able to query based on image labels - something that&amp;#8217;s not exposed in the Registry &lt;span class="caps"&gt;API&lt;/span&gt; at all. Luckily, the Registry has an option to fire a webhook every time
a new image is&amp;nbsp;pushed.&lt;/p&gt;
&lt;p&gt;Both of these problems have solutions that involve webhooks, from GitHub and Docker Distribution, respectively. They also both involve doing time-consuming things in custom code with the
data in those hooks - transforming MarkDown to another markup and pushing the result to an on-premesis system in the case of GitHub, and &lt;code&gt;pull&lt;/code&gt;ing and inspecting Docker
images in the case of the Registry. As such, the &amp;#8220;typical&amp;#8221; webhook things like &lt;a href="https://zapier.com/"&gt;Zapier&lt;/a&gt; won&amp;#8217;t fit the bill. All I really needed was something to receive webhooks
and push the content of them into a queue. Ideally, it would also be something that would utilize existing services we have, namely&amp;nbsp;&lt;span class="caps"&gt;AWS&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;After working a bunch of nights and the good part of a weekend, I have a solution: my new &lt;a href="https://pypi.python.org/pypi/webhook2lambda2sqs"&gt;webhook2lambda2sqs&lt;/a&gt; Python&amp;nbsp;package.&lt;/p&gt;
&lt;p&gt;This implements what I think is the cheapest and lowest-overhead solution for anyone with an existing &lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;nbsp;account:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setup an &lt;a href="https://aws.amazon.com/api-gateway/"&gt;&lt;span class="caps"&gt;API&lt;/span&gt; Gateway&lt;/a&gt; that receives json &lt;span class="caps"&gt;POST&lt;/span&gt; and &lt;span class="caps"&gt;GET&lt;/span&gt;&amp;nbsp;requests.&lt;/li&gt;
&lt;li&gt;It passes them to a &lt;a href="https://aws.amazon.com/lambda/"&gt;Lambda Function&lt;/a&gt; which pushes the content to one or more &lt;a href="https://aws.amazon.com/sqs/"&gt;&lt;span class="caps"&gt;SQS&lt;/span&gt;&lt;/a&gt; queues, for consumption by an&amp;nbsp;application.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The tooling is written in Python, but leverages &lt;a href="https://www.terraform.io/"&gt;HashiCorp&amp;#8217;s Terraform&lt;/a&gt; to actually manage the &lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;nbsp;resources.&lt;/p&gt;
&lt;p&gt;From a &lt;span class="caps"&gt;JSON&lt;/span&gt; configuration file as simple&amp;nbsp;as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{
  &amp;quot;endpoints&amp;quot;: {
    &amp;quot;some_resource_name&amp;quot;: {
      &amp;quot;method&amp;quot;: &amp;quot;&lt;span class="caps"&gt;POST&lt;/span&gt;&amp;quot;,
      &amp;quot;queues&amp;quot;: [&amp;quot;myqueue&amp;quot;]
    },
  },
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and a single command (&lt;code&gt;webhook2lambda2sqs genapply&lt;/code&gt;), you&amp;#8217;ll have the complete system up and running, receiving &lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;POST&lt;/span&gt; requests
at an &lt;span class="caps"&gt;AWS&lt;/span&gt;-generated &lt;span class="caps"&gt;URL&lt;/span&gt; and pushing them into the &lt;code&gt;myqueue&lt;/code&gt; &lt;span class="caps"&gt;SQS&lt;/span&gt; queue. Best of all, going by my testing (this is based on the time
the Lambda function takes to run, which can vary quite a bit), the whole thing is &lt;strong&gt;free for the first 1 million requests per month&lt;/strong&gt;
if your account is still on the Free Tier, and otherwise is less than $4/month for the first million&amp;nbsp;requests.&lt;/p&gt;
&lt;p&gt;The configuration can handle setting up multiple distinct endpoint paths in the same &lt;span class="caps"&gt;API&lt;/span&gt; Gateway, each
sending the data to one or more &lt;span class="caps"&gt;SQS&lt;/span&gt; queues. It also has options for enabling logging (to CloudWatch Logs) both in the function
and on the &lt;span class="caps"&gt;API&lt;/span&gt; Gateway, pushing &lt;span class="caps"&gt;API&lt;/span&gt; Gateway metrics to CloudWatch, and configuring rate&amp;nbsp;limiting.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;webhook2lambda2sqs&lt;/code&gt; program generates the Python code for the lambda function and packages it correctly for Lambda, and
then generates a Terraform configuration to manage all required &lt;span class="caps"&gt;AWS&lt;/span&gt; resources. Separate commands are available that wrap Terraform
(mainly to deal with some issues with its &lt;span class="caps"&gt;API&lt;/span&gt; Gateway implementation) to run &lt;code&gt;plan&lt;/code&gt;, &lt;code&gt;apply&lt;/code&gt; and &lt;code&gt;destroy&lt;/code&gt;. There are
also helper commands to view the Lambda Function and &lt;span class="caps"&gt;API&lt;/span&gt; Gateway logs from CloudWatch, view messages in the queue(s) and
&lt;span class="caps"&gt;GET&lt;/span&gt; or &lt;span class="caps"&gt;POST&lt;/span&gt; a test message to one or all of the&amp;nbsp;endpoints.&lt;/p&gt;
&lt;p&gt;Full documentation is available at &lt;a href="http://webhook2lambda2sqs.readthedocs.io/en/latest/"&gt;http://webhook2lambda2sqs.readthedocs.io/en/latest/&lt;/a&gt;
and the package (Python 2.7, 3.3-3.5) can be downloaded &lt;a href="https://pypi.python.org/pypi/webhook2lambda2sqs"&gt;from PyPI&lt;/a&gt;.&lt;/p&gt;</content><category term="aws"></category><category term="webhook"></category><category term="lambda"></category><category term="github"></category><category term="api-gateway"></category><category term="sqs"></category><category term="queue"></category><category term="python"></category><category term="terraform"></category></entry><entry><title>AwsLimitChecker - Check Your AWS Usage Against Service Limits</title><link href="https://blog.jasonantman.com/2015/07/awslimitchecker-check-your-aws-usage-against-service-limits/" rel="alternate"></link><published>2015-07-25T08:35:00-04:00</published><updated>2015-07-25T08:35:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-07-25:/2015/07/awslimitchecker-check-your-aws-usage-against-service-limits/</id><summary type="html">&lt;p&gt;Initial release of AwsLimitChecker, a tool to check your &lt;span class="caps"&gt;AWS&lt;/span&gt; usage against service limits and Trusted&amp;nbsp;Advisor.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Over the past year or so, at my day job, we&amp;#8217;ve been leveraging &lt;span class="caps"&gt;AWS&lt;/span&gt; more and more, specifically
&lt;a href="https://aws.amazon.com/cloudformation/"&gt;CloudFormation&lt;/a&gt; to manage complete application stacks. One
side-effect of this is that we went through a few periods where we were constantly hitting various
&lt;span class="caps"&gt;AWS&lt;/span&gt; Service Limits - subnet groups, ElastiCache clusters, security groups, and a whole slew of others.
In pretty much all these cases, we weren&amp;#8217;t &lt;em&gt;really&lt;/em&gt; aware of the limits; we (the Tooling and
Automation team) had succeeded in our goal of handing our internal customers the tools to spin up
complete application environments, per-developer, on-demand. And it was wonderful until we hit some
magic number of CloudFormation stacks, at which point almost every day for a week or two we had to
open a new &lt;span class="caps"&gt;AWS&lt;/span&gt; Support ticket to have a different limit increased, and deal with completely broken
deploys until that was done (or send out a frantic &amp;#8220;someone please delete a dev stack&amp;#8221;&amp;nbsp;email).&lt;/p&gt;
&lt;p&gt;Early last month we decided that we had to do something about this. As much as I tried, I couldn&amp;#8217;t
find an existing solution that would monitor our limits and alert us when we approached them; there
were some open source scripts that would do so for a handful of limits (generally just &lt;span class="caps"&gt;EC2&lt;/span&gt; usage),
and the proprietary solutions that I was able to find didn&amp;#8217;t seem much better; none of them stated
that they handle &lt;span class="caps"&gt;VPC&lt;/span&gt; or ElastiCache limits, which had been problematic for us. &lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;#8217;s own
&lt;a href="https://aws.amazon.com/premiumsupport/trustedadvisor/"&gt;Trusted Advisor&lt;/a&gt; has a Service Limits
check available to Business- and Enterprise-level support accounts, but it only monitors 17 of the
94 Service Limits that we identified as relevant to us, and it sends out &lt;em&gt;weekly&lt;/em&gt; alerts. So,
I decided to write something to solve the problem. My co-workers and I have been trying to get
corporate legal approval to release our work publicly under an &lt;span class="caps"&gt;OSI&lt;/span&gt;-approved license for years,
to no avail. I asked my team if they&amp;#8217;d support waiting a while for this work, so I could do it
entirely in my own time, publicly, under an open source license. Happily, they&amp;nbsp;agreed.&lt;/p&gt;
&lt;p&gt;Today I&amp;#8217;m making the first release of &lt;a href="https://github.com/jantman/awslimitchecker"&gt;awslimitchecker&lt;/a&gt;,
an &lt;span class="caps"&gt;AGPL&lt;/span&gt; 3.0-licensed Python tool to calculate your &lt;span class="caps"&gt;AWS&lt;/span&gt; resource usage for various services bound by
&lt;a href="http://awslimitchecker.readthedocs.org/en/latest/limits.html#current-checks"&gt;service limits&lt;/a&gt;, and tell you which ones exceed a given threshold (actually, warning and critical
thresholds). Effective limits are hard-coded to the &lt;a href="http://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html"&gt;published defaults&lt;/a&gt;,
but can be overridden in cases where you&amp;#8217;ve received limit increases, and will be automatically updated
from Trusted Advisor data for all limits that it monitors (if your account includes the full &lt;span class="caps"&gt;TA&lt;/span&gt; checks).
awslimitchecker provides warning and critical thresholds that can be set globally as a percentage of the
limit (defaults are 80% and 99%, respectively) or overridden on a per-limit basis, as either a percentage
or a fixed integer usage&amp;nbsp;value.&lt;/p&gt;
&lt;p&gt;awslimitchecker is available &lt;a href="https://pypi.python.org/pypi/awslimitchecker/0.1.0"&gt;from pypi&lt;/a&gt;.
It is compatible and tested with Python versions 2.6 through 3.4, though the library it uses to communicate
with &lt;span class="caps"&gt;AWS&lt;/span&gt;, &lt;a href="http://boto.readthedocs.org/en/latest/"&gt;boto&lt;/a&gt;, still has a few &lt;span class="caps"&gt;AWS&lt;/span&gt; services which are not python3-compatible.
awslimitchecker includes both a Python module with a &lt;a href="http://awslimitchecker.readthedocs.org/en/latest/awslimitchecker.checker.html"&gt;documented &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt; for those who
don&amp;#8217;t mind working with Python, and a command line script for those who&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;The project is still very young, and only being used by one organization, but it&amp;#8217;s proven
stable for us, and I&amp;#8217;m more than happy to accept questions, comments, criticisms,
&lt;a href="https://github.com/jantman/awslimitchecker/issues"&gt;issues/feature requests&lt;/a&gt; and Pull&amp;nbsp;Requests.&lt;/p&gt;</content><category term="aws"></category><category term="ec2"></category><category term="limits"></category><category term="python"></category><category term="awslimitchecker"></category><category term="cloud"></category></entry><entry><title>Visualization of when I’m working on personal vs work projects</title><link href="https://blog.jasonantman.com/2015/06/visualization-of-when-im-working-on-personal-vs-work-projects/" rel="alternate"></link><published>2015-06-05T21:20:00-04:00</published><updated>2015-06-05T21:20:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-06-05:/2015/06/visualization-of-when-im-working-on-personal-vs-work-projects/</id><summary type="html">&lt;p&gt;A fun python script to visualize the time of day and day of week of your commits to personal vs work&amp;nbsp;repositories.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was thinking the other day - as I was pushing out some final code reviews for work at &lt;span class="caps"&gt;11PM&lt;/span&gt; before taking a day off -
about how much work I do outside of &amp;#8220;work hours&amp;#8221;. And the answer is, I don&amp;#8217;t really know, especially when it comes to
projects that I really enjoy and find interesting. So, I decided to have some fun with &lt;a href="https://github.com/gitpython-developers/GitPython"&gt;GitPython&lt;/a&gt;
and find&amp;nbsp;out.&lt;/p&gt;
&lt;p&gt;The result of this was &lt;a href="https://github.com/jantman/misc-scripts/blob/master/whendoiwork.py"&gt;whendoiwork.py&lt;/a&gt;. It&amp;#8217;s a pretty simple script,
and also makes some pretty big assumptions, but I found the results interesting. Given some local directories which contain git clones
of my work repositories, and some which contain clones of my personal repos, it iterates over all* of the commits in them by me
(going by the git author name) in the last N days (default 365); it counts commits to personal repositories as +1 and to work
repositories as -1, and adds them to buckets per hour of day, per day of week. It then uses &lt;a href="http://matplotlib.org/"&gt;matplotlib&lt;/a&gt;
to build a heatmap, with the maximum commits per hour for work repos in blue and the maximum per hour for personal in&amp;nbsp;red.&lt;/p&gt;
&lt;p&gt;I can&amp;#8217;t vouch that it&amp;#8217;s 100% accurate, but the results were interesting to me; while it seems like I tend to do a fair amount
of work in the evenings, compared to work on personal projects, all of my work for my employer is well contained in my normal
7-3 work&amp;nbsp;day.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s an example of the output of this script, for my own work, run&amp;nbsp;with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./whendoiwork.py -v -a /home/jantman/&lt;span class="caps"&gt;GIT&lt;/span&gt; -b /home/jantman/work/git -b /home/jantman/work/git/ops -d 365 -t &amp;#39;&lt;span class="caps"&gt;US&lt;/span&gt;/Eastern&amp;#39; --repoAlabel personal --repoBlabel work
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that this iterates over every commit in all of the git repos it finds, possibly multiple times. On my own
system (9G of git repos with a few hundred thousand commits), this took about 2&amp;nbsp;minutes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="heatmap of days of week and hours of day when I commit to work vs personal repos" src="https://raw.githubusercontent.com/jantman/misc-scripts/master/whendoiwork.png"&gt;&lt;/p&gt;
&lt;p&gt;If you find any bugs/issues with it, please pass them along by &lt;a href="https://github.com/jantman/misc-scripts/issues"&gt;opening an issue&lt;/a&gt;.&lt;/p&gt;</content><category term="git"></category><category term="commits"></category><category term="python"></category><category term="graphs"></category><category term="visualization"></category></entry><entry><title>Jira to Trello Script</title><link href="https://blog.jasonantman.com/2015/04/jira-to-trello-script/" rel="alternate"></link><published>2015-04-10T05:58:00-04:00</published><updated>2015-04-10T05:58:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-04-10:/2015/04/jira-to-trello-script/</id><summary type="html">&lt;p&gt;A script to pull time tracking and dependency information for Jira tickets onto Trello&amp;nbsp;cards.&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few weeks ago, I &lt;a href="/2015/03/my-new-found-love-of-trello-and-a-helpful-greasemonkey-script/"&gt;posted about&lt;/a&gt; how I&amp;#8217;ve
started using &lt;a href="https://trello.com/"&gt;Trello&lt;/a&gt; to keep track of my work and keep things flowing smoothly. It&amp;#8217;s been
absolutely wonderful, and I feel more productive and less stressed, and like I have a better idea of what&amp;#8217;s coming
up. The one thing that Trello is missing is time tracking. I don&amp;#8217;t need anything fancy, all I really wanted was to
be able to show a time estimate on my cards. I know I could&amp;#8217;ve just put the estimate right in the title of the cards,
but that seemed like a waste of&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;At the moment we&amp;#8217;re using Jira at work, so I wrote &lt;a href="https://github.com/jantman/misc-scripts/blob/master/jira2trello.py"&gt;jira2trello.py&lt;/a&gt;.
It&amp;#8217;s a pretty simple Python script that uses the &lt;a href="https://pypi.python.org/pypi/trello"&gt;trello&lt;/a&gt; and
&lt;a href="https://pypi.python.org/pypi/jira"&gt;jira&lt;/a&gt; packages from pypi to iterate over all cards on a specified Trello
board, and for each card that matches a configurable regular expression for ticket keys (i.e.
&lt;code&gt;.*((project1|project2|project3)-\d+):.*&lt;/code&gt;), the script&amp;nbsp;will:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Determine if the Jira issue is a subtask, and if so, prefix its title with the issue key of the parent issue,
using the format of &lt;code&gt;PARENT-xxx -&amp;gt; CHILD-xxx&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Look up the &amp;#8220;Original Estimate&amp;#8221; time tracking field in Jira, and if present, prepend it to the title of
the&amp;nbsp;card.&lt;/li&gt;
&lt;li&gt;Regenerate the title of the card, using the current issue summary from&amp;nbsp;Jira.&lt;/li&gt;
&lt;li&gt;Move the card to a specified &amp;#8220;Done&amp;#8221; list if it&amp;#8217;s closed in&amp;nbsp;Jira.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are a few assumptions in the script about how the titles of cards are formed, namely that they follow the
&lt;code&gt;ISSUE-xxx: Summary Here&lt;/code&gt; format used by my &lt;a href="https://github.com/jantman/userscripts#trellocontextmenu"&gt;TrelloContextMenu&lt;/a&gt;
Firefox userscript. But I hope that this might be of use to someone else as well. Please feel free to open issues
or submit pull requests for any improvements that would be helpful, including any assumptions I&amp;#8217;ve made that aren&amp;#8217;t
valid in your environment. The source can be found on GitHub: &lt;a href="https://github.com/jantman/misc-scripts/blob/master/jira2trello.py"&gt;jira2trello.py&lt;/a&gt;.&lt;/p&gt;</content><category term="jira"></category><category term="trello"></category><category term="python"></category><category term="ticket"></category><category term="kanban"></category></entry><entry><title>Python script to backup Disqus comments</title><link href="https://blog.jasonantman.com/2014/03/python-script-to-backup-disqus-comments/" rel="alternate"></link><published>2014-03-01T19:01:00-05:00</published><updated>2014-03-01T19:01:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-03-01:/2014/03/python-script-to-backup-disqus-comments/</id><summary type="html">&lt;p&gt;Quick Python script to backup Disqus comments for a&amp;nbsp;forum&lt;/p&gt;</summary><content type="html">&lt;p&gt;Since I just &lt;a href="/2014/03/wordpress-to-pelican-with-disqus-comments"&gt;switched this blog to using Disqus for commenting&lt;/a&gt;,
I wanted a way to back up comments in case something goes wrong (like,
Disqus going the way of del.icio.us&amp;nbsp;bookmarking).&lt;/p&gt;
&lt;p&gt;I whipped up a quick &lt;a href="https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py"&gt;Python script&lt;/a&gt;
using the official &lt;a href="https://github.com/disqus/disqus-python"&gt;Disqus Python &lt;span class="caps"&gt;API&lt;/span&gt; client&lt;/a&gt;. It grabs the forum details,
threads list and posts (comments) list, and writes them out to a &lt;span class="caps"&gt;JSON&lt;/span&gt;&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;It doesn&amp;#8217;t have any restore feature, but it captures all of the&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;My first test made it look like there &lt;em&gt;may&lt;/em&gt; be some posts and theads missing (my import from
wordpress showed 56 threads and 146 comments, but this script only grabbed 52 and 125 respectively),
so exercise some caution until I verify what the problem is. If you happen to figure it out,
please submit a&amp;nbsp;&lt;span class="caps"&gt;PR&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The script is available on GitHub at &lt;a href="https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py"&gt;https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py&lt;/a&gt;.&lt;/p&gt;</content><category term="pelican"></category><category term="disqus"></category><category term="python"></category></entry><entry><title>Planning Migration from WordPress to Static Site</title><link href="https://blog.jasonantman.com/2014/01/planning-migration-from-wordpress-to-static-site/" rel="alternate"></link><published>2014-01-01T15:15:00-05:00</published><updated>2014-01-01T15:15:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2014-01-01:/2014/01/planning-migration-from-wordpress-to-static-site/</id><summary type="html">&lt;p&gt;Right now, this blog, my email, and a whole bunch of other services are
hosted on a &lt;a href="http://linode.com"&gt;Linode&lt;/a&gt; Xen &lt;span class="caps"&gt;VM&lt;/span&gt;. I don&amp;#8217;t really keep up
to date with administration and upgrades the way I used to, and
honestly, I&amp;#8217;d rather spend my time working on other things (like …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Right now, this blog, my email, and a whole bunch of other services are
hosted on a &lt;a href="http://linode.com"&gt;Linode&lt;/a&gt; Xen &lt;span class="caps"&gt;VM&lt;/span&gt;. I don&amp;#8217;t really keep up
to date with administration and upgrades the way I used to, and
honestly, I&amp;#8217;d rather spend my time working on other things (like
actually writing all of the blog posts that I&amp;#8217;ve been planning to. The
first thing I&amp;#8217;ve identified for migration is this blog itself. It&amp;#8217;s
currently on WordPress and, frankly, I don&amp;#8217;t either need nor like it.
But there are some features I like. I&amp;#8217;d like to end up with a static
site generator, hosted from either S3 or GitHub Pages. I know that means
I&amp;#8217;ll lost comments (unless I move to a third-party, &lt;span class="caps"&gt;JS&lt;/span&gt;-based comment
system like &lt;a href="http://disqus.com/"&gt;Disqus&lt;/a&gt;, which means I&amp;#8217;ll lose
&lt;em&gt;control&lt;/em&gt; over my comments) but I suppose I can live with that. What I
really want is something simple, static, cheap or free (that I&amp;#8217;ll likely
put behind a small ec2 instance running nginx for&amp;nbsp;redirects/rewrites).&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m still in the planning phase, and trying to come up with a
feature-by-feature comparison of my options. I&amp;#8217;ll likely post that when
I finally have it done (at the moment it&amp;#8217;s in a very rough &lt;a href="https://docs.google.com/spreadsheet/ccc?key=0AnHh-ye5DNiNdF9DWkJrT2kzSkNsNVp6cjMzLXJ6VEE&amp;amp;usp=sharing"&gt;Google Docs
spreadsheet&lt;/a&gt;).
I&amp;#8217;m trying to round up my static site generator options and see which
ones will do most, if not all, of what I want (though I still haven&amp;#8217;t
discounted using hosted wordpress if it comes down to it). Here are the
features I currently &amp;#8220;use&amp;#8221; (have) on my WordPress&amp;nbsp;blog:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User-defined permalinks to&amp;nbsp;posts&lt;/li&gt;
&lt;li&gt;Overall &lt;span class="caps"&gt;RSS&lt;/span&gt; feed of blog (currently powered by FeedBurner) and of&amp;nbsp;comments)&lt;/li&gt;
&lt;li&gt;Categories (a post can be in multiple&amp;nbsp;categories)&lt;/li&gt;
&lt;li&gt;Tags&lt;/li&gt;
&lt;li&gt;Category and Tag&amp;nbsp;pages&lt;/li&gt;
&lt;li&gt;per-Category and per-Tag feeds&amp;nbsp;(&lt;span class="caps"&gt;RSS&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;Tag cloud &amp;#8220;widget&amp;#8221; in&amp;nbsp;sidebar&lt;/li&gt;
&lt;li&gt;Themes. I actually like my current &lt;span class="caps"&gt;WP&lt;/span&gt;&amp;nbsp;theme&amp;#8230;&lt;/li&gt;
&lt;li&gt;Visitor statistics (currently self-hosted
    &lt;a href="http://piwik.org/"&gt;Piwik&lt;/a&gt;, formerly Google&amp;nbsp;Analytics)&lt;/li&gt;
&lt;li&gt;Post publishing via cron&amp;#8217;ed script (&lt;em&gt;see below&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Draft/Pending status (i.e. let me save a partial post, and let me
    save a complete post but mark it &amp;#8220;pending&amp;#8221; so I can just publish it&amp;nbsp;later)&lt;/li&gt;
&lt;li&gt;Commenting (this will probably be the big sticking&amp;nbsp;point)&lt;/li&gt;
&lt;li&gt;Syntax&amp;nbsp;hilighting&lt;/li&gt;
&lt;li&gt;As &amp;#8220;weird&amp;#8221; as this is, I write all my posts in raw &lt;span class="caps"&gt;HTML&lt;/span&gt;, and am
    perfectly happy doing&amp;nbsp;that.&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Subscribe via Email&amp;#8221; FeedBurner&amp;nbsp;widget&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;XML&lt;/span&gt;&amp;nbsp;Sitemap&lt;/li&gt;
&lt;li&gt;Twitter&amp;nbsp;box/widget&lt;/li&gt;
&lt;li&gt;Pingbacks (not that these are really useful for anything other than
    spam these&amp;nbsp;days)&lt;/li&gt;
&lt;li&gt;Automatic or manual post excerpts for feeds,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;Remote publishing via &lt;span class="caps"&gt;XML&lt;/span&gt;-&lt;span class="caps"&gt;RPC&lt;/span&gt;/Android app (not that I&amp;#8217;ve used it
    more than once or&amp;nbsp;twice)&lt;/li&gt;
&lt;li&gt;Advertising - I currently use Google AdSense on my blog. The revenue
    from my tiny hit count isn&amp;#8217;t enough to offset the cost of a Linode,
    but if I moved to a much less expensive hosting service, it might be
    worth considering (you can&amp;#8217;t run ads on the free hosted WordPress,
    and I doubt you can on GitHub Pages&amp;nbsp;either).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I should be updating this post when I do some more research and have a
comparison of the&amp;nbsp;options.&lt;/p&gt;
&lt;p&gt;Note on &amp;#8220;Post publishing via cron&amp;#8217;ed script&amp;#8221; - sometimes I sit down and
write half a dozen or so blog posts at a time. But I don&amp;#8217;t want them all
to show up immediately, and spam the few people who still use &lt;span class="caps"&gt;RSS&lt;/span&gt;
readers after the death of Google Reader. So I set the posts to
&amp;#8220;Pending&amp;#8221; status, and I have a cron&amp;#8217;ed script that runs every weekday
morning and publishes the one oldest &amp;#8220;pending&amp;#8221; post. Who knows if this
actually does any good or&amp;nbsp;not&amp;#8230;&lt;/p&gt;</content><category term="blog"></category><category term="jekyll"></category><category term="pelican"></category><category term="python"></category><category term="static site"></category><category term="wordpress"></category></entry><entry><title>Python script to check a list of URLs for return code, and final return code if redirected</title><link href="https://blog.jasonantman.com/2013/06/python-script-to-check-a-list-of-urls-for-return-code-and-final-return-code-if-redirected/" rel="alternate"></link><published>2013-06-10T06:00:00-04:00</published><updated>2013-06-10T06:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-06-10:/2013/06/python-script-to-check-a-list-of-urls-for-return-code-and-final-return-code-if-redirected/</id><summary type="html">&lt;p&gt;Every once in a while I need to add a bunch of redirects in Apache.
Here&amp;#8217;s a handy, dead simple Python script which takes a list of URLs on
&lt;span class="caps"&gt;STDIN&lt;/span&gt;, and for each one prints out either the response code, or, if the
response is a redirect, the response …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Every once in a while I need to add a bunch of redirects in Apache.
Here&amp;#8217;s a handy, dead simple Python script which takes a list of URLs on
&lt;span class="caps"&gt;STDIN&lt;/span&gt;, and for each one prints out either the response code, or, if the
response is a redirect, the response code of what is redirected to.
Pretty useful when you&amp;#8217;ve just added a bunch of redirects and want to
make sure none of them&amp;nbsp;404.&lt;/p&gt;
&lt;p&gt;The latest source of this script lives at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/check_url_list.py"&gt;https://github.com/jantman/misc-scripts/blob/master/check_url_list.py&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Script to check a list of URLs (passed on stdin) for response code, and for response code of the final path in a series of redirects.&lt;/span&gt;
&lt;span class="sd"&gt;Outputs (to stdout) a list of count of a given &lt;span class="caps"&gt;URL&lt;/span&gt;, response code, and if redirected, the final &lt;span class="caps"&gt;URL&lt;/span&gt; and its response code&lt;/span&gt;

&lt;span class="sd"&gt;Optionally, with verbose flag, report on all &lt;span class="caps"&gt;URL&lt;/span&gt; checks on &lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;

&lt;span class="sd"&gt;Copyright 2013 Jason Antman  all rights reserved&lt;/span&gt;
&lt;span class="sd"&gt;This script is distributed under the terms of the GPLv3, as per the&lt;/span&gt;
&lt;span class="sd"&gt;&lt;span class="caps"&gt;LICENSE&lt;/span&gt; file in this repository.&lt;/span&gt;

&lt;span class="sd"&gt;The canonical version of this script can be found at:&lt;/span&gt;

&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_url_nofollow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcode&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;+ checking &lt;span class="caps"&gt;URL&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;get_url_nofollow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;++ &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="http"></category><category term="python"></category><category term="redirect"></category><category term="urllib"></category></entry><entry><title>Pretty-Print a JSON response at the command line</title><link href="https://blog.jasonantman.com/2012/10/pretty-print-a-json-response-at-the-command-line/" rel="alternate"></link><published>2012-10-09T14:44:00-04:00</published><updated>2012-10-09T14:44:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-09:/2012/10/pretty-print-a-json-response-at-the-command-line/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been doing some work with &lt;a href="http://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;
lately, and have been doing some testing against its &lt;span class="caps"&gt;HTTP&lt;/span&gt;-based &lt;span class="caps"&gt;API&lt;/span&gt;,
which returns results in &lt;span class="caps"&gt;JSON&lt;/span&gt;. If you&amp;#8217;re looking to pretty-print a &lt;span class="caps"&gt;JSON&lt;/span&gt;
response for easier viewing, here&amp;#8217;s a nice way to do it at the command
line using …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been doing some work with &lt;a href="http://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;
lately, and have been doing some testing against its &lt;span class="caps"&gt;HTTP&lt;/span&gt;-based &lt;span class="caps"&gt;API&lt;/span&gt;,
which returns results in &lt;span class="caps"&gt;JSON&lt;/span&gt;. If you&amp;#8217;re looking to pretty-print a &lt;span class="caps"&gt;JSON&lt;/span&gt;
response for easier viewing, here&amp;#8217;s a nice way to do it at the command
line using Python and
&lt;a href="http://docs.python.org/library/json.html"&gt;json.tool&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl http://username:pass@hostname:55672/api/overview | python -m json.tool&lt;/code&gt;&lt;/p&gt;</content><category term="curl"></category><category term="json"></category><category term="python"></category><category term="rabbitmq"></category></entry><entry><title>Python script to find dependency cycles in GraphViz dot files</title><link href="https://blog.jasonantman.com/2012/03/python-script-to-find-dependency-cycles-in-graphviz-dot-files/" rel="alternate"></link><published>2012-03-28T22:05:00-04:00</published><updated>2012-03-28T22:05:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-28:/2012/03/python-script-to-find-dependency-cycles-in-graphviz-dot-files/</id><summary type="html">&lt;p&gt;Using &lt;a href="http://www.graphviz.org/"&gt;GraphViz&lt;/a&gt; to describe configurations is
relatively popular in the software and systems architecture world; the
simple text-based format makes it quiet simple, and the directed graph
(dot file) is a simple method to store a graph of information flow or
component relationships. &lt;a href="http://puppetlabs.com"&gt;Puppet&lt;/a&gt; includes
builtin support for &lt;a href="http://docs.puppetlabs.com/guides/faq.html#how-do-i-use-puppets-graphing-support"&gt;generating dot …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Using &lt;a href="http://www.graphviz.org/"&gt;GraphViz&lt;/a&gt; to describe configurations is
relatively popular in the software and systems architecture world; the
simple text-based format makes it quiet simple, and the directed graph
(dot file) is a simple method to store a graph of information flow or
component relationships. &lt;a href="http://puppetlabs.com"&gt;Puppet&lt;/a&gt; includes
builtin support for &lt;a href="http://docs.puppetlabs.com/guides/faq.html#how-do-i-use-puppets-graphing-support"&gt;generating dot
graphs&lt;/a&gt;
of its configuration resources and relationships (both those specified
by the user, and all relationships including ones generated by Puppet&amp;nbsp;itself).&lt;/p&gt;
&lt;p&gt;One of the common uses for puppet&amp;#8217;s graphs is to identify dependency
cycles, as cyclic dependencies cause an error condition. However,
Puppet&amp;#8217;s own
&lt;a href="http://docs.puppetlabs.com/guides/faq.html#how-do-i-use-puppets-graphing-support"&gt;&lt;span class="caps"&gt;FAQ&lt;/span&gt;&lt;/a&gt;
only mentions using the &lt;code&gt;dot&lt;/code&gt; command to generate a &lt;span class="caps"&gt;PNG&lt;/span&gt; graphical
representation of the the graph. When debugging a recent problem with
puppet, I ended up with a message&amp;nbsp;like:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Could not apply complete catalog: Found dependency cycles in the following relationships: Service[puppet] =&amp;gt; File[/var/lib/puppet/yaml/foreman], File[/var/lib/puppet/yaml] =&amp;gt; File[/var/lib/puppet/yaml/foreman], Service[puppet] =&amp;gt; File[/etc/puppet/node.rb], File[fileserver.conf] =&amp;gt; Service[apache], File[namespaceauth.conf] =&amp;gt; Service[apache], File[puppet.conf] =&amp;gt; Service[apache], File[puppet.conf] =&amp;gt; Service[puppet], Service[puppet] =&amp;gt; File[foreman-report.rb], File[/var/lib/puppet/yaml/foreman] =&amp;gt; Package[puppet-server], Service[foreman-proxy] =&amp;gt; Package[puppet-server], File[foreman-proxy-settings.yml] =&amp;gt; Package[puppet-server], Package[foreman-proxy] =&amp;gt; Package[puppet-server], User[foreman-proxy] =&amp;gt; Package[puppet-server], File[/var/lib/puppet/yaml] =&amp;gt; Package[puppet-server], File[foreman-report.rb] =&amp;gt; Package[puppet-server], File[/etc/puppet/node.rb] =&amp;gt; Package[puppet-server], File[/var/lib/puppet/yaml/foreman] =&amp;gt; Exec[create_puppetmaster_certs], Service[foreman-proxy] =&amp;gt; Exec[create_puppetmaster_certs], File[foreman-proxy-settings.yml] =&amp;gt; Exec[create_puppetmaster_certs], Package[foreman-proxy] =&amp;gt; Exec[create_puppetmaster_certs], User[foreman-proxy] =&amp;gt; Exec[create_puppetmaster_certs], File[/var/lib/puppet/yaml] =&amp;gt; Exec[create_puppetmaster_certs], File[foreman-report.rb] =&amp;gt; Exec[create_puppetmaster_certs], File[/etc/puppet/node.rb] =&amp;gt; Exec[create_puppetmaster_certs], File[/var/lib/puppet/yaml/foreman] =&amp;gt; File[/etc/puppet/environments], Service[foreman-proxy] =&amp;gt; File[/etc/puppet/environments], File[foreman-proxy-settings.yml] =&amp;gt; File[/etc/puppet/environments], Package[foreman-proxy] =&amp;gt; File[/etc/puppet/environments], User[foreman-proxy] =&amp;gt; File[/etc/puppet/environments], File[/var/lib/puppet/yaml] =&amp;gt; File[/etc/puppet/environments], File[foreman-report.rb] =&amp;gt; File[/etc/puppet/environments], File[/etc/puppet/node.rb] =&amp;gt; File[/etc/puppet/environments], File[foreman-proxy-settings.yml] =&amp;gt; Service[foreman-proxy], Package[foreman-proxy] =&amp;gt; Service[foreman-proxy], Service[puppet]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Not exactly easy to follow, or to pull much meaning out of, even if I
did some slight reformatting by putting in some newlines. I then
generated the png as described in the Puppet FAQs, but even scrolling
back and forth on this for 20 minutes didn&amp;#8217;t help: &lt;em&gt;(note: link is to
the original 14405x665px png)&lt;/em&gt;&lt;br&gt;
&lt;a href="/GFX/relationships.dot.png"&gt;&lt;img alt="dot file
png" src="/GFX/relationships.dot.small.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With a little research, I managed to find the
&lt;a href="http://networkx.lanl.gov"&gt;NetworkX&lt;/a&gt; package for Python; according to
their site, &amp;#8220;NetworkX is a Python language software package for the
creation, manipulation, and study of the structure, dynamics, and
functions of complex networks.&amp;#8221; Among its features are the ability to
&lt;a href="http://networkx.lanl.gov/reference/drawing.html#module-networkx.drawing.nx_pydot"&gt;read dot
files&lt;/a&gt;
using the &lt;a href="http://code.google.com/p/pydot/"&gt;pydot&lt;/a&gt; library, and the
ability to &lt;a href="http://networkx.lanl.gov/reference/generated/networkx.algorithms.cycles.simple_cycles.html#networkx.algorithms.cycles.simple_cycles"&gt;find simple
cycles&lt;/a&gt;
within a graph. In about 20 minutes, I hacked together the dead-simple
script&amp;nbsp;below.&lt;/p&gt;
&lt;p&gt;Given a dot file (of the type generated, for example, by Puppet), this
will output all of the cycles found within the graph. I ran this script
on the &lt;code&gt;expanded_relationships.dot&lt;/code&gt; file from Puppet, which had 99 nodes
(nodes on the graph, not puppet clients), and got the following&amp;nbsp;output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[&amp;#39;File[foreman-report.rb]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-report.rb]&amp;#39;]
[&amp;#39;File[foreman-report.rb]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-report.rb]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/var/lib/puppet/yaml/foreman]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;]
[&amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/var/lib/puppet/yaml/foreman]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It probably would have taken me hours to come up with that by hand, let
alone realize that &lt;code&gt;Service[puppet]&lt;/code&gt; is the common item in all of them,
and hence the problem. With that little tidbit of information, I managed
to track down an extraneous &amp;#8220;require puppet&amp;#8221; that this all originated
from. I sincerely hope that this script will save someone else at least
as much time as it took me to write (I know it will for&amp;nbsp;me&amp;#8230;).&lt;/p&gt;
&lt;p&gt;You can always obtain the latest version of this script from
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/dot_find_cycles.py"&gt;my github repository&lt;/a&gt;
It&amp;#8217;s free for use
and distribution, provided that you leave my copyright/attribution and
source &lt;span class="caps"&gt;URL&lt;/span&gt; notice intact, update the changelog, and send any
features/fixes back to me. The script is written in Python, and depends
on the python-networkx, graphviz-python, and pydot packages (all of
which are available as packages in the default repos of Fedora and
CentOS at least). For Puppet purposes, I&amp;#8217;d recommend running this on
&lt;code&gt;expanded_relationships.dot&lt;/code&gt; to get the full&amp;nbsp;information.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;dot_find_cycles.py - uses Pydot and NetworkX to find cycles in a dot file directed graph.&lt;/span&gt;

&lt;span class="sd"&gt;Very helpful for &lt;/span&gt;

&lt;span class="sd"&gt;By Jason Antman  2012.&lt;/span&gt;

&lt;span class="sd"&gt;Free for all use, provided that you send any changes you make back to me, update the changelog, and keep this comment intact.&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;REQUIREMENTS&lt;/span&gt;:&lt;/span&gt;
&lt;span class="sd"&gt;Python&lt;/span&gt;
&lt;span class="sd"&gt;python-networkx - &lt;/span&gt;
&lt;span class="sd"&gt;graphviz-python - &lt;/span&gt;
&lt;span class="sd"&gt;pydot - &lt;/span&gt;
&lt;span class="sd"&gt;(all of these are available as native packages at least on CentOS)&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;USAGE&lt;/span&gt;:&lt;/span&gt;
&lt;span class="sd"&gt;dot_find_cycles.py /path/to/file.dot&lt;/span&gt;

&lt;span class="sd"&gt;The canonical source of this script can always be found from:&lt;/span&gt;


&lt;span class="sd"&gt;$HeadURL: http://svn.jasonantman.com/misc-scripts/dot_find_cycles.py $&lt;/span&gt;
&lt;span class="sd"&gt;$LastChangedRevision: 33 $&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;CHANGELOG&lt;/span&gt;:&lt;/span&gt;
&lt;span class="sd"&gt;    Wednesday 2012-03-28 Jason Antman :&lt;/span&gt;
&lt;span class="sd"&gt;        - initial script creation&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;access&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;R_OK&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;networkx&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;nx&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dot_find_cycles.py by Jason Antman &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;  finds cycles in dot file graphs, such as those from Puppet&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: dot_find_cycles.py /path/to/file.dot&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;fh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;IOError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: could not read file &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# read in the specified file, create a networkx DiGraph&lt;/span&gt;
    &lt;span class="n"&gt;G&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DiGraph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;simple_cycles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;G&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;

&lt;span class="c1"&gt;# Run&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="dot"></category><category term="graph"></category><category term="graphviz"></category><category term="puppet"></category><category term="python"></category></entry><entry><title>Adding Piwik Web Analytics Integration to ViewVC</title><link href="https://blog.jasonantman.com/2012/03/adding-piwik-web-analytics-integration-to-viewvc/" rel="alternate"></link><published>2012-03-23T21:15:00-04:00</published><updated>2012-03-23T21:15:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-23:/2012/03/adding-piwik-web-analytics-integration-to-viewvc/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update February 2014:&lt;/strong&gt; Give up the analytics, and just host your code
on &lt;a href="https://github.com"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All of my public &lt;a href="http://viewvc.jasonantman.com"&gt;subversion
repositories&lt;/a&gt; and &lt;a href="http://cvs.jasonantman.com"&gt;&lt;span class="caps"&gt;CVS&lt;/span&gt;
repositories&lt;/a&gt; are available online through a
great Python application called &lt;a href="http://viewvc.org/"&gt;ViewVC&lt;/a&gt;, which
provides a web-based interface to &lt;span class="caps"&gt;CVS&lt;/span&gt; and &lt;span class="caps"&gt;SVN&lt;/span&gt; repositories, as well as
history browsing, graphical diffs …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Update February 2014:&lt;/strong&gt; Give up the analytics, and just host your code
on &lt;a href="https://github.com"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All of my public &lt;a href="http://viewvc.jasonantman.com"&gt;subversion
repositories&lt;/a&gt; and &lt;a href="http://cvs.jasonantman.com"&gt;&lt;span class="caps"&gt;CVS&lt;/span&gt;
repositories&lt;/a&gt; are available online through a
great Python application called &lt;a href="http://viewvc.org/"&gt;ViewVC&lt;/a&gt;, which
provides a web-based interface to &lt;span class="caps"&gt;CVS&lt;/span&gt; and &lt;span class="caps"&gt;SVN&lt;/span&gt; repositories, as well as
history browsing, graphical diffs, etc. An amazingly large amount of the
traffic to my web server is for the vhosts that serve this, so I decided
that I should add some analytics to it. I&amp;#8217;m in the process of trying out
&lt;a href="http://piwik.org"&gt;Piwik&lt;/a&gt;, a full-featured, &lt;span class="caps"&gt;GPL&lt;/span&gt;-licensed, self-hosted
alternative to &lt;a href="http://www.google.com/analytics/"&gt;Google Analytics&lt;/a&gt;. It
gives lots of useful information like number of visits and unique visits
per page, search engine keywords, referrers, average time on page,
bounce rate (number of one-page visits),&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;I have ViewVC installed from the &lt;a href="http://pkgs.repoforge.org/viewvc/"&gt;RPMforge
packages&lt;/a&gt;, so there&amp;#8217;s one code base
for both of my vhosts. This means that I can&amp;#8217;t simply slap the tracking
code at the bottom of the templates and call it a day. I opted to go for
a nicer solution, and what follows is a patch (diff -u) to the current
(1.1.13) version of ViewVC that adds a &amp;#8220;piwik&amp;#8221; section to viewvc.conf,
and adds the piwik tracking code with the specified base &lt;span class="caps"&gt;URL&lt;/span&gt; and site &lt;span class="caps"&gt;ID&lt;/span&gt;
into all ViewVC pages.&amp;nbsp;Enjoy.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gh"&gt;diff -ru viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/lib/config.py viewvc/lib/config.py&lt;/span&gt;
&lt;span class="gd"&gt;--- viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/lib/config.py   2012-01-25 08:31:52.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ viewvc/lib/config.py    2012-03-23 21:57:08.000000000 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -108,6 +108,7 @@&lt;/span&gt;
     &amp;#39;query&amp;#39;,
     &amp;#39;templates&amp;#39;,
     &amp;#39;utilities&amp;#39;,
&lt;span class="gi"&gt;+    &amp;#39;piwik&amp;#39;,&lt;/span&gt;
     )
   _force_multi_value = (
     # Configuration values with multiple, comma-separated values.
&lt;span class="gu"&gt;@@ -127,6 +128,7 @@&lt;/span&gt;
                &amp;#39;options&amp;#39;,
                &amp;#39;templates&amp;#39;,
                &amp;#39;utilities&amp;#39;,
&lt;span class="gi"&gt;+               &amp;#39;piwik&amp;#39;,&lt;/span&gt;
                ),
     &amp;#39;root&amp;#39;  : (&amp;#39;authz-*&amp;#39;,
                &amp;#39;options&amp;#39;,
&lt;span class="gu"&gt;@@ -461,7 +463,14 @@&lt;/span&gt;
     self.cvsdb.check_database_for_root = 0

     self.query.viewvc_base_url = None
&lt;span class="gd"&gt;-    &lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+    # begin  patch for piwik integration&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.use_piwik = 0&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.base_url = &amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.site_id = &amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="gi"&gt;+    self.piwik.use_jsindex = 0&lt;/span&gt;
&lt;span class="gi"&gt;+    # end  patch for piwik integration&lt;/span&gt;
&lt;span class="gi"&gt;+   &lt;/span&gt;
 def _startswith(somestr, substr):
   return somestr[:len(substr)] == substr

&lt;span class="gh"&gt;diff -ru viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/templates/include/footer.ezt viewvc/templates/include/footer.ezt&lt;/span&gt;
&lt;span class="gd"&gt;--- viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/templates/include/footer.ezt    2012-01-25 08:31:52.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ viewvc/templates/include/footer.ezt 2012-03-23 22:03:04.000000000 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -13,5 +13,17 @@&lt;/span&gt;



&lt;span class="gi"&gt;+[is cfg.piwik.use_piwik &amp;quot;1&amp;quot;]&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+var pkBaseURL = ((&amp;quot;https:&amp;quot; == document.location.protocol) ? &amp;quot;https://[cfg.piwik.base_url]/&amp;quot; : &amp;quot;http://[cfg.piwik.base_url]/&amp;quot;);&lt;/span&gt;
&lt;span class="gi"&gt;+document.write(unescape(&amp;quot;%3Cscript src=&amp;#39;&amp;quot; + pkBaseURL + &amp;quot;[is cfg.piwik.use_jsindex &amp;quot;1&amp;quot;]js/[else]piwik.js[end]&amp;#39; type=&amp;#39;text/javascript&amp;#39;%3E%3C/script%3E&amp;quot;));&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+try {&lt;/span&gt;
&lt;span class="gi"&gt;+var piwikTracker = Piwik.getTracker(pkBaseURL + &amp;quot;piwik.php&amp;quot;, [cfg.piwik.site_id]);&lt;/span&gt;
&lt;span class="gi"&gt;+piwikTracker.trackPageView();&lt;/span&gt;
&lt;span class="gi"&gt;+piwikTracker.enableLinkTracking();&lt;/span&gt;
&lt;span class="gi"&gt;+} catch( err ) {}&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+[else][end]&lt;/span&gt;


Only in viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/templates/include: header.ezt~
&lt;span class="gh"&gt;diff -ru viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/viewvc.conf.dist viewvc/viewvc.conf.dist&lt;/span&gt;
&lt;span class="gd"&gt;--- viewvc-&lt;span class="caps"&gt;ORIG&lt;/span&gt;/viewvc.conf.dist    2012-01-25 08:31:52.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ viewvc/viewvc.conf.dist 2012-03-23 21:44:02.000000000 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -1131,3 +1131,29 @@&lt;/span&gt;
 #viewvc_base_url =

 ##---------------------------------------------------------------------------
&lt;span class="gi"&gt;+[piwik]&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+## This section enables Piwik  web analytics tracking.&lt;/span&gt;
&lt;span class="gi"&gt;+## If piwik is enabled (use_piwik = 1) all other options must be specified.&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## This is based on a patch by Jason Antman  &lt;/span&gt;
&lt;span class="gi"&gt;+## to ViewVC 1.1.13, written 2012-03-23.&lt;/span&gt;
&lt;span class="gi"&gt;+## The latest version of the patch, and information on it, can always be found at:&lt;/span&gt;
&lt;span class="gi"&gt;+## &lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## To enable piwik, change use_piwik to 1. Set to 0 to disable&lt;/span&gt;
&lt;span class="gi"&gt;+use_piwik = 1&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## Set base_url to the hostname and path to your piwik installation, with no trailing slash.&lt;/span&gt;
&lt;span class="gi"&gt;+## i.e. piwik.example.com or www.example.com/piwik&lt;/span&gt;
&lt;span class="gi"&gt;+base_url = piwik.example.com&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## Set to the numeric id of your website in Piwik&lt;/span&gt;
&lt;span class="gi"&gt;+site_id = 5&lt;/span&gt;
&lt;span class="gi"&gt;+##&lt;/span&gt;
&lt;span class="gi"&gt;+## Set to 1 if you want to use js/index.php to serve the tracking code, &lt;/span&gt;
&lt;span class="gi"&gt;+## or leave at 0 if you want to call piwik.js directly&lt;/span&gt;
&lt;span class="gi"&gt;+use_jsindex = 0&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+##---------------------------------------------------------------------------&lt;/span&gt;
\ No newline at end of file
&lt;/pre&gt;&lt;/div&gt;</content><category term="analytics"></category><category term="piwik"></category><category term="python"></category><category term="subversion"></category><category term="svn"></category><category term="tracking"></category><category term="viewvc"></category></entry></feed>