<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jason Antman's Blog - linux</title><link href="https://blog.jasonantman.com/" rel="alternate"></link><link href="https://blog.jasonantman.com/feeds/tags/linux.atom.xml" rel="self"></link><id>https://blog.jasonantman.com/</id><updated>2018-07-02T06:10:00-04:00</updated><entry><title>IP Camera, Home Security and Automation Update</title><link href="https://blog.jasonantman.com/2018/07/ip-camera-home-security-and-automation-update/" rel="alternate"></link><published>2018-07-02T06:10:00-04:00</published><updated>2018-07-02T06:10:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-07-02:/2018/07/ip-camera-home-security-and-automation-update/</id><summary type="html">&lt;p&gt;An update on my &lt;span class="caps"&gt;IP&lt;/span&gt; camera and home security project, now branching out into home automation and machine learning as&amp;nbsp;well.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#amcrest-cameras"&gt;Amcrest Cameras&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#ir-illuminator"&gt;&lt;span class="caps"&gt;IR&lt;/span&gt;&amp;nbsp;Illuminator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#surveillance-software-zoneminder"&gt;Surveillance Software - ZoneMinder&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#notifications"&gt;Notifications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image-processing-ir-switch-detection"&gt;Image Processing - &lt;span class="caps"&gt;IR&lt;/span&gt; Switch&amp;nbsp;Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#monitoring"&gt;Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#neural-network-object-detection"&gt;Neural Network Object&amp;nbsp;Detection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#homeassistant-and-z-wave"&gt;HomeAssistant and Z-Wave&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#doorwindow-and-motion-sensors"&gt;Door/Window and Motion&amp;nbsp;Sensors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#thermostat"&gt;Thermostat&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#whats-next"&gt;What&amp;#8217;s&amp;nbsp;Next&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Last month I posted about my &lt;a href="/2018/05/linux-surveillance-camera-software-evaluation/"&gt;Linux Surveillance Camera Software Evaluation&lt;/a&gt; and my plans for turning some Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt; cameras into a home security system. I&amp;#8217;ve made a lot of progress and some big changes since then and decided that I had better post an update before the effort of doing so becomes overwhelming. There are a lot of changes and new information, and some really cool plans for the future (this has become my new obsession, albeit a prohibitively expensive one), so I&amp;#8217;ll break this up into a number of&amp;nbsp;sections.&lt;/p&gt;
&lt;h2 id="amcrest-cameras"&gt;&lt;a class="toclink" href="#amcrest-cameras"&gt;Amcrest&amp;nbsp;Cameras&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m extremely happy with the two Amcrest cameras I purchased, and am planning to add two more at some point in the near future to cover the rest of the exterior of my house. The one I currently have outside is an Amcrest &lt;a href="https://amcrest.com/amcrest-1-3mp-bullt-wifi-video-security-ip-camera-pt-ipm-723w.html"&gt;&lt;span class="caps"&gt;IPM&lt;/span&gt;-723W&lt;/a&gt; WiFi camera with a 1.&lt;span class="caps"&gt;3MP&lt;/span&gt; 1280x960 resolution and a 92º field of view. It&amp;#8217;s a decent camera and the resolution is perfectly adequate but I wouldn&amp;#8217;t mind a bit more, and more importantly, both sides of my house would benefit a lot from a winder field of view. I believe I&amp;#8217;ve settled on two Amcrest &lt;a href="https://amcrest.com/amcrest-prohd-outdoor-1080p-wifi-wireless-ip-security-bullet-camera-ip67-weatherproof-1080p-1920tvl-ip2m-852w-white.html"&gt;&lt;span class="caps"&gt;IP2M&lt;/span&gt;-852W&lt;/a&gt;, which are similar outdoor WiFi cameras but with 1920x1080 resolution and a super-wide 128º field of&amp;nbsp;view.&lt;/p&gt;
&lt;p&gt;I received some questions via email after writing this post about the Amcrest cameras with Linux as well as the security of them. I think I&amp;#8217;m quite happy with both, but both with some caveats. First of all, regarding security, I&amp;#8217;m skeptical of the security of any proprietary software (especially from a small vendor or one not in the software business) and generally expect all IoT devices to have abysmal security. When I originally purchased the devices, I blocked all Internet-bound traffic from them at my router before even plugging them in. For the time being at least, I&amp;#8217;m going to assume that to be enough for my needs. I certainly wouldn&amp;#8217;t expose these directly to the Internet or allow them to access both the Internet and my home network, as is the case for any consumer-oriented&amp;nbsp;devices.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve also received some questions about the Linux support for Amcrest cameras. My experience so far has been consistent with my &lt;a href="/2018/05/amcrest-ip-camera-first-impressions/"&gt;Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt; Camera First Impressions - Jason Antman&amp;#8217;s Blog&lt;/a&gt;. The cameras certainly work fine under Linux in general; they can be fully controlled and configured via any browser and you can view the low-resolution &lt;span class="caps"&gt;MJPEG&lt;/span&gt; stream in any browser. Viewing the full-resolution &lt;span class="caps"&gt;RTSP&lt;/span&gt; stream requires either the Amcrest Web View Chrome app or a viewer that supports &lt;span class="caps"&gt;RTSP&lt;/span&gt; streams (&lt;span class="caps"&gt;VLC&lt;/span&gt; or any common surveillance camera software). Aside from watching the stream in &lt;span class="caps"&gt;VLC&lt;/span&gt; or Amcrest Web View while I was outside aiming the camera, I&amp;#8217;ve been using either the low-res &lt;span class="caps"&gt;MJPEG&lt;/span&gt; stream in a browser or, more recently ZoneMinder and HomeAssistant, to view it. Unless you want a closed-source native desktop app, I can&amp;#8217;t find any meaningful difference between how the cameras work on Linux vs Mac or presumably&amp;nbsp;Windows.&lt;/p&gt;
&lt;h3 id="ir-illuminator"&gt;&lt;a class="toclink" href="#ir-illuminator"&gt;&lt;span class="caps"&gt;IR&lt;/span&gt;&amp;nbsp;Illuminator&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;My first step in attempting to reduce false-positive motion detection caused by flying bugs at night was purchasing an external &lt;span class="caps"&gt;IR&lt;/span&gt; illuminator. I opted for a 12V &lt;span class="caps"&gt;DC&lt;/span&gt; model on amazon that uses the same power supply as the camera (I purchased a splitter for them), the
&lt;a href="https://www.amazon.com/gp/product/B01G6EDOO2/"&gt;Univivi 850nm 12 &lt;span class="caps"&gt;LED&lt;/span&gt; Wide Angle &lt;span class="caps"&gt;IR&lt;/span&gt; Illuminator&lt;/a&gt;. It&amp;#8217;s a large-ish unit that looks much like a &lt;span class="caps"&gt;LED&lt;/span&gt; floodlight, except that when on it emits only a barely-visible red glow from the LEDs. This has helped immensely; I have it placed about a foot and a half away from the camera and it has dramatically cut down on (but not eliminated) the number of times that the motion detection is triggered at night by moths and other light-seeking insects. That being said, with some of the advances I&amp;#8217;ve made in other areas (read on) I probably won&amp;#8217;t be replicating this for my other cameras, at least not initially. I &lt;em&gt;will&lt;/em&gt; also remark that the light output from this unit isn&amp;#8217;t wide enough to cover the camera&amp;#8217;s whole field of view, and it does suffer from some definite hot&amp;nbsp;spots.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a view of the camera and &lt;span class="caps"&gt;IR&lt;/span&gt; illuminator during the&amp;nbsp;day:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/ir_illuminator_day.jpg"&gt;&lt;img alt="camera and IR illuminator as installed, during the day" src="/GFX/ir_illuminator_day_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And here&amp;#8217;s a view of it at night. Note that this was taken in almost total darkness and to the human eye the illuminator only emits a barely-visible red glow; unfortunately this photo does more to illustrate how sensitive my phone camera is to &lt;span class="caps"&gt;IR&lt;/span&gt; than what it actually looks&amp;nbsp;like.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/ir_illuminator_night.jpg"&gt;&lt;img alt="camera and IR illuminator at night" src="/GFX/ir_illuminator_night_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="surveillance-software-zoneminder"&gt;&lt;a class="toclink" href="#surveillance-software-zoneminder"&gt;Surveillance Software -&amp;nbsp;ZoneMinder&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When I last posted I&amp;#8217;d done an &lt;a href="/2018/05/linux-surveillance-camera-software-evaluation/"&gt;evaluation&lt;/a&gt; of a number of options for Linux-based video surveillance, discounted ZoneMinder mainly because of its age, resource requirements, and difficulty getting it running in Docker. I ended up settling on the &lt;a href="https://motion-project.github.io/"&gt;Motion Project&lt;/a&gt; (&lt;code&gt;motion&lt;/code&gt;) because of its simplicity and low resource requirements. Unfortunately, that path ended up being a dead&amp;nbsp;end.&lt;/p&gt;
&lt;p&gt;I spent quite a bit of time tuning motion and developing a horribly simple proof-of-concept web interface for it (the defunct project lives at &lt;a href="https://github.com/jantman/motion-pipeline"&gt;https://github.com/jantman/motion-pipeline&lt;/a&gt; if anyone is interested) and playing with masks and various values to get reliable motion detection at 1920x1080 10fps on a RaspberryPi 3B+. While I eventually got that working including notifications with images, it failed completely when I installed the camera in its final environment - the exterior of my house. No matter how hard I tried, I couldn&amp;#8217;t get the motion detection to capture legitimate events but ignore the large amounts of shadow motion when wind caught the trees around my house. I hadn&amp;#8217;t considered this relatively obvious issue when I did my initial tests at my former (and relatively tree-free) apartment complex. It&amp;#8217;s also worth noting that when running motion detection at 1920x1080 10fps, the RaspberryPi 3B+ was essentially at its limits; if I wanted to add another camera of equal resolution and frame rate I&amp;#8217;d need a Pi per&amp;nbsp;camera.&lt;/p&gt;
&lt;p&gt;After that non-starter I remembered that the motion detection algorithm in &lt;code&gt;motion&lt;/code&gt; only takes luminance into account (effectively a black-and-white image) but ZoneMinder uses full color in its motion detection. So, I decided to take another look at ZoneMinder. After some initial hiccups I decided to just install the &lt;code&gt;zoneminder&lt;/code&gt; package on the RaspberryPi 3B+ running Debian 9. After a bit of setup, I had it running and processing 1920x1080 10fps on the Pi. This taxed the system quite a bit and the web &lt;span class="caps"&gt;UI&lt;/span&gt; was almost unusably sluggish, but it was enough for me to get &lt;span class="caps"&gt;ZM&lt;/span&gt; up and running and to prove that its motion detection algorithm handles clouds and shadows &lt;em&gt;much&lt;/em&gt; better than &lt;code&gt;motion&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It was apparent that if I wanted to make use of &lt;span class="caps"&gt;ZM&lt;/span&gt; with multiple cameras and also have it be useful and reliable, I needed significantly better hardware than the RaspberryPi. After some searching on Amazon, I found a &lt;a href="https://www.amazon.com/gp/product/B01KWP82CK/"&gt;refurbished &lt;span class="caps"&gt;HP&lt;/span&gt; Elite 8200 small-form-factor desktop&lt;/a&gt; on Amazon for $300. It was quite a bit more money than I&amp;#8217;d wanted to put into this system, but with an Intel Core i7-2600 with four cores (plus hyper-threading) at 3.4GHz, &lt;span class="caps"&gt;16GB&lt;/span&gt; memory and a &lt;span class="caps"&gt;2TB&lt;/span&gt; spinning disk, I figured it would be more than adequate for four or more cameras (in fact the specs are shockingly close to my desktop computer, which was quite beefy when I built it three or four years&amp;nbsp;ago).&lt;/p&gt;
&lt;p&gt;That machine arrived two weeks ago and I installed Debian 9 on it along with the official ZoneMinder package, and it&amp;#8217;s performing amazingly well. With one camera at 1920x1080 10fps in monitor mode and another at 1280x960 10fps in motion detection (Modect) mode, the system barely breaks a sweat with half of its memory free and half or three-quarters of the &lt;span class="caps"&gt;CPU&lt;/span&gt; cores idle. &lt;span class="caps"&gt;ZM&lt;/span&gt; is performing exceedingly well, with the web &lt;span class="caps"&gt;UI&lt;/span&gt; fast and streaming working very well. I&amp;#8217;m still having some false positives from shadows when it gets very windy, but I have a plan for addressing that as well. Overall I&amp;#8217;m really glad I switched to ZoneMinder with decent hardware, and plan on further improving and expanding this set-up in the&amp;nbsp;future.&lt;/p&gt;
&lt;h3 id="notifications"&gt;&lt;a class="toclink" href="#notifications"&gt;Notifications&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;One thing that ZoneMinder completely lacks is the built-in ability to notify immediately on new events/alarms. The closest that it has are &amp;#8220;filters&amp;#8221;, which run at a configurable interval (usually 60 seconds) and can be set to send email or execute an external command for new alarms. Unfortunately there are some issues around how they&amp;#8217;re configured that result in either notification storms or severe delays when multiple short events happen in rapid succession. After using this method for a few days and researching other possibilities, I found the &lt;a href="https://github.com/pliablepixels/zmeventserver"&gt;zmeventserver&lt;/a&gt; project, a daemon written in Perl that polls the ZoneMinder shared memory map for new events at a short interval and pushes them to clients via a websocket server. After some initial experimentation, I unashamedly hacked up the Perl source, ripped out the websocket server, and modified it to execute a shell command with the event &lt;span class="caps"&gt;ID&lt;/span&gt; as an argument (backgrounded with &lt;code&gt;&amp;amp;&lt;/code&gt; so as not to tie up the Perl&amp;nbsp;code).&lt;/p&gt;
&lt;p&gt;For my event handler script I wrote something in Python that grabs the details of the event directly from ZoneMinder&amp;#8217;s database, along with the first and best (most motion) frames, and sends them to me via email and Pushover. I&amp;#8217;ve added a bit more to the script but it&amp;#8217;s still quite a hack-ish proof-of-concept and too rough to share, but there&amp;#8217;s really nothing terribly complicated about it: it gets called with ZoneMinder&amp;#8217;s EventId, looks up that event and a bunch of related stuff in the database, and then generates an email and Pushover notification. I&amp;#8217;m not sure if I&amp;#8217;m going to keep using this or try to push most of the logic into HomeAssistant (see below); if I do stick with this script, I&amp;#8217;ll make an effort to clean it up and publish the&amp;nbsp;code.&lt;/p&gt;
&lt;h3 id="image-processing-ir-switch-detection"&gt;&lt;a class="toclink" href="#image-processing-ir-switch-detection"&gt;Image Processing - &lt;span class="caps"&gt;IR&lt;/span&gt; Switch&amp;nbsp;Detection&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once I got ZoneMinder relatively well tuned for motion detection in my environment and notifications up and running, my first bit of intelligence in the alerting process was disregarding events when the camera switched from visible light to infra-red mode. This &lt;span class="caps"&gt;IR&lt;/span&gt; switch occurs twice a day - visible to &lt;span class="caps"&gt;IR&lt;/span&gt; around dusk and &lt;span class="caps"&gt;IR&lt;/span&gt; to visible around dawn - and was a bit of an annoyance to me. When the switch-over happens, virtually all pixels in the image go white for a frame or two and the image switches between color and black and white. My gut reaction was to ignore events with a massive percentage of changed pixels around dawn or dusk, but that seemed too uncertain. With a bit of thought, I realized that detecting a change from color to black-and-white (or vice-versa) should be rather&amp;nbsp;straightforward.&lt;/p&gt;
&lt;p&gt;As the script was already written in Python, I installed &lt;a href="https://pillow.readthedocs.io/"&gt;pillow&lt;/a&gt;, a modern fork of the Python Imaging Library, and came up with the following snippet to tell whether a specific Frame from ZoneMinder is color or black-and-white (note this is a partial snippet with a lot of unrelated code&amp;nbsp;removed):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;&lt;span class="caps"&gt;PIL&lt;/span&gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="c1"&gt;# lots of internals redacted here...&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frame_fmt&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FrameId&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;is_color&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Finding if image is color or not for &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;bands&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;histos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;histogram&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;bands&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;histos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;histos&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Loading image for &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; from: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This loads the &lt;span class="caps"&gt;JPEG&lt;/span&gt; image (frame) from ZoneMinder as a &lt;span class="caps"&gt;PIL&lt;/span&gt; &lt;code&gt;Image&lt;/code&gt;, splits the image
into its color-component bands (red, green, and blue), and then checks if the histograms
of the three color bands are identical. If so, the image is&amp;nbsp;black-and-white.&lt;/p&gt;
&lt;p&gt;My notification script simply looks at each event, checks if the first frame is color
and the last is black and white or vice-versa, and if so suppresses the notification
and renames the Event in ZoneMinder for later&amp;nbsp;cleanup.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;There is one issue with this method,&lt;/strong&gt; when ZoneMinder loses signal from a camera it
generates a completely blue frame until signal is regained. I&amp;#8217;ve only had this happen
once, but at some point I plan on modifying the above to ignore the blue &amp;#8220;loss of signal&amp;#8221;&amp;nbsp;frames.&lt;/p&gt;
&lt;h3 id="monitoring"&gt;&lt;a class="toclink" href="#monitoring"&gt;Monitoring&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;At this point I decided that I was sufficiently close to having a minimally-usable system that
I should turn my attention to monitoring it, and making sure I&amp;#8217;m alerted if it stops working.
Since I&amp;#8217;ve moved all of my personal services to &lt;span class="caps"&gt;AWS&lt;/span&gt;, I didn&amp;#8217;t have an existing monitoring
infrastructure for anything running in my home. Not wanting anything too heavy-weight or
complicated, and having an existing Lambda function to handle re-notification of CloudWatch
alarms, I hacked a &amp;#8220;monitoring system&amp;#8221; together using that Lambda function and &lt;span class="caps"&gt;API&lt;/span&gt; Gateway
in a few&amp;nbsp;hours.&lt;/p&gt;
&lt;p&gt;The functionality is relatively simple: every five minutes a Python script runs on my ZoneMinder
system that does a bunch of checks and &lt;span class="caps"&gt;POSTS&lt;/span&gt; them to &lt;span class="caps"&gt;API&lt;/span&gt; Gateway as a &lt;span class="caps"&gt;JSON&lt;/span&gt; array of results. The
POSTed data for each check includes the timestamp, a check name, a boolean &lt;code&gt;is_ok&lt;/code&gt; field, and
an optional string with additional information. &lt;span class="caps"&gt;API&lt;/span&gt; Gateway writes this information to DynamoDB,
and triggers a Lambda function if any of the &lt;code&gt;is_ok&lt;/code&gt; fields changed from true to false. The
Lambda is also run every 30 minutes, and notifies me via email or text message if any of the
check &lt;code&gt;is_ok&lt;/code&gt; fields is False &lt;em&gt;or&lt;/em&gt; if any of the timestamp values are more than 10 minutes old.
For now, this should suffice as a really simple monitoring system. I also have a quick and simple
single-page web view of the current Dynamo&amp;nbsp;contents.&lt;/p&gt;
&lt;p&gt;The checks that I&amp;#8217;m currently running&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;System load average&lt;sup&gt;1&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Disk free space as reported by&amp;nbsp;ZoneMinder&lt;/li&gt;
&lt;li&gt;ZoneMinder daemon status as reported by&amp;nbsp;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;ZoneMinder Run State (one of my custom values, not&amp;nbsp;&amp;#8220;stopped&amp;#8221;)&lt;/li&gt;
&lt;li&gt;ZoneMinder &lt;span class="caps"&gt;SHM&lt;/span&gt;&amp;nbsp;free&lt;/li&gt;
&lt;li&gt;ZoneMinder status as reported by &lt;code&gt;zmpkg.pl&lt;/code&gt; (&amp;#8220;running&amp;#8221;)&lt;/li&gt;
&lt;li&gt;ZoneMinder &lt;span class="caps"&gt;UI&lt;/span&gt; - page loads and has a link to my primary&amp;nbsp;camera&lt;/li&gt;
&lt;li&gt;zmdc process&amp;nbsp;running&lt;/li&gt;
&lt;li&gt;zmwatch process&amp;nbsp;running&lt;/li&gt;
&lt;li&gt;My custom event server process running (based on zmeventnotification.pl; see&amp;nbsp;above)&lt;/li&gt;
&lt;li&gt;For each&amp;nbsp;camera:&lt;/li&gt;
&lt;li&gt;Direct image check against the Amcrest&amp;nbsp;camera&lt;/li&gt;
&lt;li&gt;Camera&amp;nbsp;enabled&lt;/li&gt;
&lt;li&gt;Image check via&amp;nbsp;ZoneMinder&lt;/li&gt;
&lt;li&gt;zmu frame&amp;nbsp;rate&lt;/li&gt;
&lt;li&gt;zmu last frame&amp;nbsp;time&lt;/li&gt;
&lt;li&gt;zmc process&amp;nbsp;running&lt;/li&gt;
&lt;li&gt;zma process running if Monitor is set to a motion-detecting&amp;nbsp;state&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the &amp;#8220;Image check&amp;#8221; tests, I do the&amp;nbsp;following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Retrieve the binary image from the camera or&amp;nbsp;&lt;span class="caps"&gt;ZM&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Use the python &lt;code&gt;imghdr.what()&lt;/code&gt; function to ensure it&amp;#8217;s a &lt;span class="caps"&gt;JPEG&lt;/span&gt;&amp;nbsp;image&lt;/li&gt;
&lt;li&gt;Ensure that the size of the image matches what &lt;span class="caps"&gt;ZM&lt;/span&gt; thinks the monitor size&amp;nbsp;is&lt;/li&gt;
&lt;li&gt;Use the &lt;span class="caps"&gt;PIL&lt;/span&gt; &lt;code&gt;getextrema()&lt;/code&gt; function to ensure that there&amp;#8217;s more than one color in the image (i.e. fail if it&amp;#8217;s an all-blue &amp;#8220;signal lost&amp;#8221; or an all-black&amp;nbsp;image).&lt;/li&gt;
&lt;li&gt;Ensure that the histogram of the image has more than 20 distinct buckets / pixel&amp;nbsp;values.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; I&amp;#8217;ve usually found Load Average to be an often misunderstood metric, and one that people rely on much too often (generally without knowing enough about it). ZoneMinder exposes it prominently in the &lt;span class="caps"&gt;UI&lt;/span&gt; as one of the three health metrics, and while I&amp;#8217;m not sure I agree with this, it &lt;em&gt;is&lt;/em&gt; a good metric for the specific workload of this particular system of mine. If you&amp;#8217;d like to learn more about Load Average as a performance metric on modern Linux systems, system performance expert and current Senior Performance Architect at Netflix Brendan Gregg has an excellent blog post, &lt;a href="http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html"&gt;Linux Load Averages: Solving the Mystery&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="neural-network-object-detection"&gt;&lt;a class="toclink" href="#neural-network-object-detection"&gt;Neural Network Object&amp;nbsp;Detection&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When I was researching how other ZoneMinder users are attempting to reduce false positives, I came by a &lt;a href="https://forums.zoneminder.com/viewtopic.php?f=36&amp;amp;t=26222"&gt;post on the ZoneMinder Forums&lt;/a&gt; from someone who is using &lt;a href="https://pjreddie.com/darknet/yolo/"&gt;Joseph Redmon&amp;#8217;s Darknet yolo3&lt;/a&gt; neutral network object detection implementation for detecting and localizing meaningful changes in ZoneMinder&amp;#8217;s captured frames. This idea immediately appealed to me; if I could reliably tell whether a frame contains a person, for my purposes as a security system, that would completely solve the environmental false positive problem. I was also very interested in Darknet yolo3 as it is simple to build and distributes pre-trained models - my initial testing was as simple as cloning a repo, downloading a few files, running &lt;code&gt;make&lt;/code&gt;, and then running the included command-line script on a &lt;span class="caps"&gt;JPEG&lt;/span&gt; image. I was pretty amazed at how accurately it recognized the person, car, and dogs in the image I selected. There is also a Python wrapper around yolo3, &lt;a href="https://github.com/madhawav/YOLO3-4-Py"&gt;yolo34py&lt;/a&gt;, which I found quite easy to&amp;nbsp;use.&lt;/p&gt;
&lt;p&gt;Using yolo34py I was able to relatively quickly add object detection to my Python-based ZoneMinder event notification script. Over three or four days of testing, I found yolo3 using the pre-trained model to be &lt;em&gt;extremely&lt;/em&gt; accurate across all of the events my camera captured. The one down side was that, running on my Intel i7-2600 at 3.4GHz, it was taking a full &lt;em&gt;ten to fifteen seconds per frame&lt;/em&gt; to run the object detection. That&amp;#8217;s fine for testing, but if I were to rely on this as an alarm system, I&amp;#8217;d want something considerably&amp;nbsp;faster.&lt;/p&gt;
&lt;p&gt;A cursory glance at the Darknet documentation told me what I already knew - though I have no prior experience with the subject - that running neural network image processing with any reasonable speed requires a &lt;span class="caps"&gt;GPU&lt;/span&gt;. I decided that I could allocate around $100 to speeding up the detection given the Darknet documentation&amp;#8217;s claim of a 10x or better speedup on a &lt;span class="caps"&gt;GPU&lt;/span&gt;. I found that about the best $100 &lt;span class="caps"&gt;GPU&lt;/span&gt; I could get on Amazon was a &lt;span class="caps"&gt;1GB&lt;/span&gt; Nvidia Quadro K600, so I purchased &lt;a href="https://www.amazon.com/gp/product/B00BLTE8HK/"&gt;this&lt;/a&gt; &lt;span class="caps"&gt;PNY&lt;/span&gt;&amp;nbsp;card.&lt;/p&gt;
&lt;p&gt;When I got the card and requisite software installed and recompiled Darknet with &lt;span class="caps"&gt;CUDA&lt;/span&gt; support and attempted to run detection on an image, I was rather dismayed to be greeted with an error&amp;nbsp;message:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;0 &lt;span class="caps"&gt;CUDA&lt;/span&gt; Error: out of&amp;nbsp;memory&lt;/p&gt;
&lt;p&gt;darknet: ./src/cuda.c:36: check_error: Assertion &lt;code&gt;0&lt;/code&gt; failed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Unfortunately, after just googling that error for Darknet, I found quite a few GitHub issues and mailing list threads explaining that Darknet Yolo3&amp;#8217;s default (and most accurate) model requires about 3.&lt;span class="caps"&gt;6GB&lt;/span&gt; of &lt;span class="caps"&gt;GPU&lt;/span&gt; memory, far too much for my &lt;span class="caps"&gt;1GB&lt;/span&gt; card (at the moment, &lt;span class="caps"&gt;4GB&lt;/span&gt; GPUs start at&amp;nbsp;$&lt;span class="caps"&gt;500USD&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Luckily for the fate of my project, Darknet also has a pre-trained &amp;#8220;tiny&amp;#8221; model designed to work for low-memory GPUs - like the apparently-puny one I just bought. The project states that its accuracy is only about 2-3% lower, though the results I&amp;#8217;ve seen are noticeably inferior especially when two objects are in close proximity or overlap. For the time being, I&amp;#8217;m still getting notified by my Python script for every motion detection event, along with the &lt;span class="caps"&gt;YOLO&lt;/span&gt; object detection results. I&amp;#8217;m saving every event that has questionable results for later comparison against the full (albeit slow, running on &lt;span class="caps"&gt;CPU&lt;/span&gt;) model and possibly other object detection&amp;nbsp;tools.&lt;/p&gt;
&lt;h2 id="homeassistant-and-z-wave"&gt;&lt;a class="toclink" href="#homeassistant-and-z-wave"&gt;HomeAssistant and&amp;nbsp;Z-Wave&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Just before I began experimenting with Darknet object detection, I decided that the number of false positive motion detection events I was receiving merited investigation into a more classic alarm system approach. I also received a coupon for the &lt;a href="https://simplisafe.com/"&gt;SimpliSafe&lt;/a&gt; home security system in my address change packet from the &lt;span class="caps"&gt;USPS&lt;/span&gt;. After a fair amount of investigation I decided that there weren&amp;#8217;t any off-the-shelf wireless home alarm systems that seemed attractive to me (I don&amp;#8217;t really need central monitoring, but I do need to be able to access the system and status programmatically) but this did get me doing some research, and I found there is a wide array of alarm system components using the &lt;a href="http://www.z-wave.com/"&gt;Z-Wave&lt;/a&gt; radio technology that seemed suitable for a &lt;span class="caps"&gt;DIY&lt;/span&gt;&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;One of my colleagues speaks quite highly of &lt;a href="https://www.home-assistant.io/"&gt;HomeAssistant&lt;/a&gt;, an open source (though Apache licensed) home automation suite written in Python3. Browsing through the project&amp;#8217;s website and documentation, I became reasonably confident that it could handle my needs for an alarm system (it has a fair amount of built-in logic for this use case, and other people actively use it for this) and that it also integrates natively with Z-Wave. Even better, it also has a native integration with ZoneMinder to tie the two systems&amp;nbsp;together.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m really, &lt;em&gt;really&lt;/em&gt; liking HomeAssistant so far, but I&amp;#8217;ll leave the details of that for a future&amp;nbsp;post.&lt;/p&gt;
&lt;h3 id="doorwindow-and-motion-sensors"&gt;&lt;a class="toclink" href="#doorwindow-and-motion-sensors"&gt;Door/Window and Motion&amp;nbsp;Sensors&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After a bit of research, I determined that I wanted Z-Wave Plus components for their better (than none) security and advanced features and purchased some initial Z-Wave components to test from Amazon: a &lt;span class="caps"&gt;USB&lt;/span&gt; &lt;a href="https://www.amazon.com/gp/product/B00X0AWA6E/"&gt;Aeotec Gen5 Z-Stick&lt;/a&gt; Z-Wave controller for $45, an &lt;a href="https://www.amazon.com/gp/product/B01N5HB4U5/"&gt;Ecolink Z-Wave Plus magnetic Door/Window sensor&lt;/a&gt; for $30, and an &lt;a href="https://www.amazon.com/gp/product/B01MQXXG0I/"&gt;Ecolink Z-Wave Plus &lt;span class="caps"&gt;PIR&lt;/span&gt; Motion Sensor&lt;/a&gt; for $40. I figured that was a reasonable enough price to test the system and determine how well it works, and either move forward or return the&amp;nbsp;items.&lt;/p&gt;
&lt;p&gt;So far I&amp;#8217;ve had the Z-Wave components running via HomeAssistant for seven days, with the door sensor on my front door and the motion sensor placed atop the adjacent window. I&amp;#8217;ve configured HomeAssistant to do nothing more than notify me via Pushover when the door opens or motion is sensed. So far in a week, I&amp;#8217;ve received zero false-positive alarms and zero false-negative alarms, so I&amp;#8217;m quite happy. The motion or door opening signals make it from the sensors to HomeAssistant, out to Pushover, and to my phone within one to three seconds, which seems quite reasonable to me. The &amp;#8220;pet immunity&amp;#8221; on the motion sensor &lt;em&gt;is&lt;/em&gt; still triggered by my two dogs walking around, but that&amp;#8217;s rather expected since they&amp;#8217;re fifty-five and seventy pounds, respectively, and not a problem since they&amp;#8217;re crated whenever I&amp;#8217;m not home. I&amp;#8217;m quite happy with the performance of both of these sensors so&amp;nbsp;far.&lt;/p&gt;
&lt;h3 id="thermostat"&gt;&lt;a class="toclink" href="#thermostat"&gt;Thermostat&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Last weekend, after unpacking and enabling my two &lt;a href="https://github.com/jantman/pi2graphite"&gt;RaspberryPi-to-Graphite temperature sensors&lt;/a&gt;, I finally determined that I&amp;#8217;m not going crazy but the thermostat in my house was. It was wildly inaccurate, and letting the house overheat during the day and then over-cooling at night. I knew I had to replace it and, having seen that HomeAssistant supports climate control systems, immediately remembered my dream of having a computer-controlled thermostat that I briefly &lt;a href="https://github.com/jantman/RPyMostat"&gt;explored&lt;/a&gt; since I first built a &lt;a href="https://github.com/jantman/tuxostat"&gt;crude solution&lt;/a&gt; back &lt;a href="http://blog.jasonantman.com/2008/06/new-project/"&gt;in 2008&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After a short search on Amazon, I found the &lt;a href="https://www.amazon.com/gp/product/B0095P7B80/"&gt;Iris &lt;span class="caps"&gt;CT&lt;/span&gt;-101 Z-Wave thermostat&lt;/a&gt;. It&amp;#8217;s a touchscreen 7-day programmable thermostat with Z-Wave, essentially the same unit as the &lt;a href="http://www.radiothermostat.com/products/"&gt;Radio Thermostat &lt;span class="caps"&gt;CT&lt;/span&gt;-101&lt;/a&gt; but intended to work with the Lowes Iris home automation system. A number of the positive reviews mentioned it working with HomeAssistant or other F/&lt;span class="caps"&gt;OSS&lt;/span&gt; home automation systems, and the $40 price was well below most networked thermostats and about the same as a normal &amp;#8220;dumb&amp;#8221; 7-day thermostat at local&amp;nbsp;stores.&lt;/p&gt;
&lt;p&gt;So far I&amp;#8217;m quite happy with it. I had some initial concerns - even though the device is constantly powered and even a Z-Wave repeater, I had to configure HomeAssistant to explicitly poll it on a regular interval for up-to-date information - but now that I&amp;#8217;ve figured it out, the thermostat seems to be working quite well. I can view the current and target temperatures, the operational/power status of my &lt;span class="caps"&gt;HVAC&lt;/span&gt; system&amp;#8217;s fan and compressor, and set the target temperature and on/off controls. The unit &lt;em&gt;does&lt;/em&gt; show up as two separate controls - heating and cooling - but that seems to be the standard for Z-Wave climate controls and logically matches up with the physical thermostat&amp;#8217;s &amp;#8220;heat/off/cool&amp;#8221; controls. I haven&amp;#8217;t done any automation with it yet, but at a minimum this should make it easy for me to control heating and cooling based on different temperature sensors throughout the house at different times of&amp;nbsp;day.&lt;/p&gt;
&lt;h2 id="whats-next"&gt;&lt;a class="toclink" href="#whats-next"&gt;What&amp;#8217;s&amp;nbsp;Next&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This past weekend I purchased two more outdoor Amcrest WiFi cameras - this time the &lt;a href="https://amcrest.com/amcrest-prohd-outdoor-1080p-wifi-wireless-ip-security-bullet-camera-ip67-weatherproof-1080p-1920tvl-ip2m-852w-white.html"&gt;&lt;span class="caps"&gt;IP2M&lt;/span&gt;-852W&lt;/a&gt; 1080P models with an impressive 128º field of view - to complete my camera coverage, as well as a few more of the same &lt;a href="https://www.amazon.com/gp/product/B01N5HB4U5/"&gt;Z-Wave door/window sensors&lt;/a&gt;, a pair of Z-Wave lightbulbs to try, and some well-reviewed &lt;a href="https://www.amazon.com/gp/product/B01AKSO80O/"&gt;&lt;span class="caps"&gt;ZOOZ&lt;/span&gt; Z-Wave 4-in-1 sensors&lt;/a&gt; that combine motion sensors with light level, temperature, and humidity. Over the next week or two I&amp;#8217;ll be installing all of that to finally finish the system, and also spending quite a bit of time customizing HomeAssistant to be the heart of it all. I&amp;#8217;ll share my experiences in follow-up posts, but some of the things I have planned&amp;nbsp;include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Experimenting with some other machine-learning-based object detection&amp;nbsp;implementations&lt;/li&gt;
&lt;li&gt;Localizing detected objects to a ZoneMinder zone in the image, and using that to determine whether to alarm or&amp;nbsp;not&lt;/li&gt;
&lt;li&gt;Modifying the ZoneMinder HomeAssistant integration to know about run&amp;nbsp;states&lt;/li&gt;
&lt;li&gt;Using HomeAssistant&amp;#8217;s alarm control panel component to implement real alarm system logic, with notifications to my&amp;nbsp;phone&lt;/li&gt;
&lt;li&gt;Having my Amcrest ProHD pan/tilt camera, which has clear line of sight to both front and back doors, pan to a door and capture a snapshot when the door sensor&amp;nbsp;activates.&lt;/li&gt;
&lt;/ul&gt;</content><category term="amcrest"></category><category term="camera"></category><category term="security"></category><category term="surveillance"></category><category term="video"></category><category term="linux"></category><category term="IP camera"></category><category term="evaluation"></category><category term="alarm"></category><category term="IR"></category><category term="homeassistant"></category><category term="hass"></category><category term="automation"></category><category term="z-wave"></category><category term="darknet"></category><category term="yolo"></category><category term="machine learning"></category><category term="neural network"></category><category term="object detection"></category></entry><entry><title>Linux Surveillance Camera Software Evaluation</title><link href="https://blog.jasonantman.com/2018/05/linux-surveillance-camera-software-evaluation/" rel="alternate"></link><published>2018-05-12T07:18:00-04:00</published><updated>2018-05-12T07:18:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-05-12:/2018/05/linux-surveillance-camera-software-evaluation/</id><summary type="html">&lt;p&gt;My evaluation of some options for streaming and motion-activated recording of &lt;span class="caps"&gt;IP&lt;/span&gt;&amp;nbsp;cameras.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#initial-requirements"&gt;Initial&amp;nbsp;Requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contenders"&gt;Contenders&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#zoneminder"&gt;ZoneMinder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#kerberosio"&gt;Kerberos.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#shinobi"&gt;Shinobi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#motion"&gt;Motion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#final-choice"&gt;Final&amp;nbsp;Choice&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; The next post in this series is up, &lt;a href="/2018/07/ip-camera-home-security-and-automation-update"&gt;&lt;span class="caps"&gt;IP&lt;/span&gt; Camera, Home Security and Automation Update&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In my last post, &lt;a href="/2018/05/amcrest-ip-camera-first-impressions/"&gt;Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt; Camera First Impressions&lt;/a&gt;, I went over what I&amp;#8217;d found about the pair of &lt;span class="caps"&gt;IP&lt;/span&gt; cameras that I bought to keep an eye on my dogs and my new house. My next step was to figure out how I&amp;#8217;d handle motion-activated recording, and that&amp;#8217;s what I&amp;#8217;ll discuss this time. I&amp;#8217;ve spent all of my spare time in the past week - probably twenty to thirty hours - researching and experimenting and the results have actually been quite&amp;nbsp;surprising.&lt;/p&gt;
&lt;h2 id="initial-requirements"&gt;&lt;a class="toclink" href="#initial-requirements"&gt;Initial&amp;nbsp;Requirements&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The initial requirements that I identified&amp;nbsp;were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open source (preferably &lt;span class="caps"&gt;GPL&lt;/span&gt;) and runs on&amp;nbsp;Linux&lt;/li&gt;
&lt;li&gt;Must be able to run with low-end hardware - either a Raspberry Pi or another small and inexpensive system (I don&amp;#8217;t want this to depend on my desktop, and I don&amp;#8217;t want to invest a lot in&amp;nbsp;it)&lt;/li&gt;
&lt;li&gt;Support multiple cameras - at least two, ideally four or&amp;nbsp;six&lt;/li&gt;
&lt;li&gt;Works behind a &lt;span class="caps"&gt;HTTP&lt;/span&gt; reverse proxy, such as nginx with certificate&amp;nbsp;auth&lt;/li&gt;
&lt;li&gt;Can stream live via the &lt;span class="caps"&gt;UI&lt;/span&gt;, ideally full resolution with low&amp;nbsp;latency&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PTZ&lt;/span&gt; (pan/tilt/zoom) control from the&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;List, search and playback videos from the&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Decent mobile support, either via built-in web &lt;span class="caps"&gt;UI&lt;/span&gt; or native&amp;nbsp;app&lt;/li&gt;
&lt;li&gt;Motion detection to trigger recording and notifications/scripts; configurable post-motion recording time; prerecord&amp;nbsp;buffer&lt;/li&gt;
&lt;li&gt;On-demand manual recording (ideally via both &lt;span class="caps"&gt;UI&lt;/span&gt; and&amp;nbsp;script/&lt;span class="caps"&gt;API&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;Ability to disable motion activation/recording via script or&amp;nbsp;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Detect loss of video/tamper and trigger&amp;nbsp;notification&lt;/li&gt;
&lt;li&gt;Detect loss of camera (on network) and trigger&amp;nbsp;notification&lt;/li&gt;
&lt;li&gt;Relatively straightforward monitoring (i.e. I should get a text message if the system goes down or stops working&amp;nbsp;correctly)&lt;/li&gt;
&lt;li&gt;Bonuses:&lt;/li&gt;
&lt;li&gt;Runs in Docker, even if not officially&amp;nbsp;supported&lt;/li&gt;
&lt;li&gt;Written in a language I have some experience in (which essentially means Python, Ruby, or maybe (maaaaybe)&amp;nbsp;NodeJS)&lt;/li&gt;
&lt;li&gt;Only uses&amp;nbsp;&lt;span class="caps"&gt;HTTP&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Nice multi-camera&amp;nbsp;view&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="contenders"&gt;&lt;a class="toclink" href="#contenders"&gt;Contenders&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Right away I knew two of the projects I wanted to look at: &lt;a href="https://zoneminder.com/"&gt;ZoneMinder&lt;/a&gt;, which I&amp;#8217;ve heard many people mention and seems to be the de-facto standard in open-source video surveillance, and &lt;a href="https://motion-project.github.io/"&gt;Motion&lt;/a&gt; which I&amp;#8217;ve used before and only knew as a limited and somewhat archaic daemon. After some investigation and reading of feature lists, I came up with two other, much newer, contenders in &lt;a href="https://shinobi.video/"&gt;Shinobi&lt;/a&gt; and &lt;a href="https://www.kerberos.io/"&gt;Kerberos.io&lt;/a&gt;. I saw a few other possibilities online, but they didn&amp;#8217;t fit the above&amp;nbsp;criteria.&lt;/p&gt;
&lt;p&gt;I did all of my initial tests in Docker since I was testing each of these on my main computer and didn&amp;#8217;t want to clutter up the system, and I also &lt;em&gt;really&lt;/em&gt; like using Docker for testing and deployment of software. That may be unfair for some of them, but it&amp;#8217;s both how I intend on deploying the final choice and my preferred deployment strategy lately in general. I can&amp;#8217;t say that I dove deep into all, or even any, of these options but I gave each of them at least four hours (and quite more than that for some of them) of experimentation. I expect to be able to get something at least minimally working within that amount of&amp;nbsp;time.&lt;/p&gt;
&lt;h3 id="zoneminder"&gt;&lt;a class="toclink" href="#zoneminder"&gt;ZoneMinder&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://zoneminder.com/"&gt;ZoneMinder&lt;/a&gt; seems to be what everyone talks about when the topic of Linux-based open source surveillance software comes up. It&amp;#8217;s an incredibly mature and long-lived project - first released in 2002 - and for a long time seems to have been the only option. It&amp;#8217;s probably most famous for allowing the user to select various &amp;#8220;zones&amp;#8221; (regions of the image) with different motion detection sensitivity levels, including completely ignoring certain areas. When I started actually looking into it, though, my expectations decreased significantly. During my testing the first problem I found was that, while Docker is now a &lt;a href="https://zoneminder.readthedocs.io/en/latest/installationguide/packpack.html"&gt;recommended installation method&lt;/a&gt;, all of the &lt;a href="https://github.com/ZoneMinder/zmdockerfiles"&gt;official Dockerfiles&lt;/a&gt; and most of the others that I could find run it in a single super-container with &lt;em&gt;every&lt;/em&gt; process, including MySQL and all of the web tier (which ends up being 20-something processes). This is extremely un-Docker-like, and horribly inefficient for me since my test system (my desktop) already runs MariaDB for a number of other applications. The official Dockerfiles are also based on a full and bloated &lt;code&gt;centos:7&lt;/code&gt; image (73 &lt;span class="caps"&gt;MB&lt;/span&gt; just for the base image). Lastly, and most shocking to me, while Docker is an officially-supported installation method the project doesn&amp;#8217;t actually distribute Docker images. While ZoneMinder has packages for Ubuntu, &lt;span class="caps"&gt;RHEL&lt;/span&gt;, Debian and Gentoo, their Docker-based installation instructions build the image locally which almost completely obviates the entire purpose and idea of Docker as a build-once, run-anywhere packaging&amp;nbsp;format.&lt;/p&gt;
&lt;p&gt;After some investigation, I was able to find &lt;a href="https://github.com/pschmitt/docker-zoneminder"&gt;Philipp Schmitt&amp;#8217;s docker-zoneminder repo&lt;/a&gt; which provides an Alpine 3.4-based ZoneMinder image. Unfortunately it includes MySQL and doesn&amp;#8217;t build anymore (the last commit was two years ago), but I &lt;a href="https://github.com/jantman/docker-zoneminder"&gt;forked the repo&lt;/a&gt; and was able to get it to build and run on the latest Alpine Linux 3.7 with the distro&amp;#8217;s official zoneminder package. That took me a mere three days, which included giving up on Philipp&amp;#8217;s use of lighttpd and switching to Apache httpd 2.4 configured according to ZoneMinder&amp;#8217;s upstream instructions. Let&amp;#8217;s just say that the process was anything but easy. I eventually got ZoneMinder working, but didn&amp;#8217;t even get as far as setting up motion detection. I attempted to tell my &lt;span class="caps"&gt;ONVIF&lt;/span&gt;-compliant Amcrest ProHD camera to pan right using ZoneMinder&amp;#8217;s builtin &lt;span class="caps"&gt;ONVIF&lt;/span&gt; control support, and my entire machine locked up for about an hour (note this is an Arch Linux desktop with a 4-core/8-thread (&lt;span class="caps"&gt;HT&lt;/span&gt;) Intel i7-3770 at 3.4GHz and &lt;span class="caps"&gt;16GB&lt;/span&gt; of &lt;span class="caps"&gt;DDR3&lt;/span&gt; memory). Even before that just watching the live streams of my two cameras (1920x1080 and 1280x960) at 15fps, with motion detection and recording and all other features disabled, would result in them regularly dropping to 1-2 fps for a minute or&amp;nbsp;two.&lt;/p&gt;
&lt;p&gt;After the lockup caused by &lt;span class="caps"&gt;ONVIF&lt;/span&gt; support, I went about setting up resource constraints on memory and &lt;span class="caps"&gt;CPU&lt;/span&gt; usage for the container. That was the final straw; no matter what I set the constraints to, even values far in excess of the maximum of what the container was actually using, ZoneMinder seemed to behave horribly. I tried setting the memory limits to 12G (75% of my system&amp;#8217;s memory, when the container was only using ~&lt;span class="caps"&gt;512MB&lt;/span&gt;) and the &lt;span class="caps"&gt;CPU&lt;/span&gt; limits to a period of 100000 and a limit of 700000 (allowing it to consume 7 of my 8 threads/virtual cores) and it still performed as though ZoneMinder was crippled. Given that my target platform is a Raspberry Pi (3 B+ with 1.4GHz 64-bit quad-core &lt;span class="caps"&gt;ARM&lt;/span&gt; Coretx-A53 and &lt;span class="caps"&gt;1GB&lt;/span&gt; &lt;span class="caps"&gt;LPDDR2&lt;/span&gt; memory), I figured it was time to stop my ZoneMinder experiments. I know people and have heard many positive stories about ZoneMinder, and work with a few people who use it and find it to be great, but I think it&amp;#8217;s just capable of doing too much - and has too high resource requirements - for my&amp;nbsp;needs.&lt;/p&gt;
&lt;p&gt;In the interest of transparency, here are some of the &lt;a href="https://github.com/jantman/docker-zoneminder/blob/master/README.md#current-status"&gt;notes&lt;/a&gt; I wrote down during my attempt at an Alpine-based Docker&amp;nbsp;container:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As a preface, I need to mention that ZoneMinder was first released in 2002. It is a mature, even aged, piece of software. The level of effort that has gone into it is astonishing, and the mere fact that it&amp;#8217;s still an active and well-respected project after 16 years is pretty damn amazing, even more so for an open source project. That being said, two of my main criteria for selecting home security/surveillance software are how stable I think it will be (will it run for weeks/months without me even looking at it, and be working when I need it to) and how easily I can customize it&amp;nbsp;(code).&lt;/li&gt;
&lt;li&gt;ZoneMinder is a &lt;em&gt;giant&lt;/em&gt; codebase made up of Perl, &lt;span class="caps"&gt;PHP&lt;/span&gt;, C++, JavaScript, and probably some others. There are just &lt;em&gt;so&lt;/em&gt; many moving pieces (see the &lt;a href="http://zoneminder.readthedocs.io/en/stable/userguide/components.html"&gt;Components documentation&lt;/a&gt;) that I can&amp;#8217;t really imagine this running reliably without intervention for terribly&amp;nbsp;long.&lt;/li&gt;
&lt;li&gt;As a corollary, when I did finally get this running, the logs (written to the &lt;span class="caps"&gt;DB&lt;/span&gt; and shown in the &lt;span class="caps"&gt;UI&lt;/span&gt;) kept reporting Errors (in red nonetheless) for processes that died and were then respawned by the watchdog without any noticeable effects in the &lt;span class="caps"&gt;UI&lt;/span&gt;/streams. I don&amp;#8217;t want to take on a system that doesn&amp;#8217;t even know the difference between an error and a warning, or that reports errors (with whistles and bells and sirens) to the user that it can self-recover from. I intend on leaving this alone as a security system, and need to be able to reliably tell (and programmatically alert on) whether it&amp;#8217;s &amp;#8220;working&amp;#8221; or &amp;#8220;not working&amp;#8221;. A process dying and being successfully restarted a second later isn&amp;#8217;t what I&amp;#8217;d call an&amp;nbsp;&amp;#8220;error&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Apparently Docker is now &lt;a href="https://github.com/ZoneMinder/ZoneMinder/wiki/Docker"&gt;a recommended install mathod&lt;/a&gt;, but the &lt;a href="https://github.com/ZoneMinder/zmdockerfiles"&gt;official Dockerfiles&lt;/a&gt; (and almost all of the others I&amp;#8217;ve found) are decidedly un-Docker-like, running &lt;em&gt;everything&lt;/em&gt; including both the web and &lt;span class="caps"&gt;DB&lt;/span&gt; tiers in one container. Given how many components make up ZoneMinder, it seems like it would much more naturally be made up of a handful of containers - maybe half a dozen plus a container per&amp;nbsp;camera.&lt;/li&gt;
&lt;li&gt;Even on my main desktop computer - a relatively beefy machine for its day, with a four-core/eight-thread Intel i7-3770 @ 3.4GHz and &lt;span class="caps"&gt;16GB&lt;/span&gt; &lt;span class="caps"&gt;DDR3&lt;/span&gt; - ZoneMinder seemed to be struggling with two &lt;span class="caps"&gt;IP&lt;/span&gt; cameras and I saw occasional framerate drops down to one to two fps. It just seems to be trying to do too&amp;nbsp;much.&lt;/li&gt;
&lt;li&gt;I still think there&amp;#8217;s a ghost in the machine re: docker resource constraints. Once I set &lt;span class="caps"&gt;CPU&lt;/span&gt; or memory limits on the container, even if I set them way (i.e. ten times) above what Docker reports ZoneMinder to be using, &lt;span class="caps"&gt;ZM&lt;/span&gt; behaves differently and starts to have crippling performance&amp;nbsp;issues.&lt;/li&gt;
&lt;li&gt;Bottom line: I do a lot of work with Docker, and automating deployment and monitoring of software has been a big part of my job for the last decade. I need something that&amp;#8217;s simpler, feels more reliable, and is easier to deploy and monitor. Something that logs to &lt;span class="caps"&gt;STDOUT&lt;/span&gt;/&lt;span class="caps"&gt;STDERR&lt;/span&gt;, looks at least something like a 12-factor app, and feels like it can actually run (if not be designed) natively in&amp;nbsp;Docker.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So after three or four incredibly frustrating afternoons and evenings, I put ZoneMinder aside and continued down my evaluation&amp;nbsp;list.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Postscript:&lt;/strong&gt; One of my colleagues, &lt;a href="https://github.com/jbruce12000"&gt;Jason Bruce&lt;/a&gt;, told me that he uses the &lt;a href="https://hub.docker.com/r/aptalca/zoneminder-1.29/"&gt;aptalca/zoneminder-1.29&lt;/a&gt; Docker image to great success. If you&amp;#8217;re considering ZoneMinder, it&amp;#8217;s probably worth trying that image, and it&amp;#8217;s only&amp;nbsp;&lt;span class="caps"&gt;310MB&lt;/span&gt;.&lt;/p&gt;
&lt;h3 id="kerberosio"&gt;&lt;a class="toclink" href="#kerberosio"&gt;Kerberos.io&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The next candidate on my list was &lt;a href="https://www.kerberos.io/"&gt;Kerberos.io&lt;/a&gt;, one of the newcomers that I&amp;#8217;d never heard of before. It&amp;#8217;s billed as a &amp;#8220;free [and open-source] video surveillance solution, which works with any camera and on every Linux based machine. You can deploy a fully configured video surveillance system within a few minutes on the environment you prefer: Raspberry Pi, Orange Pi, Docker, etc.&amp;#8221; So that caught my attention as it seemed to check a lot of the non-functional boxes - Docker, modern, etc. - right in the introductory &amp;#8220;advertising&amp;#8221;. The website also looks clean and modern, and the screenshots and demo look nice. The one negative instantly apparent is that it only supports one camera unless you use the paid and hosted Kerberos.cloud product, but I figured that I could either run the cloud software myself or else hack something together (their &lt;a href="https://doc.kerberos.io/2.0/installation/Multi-camera/Docker"&gt;docs on Multi-Camera Docker&lt;/a&gt; are essentially just how to run multiple instances, one per&amp;nbsp;camera).&lt;/p&gt;
&lt;p&gt;On the positive side, Kerberos.io &lt;em&gt;was&lt;/em&gt; incredibly easy to get running. The &lt;a href="https://doc.kerberos.io/2.0/installation/Docker"&gt;docs&lt;/a&gt; just point to their &lt;a href="https://hub.docker.com/u/kerberos/"&gt;public images on the Docker Hub&lt;/a&gt; and a &lt;a href="https://github.com/kerberos-io/docker"&gt;github repo&lt;/a&gt; with a &lt;code&gt;docker-compose.yml&lt;/code&gt; that runs the appropriate containers (one for the &amp;#8220;machinery&amp;#8221; capture backend and one for the &amp;#8220;web&amp;#8221; frontend), and even has an &lt;span class="caps"&gt;ARM&lt;/span&gt;-specific Dockerfile for Raspberry Pi users. Setup was a complete breeze as the web &lt;span class="caps"&gt;UI&lt;/span&gt; starts out with an installation wizard that walks you through configuring the app. After setting up a user I was able to log in and click the &amp;#8220;Configuration&amp;#8221; button on the top menu bar and configure my camera. It was quite straightforward - just select &amp;#8220;&lt;span class="caps"&gt;IP&lt;/span&gt; Camera&amp;#8221; and specify the &lt;span class="caps"&gt;RSTP&lt;/span&gt; &lt;span class="caps"&gt;URL&lt;/span&gt;, dimensions, delay (zero) and live stream framerate, click save, and view the camera. I had a &lt;span class="caps"&gt;UI&lt;/span&gt; showing the stream from my 1080P camera and the ability to record within about two minutes. The &lt;span class="caps"&gt;UI&lt;/span&gt; initially loads to a dashboard with the live camera view and some graphs of motion detection metrics by hour of day, day of week, and today vs average, as well as a listing of dates (presumably motion detection history/recordings) on the left sidebar. There&amp;#8217;s also a handy &amp;#8220;System&amp;#8221; video that shows uptime, some system information, the currently-running Kerberos.io versions, statistics on captured images, and some system performance information (disk space that was incorrect in Docker, network &lt;span class="caps"&gt;IO&lt;/span&gt;, and &lt;span class="caps"&gt;CPU&lt;/span&gt;&amp;nbsp;usage).&lt;/p&gt;
&lt;p&gt;Unfortunately, the system almost instantly showed a &amp;#8220;Hey, your disk is almost full. Please remove some images..&amp;#8221; header at the top of the pages. Yes, with the containers running, my &lt;code&gt;/var&lt;/code&gt; partition was 97% full (lots of churn lately, and lots of cruft from the ZoneMinder&amp;nbsp;tests).&lt;/p&gt;
&lt;p&gt;At this point I went back to &amp;#8220;Configuration&amp;#8221; and clicked the &amp;#8220;Motion&amp;#8221; button to set up motion detection. I was presented with a gray box that I assume was supposed to show the live image from the camera, and some points on a polygon to select a motion detection region. I did the best I could with the missing image and moved on to some sliders for &amp;#8220;sensitivity&amp;#8221; (default fifteen on a scale of zero to thirty) and &amp;#8220;number of detections before valid&amp;#8221; (default two on a scale of zero to ten) and then configured the recording settings: both images and video, no timestamp overlays, fifteen frames per second (the same as the cameras), record five seconds after motion detection, and nothing set for the options to trigger webhooks, scripts, &lt;span class="caps"&gt;GPIO&lt;/span&gt; or &lt;span class="caps"&gt;MQTT&lt;/span&gt; on detection. I should note that the &amp;#8220;seconds to record&amp;#8221; field is a slider for &amp;#8220;The number of seconds that will be recorded after motion was detected&amp;#8221;, which defaults to five and can go from zero to&amp;nbsp;thirty.&lt;/p&gt;
&lt;p&gt;I confirmed those settings and browsed back to the Dashboard, where I could see the live video view and&amp;#8230; a whole lot of nothing&amp;nbsp;else:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/kerberos1.png"&gt;&lt;img alt="screenshot of Kerberos.io dashboard with live webcam feed but all graphs saying &amp;quot;No data available&amp;quot;" src="/GFX/kerberos1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Refreshing the page didn&amp;#8217;t seem to help get any of the other data to show up, even when there was obviously motion. There&amp;#8217;s a Heatmap feature in the Configuration page, but I haven&amp;#8217;t been able to get it to display anything other than &amp;#8220;No data available&amp;#8221;. Thinking that something was wrong, I went back through the motion detection configuration and found that the region I&amp;#8217;d selected was reset back to the strange-shaped default. I fixed it, pressed the &amp;#8220;Confirm and Select&amp;#8221; button without going through to the second and third screens of the Motion configuration dialog, and then opened the Motion configuration dialog again. This time, the region was effectively empty (a flat line in the top left corner, with multiple points on it) but I could actually see the camera stream albeit frozen at the latest frame. I adjusted the region polygon again, Saved, and then reloaded the Motion configuration dialog&amp;#8230; and got back to a correct-looking region but no picture. I assumed that was right and proceeded back through the three screens of the dialog and found the rest of my settings back to default. Through trial and error, I found that the configuration dialog for the Motion detection has three screens, which are paged through by using either left/right arrows on the sides of the dialog or one of three small circles (inactive two grayed out) at the bottom of the settings. Apparently, while the &amp;#8220;Confirm and Select&amp;#8221; button dismisses the dialog, it only saves the settings on the &lt;em&gt;current&lt;/em&gt; one of three pages. So eventually, I realized that I had to edit the first page, save, bring the dialog back up, move to the second page, save, then bring the dialog back up, move to the third page, and save. I then needed to press the &amp;#8220;Update&amp;#8221; button on the main Configuration page to commit my&amp;nbsp;changes.&lt;/p&gt;
&lt;p&gt;After all that, things seemed to be working. Navingating back to the Dashboard showed some actual data on the graphs including a large number of detections for the current&amp;nbsp;hour:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/kerberos2.png"&gt;&lt;img alt="screenshot of Kerberos.io dashboard with data in graphs and hourly graph showing 18 motion detections this hour" src="/GFX/kerberos2_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;However, when I clicked on the date in the left sidebar, something seemed to be very&amp;nbsp;amiss:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/kerberos3.png"&gt;&lt;img alt="screenshot of Kerberos.io dashboard for current date, saying &amp;quot;Oeps, no detections found at 11 o'clock&amp;quot;" src="/GFX/kerberos3_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The main Dashboard had reported 18 detections, and the slider bar on the view for today&amp;#8217;s date (above) clearly showed some heatmap colors for the current hour, but it was also telling me that it couldn&amp;#8217;t find any detections (videos/images). On a hunch I looked at the Docker logs for the container, and found the &amp;#8220;machinery&amp;#8221; (capture and storage) container&amp;#8217;s logs full of this, repeated over and&amp;nbsp;over:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;machinery_1  | Cleaning disk
machinery_1  | Cleaning disk
machinery_1  | rm: missing operand
machinery_1  | Try &amp;#39;rm --help&amp;#39; for more information.
machinery_1  | Cleaning disk
machinery_1  | rm: missing operand
machinery_1  | Try &amp;#39;rm --help&amp;#39; for more information.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As best I can tell, it was detecting that the disk backing the Docker volume was 97% full (it&amp;#8217;s a 100G volume) and cleaning up the disk&amp;#8230; which apparently meant deleting all of the recordings, including the ones that had just been made and I hadn&amp;#8217;t reviewed&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;That was the end of my experimentation with Kerberos.io. Not only was it apparently executing a shell command (&lt;code&gt;rm&lt;/code&gt;) with invalid/missing arguments, but it was also deleting all of the recordings it had because the disk was 97% full. First and foremost, the camera I&amp;#8217;m using is streaming 1920x1080 H.264 at 15 frames per second; &lt;span class="caps"&gt;3GB&lt;/span&gt; of disk space remaining shouldn&amp;#8217;t be a reason to delete all of the five-second video clips unless the cleanup logic is purely based on percentages. I didn&amp;#8217;t dig into the source code, but I&amp;#8217;m pretty sure if my 100-Petabyte disk was 97% full, it would still start deleting single-digit-megabyte images to free up space. Secondly, and more importantly, I intend on using this as part of a security system which to me means engineering for the worst-case scenario. Under normal circumstances, I should be able to respond to a low disk warning and manually free up some space. My Internet connection is generally very stable, so the &amp;#8220;worst case&amp;#8221; I want to engineer for is someone burglarizing my house and being smart enough to cut the cable line. If that happens, causing storage to fill up, the most important video is actually the &lt;em&gt;oldest&lt;/em&gt;! It&amp;#8217;s the video that was recorded closest to when I lost access to the system. In which case, I&amp;#8217;d want the failure mode to be either filling up the storage or ceasing to record, but definitely not to arbitrarily delete old-but-unreviewed&amp;nbsp;recordings.&lt;/p&gt;
&lt;h3 id="shinobi"&gt;&lt;a class="toclink" href="#shinobi"&gt;Shinobi&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Aside from my old standby of Motion, the last candidate on my list was &lt;a href="https://shinobi.video/"&gt;Shinobi&lt;/a&gt;. Shinobi&amp;#8217;s tag line is &amp;#8220;The open source &lt;span class="caps"&gt;CCTV&lt;/span&gt; solution&amp;#8221; and prides itself on being modern and using modern technologies. The first section of their pretty and modern homepage, https://shinobi.video/, includes a link to the docs and GitHub and&amp;nbsp;states:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Shinobi is Open Source, written in Node.js, and real easy to use. It is the future of &lt;span class="caps"&gt;CCTV&lt;/span&gt; and &lt;span class="caps"&gt;NVR&lt;/span&gt; for developers and end-users alike. It is catered to by professionals and most importantly by the one who created&amp;nbsp;it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After seeing what&amp;#8217;s happening under the hood of ZoneMinder, this certainly got my attention, as did the general modern open-source community feel of the site. Granted, I initially missed the section comparing Shinobi &lt;span class="caps"&gt;CE&lt;/span&gt; (Community Edition; GPLv3) and Shinobi Pro (Professional but free for non-commercial use; Creative Commons) and that Community Edition is &amp;#8220;updated only for major changes or bug fixes.&amp;#8221; But the &lt;a href="https://github.com/ShinobiCCTV/Shinobi/blob/2bc74064da5484545d86fce9cf95db74ace0db48/README.md#key-aspects"&gt;current features list&lt;/a&gt; includes most of what I wanted (even audio recording too, from my&amp;nbsp;ProHD)&lt;/p&gt;
&lt;p&gt;First I headed over to the &lt;a href="https://github.com/moeiscool/docker-shinobi"&gt;Dockerfiles from Shinobi&amp;#8217;s author&lt;/a&gt;. I had some issues with the Alpine-based vatiant and decided to give the Debian ones a try. One &lt;code&gt;docker-compose up&lt;/code&gt; and some patience later, I had two containers running: camera and cron. I immediately hit the web port and got a login box, which confused me with invalid logins for a while until I went back and re-read the &lt;a href="https://shinobi.video/docs/start"&gt;installation docs&lt;/a&gt; and realized that Shinobi supports multiple users, and I had to login via &lt;code&gt;/super&lt;/code&gt; (superuser) to set up a user account for myself. I did that and logged in as a regular user, and was greeted with a clean, modern, responsive&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Not being one to read documentation for end-user software, I muddled around in the &lt;span class="caps"&gt;UI&lt;/span&gt; a bit until I managed to add my two cameras. It wasn&amp;#8217;t terribly difficult: click the &amp;#8220;+&amp;#8221; icon in the top left of the &lt;span class="caps"&gt;UI&lt;/span&gt; (tooltip says, &amp;#8220;Add Monitor&amp;#8221;) and fill out the form. One early problem I had adding the first camera is that the &lt;span class="caps"&gt;URL&lt;/span&gt; parsing discards query strings. I added my Amcrest ProHD with its primary stream &lt;span class="caps"&gt;URL&lt;/span&gt;, which has a path of &lt;code&gt;/cam/realmonitor?channel=1&amp;amp;subtype=0&lt;/code&gt;. The stream didn&amp;#8217;t work and when I went back into the settings to edit it, the query string had been discarded. I just changed the &amp;#8220;Automatic&amp;#8221; (parsing of &lt;span class="caps"&gt;URL&lt;/span&gt;) to &amp;#8220;No&amp;#8221; and manually entered the protocol, host, port, authentication and path details myself, and it worked fine. Shinobi has a very nice interface for adding cameras, and one of the things I liked the most was the ability to choose the streaming details for the live stream; it supports Poseidon, &lt;span class="caps"&gt;JPEG&lt;/span&gt;, &lt;span class="caps"&gt;MJPEG&lt;/span&gt;, &lt;span class="caps"&gt;FLV&lt;/span&gt;, &lt;span class="caps"&gt;HLS&lt;/span&gt; (with audio) or a custom base64-over-websockets. The &lt;span class="caps"&gt;HLS&lt;/span&gt; stream also allows selection of video and audio codecs including copying the source codec (which is what I did). There&amp;#8217;s also an option for a &lt;span class="caps"&gt;CGI&lt;/span&gt;-style &lt;span class="caps"&gt;JPEG&lt;/span&gt; snapshot&amp;nbsp;&lt;span class="caps"&gt;API&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi1.png"&gt;&lt;img alt="screenshot of Shinobi dialog to add a monitor" src="/GFX/shinobi1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class="caps"&gt;UI&lt;/span&gt; is smooth and modern, with a fully responsive design that apparently works on mobile too (though I didn&amp;#8217;t test it). It even includes nice dropdown menus and mouseover menus for streams that  include snapshot, start/stop recording, pop-out, recording list, calendar of events, monitor/stream settings, and fullscreen. It also includes something called the &amp;#8220;Power Viewer&amp;#8221; that I&amp;#8217;ll discuss&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi2.png"&gt;&lt;img alt="screenshot of Shinobi with mouseover controls for streams" src="/GFX/shinobi2_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Within a few minutes, I had both cameras up and running with their full resolution H.264 &lt;span class="caps"&gt;RTSP&lt;/span&gt; streams (1920x1080 and 1280x960, respectively) at 15fps. The camera streams are shown by clicking on the camera in the left sidebar, and the stream windows can be resized by dragging the lower right corner (though it doesn&amp;#8217;t keep the aspect ratio) and rearranged via&amp;nbsp;drag-and-drop.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi3.png"&gt;&lt;img alt="screenshot of Shinobi with both streams" src="/GFX/shinobi3_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I was happy to see that, in this configuration with video streaming but not being analyzed, the Docker containers were only using a combined total of about 5% of my &lt;span class="caps"&gt;CPU&lt;/span&gt; and &lt;span class="caps"&gt;100MB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;. I tried some experiments with snapshots (they force-download) and manually-requested recordings and was quite happy with both. I did have some occasional issues with live streams freezing if I refreshed the page, but they resumed fine if I logged back in. The calendar interface seemed handy - it shows a monthly calendar with the time, camera name, and size of each recording for each day - and the videos list for each camera lists the start and end time, filename, and size of each video for each camera, along with buttons to preview (on the same dialog), watch (fullscreen-ish in the viewer), download, and&amp;nbsp;delete.&lt;/p&gt;
&lt;p&gt;This all seemed wonderful, so I figured it was time to enable motion detection. Well&amp;#8230; little did I know that would be a six-hour struggle. The &lt;a href="https://shinobi.video/docs/motion"&gt;documentation on Motion detection&lt;/a&gt; is separate, and states that motion detection isn&amp;#8217;t built-in because not everybody wants it and it has dependencies, which is also started at other places on their site. The &lt;a href="https://shinobi.video/docs/motion#content-use-builtin"&gt;first section on the Motion detection docs page&lt;/a&gt; says that it&amp;#8217;s now built-in and people should just use that, but is rather easy to miss (the section heading is at the same level as &amp;#8220;Install on Ubuntu/Debian&amp;#8221;, &amp;#8220;Install on CentOS/Fedora&amp;#8221;, etc.) and doesn&amp;#8217;t explicitly say whether there are external dependencies or not. Without going into the details, I went through a six-hour marathon of trying different Docker images, installing dependencies, running NodeJS scripts, starting other processes, adding containers, etc. in an attempt to get motion detection&amp;nbsp;working.&lt;/p&gt;
&lt;p&gt;Through the course of this I found that Shinobi&amp;#8217;s documentation is quite lacking, and also that it seems to be sporadically updated. The &lt;a href="https://shinobi.video/docs/settings"&gt;settings documentation&lt;/a&gt; contains a lot that doesn&amp;#8217;t seem to line up with what I&amp;#8217;m seeing in the &lt;span class="caps"&gt;UI&lt;/span&gt;, and I&amp;#8217;m not sure if it&amp;#8217;s because the docs are out of date or because they&amp;#8217;re ahead of the code, or a Pro vs Community Edition issue, or what. There are other places in the docs that seem horribly outdated, and many sections that seem to give conflicting&amp;nbsp;information.&lt;/p&gt;
&lt;p&gt;At one point I also stopped and tried to configure pan/tilt control, but couldn&amp;#8217;t find a setting for that either, so I went back to motion&amp;nbsp;detection.&lt;/p&gt;
&lt;p&gt;Most of my frustration was based on the Motion Detection documentation page and its statements that once Motion Detection is set up you should see &amp;#8220;Detector: Motion Connected&amp;#8221; in the Monitor Settings, and have configuration options for motion detection. No matter what I tried - Debian or Alpine, different images, adding packages and &lt;span class="caps"&gt;OS&lt;/span&gt;-level dependencies, restarting the services, trying the older, no-longer-recommended plugin-based method - I couldn&amp;#8217;t find or see the Motion Detection settings like the docs said I should. I just kept trying different things to get those settings to show up. When I was just about to give up and was searching through Shinobi&amp;#8217;s &lt;a href="https://forum.shinobi.video/"&gt;forums&lt;/a&gt; for some confirmation of whether anyone could get this working, I stumbled upon a &lt;a href="https://forum.shinobi.video/post/160"&gt;forum post&lt;/a&gt; that mentioned something about &amp;#8220;Advanced&amp;nbsp;settings&amp;#8221;.&lt;/p&gt;
&lt;p&gt;I started the containers back up and sure enough, in the far lower right corner of the Monitor Settings dialog, colored almost the same as the background, was a button that says &amp;#8220;Simple&amp;#8221; and has an arrow. I clicked it, selected &amp;#8220;Advanced&amp;#8221;, and suddenly the left sidebar of the dialog grew&amp;#8230; to include Global Detector Settings and Control, among other&amp;nbsp;options.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi4.png"&gt;&lt;img alt="screenshot of Shinobi Monitor Settings in Advanced mode" src="/GFX/shinobi4_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As far as I can tell, motion detection was probably working the whole time and my six-ish hours of struggling were all for naught. The only problem I had was not changing the Monitor Settings dialog from Simple mode - which hides all motion detection and control settings - to Advanced. I&amp;#8217;ve gone back over the documentation multiple times, and there&amp;#8217;s not a single occurrence of the word &amp;#8220;Advanced&amp;#8221; on the Motion Detection page or the Settings page, and certainly nothing telling users that they need to explicitly switch to Advanced Mode to see these&amp;nbsp;settings.&lt;/p&gt;
&lt;p&gt;At that point, I was already quite frustrated with Shinobi and felt that if this was at all indicative of the quality of documentation and user experience, I should definitely avoid it. But I at least wanted to know what its motion detection could&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://shinobi.video/docs/settings#content-detector"&gt;settings documentation for Motion Detection&lt;/a&gt; was mostly straightforward, with the exception of a few&amp;nbsp;settings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Recording Timeout&lt;/strong&gt; - &amp;#8220;The length of time &amp;#8220;Trigger Record&amp;#8221; will run for. This is read in minutes.&amp;#8221; Apparently when Shinobi detects motion it records &lt;em&gt;minutes&lt;/em&gt; of video, with a minimum of one and a default of ten. This was very strange to me, especially since many motion events that I&amp;#8217;ve seen only span a few&amp;nbsp;seconds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timeout Reset on Next Motion&lt;/strong&gt; - &amp;#8220;If there is an overlap in trigger record should it reset. &lt;strong&gt;No:&lt;/strong&gt; Finish the current 10 minute order.. &lt;strong&gt;Yes:&lt;/strong&gt; Reset the timer&amp;#8221;. I didn&amp;#8217;t have to worry about this since it wasn&amp;#8217;t visible in my&amp;nbsp;version.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Save Events to &lt;span class="caps"&gt;SQL&lt;/span&gt;&lt;/strong&gt; - &amp;#8220;Save Motion Events in &lt;span class="caps"&gt;SQL&lt;/span&gt;. This will allow display of motion over video during the time motion events occured [sic] in the Power&amp;nbsp;Viewer.&amp;#8221;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Indifference&lt;/strong&gt; - &amp;#8220;How much Shinobi doesn&amp;#8217;t care about motion before doing something. The opposite of sensitivity; a lower number means it will trigger sooner. The value ranges up to 15(+) decimal places. 10 is default, 0.005 is pretty sensitive to motion changes. Note: If using Region Editor, leave this blank, and set indifference in the Region Editor (below).&amp;#8221; So&amp;#8230; firstly, the semantics of this are awful. Secondly, in my version, the global default (if not using Regions) isn&amp;#8217;t 10 it&amp;#8217;s 0.5, and the per-region default is&amp;nbsp;0.0005.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There were also a number of settings visible in the &lt;span class="caps"&gt;UI&lt;/span&gt; for the version I was running (&lt;a href="https://github.com/ShinobiCCTV/Shinobi/commit/4bf071abb5706f9240f32617bf3bb4b8aa52f3ca"&gt;https://github.com/ShinobiCCTV/Shinobi.git &amp;#8220;dev&amp;#8221; branch 4bf071abb5706f9240f32617bf3bb4b8aa52f3ca&lt;/a&gt;) that weren&amp;#8217;t in the&amp;nbsp;documentation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Allow Next Trigger&lt;/strong&gt; - &amp;#8220;in Milliseconds&amp;#8221;, default&amp;nbsp;2000.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Send Events to &lt;span class="caps"&gt;SQL&lt;/span&gt;&lt;/strong&gt; - &amp;#8220;Save Motion Events in &lt;span class="caps"&gt;SQL&lt;/span&gt;. This will allow display of motion over video during the time motion events occured [sic] in the Power Viewer.&amp;#8221; As I found out later, the Power Viewer does barely anything without&amp;nbsp;this.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After configuring the detection settings, the documentation told me that I had to add regions (zones) or else the detection would use the full frame. I did that via an editor modal from the Monitor Settings which allows adding multiple region polygons to the video via a simple but somewhat jerky and annoying (drag too close to the edges and points won&amp;#8217;t stick there) polygon editor. It was supposed to show the live video stream under the polygon, but that only worked once or twice for me, usually being a brown box where the video should&amp;nbsp;be.&lt;/p&gt;
&lt;p&gt;I was happy to see that running almost-full-frame, 15fps motion detection on both video feeds was only using about &lt;span class="caps"&gt;400MB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt; and the equivalent of one core (on my host &lt;span class="caps"&gt;OS&lt;/span&gt; it showed all 8 cores running around 20%, which is pretty good since I was also running graphite, grafana, nginx, apache, MySQL, Chrome, Atom,&amp;nbsp;etc.).&lt;/p&gt;
&lt;p&gt;One thing I immediately noticed after enabling motion detection, though, is that there&amp;#8217;s no &lt;span class="caps"&gt;UI&lt;/span&gt; indication of motion events. To see motion events for a camera, you need to use the Calendar, Video List, or Power Viewer modals. The other thing I noticed immediately is that using the default &amp;#8220;indifference&amp;#8221; value, my outdoor camera was recording constantly. I tried adjusting this value on both cameras but it certainly wasn&amp;#8217;t scientific; the default indifference for a zone was &amp;#8220;0.0005&amp;#8221; so I tried increasing it (decreasing sensitivity) by powers of 10. The best I could get that way was a point where almost everything was recorded, and then another point where it never&amp;nbsp;triggered.&lt;/p&gt;
&lt;p&gt;After that experience, I turned to the &amp;#8220;Power Viewer&amp;#8221; which seemed like it might be able to solve this. The layout actually seems quite well done and useful, despite the fact that the Live View of the camera was only sporadically working for&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi5.png"&gt;&lt;img alt="screenshot of Shinobi Power Viewer" src="/GFX/shinobi5_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The main elements&amp;nbsp;are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Live View&lt;/strong&gt; - This only worked sporadically for me, and I was unable to get a screenshot of it. When it worked, it showed the live stream from the&amp;nbsp;camera.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timeline&lt;/strong&gt; - A relatively handy view of all recordings and motion events for the specified date range. It seems to default to two days, though I only had the system running and recording for an hour or so. The blue dots along the timeline represent recordings; clicking one of them brings up the recording and starts playing it. The red bars represent the count of motion detection events in each&amp;nbsp;recording.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recording&lt;/strong&gt; - Plays the selected recording along with displaying the&amp;nbsp;filename.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Playback Timer&lt;/strong&gt; - It&amp;#8217;s a simple playback timer for the currently-playing video. It&amp;#8217;s clickable and draggable to advance through the&amp;nbsp;video.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Motion Meter&lt;/strong&gt; - The tooltip for this says &amp;#8220;Motion Meter&amp;#8221;, and the only clear documentation I could find on this says, &amp;#8220;When motion occurs a red bar will appear under your stream to indicate how much motion has happened.&amp;#8221; Some other documentation &lt;em&gt;implies&lt;/em&gt; that this should be the detected indifference value, presumably on a scale of zero to 100, but nothing explains that specifically. This also appeared to lag quite a bit behind the video and doesn&amp;#8217;t have a numeric output even on&amp;nbsp;hover.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Motion Confidence&lt;/strong&gt; - This is a graph over time (for the currently-playing recording) of &amp;#8220;Motion Confidence&amp;#8221;. I was unable to find any reference to this in the documentation and haven&amp;#8217;t yet received a response to my &lt;a href="https://forum.shinobi.video/topic/216/relationship-between-indifference-and-motion-confidence"&gt;forum post&lt;/a&gt; asking about it. The numeric definitely seems different from the &amp;#8220;Motion Meter&amp;#8221; to me, but I don&amp;#8217;t know what it&amp;nbsp;means.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point it seemed like Shinobi was the frontrunner in everything except motion detection, which it seemed to fail horribly at. There&amp;#8217;s a Noise Filter setting that I tried, but I couldn&amp;#8217;t find any clear documentation on how to tune Shinobi for motion thresholds and it certainly seemed to lack many of the advanced tuning features of &lt;code&gt;motion&lt;/code&gt; such as imprinting the number of changed pixels in the frame, debug images/videos with motion highlighted, adaptive thresholds or blob detection. I decided that I might as well explore &lt;code&gt;motion&lt;/code&gt; since I understand it and it&amp;#8217;s well documented, and come back to Shinobi later if I want&amp;nbsp;to.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Postscript:&lt;/strong&gt; Some of my other notes on&amp;nbsp;Shinobi:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One feature I do like about Shinobi is the &amp;#8220;Delete Motionless&amp;#8221; toggle that apparently records all the time and then deletes recording segments that didn&amp;#8217;t have motion detected. This seems like a &lt;em&gt;very&lt;/em&gt; good idea and, if done right, could help with capturing the low-motion events leading up to an event that crosses the&amp;nbsp;threshold.&lt;/li&gt;
&lt;li&gt;There were some annoying timezone bugs, where the &lt;span class="caps"&gt;UI&lt;/span&gt; showed the time in my local timezone (including the clock in the upper right corner) but the filenames and Power Viewer were using&amp;nbsp;&lt;span class="caps"&gt;UTC&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="motion"&gt;&lt;a class="toclink" href="#motion"&gt;Motion&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I&amp;#8217;ve used the &lt;a href="https://motion-project.github.io/"&gt;Motion Project&lt;/a&gt; a few times over the years and had a pretty good impression of it - at one point I had it running motion detection with a 1080P webcam on an original Raspberry Pi Model B (700MHz &lt;span class="caps"&gt;ARM&lt;/span&gt; with &lt;span class="caps"&gt;512MB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;). It&amp;#8217;s an established project (the git history goes back to 2005, but the initial commit is &amp;#8220;initial import&amp;#8221;), written in C and highly performant, and follows the Unix philosophy of doing one thing and doing it well. The project has been recently taken over by new developers and has a new home in the &lt;a href="https://github.com/Motion-Project"&gt;Motion-Project GitHub org&lt;/a&gt; but the previous maintainer&amp;#8217;s amazingly detailed and helpful wiki is still available at &lt;a href="http://www.lavrsen.dk/foswiki/bin/view/Motion/WebHome"&gt;http://www.lavrsen.dk/foswiki/bin/view/Motion/WebHome&lt;/a&gt;. Also note that I&amp;#8217;m not sure about the other projects listed here, but Motion uses luminance / intensity only to detect motion, i.e. no color&amp;nbsp;information.&lt;/p&gt;
&lt;p&gt;The main things that I remember about Motion from using it in the past (aside from feeling somewhat archaic though amazingly stable and fast)&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tuning of thresholds as a number of changed&amp;nbsp;pixels.&lt;/li&gt;
&lt;li&gt;For tuning, the ability to output &amp;#8220;debug&amp;#8221; images showing only the pixels that triggered motion&amp;nbsp;detection.&lt;/li&gt;
&lt;li&gt;Output as videos and/or &lt;span class="caps"&gt;JPEG&lt;/span&gt; snapshots, but it handles everything internally as still&amp;nbsp;frames.&lt;/li&gt;
&lt;li&gt;Ability to mask off certain parts of the frame using a manually-generated mask&amp;nbsp;image.&lt;/li&gt;
&lt;li&gt;Ability to watermark every frame with the number of changes pixels, for&amp;nbsp;debugging/tuning.&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Lightswitch mode&amp;#8221; that automatically ignores massive changes in&amp;nbsp;brightness.&lt;/li&gt;
&lt;li&gt;Motion detection based on the largest contiguous region of changed pixels, so it&amp;#8217;s less effected by&amp;nbsp;wind/leaves/rain/etc.&lt;/li&gt;
&lt;li&gt;Support for multiple&amp;nbsp;cameras.&lt;/li&gt;
&lt;li&gt;Snapshots either on a regular interval automatically, or triggered by a&amp;nbsp;signal.&lt;/li&gt;
&lt;li&gt;Ability to execute arbitrary programs/scripts when events occur (&lt;em&gt;many&lt;/em&gt; events; motion detect start and end, pictures and movies being written, event start and end,&amp;nbsp;etc.)&lt;/li&gt;
&lt;li&gt;Built-in ability to write extremely detailed information to&amp;nbsp;MySQL/PostgreSQL/SQLite3&lt;/li&gt;
&lt;li&gt;Highly configurable picture/video paths/filenames and overlay of text on&amp;nbsp;images.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Apparently since I last looked at the project, a number of major new features have been introduced&amp;nbsp;including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Live streaming of incoming cam video via &lt;span class="caps"&gt;HTTP&lt;/span&gt;&amp;nbsp;&lt;span class="caps"&gt;MJPEG&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Motion tracking in the frame, and experimental control of tracking motion via pan/tilt camera&amp;nbsp;controls.&lt;/li&gt;
&lt;li&gt;Control via a simple web interface, even including the ability to change/tune many settings live from the web&amp;nbsp;interface.&lt;/li&gt;
&lt;li&gt;Automatic/adaptive noise and threshold&amp;nbsp;control.&lt;/li&gt;
&lt;li&gt;Official support for both the RaspberryPi and &lt;span class="caps"&gt;MUSL&lt;/span&gt; LibC (i.e. Alpine&amp;nbsp;Linux)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The project also has wonderfully detailed documentation, as well as active &lt;span class="caps"&gt;IRC&lt;/span&gt; and mailing&amp;nbsp;lists.&lt;/p&gt;
&lt;p&gt;While Motion only has a very basic web interface for control, there are a number of more full-featured web UIs for it including the quite popular &lt;a href="https://github.com/ccrisan/motioneye"&gt;MotionEye&lt;/a&gt; that uses Python and&amp;nbsp;Tornado.&lt;/p&gt;
&lt;h2 id="final-choice"&gt;&lt;a class="toclink" href="#final-choice"&gt;Final&amp;nbsp;Choice&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After my frustrations with ZoneMinder, Kerberos.io, and Shinobi, I believe I&amp;#8217;m going to be going the minimalist route and using Motion with some sort of web &lt;span class="caps"&gt;UI&lt;/span&gt; for motion detection, recording, and review, and the cameras&amp;#8217; built-in &lt;span class="caps"&gt;RSTP&lt;/span&gt; stream for high-resolution live viewing. Given how long this post ended up being, I&amp;#8217;ll save the Motion setup and testing for my next&amp;nbsp;installment.&lt;/p&gt;</content><category term="amcrest"></category><category term="camera"></category><category term="security"></category><category term="surveillance"></category><category term="video"></category><category term="linux"></category><category term="IP camera"></category><category term="evaluation"></category></entry><entry><title>VyOS on Alix 2C1 Single Board Computer</title><link href="https://blog.jasonantman.com/2017/03/vyos-on-alix-2c1-single-board-computer/" rel="alternate"></link><published>2017-03-04T12:27:00-05:00</published><updated>2017-03-04T12:27:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2017-03-04:/2017/03/vyos-on-alix-2c1-single-board-computer/</id><summary type="html">&lt;p&gt;How to install VyOS 1.1.7 on an Alix 2c1 or similar i386 single board&amp;nbsp;computer&lt;/p&gt;</summary><content type="html">&lt;p&gt;Back in 2011 I &lt;a href="/2011/09/vyatta-networkos-routerfirewall-on-alix-board-compact-flash/"&gt;wrote a post&lt;/a&gt; on installing
the formerly open-source &lt;a href="https://wiki.vyos.net/wiki/Vyatta"&gt;Vyatta&lt;/a&gt; router/firewall distribution on an Alix compact flash-based single board
computer. I&amp;#8217;d been using it for many years, since Vyatta Community was a completely F/&lt;span class="caps"&gt;OSS&lt;/span&gt; project. I stopped updating regularly sometime around
when Vyatta (now Vyatta Core, differentiated from their paid offering) began widening the gap between its F/&lt;span class="caps"&gt;OSS&lt;/span&gt; Core and paid versions.
It got much worse when &lt;a href="http://newsroom.brocade.com/press-releases/brocade-acquires-vyatta-a-pioneer-and-leader-in-s-nasdaq-brcd-0949599#.WLr6DkArJhE"&gt;Brocade acquired Vyatta&lt;/a&gt;
in 2012. Soon thereafter open source builds stopped, the forums were shut down, the source code was made much more difficult to find, and
eventually vyatta.org itself was shut down. I won&amp;#8217;t go into further detail as there&amp;#8217;s been a lot written about this debacle and forcible destruction of a community,
such as &lt;a href="http://dotbalm.org/brocade-missed-the-boat-with-vyatta/"&gt;Chris Wadge&amp;#8217;s post&lt;/a&gt; and
&lt;a href="https://libertysys.com.au/2013/08/the-tragedy-of-vyatta-cores-demise/"&gt;this one&lt;/a&gt;, but I will say that the above made it increasingly difficult to plan
an upgrade of my home&amp;nbsp;router.&lt;/p&gt;
&lt;p&gt;On the positive side, however, the &lt;a href="https://vyos.io/"&gt;VyOS&lt;/a&gt; F/&lt;span class="caps"&gt;OSS&lt;/span&gt; fork has emerged, and seems to have quite a vibrant community
at this point. A few weeks ago, I decided to finally take the time to upgrade to the latest VyOS 1.1.7 on my aged
&lt;a href="https://www.pcengines.ch/alix2c1.htm"&gt;Alix 2c1&lt;/a&gt; single board router (purchased in 2008; 3 &lt;span class="caps"&gt;LAN&lt;/span&gt;, 433 MHz &lt;span class="caps"&gt;AMG&lt;/span&gt; Geode &lt;span class="caps"&gt;LX700&lt;/span&gt;, &lt;span class="caps"&gt;128MB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;).
VyOS is targeted at the cloud (virtualization) or &amp;#8220;real&amp;#8221; hardware, and doesn&amp;#8217;t seem to have anywhere near as many people
installing on dedicated SBCs as the former Vyatta community (probably because of the astonishing drop in the price of small, fanless
systems in recent years). I wasn&amp;#8217;t able to find much information about installing VyOS on such hardware, aside from
&lt;a href="https://forum.vyos.net/showthread.php?tid=6045"&gt;a few&lt;/a&gt; &lt;a href="https://forum.vyos.net/showthread.php?tid=26029"&gt;forum&lt;/a&gt;
&lt;a href="https://forum.vyos.net/showthread.php?tid=26881"&gt;threads&lt;/a&gt; and a &lt;a href="http://elderguerra.blogspot.com/2014/04/vyos-routerfirewall-on-alix-board.html"&gt;post on Elder Guerra&amp;#8217;s blog&lt;/a&gt;
that actually makes reference to and is based on my original post from&amp;nbsp;2011.&lt;/p&gt;
&lt;p&gt;So, for anyone who&amp;#8217;s interested, here&amp;#8217;s how I got VyOS 1.1.7 installed on my Alix&amp;nbsp;&lt;span class="caps"&gt;SBC&lt;/span&gt;:&lt;/p&gt;
&lt;h2 id="prerequisites"&gt;&lt;a class="toclink" href="#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A Linux machine with VirtualBox. For posterity, I did this on a recently updated Arch Linux machine, using VirtualBox 5.1.12 from Arch&amp;#8217;s repos (running via &lt;span class="caps"&gt;DKMS&lt;/span&gt; and with the Oracle extensions&amp;nbsp;installed).&lt;/li&gt;
&lt;li&gt;A Compact Flash card to perform the install on (I used &lt;a href="https://www.amazon.com/gp/product/B00PW1PH14/"&gt;this&lt;/a&gt; Wintec &amp;#8220;Industrial Grade&amp;#8221; &lt;span class="caps"&gt;SLC&lt;/span&gt; &lt;span class="caps"&gt;NAND&lt;/span&gt; &lt;span class="caps"&gt;4GB&lt;/span&gt; card from&amp;nbsp;amazon).&lt;/li&gt;
&lt;li&gt;A reader/writer for the card (my previous one was throwing errors, so I got &lt;a href="https://www.amazon.com/gp/product/B0056TYRMW/"&gt;this&lt;/a&gt; &lt;span class="caps"&gt;USB&lt;/span&gt; one from&amp;nbsp;Amazon).&lt;/li&gt;
&lt;li&gt;Ensure your user can read and write the raw disk devices. On Linux, this means your user must be in the &lt;code&gt;disk&lt;/code&gt; group. If it isn&amp;#8217;t, you&amp;#8217;ll need to log out and back in after making that&amp;nbsp;change.&lt;/li&gt;
&lt;li&gt;Assuming you&amp;#8217;re installing onto a headless board like the Alix, you&amp;#8217;ll need a null modem cable to connect to the serial console port, and whatever you need (&lt;span class="caps"&gt;USB&lt;/span&gt; to serial adapter) to plug that in to your&amp;nbsp;computer.&lt;/li&gt;
&lt;li&gt;A terminal emulator installed on your computer (I use &lt;a href="https://alioth.debian.org/projects/minicom"&gt;minicom&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="configuration-migration"&gt;&lt;a class="toclink" href="#configuration-migration"&gt;Configuration&amp;nbsp;Migration&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I just wanted to upgrade from my existing &lt;span class="caps"&gt;VC&lt;/span&gt; 6.3 installation, and use a new &lt;span class="caps"&gt;CF&lt;/span&gt; card. If you are doing a fresh install
and do not need to migrate the configuration, you can skip this&amp;nbsp;section.&lt;/p&gt;
&lt;p&gt;To migrate the configuration, I first set up a VyOS 1.1.7 VirtualBox &lt;span class="caps"&gt;VM&lt;/span&gt;, using the &lt;a href="https://github.com/higebu/vagrant-vyos"&gt;vagrant-vyos&lt;/a&gt;
plugin for &lt;a href="https://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt; and the author&amp;#8217;s &lt;a href="https://atlas.hashicorp.com/higebu/boxes/vyos"&gt;vyos Vagrant box&lt;/a&gt;. I setup
three network interfaces on the &lt;span class="caps"&gt;VM&lt;/span&gt; to match the three on my Alix board, and put the &lt;code&gt;Vagrantfile&lt;/code&gt; in the same directory as my config
backups from the current&amp;nbsp;router.&lt;/p&gt;
&lt;p&gt;Once I had the &lt;span class="caps"&gt;VM&lt;/span&gt; up and running with &lt;span class="caps"&gt;SSH&lt;/span&gt; access, I ran &lt;code&gt;load /vagrant/config.boot&lt;/code&gt; to load the configuration backup, and let the
config migration tool do its work. This took a few iterations of modifying the old (&lt;span class="caps"&gt;VC&lt;/span&gt; 6.3) config until I got something that would
load cleanly into VyOS 1.1.7; note that per the &lt;a href="https://wiki.vyos.net/wiki/Migrating_from_Vyatta"&gt;Migrating from Vyatta&lt;/a&gt; documentation,
coming from &lt;span class="caps"&gt;VC&lt;/span&gt; 6.4 or earlier, there were some manual changes I had to make before the old configuration would load in VyOS.
Once that was done, I committed and saved the config, then rebooted the &lt;span class="caps"&gt;VM&lt;/span&gt; and confirmed that it
came up correctly configured. I run &lt;span class="caps"&gt;SSH&lt;/span&gt; on a non-default port, so before reloading the &lt;span class="caps"&gt;VM&lt;/span&gt; I needed to edit the &lt;code&gt;Vagrantfile&lt;/code&gt;
to add &lt;code&gt;config.ssh.guest_port = SSH_PORT_NUMBER&lt;/code&gt; and &lt;code&gt;config.vm.network "forwarded_port", guest: SSH_PORT_NUMBER, host: SSH_PORT_NUMBER, id: "ssh"&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once finished, I copied &lt;code&gt;/config/config.boot&lt;/code&gt; from the &lt;span class="caps"&gt;VM&lt;/span&gt; to my host &lt;span class="caps"&gt;OS&lt;/span&gt;. I removed the &lt;span class="caps"&gt;MAC&lt;/span&gt; addresses for the interfaces
and the &lt;code&gt;vagrant&lt;/code&gt; user, and then used that as the starting configuration for my new install on the Alix&amp;nbsp;board.&lt;/p&gt;
&lt;h2 id="installation"&gt;&lt;a class="toclink" href="#installation"&gt;Installation&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Put your new &lt;span class="caps"&gt;CF&lt;/span&gt; card in the &lt;span class="caps"&gt;USB&lt;/span&gt; adapter and plug it in. Watch &lt;code&gt;dmesg&lt;/code&gt; to see what device name it&amp;#8217;s assigned. &lt;strong&gt;In this example, we&amp;#8217;ll call it /dev/sdX. Make &lt;span class="caps"&gt;SURE&lt;/span&gt; you correct that path in the below instructions to be the correct one for your &lt;span class="caps"&gt;CF&lt;/span&gt;&amp;nbsp;card.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Create a raw &lt;span class="caps"&gt;VMDK&lt;/span&gt; so VirtualBox can use the raw disk: &lt;code&gt;VBoxManage internalcommands createrawvmdk -filename /home/$USER/vyos_cf.vmdk -rawdisk /dev/sdX&lt;/code&gt; (note that the filename must be an absolute&amp;nbsp;path).&lt;/li&gt;
&lt;li&gt;Download the VyOS i586 &lt;span class="caps"&gt;ISO&lt;/span&gt; from &lt;a href="https://vyos.io/"&gt;vyos.net&lt;/a&gt;. Optionally verify the &lt;span class="caps"&gt;GPG&lt;/span&gt;&amp;nbsp;signature.&lt;/li&gt;
&lt;li&gt;Manually create a new VirtualBox&amp;nbsp;&lt;span class="caps"&gt;VM&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Select &amp;#8220;Linux&amp;#8221; and then &amp;#8220;Other Linux (32-bit)&amp;#8221; for the &lt;span class="caps"&gt;OS&lt;/span&gt;&amp;nbsp;type.&lt;/li&gt;
&lt;li&gt;Select the appropriate amount of &lt;span class="caps"&gt;RAM&lt;/span&gt; for your board (older Alix are 128 &lt;span class="caps"&gt;MB&lt;/span&gt; or 256&amp;nbsp;&lt;span class="caps"&gt;MB&lt;/span&gt;).&lt;/li&gt;
&lt;li&gt;Select &amp;#8220;Use an existing virtual hard disk file&amp;#8221; and select the raw &lt;span class="caps"&gt;VMDK&lt;/span&gt; you created in Step 2. Uncheck &amp;#8220;use host I/O&amp;nbsp;cache&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Create the&amp;nbsp;&lt;span class="caps"&gt;VM&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Edit the &lt;span class="caps"&gt;VM&lt;/span&gt; settings to remove the floppy disk device, mount the &lt;span class="caps"&gt;ISO&lt;/span&gt; in the optical drive, disable audio, and disable all network&amp;nbsp;adapters.&lt;/li&gt;
&lt;li&gt;Boot the &lt;span class="caps"&gt;VM&lt;/span&gt;. Wait for the VyOS &lt;span class="caps"&gt;ISO&lt;/span&gt; to boot and log in using the information provided in the&amp;nbsp;banner.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;install image&lt;/code&gt; and answer yes to the&amp;nbsp;prompt.&lt;/li&gt;
&lt;li&gt;Select Auto partitioning and select the &lt;span class="caps"&gt;CF&lt;/span&gt; card (it should be &lt;code&gt;sda&lt;/code&gt;, the only&amp;nbsp;option).&lt;/li&gt;
&lt;li&gt;Fill the whole device with the root&amp;nbsp;partition.&lt;/li&gt;
&lt;li&gt;Use the default name for the image and copy &lt;code&gt;/config/config.boot&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Set a password for the vyos Administrator&amp;nbsp;account.&lt;/li&gt;
&lt;li&gt;Setup grub on the one disk (&lt;code&gt;sda&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;You should now be returned to the&amp;nbsp;prompt.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reboot&lt;/code&gt; and shut down the &lt;span class="caps"&gt;VM&lt;/span&gt; once it gets back to the &lt;span class="caps"&gt;BIOS&lt;/span&gt; or bootloader; installation is&amp;nbsp;complete.&lt;/li&gt;
&lt;li&gt;Delete the &lt;span class="caps"&gt;VM&lt;/span&gt; (don&amp;#8217;t delete files) and then remove the raw &lt;span class="caps"&gt;VMDK&lt;/span&gt; you created in Step&amp;nbsp;2.&lt;/li&gt;
&lt;li&gt;Mount the &lt;span class="caps"&gt;CF&lt;/span&gt; card partition on your host &lt;span class="caps"&gt;OS&lt;/span&gt; (it&amp;#8217;s an ext4 partition). For the purposes of this example, we&amp;#8217;ll assume we&amp;#8217;re mounting it at &lt;code&gt;/mnt/tmp&lt;/code&gt;: &lt;code&gt;mount /dev/sdX1 /mnt/tmp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cd to the root of the partition: &lt;code&gt;cd /mnt/tmp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Find and &lt;code&gt;cd&lt;/code&gt; to the &lt;code&gt;live-rw&lt;/code&gt; directory for your image; for VyOS 1.1.7 installed with the default image name of &amp;#8220;1.1.7&amp;#8221;, this is &lt;code&gt;boot/1.1.7/live-rw&lt;/code&gt; on the&amp;nbsp;partition.&lt;/li&gt;
&lt;li&gt;If you are migrating a configuration file (above section), copy your configuration file to &lt;code&gt;opt/vyatta/etc/config/config.new&lt;/code&gt; and chmod it&amp;nbsp;0755.&lt;/li&gt;
&lt;li&gt;Unmount the &lt;span class="caps"&gt;CF&lt;/span&gt; card and remove it from your&amp;nbsp;system.&lt;/li&gt;
&lt;li&gt;Find a &lt;span class="caps"&gt;DB9&lt;/span&gt; null modem cable and a &lt;span class="caps"&gt;USB&lt;/span&gt; to serial adapter. Plug the cable into the Alix board&amp;#8217;s serial port, and into your adapter, and plug it into the&amp;nbsp;system.&lt;/li&gt;
&lt;li&gt;Fire up your favorite terminal emulator (I use minicom) and connect at 9600&amp;nbsp;8N1.&lt;/li&gt;
&lt;li&gt;If you have the board running already (already being used for something), connect and make sure you get a prompt. It helps to know that the serial&amp;nbsp;works.&lt;/li&gt;
&lt;li&gt;If the board is running, power it down and unplug all connections before proceeding to the next&amp;nbsp;step.&lt;/li&gt;
&lt;li&gt;Open up the Alix enclosure, and swap in your new &lt;span class="caps"&gt;CF&lt;/span&gt;&amp;nbsp;card.&lt;/li&gt;
&lt;li&gt;Close the board, plug in serial and network&amp;nbsp;cables.&lt;/li&gt;
&lt;li&gt;Plug in the power cable, and watch your terminal emulator. If all went well, you&amp;#8217;ll get the board&amp;#8217;s &lt;span class="caps"&gt;BIOS&lt;/span&gt; and then the bootloader and kernel output. Eventually you should be dropped to a login&amp;nbsp;prompt.&lt;/li&gt;
&lt;li&gt;Log in as the vyos&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;configure&lt;/code&gt; to enter configuration mode. Then:&lt;ul&gt;
&lt;li&gt;If you are migrating a configuration as discussed above, &lt;code&gt;load /opt/vyatta/etc/config/config.new&lt;/code&gt;. It will take a while to load. Make any necessary changes, then run &lt;code&gt;commit&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you are starting from scratch, follow the &lt;a href="https://wiki.vyos.net/wiki/User_Guide"&gt;User Guide&lt;/a&gt; to setup the&amp;nbsp;system.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Once the commit is done (it will take a while), &lt;code&gt;save&lt;/code&gt;. The router should now be up and running with the desired&amp;nbsp;configuration.&lt;/li&gt;
&lt;li&gt;Reboot the router to ensure it comes up&amp;nbsp;correctly.&lt;/li&gt;
&lt;li&gt;Backup the running configuration somewhere&amp;nbsp;safe.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you&amp;#8217;re running the &lt;span class="caps"&gt;PC&lt;/span&gt; Engines Alix.2, update the serial settings on the board as described on &lt;a href="http://blog.jasonantman.com/2011/09/vyatta-networkos-routerfirewall-on-alix-board-compact-flash/"&gt;my blog&lt;/a&gt; or &lt;a href="http://elderguerra.blogspot.com/2014/04/vyos-routerfirewall-on-alix-board.html"&gt;this post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I hope this can be of use to&amp;nbsp;others.&lt;/p&gt;</content><category term="vyos"></category><category term="vyatta"></category><category term="alix"></category><category term="virtualbox"></category><category term="network"></category><category term="router"></category><category term="firewall"></category><category term="linux"></category><category term="sbc"></category></entry><entry><title>Search for a small-scale but automated RPM build system</title><link href="https://blog.jasonantman.com/2013/05/search-for-a-small-scale-but-automated-rpm-build-system/" rel="alternate"></link><published>2013-05-13T05:00:00-04:00</published><updated>2013-05-13T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-13:/2013/05/search-for-a-small-scale-but-automated-rpm-build-system/</id><summary type="html">&lt;p&gt;&lt;strong&gt;This post is part of a series of older draft posts from a few months
ago that I&amp;#8217;m just getting around to publishing. Unfortunately, I have
yet to find a build system that meets my requirements (see the last&amp;nbsp;paragraph).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At work, we have a handful - currently a really …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;This post is part of a series of older draft posts from a few months
ago that I&amp;#8217;m just getting around to publishing. Unfortunately, I have
yet to find a build system that meets my requirements (see the last&amp;nbsp;paragraph).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At work, we have a handful - currently a really small number - of &lt;span class="caps"&gt;RPM&lt;/span&gt;
packages that we need to build and deploy internally for our CentOS
server infrastructure. A number of them are just pulled down from
specific third-party repositories and rebuilt to have the vendor set as
us, and some are internally patched or developed software. We run
websites, and on the product side, we&amp;#8217;re a
Python/&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; shop (in fact, probably
one of the largest Django apps out there). We don&amp;#8217;t deploy our Django
apps via &lt;span class="caps"&gt;RPM&lt;/span&gt;, so building and distributing RPMs is definitely not one of
our core competencies. In fact, we really only want to do it when we&amp;#8217;re
testing/deploying a new distro, or when an upstream package is&amp;nbsp;updated.&lt;/p&gt;
&lt;p&gt;Last week I pulled a ticket to deploy &lt;a href="http://nodejs.org/"&gt;node.js&lt;/a&gt; to
one of our build hosts, and we&amp;#8217;ve got a few things in the pipeline that
also rely on it. I found the
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module on Github that&amp;#8217;s supposed to install it on &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS, but it
pulls packages from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;,
and the newest version of nodejs there is 0.6.18, which is quite old. I
can&amp;#8217;t find any actively maintained sources of newer nodejs packages for
&lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS (yeah, I know, that&amp;#8217;s one down side to the
distributions&amp;#8230;). However, I did find that nodejs 0.9.5 is being &lt;a href="http://koji.fedoraproject.org/koji/packageinfo?packageID=15154"&gt;built
for Fedora 18/19 in the Fedora build
system&lt;/a&gt;,
is already in the Fedora 18 Testing and Fedora Rawhide repos, but is
failing its &lt;span class="caps"&gt;EL6&lt;/span&gt; builds in their system. The decision I&amp;#8217;ve come to is to
use the puppetlabs-nodejs module to install it, but try and rebuild the
Fedora 18 RPMs under CentOS 5 and&amp;nbsp;6.&lt;/p&gt;
&lt;p&gt;So that&amp;#8217;s the background. Now, my current task: to search for an &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system for my current job. My core requirements, in no specific
order,&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be relatively easy and quick to use for people who have a specfile
    or &lt;span class="caps"&gt;SRPM&lt;/span&gt; and want to be able to &amp;#8220;ensure =&gt; present&amp;#8221; the finished &lt;span class="caps"&gt;RPM&lt;/span&gt;
    on a system. i.e., require as little per-package configuration as&amp;nbsp;possible.&lt;/li&gt;
&lt;li&gt;Be able to handle rebuilding &amp;#8220;all&amp;#8221; of our RPMs when we roll out a
    new distro version. Doesn&amp;#8217;t necessarily need to be automatic, but
    should be relatively&amp;nbsp;simple.&lt;/li&gt;
&lt;li&gt;Ideally, not need to be running constantly - i.e. something that
    will cope well with build hosts being VMs that are shut down when
    they&amp;#8217;re not&amp;nbsp;needed.&lt;/li&gt;
&lt;li&gt;Handle automatically putting successfully built packages into a
    repository, ideally with some sort of (manual) promotion process
    from staging to&amp;nbsp;stable.&lt;/li&gt;
&lt;li&gt;Have minimal external (infrastructure) dependencies that we can&amp;#8217;t
    satisfy with existing&amp;nbsp;systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the first step was to research existing &lt;span class="caps"&gt;RPM&lt;/span&gt; build systems and how
others do this. Here&amp;#8217;s a list of what I could find online, though most
of these are from distributions and software vendors/projects, not
end-user companies that are only building for internal&amp;nbsp;use.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://fedorahosted.org/koji/wiki"&gt;Koji&lt;/a&gt; is the build system used
    by &lt;a href="http://fedoraproject.org/wiki/Koji"&gt;Fedora&lt;/a&gt; and RedHat. It&amp;#8217;s
    about as full-featured as any can be, and I&amp;#8217;m familiar with it from
    my time at &lt;a href="http://koji.rutgers.edu/koji/"&gt;Rutgers University&lt;/a&gt;, as
    it&amp;#8217;s used to maintain their CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; packages. It&amp;#8217;s based largely
    on Mock. However, &lt;a href="http://fedoraproject.org/wiki/Koji/ServerHowTo"&gt;setting up the build
    server&lt;/a&gt; is no
    trivial task; there are few installations outside of Fedora/RedHat,
    and it relies on either Kerberos or an &lt;span class="caps"&gt;SSL&lt;/span&gt; &lt;span class="caps"&gt;CA&lt;/span&gt; infrastructure to
    authenticate machines and clients. So, it&amp;#8217;s designed for too large a
    scale and too much infrastructure for&amp;nbsp;me.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux has a &lt;a href="https://www.pld-linux.org/developingpld/builderscript"&gt;builder
    script&lt;/a&gt; that
    seems to automate &lt;code&gt;rpmbuild&lt;/code&gt; as well as fetching sources and
    resolving/building dependencies. I haven&amp;#8217;t looked at the script yet,
    but apparently it&amp;#8217;s in &lt;span class="caps"&gt;PLD&lt;/span&gt;&amp;#8217;s &amp;#8220;rpm-build-tools&amp;#8221;&amp;nbsp;package.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux also has a &lt;span class="caps"&gt;CVS&lt;/span&gt; repository for something called
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new"&gt;pld-builder.new&lt;/a&gt;.
    The
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/README?rev=1.5"&gt;&lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt;
    and
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/ARCHITECTURE?rev=1.6"&gt;&lt;span class="caps"&gt;ARCHITECTURE&lt;/span&gt;&lt;/a&gt;
    files make it sound like a relatively simple mainly-Python system
    that builds &lt;span class="caps"&gt;SRPMS&lt;/span&gt; and binary packages when requested, and most
    importantly, seems like a simple system that uses little more than
    shared filesystem access for communication and&amp;nbsp;coordination.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;ALT&lt;/span&gt; Linux has &lt;a href="http://en.altlinux.org/Sisyphus"&gt;Sisyphus&lt;/a&gt;, which
    combines repository management and web interface tools, package
    building and testing tools, and&amp;nbsp;more.&lt;/li&gt;
&lt;li&gt;The Dries &lt;span class="caps"&gt;RPM&lt;/span&gt; repository uses (or at least used&amp;#8230; my reference is
    quite old) &lt;a href="http://dries.ulyssis.org/rpm/pydar2/index.html"&gt;pydar2&lt;/a&gt;,
    &amp;#8220;a distributed client/server program which allows you to build
    multiple spec files on multiple distribution/architecture
    combinations automatically.&amp;#8221; That sounds like it could be what I
    need, but the last update says that it isn&amp;#8217;t finished yet, and that
    was in &lt;strong&gt;2005&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Mandriva Linux has pretty extensive information on their build
    system &lt;a href="http://wiki.mandriva.com/en/Category:Build_System"&gt;on their
    wiki&lt;/a&gt; and a
    &lt;a href="http://wiki.mandriva.com/en/Development/Packaging/BuildSystem/Theory"&gt;build system theory
    page&lt;/a&gt;,
    but it seems to be largely a hodgepodge of shell scripts and
    cronjobs, and is likely not a candidate for use by anyone other than
    its&amp;nbsp;designers.&lt;/li&gt;
&lt;li&gt;Argeo provides the &lt;a href="https://www.argeo.org/wiki/SLC"&gt;&lt;span class="caps"&gt;SLC&lt;/span&gt; framework&lt;/a&gt;
    which has a &amp;#8220;&lt;span class="caps"&gt;RPM&lt;/span&gt; Factory&amp;#8221; component, but I can&amp;#8217;t seem to find much
    more than a wiki page, and can&amp;#8217;t tell if it&amp;#8217;s a build automation
    system or just handles mocking packages and putting them in a repo
    on a single&amp;nbsp;host.&lt;/li&gt;
&lt;li&gt;Dag Wieers&amp;#8217; repositories use (or used) a set of python scripts
    called &lt;a href="http://dag.wieers.com/home-made/dar/"&gt;&lt;span class="caps"&gt;DAR&lt;/span&gt;, &amp;#8220;Dynamic Apt Repository
    builder&amp;#8221;&lt;/a&gt;. They&amp;#8217;re on
    &lt;a href="https://github.com/dagwieers/dar"&gt;github&lt;/a&gt; but are listed as &amp;#8220;old&amp;#8221;
    and haven&amp;#8217;t been updated in at least 2 years. The features sound
    quite interesting, and though it&amp;#8217;s based on the Apt repo format, it
    might provide some good ideas for implementing a similar&amp;nbsp;system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Update four months later:&lt;/strong&gt; I&amp;#8217;ve yet to find a build system that meets
my requirements above. For the moment I&amp;#8217;m only managing \~20 packages,
so my &amp;#8220;build system&amp;#8221; is a single shell script that reads in some
environment variables and runs through using
&lt;a href="http://fedoraproject.org/wiki/Projects/Mock"&gt;mock&lt;/a&gt; to build them in the
correct order (including pushing the finished RPMs back into the local
repository that mock reads from) and then pushing the finished packages
to our internal repository. Maybe when I have some spare time, I&amp;#8217;ll
consider a project to either make a slightly better (but simple) &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system based on Python, or get our
&lt;a href="http://jenkins-ci.org/"&gt;Jenkins&lt;/a&gt; install to handle this for&amp;nbsp;me.&lt;/p&gt;</content><category term="build"></category><category term="linux"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="repository"></category><category term="rpm"></category><category term="rpmbuild"></category><category term="software"></category><category term="sysadmin"></category><category term="yum"></category></entry><entry><title>CentOS/Fedora Install on SuperMicro Servers via IPMI Card KVM Over IP</title><link href="https://blog.jasonantman.com/2012/04/centosfedora-install-on-supermicro-servers-via-ipmi-card-kvm-over-ip/" rel="alternate"></link><published>2012-04-13T15:19:00-04:00</published><updated>2012-04-13T15:19:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-13:/2012/04/centosfedora-install-on-supermicro-servers-via-ipmi-card-kvm-over-ip/</id><summary type="html">&lt;p&gt;I recently had to setup Fedora 16 to test something on a &lt;a href="http://www.supermicro.com/products/system/1U/6015/SYS-6015T-T.cfm"&gt;SuperMicro
6015T-&lt;span class="caps"&gt;TV&lt;/span&gt;&lt;/a&gt;
1U &amp;#8220;dual&amp;#8221; server. This is a 1U enclosure with two separate servers in it
- based on the &lt;a href="http://www.supermicro.com/products/motherboard/Xeon1333/5000P/X7DBT.cfm"&gt;SuperMicro
&lt;span class="caps"&gt;X7DBT&lt;/span&gt;&lt;/a&gt;
motherboards - each with an
&lt;a href="http://www.supermicro.com/products/accessories/addon/SIM.cfm"&gt;&lt;span class="caps"&gt;AOC&lt;/span&gt;-&lt;span class="caps"&gt;SIMSO&lt;/span&gt;+&lt;/a&gt;
&lt;span class="caps"&gt;IPMI&lt;/span&gt; and &lt;span class="caps"&gt;KVM&lt;/span&gt;-over-&lt;span class="caps"&gt;IP&lt;/span&gt; management card. Every time I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently had to setup Fedora 16 to test something on a &lt;a href="http://www.supermicro.com/products/system/1U/6015/SYS-6015T-T.cfm"&gt;SuperMicro
6015T-&lt;span class="caps"&gt;TV&lt;/span&gt;&lt;/a&gt;
1U &amp;#8220;dual&amp;#8221; server. This is a 1U enclosure with two separate servers in it
- based on the &lt;a href="http://www.supermicro.com/products/motherboard/Xeon1333/5000P/X7DBT.cfm"&gt;SuperMicro
&lt;span class="caps"&gt;X7DBT&lt;/span&gt;&lt;/a&gt;
motherboards - each with an
&lt;a href="http://www.supermicro.com/products/accessories/addon/SIM.cfm"&gt;&lt;span class="caps"&gt;AOC&lt;/span&gt;-&lt;span class="caps"&gt;SIMSO&lt;/span&gt;+&lt;/a&gt;
&lt;span class="caps"&gt;IPMI&lt;/span&gt; and &lt;span class="caps"&gt;KVM&lt;/span&gt;-over-&lt;span class="caps"&gt;IP&lt;/span&gt; management card. Every time I tried different
options for the kernel parameters (I was using Cobbler), I could get the
&lt;span class="caps"&gt;OS&lt;/span&gt; to boot, but once Anaconda started, I&amp;#8217;d lose image (&amp;#8220;No Signal&amp;#8221;) on
the &lt;span class="caps"&gt;IP&lt;/span&gt; &lt;span class="caps"&gt;KVM&lt;/span&gt;, and the serial console would go quiet. It took me about a
dozen tries before I found a mailing list reference to the &amp;#8220;nomodeset&amp;#8221;
option. This did the trick perfectly, and kept Anaconda&amp;nbsp;working.&lt;/p&gt;</content><category term="anaconda"></category><category term="centos"></category><category term="fedora"></category><category term="ipmi"></category><category term="kvm"></category><category term="linux"></category><category term="raritan"></category><category term="supermicro"></category></entry><entry><title>Linux Memory Usage and Disk Caching</title><link href="https://blog.jasonantman.com/2011/08/linux-memory-usage-and-disk-caching/" rel="alternate"></link><published>2011-08-23T08:17:00-04:00</published><updated>2011-08-23T08:17:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-08-23:/2011/08/linux-memory-usage-and-disk-caching/</id><summary type="html">&lt;p&gt;I recently added some &lt;a href="http://www.cacti.net"&gt;Cacti&lt;/a&gt;-based graphing to a
number of Linux-based servers prior to rolling out a new service. When I
was looking over the performance graphs of the initial testing, I
noticed that memory usage on our &lt;a href="http://www.rsyslog.com"&gt;rsyslog&lt;/a&gt;
server was near 98%. Looking at &lt;code&gt;top(1)&lt;/code&gt;, I saw …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently added some &lt;a href="http://www.cacti.net"&gt;Cacti&lt;/a&gt;-based graphing to a
number of Linux-based servers prior to rolling out a new service. When I
was looking over the performance graphs of the initial testing, I
noticed that memory usage on our &lt;a href="http://www.rsyslog.com"&gt;rsyslog&lt;/a&gt;
server was near 98%. Looking at &lt;code&gt;top(1)&lt;/code&gt;, I saw numbers that agreed,
though processor usage was around 99% idle, and no process appeared to
be using more than 1% of memory. It took me a minute or two to open my
eyes and see past the panic of memory usage, and finally look at the
complete output from &lt;code&gt;free(1)&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;             total       used       free     shared    buffers     cached
Mem:       8171508    8032632     138876          0     162084    7253716
-/+ buffers/cache:     616832    7554676
Swap:      4192956        152    4192804
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The pertinent part is the last column: &amp;#8220;cached&amp;#8221;. It slipped my mind that
while rsyslog is writing vast amounts of data to disk, which may or may
not ever be read back, the kernel is using free memory to cache as much
of that as it reliably can. Hence the difference between what the kernel
and userland tools call &amp;#8220;free&amp;#8221;, and what most human beings (or at least
sysadmins) would consider &amp;#8220;free&amp;#8221; - or, more correctly, &amp;#8220;available for&amp;nbsp;use&amp;#8221;.&lt;/p&gt;
&lt;p&gt;When I get a chance, maybe I&amp;#8217;ll submit patches to the Cacti Memory Usage
Percent (&lt;span class="caps"&gt;SNMP&lt;/span&gt;) template to either graph cache separately, or remove it
from the&amp;nbsp;total.&lt;/p&gt;
&lt;p&gt;Interestingly, I also found a somewhat cute page entitled &amp;#8220;Help! Linux
ate my &lt;span class="caps"&gt;RAM&lt;/span&gt;!&amp;#8221; at
&lt;a href="http://www.linuxatemyram.com/"&gt;http://www.linuxatemyram.com/&lt;/a&gt;.&lt;/p&gt;</content><category term="linux"></category><category term="memory"></category><category term="rsyslog"></category><category term="syslog"></category></entry><entry><title>Article on theInquirer.net</title><link href="https://blog.jasonantman.com/2011/07/article-on-theinquirer-net/" rel="alternate"></link><published>2011-07-11T15:55:00-04:00</published><updated>2011-07-11T15:55:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-07-11:/2011/07/article-on-theinquirer-net/</id><summary type="html">&lt;p&gt;I guess it&amp;#8217;s pretty strange that I just found out about it now, three
years later, but there&amp;#8217;s an &lt;a href="http://www.theinquirer.net/inquirer/news/1026958/citibank-infuriating-customers-linux-hostile-site"&gt;article on
TheInquirer.net&lt;/a&gt;
about Citibank&amp;#8217;s website not allowing Linux, that heavily quotes &lt;a href="/2008/08/linux-choice-updates-citibank-issues/"&gt;a blog
post of mine&lt;/a&gt; about the
issue.&amp;nbsp;Cool.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I guess it&amp;#8217;s pretty strange that I just found out about it now, three
years later, but there&amp;#8217;s an &lt;a href="http://www.theinquirer.net/inquirer/news/1026958/citibank-infuriating-customers-linux-hostile-site"&gt;article on
TheInquirer.net&lt;/a&gt;
about Citibank&amp;#8217;s website not allowing Linux, that heavily quotes &lt;a href="/2008/08/linux-choice-updates-citibank-issues/"&gt;a blog
post of mine&lt;/a&gt; about the
issue.&amp;nbsp;Cool.&lt;/p&gt;</content><category term="citibank"></category><category term="linux"></category><category term="me"></category></entry><entry><title>Netgear ReadyNAS 1100 Bug causes NFS Failure after reboot - workaround</title><link href="https://blog.jasonantman.com/2011/06/netgear-readynas-1100-bug-causes-nfs-failure-after-reboot-workaround/" rel="alternate"></link><published>2011-06-28T08:40:00-04:00</published><updated>2011-06-28T08:40:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-06-28:/2011/06/netgear-readynas-1100-bug-causes-nfs-failure-after-reboot-workaround/</id><summary type="html">&lt;p&gt;At work, we have a &lt;a href="http://www.readynas.com/?cat=23"&gt;Netgear ReadyNAS
1100&lt;/a&gt;. It&amp;#8217;s a &lt;span class="caps"&gt;4TB&lt;/span&gt; &lt;span class="caps"&gt;NAS&lt;/span&gt; appliance, a cute
little 1U half-depth Linux box with 4 &lt;span class="caps"&gt;SATA&lt;/span&gt; disks, a &lt;span class="caps"&gt;RAID&lt;/span&gt; controller, and
some firmware to do a whole bunch of fancy stuff (mainly geared towards
consumers and very small shops - all configuration is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;At work, we have a &lt;a href="http://www.readynas.com/?cat=23"&gt;Netgear ReadyNAS
1100&lt;/a&gt;. It&amp;#8217;s a &lt;span class="caps"&gt;4TB&lt;/span&gt; &lt;span class="caps"&gt;NAS&lt;/span&gt; appliance, a cute
little 1U half-depth Linux box with 4 &lt;span class="caps"&gt;SATA&lt;/span&gt; disks, a &lt;span class="caps"&gt;RAID&lt;/span&gt; controller, and
some firmware to do a whole bunch of fancy stuff (mainly geared towards
consumers and very small shops - all configuration is point-and-click
web &lt;span class="caps"&gt;UI&lt;/span&gt;). We&amp;#8217;ve been using it for storing archived log data and
low-priority backups. At the beginning of this problem, it was running
RAIDiator 4.1.6 firmware since December of last year (over 6 months),
and hadn&amp;#8217;t had any configuration changes in at least 4&amp;nbsp;months.&lt;/p&gt;
&lt;p&gt;Last week, I had to power off the unit and remove the power cables for
some rack maintenance. I went through the usual full shutdown procedure
in the web &lt;span class="caps"&gt;UI&lt;/span&gt;, and also told it to `fsck` the volumes, as that hadn&amp;#8217;t
been done in quite some time. Unfortunately, when the unit came back up,
even after I could log into the web &lt;span class="caps"&gt;UI&lt;/span&gt;, I couldn&amp;#8217;t mount the &lt;span class="caps"&gt;NFS&lt;/span&gt; shares
on my backup server. I kept getting messages&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;[root@backup-server ~]#&lt;/span&gt; mount -a
&lt;span class="go"&gt;mount: mount to &lt;span class="caps"&gt;NFS&lt;/span&gt; server &amp;#39;css-readynas&amp;#39; failed: &lt;span class="caps"&gt;RPC&lt;/span&gt; Error: Program not registered.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;so my next step was to check &lt;span class="caps"&gt;RPC&lt;/span&gt; status of the readynas, from the
client. That was also a bit of a&amp;nbsp;surprise:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;[root@backup-server ~]#&lt;/span&gt; rpcinfo -p css-readynas                        
&lt;span class="go"&gt;   program vers proto   port                                              &lt;/span&gt;
&lt;span class="go"&gt;    100000    2   tcp    111  portmapper                                  &lt;/span&gt;
&lt;span class="go"&gt;    100000    2   udp    111  portmapper                                  &lt;/span&gt;
&lt;span class="go"&gt;    100011    1   udp    620  rquotad                                     &lt;/span&gt;
&lt;span class="go"&gt;    100011    2   udp    620  rquotad                                     &lt;/span&gt;
&lt;span class="go"&gt;    100011    1   tcp    623  rquotad                                     &lt;/span&gt;
&lt;span class="go"&gt;    100011    2   tcp    623  rquotad                                     &lt;/span&gt;
&lt;span class="go"&gt;    100024    1   udp  32765  status                                      &lt;/span&gt;
&lt;span class="go"&gt;    100024    1   tcp  32765  status                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    1   udp   2051  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    1   tcp   3006  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    2   udp   2051  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    2   tcp   3006  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    3   udp   2051  mountd                                      &lt;/span&gt;
&lt;span class="go"&gt;    100005    3   tcp   3006  mountd &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Somewhere in that list is supposed to be nfsd, listening on port 2049.
Next, I did an nmap (port scan) of the&amp;nbsp;readynas:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;[root@backup-server ~]#&lt;/span&gt; nmap -sU -p2047-2050 css-readynas             

&lt;span class="go"&gt;Starting Nmap 4.11 ( http://www.insecure.org/nmap/ ) at 2011-06-23 15:21 &lt;span class="caps"&gt;EDT&lt;/span&gt;&lt;/span&gt;
&lt;span class="go"&gt;Interesting ports on css-readynas.rutgers.edu (172.16.25.108):              &lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;PORT&lt;/span&gt;     &lt;span class="caps"&gt;STATE&lt;/span&gt;         &lt;span class="caps"&gt;SERVICE&lt;/span&gt;                                              &lt;/span&gt;
&lt;span class="go"&gt;2047/udp closed        dls                                                  &lt;/span&gt;
&lt;span class="go"&gt;2048/udp closed        dls-monitor                                          &lt;/span&gt;
&lt;span class="go"&gt;2049/udp open|filtered nfs                                                  &lt;/span&gt;
&lt;span class="go"&gt;2050/udp closed        unknown  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Interesting. The port scan shows that &lt;em&gt;something&lt;/em&gt; is listening on port
2049. But rpcinfo doesn&amp;#8217;t seem to recognize it as a &lt;span class="caps"&gt;NFS&lt;/span&gt;&amp;nbsp;server.&lt;/p&gt;
&lt;p&gt;At this point, through FrontView (the web &lt;span class="caps"&gt;UI&lt;/span&gt;) I backed up the
configuration and went through a few reboot cycles, with no change. I
then started tweaking everything I could that I thought would restart
the &lt;span class="caps"&gt;NFS&lt;/span&gt; server - I added and removed allowed hosts for the &lt;span class="caps"&gt;NFS&lt;/span&gt; share,
enabled and disabled sync mode, etc. I started searching the &lt;a href="http://www.readynas.com/forum/"&gt;ReadyNAS
Forum&lt;/a&gt; and found a post that reported a
very similar problem - &lt;a href="http://www.readynas.com/forum/viewtopic.php?f=20&amp;amp;t=23139"&gt;upnpd grabbing nfsd
port&lt;/a&gt;. The
user reported that he was getting the same &amp;#8220;&lt;span class="caps"&gt;RPC&lt;/span&gt; Error: Program not
registered&amp;#8221; message, and in &lt;code&gt;daemon.log&lt;/code&gt; on the ReadyNAS, found a line
including &amp;#8220;storage nfsd[1087]: nfssvc: Address already in use&amp;#8221;. I
remembered that I&amp;#8217;d setup the ReadyNAS to forward all logs to our
central syslog server and, sure enough, found an identical message that
something had already bound to &lt;span class="caps"&gt;UDP&lt;/span&gt; port 2049 when &lt;span class="caps"&gt;NFS&lt;/span&gt; was starting. I
tried confirming that upnpd was disabled and rebooting, but that didn&amp;#8217;t
help. Grepping my logs for &amp;#8220;nfs&amp;#8221;&amp;nbsp;returned:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;daemon.log:Jun 23 12:43:43 css-readynas nfsd[2331]: nfssvc: Address already in use
daemon.log:Jun 23 15:26:33 css-readynas nfsd[2724]: nfssvc: Address already in use
kern.log:Jun 23 11:35:29 css-readynas kernel: Installing knfsd (copyright (C) 1996 okir@monad.swb.de).
kern.log:Jun 23 12:43:43 css-readynas kernel: &lt;span class="caps"&gt;NFSD&lt;/span&gt;: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory
kern.log:Jun 23 12:43:43 css-readynas kernel: &lt;span class="caps"&gt;NFSD&lt;/span&gt;: starting 90-second grace period
kern.log:Jun 23 14:56:20 css-readynas kernel: Installing knfsd (copyright (C) 1996 okir@monad.swb.de).
kern.log:Jun 23 15:12:41 css-readynas kernel: &lt;span class="caps"&gt;NFSD&lt;/span&gt;: starting 90-second grace period
kern.log:Jun 23 15:26:33 css-readynas kernel: &lt;span class="caps"&gt;NFSD&lt;/span&gt;: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory
kern.log:Jun 23 15:26:33 css-readynas kernel: &lt;span class="caps"&gt;NFSD&lt;/span&gt;: starting 90-second grace period
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;My next step was a few more reboots, with no change. I then upgraded the
RAIDiator firmware to the latest, 4.1.7. Still no luck. I installed the
&lt;a href="http://www.readynas.com/?p=4203"&gt;Enable root &lt;span class="caps"&gt;SSH&lt;/span&gt;&lt;/a&gt; addon, and that&amp;#8217;s
when things became very&amp;nbsp;clear:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; netstat -unlp
&lt;span class="go"&gt;Active Internet connections (only servers)&lt;/span&gt;
&lt;span class="go"&gt;Proto Recv-Q Send-Q Local Address           Foreign Address         State       &lt;span class="caps"&gt;PID&lt;/span&gt;/Program name   &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2049            0.0.0.0:*                           794/snmpd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:514             0.0.0.0:*                           673/syslogd         &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:137       0.0.0.0:*                           1672/nmbd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:137             0.0.0.0:*                           1672/nmbd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:138       0.0.0.0:*                           1672/nmbd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:138             0.0.0.0:*                           1672/nmbd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:161             0.0.0.0:*                           794/snmpd           &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:162             0.0.0.0:*                           802/snmptrapd       &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2086            0.0.0.0:*                           1565/rpc.mountd     &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 127.0.0.1:22081         0.0.0.0:*                           1599/raidard        &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:22081     0.0.0.0:*                           1599/raidard        &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:22081           0.0.0.0:*                           1599/raidard        &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:988             0.0.0.0:*                           819/rpc.rquotad     &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:5353            0.0.0.0:*                           729/avahi-daemon: r &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:111             0.0.0.0:*                           666/portmap         &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:881             0.0.0.0:*                           1553/rpc.statd      &lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:32765           0.0.0.0:*                           1553/rpc.statd     &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For some &lt;strong&gt;&lt;em&gt;very&lt;/em&gt;&lt;/strong&gt; strange reason, snmpd had bound to port 2049 (the
nfs port) instead of 161. That left no port for nfs to bind&amp;nbsp;to.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; /etc/init.d/snmpd stop                                                       
&lt;span class="go"&gt;Stopping network management services: snmpd snmptrapd readynas-agent.                               &lt;/span&gt;
&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; /etc/init.d/nfs-kernel-server start
&lt;span class="go"&gt;Exporting directories for &lt;span class="caps"&gt;NFS&lt;/span&gt; kernel daemon...done.&lt;/span&gt;
&lt;span class="go"&gt;Starting &lt;span class="caps"&gt;NFS&lt;/span&gt; kernel daemon:mount: nfsd already mounted or /proc/fs/nfsd/ busy&lt;/span&gt;
&lt;span class="go"&gt;mount: according to mtab, nfsd is mounted on /proc/fs/nfsd&lt;/span&gt;
&lt;span class="go"&gt; statd nfsd mountd.&lt;/span&gt;
&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; /etc/init.d/snmpd start
&lt;span class="go"&gt;Starting network management services: snmpd snmptrapd readynas-agent.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Stop snmpd, restart nfs-kernel-server so that it grabs port 2049 like it
should, and then start snmpd back up. If all went well, nfsd should now
be listening on &lt;span class="caps"&gt;UDP&lt;/span&gt; 2049, and snmpd should be listening on &lt;span class="caps"&gt;UDP&lt;/span&gt; 161 like
it should. To&amp;nbsp;confirm:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;css-readynas:/var/log#&lt;/span&gt; netstat -unlp
&lt;span class="go"&gt;Active Internet connections (only servers)&lt;/span&gt;
&lt;span class="go"&gt;Proto Recv-Q Send-Q Local Address           Foreign Address         State       &lt;span class="caps"&gt;PID&lt;/span&gt;/Program name&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2049            0.0.0.0:*                           -&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:514             0.0.0.0:*                           673/syslogd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:137       0.0.0.0:*                           1672/nmbd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:137             0.0.0.0:*                           1672/nmbd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:138       0.0.0.0:*                           1672/nmbd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:138             0.0.0.0:*                           1672/nmbd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:161             0.0.0.0:*                           26161/snmpd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:162             0.0.0.0:*                           26163/snmptrapd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2086            0.0.0.0:*                           1565/rpc.mountd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 127.0.0.1:22081         0.0.0.0:*                           1599/raidard&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 172.16.25.108:22081     0.0.0.0:*                           1599/raidard&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:22081           0.0.0.0:*                           1599/raidard&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:988             0.0.0.0:*                           819/rpc.rquotad&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:5353            0.0.0.0:*                           729/avahi-daemon: r&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2158            0.0.0.0:*                           -&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:111             0.0.0.0:*                           666/portmap&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:2160            0.0.0.0:*                           26161/snmpd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:881             0.0.0.0:*                           1553/rpc.statd&lt;/span&gt;
&lt;span class="go"&gt;udp        0      0 0.0.0.0:32765           0.0.0.0:*                           1553/rpc.statd&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All is well. Now to confirm this from the client&amp;nbsp;machine:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;[root@backup-server ~]#&lt;/span&gt; rpcinfo -p css-readynas
&lt;span class="go"&gt;   program vers proto   port&lt;/span&gt;
&lt;span class="go"&gt;    100000    2   tcp    111  portmapper&lt;/span&gt;
&lt;span class="go"&gt;    100000    2   udp    111  portmapper&lt;/span&gt;
&lt;span class="go"&gt;    100011    1   udp    988  rquotad&lt;/span&gt;
&lt;span class="go"&gt;    100011    2   udp    988  rquotad&lt;/span&gt;
&lt;span class="go"&gt;    100011    1   tcp    991  rquotad&lt;/span&gt;
&lt;span class="go"&gt;    100011    2   tcp    991  rquotad&lt;/span&gt;
&lt;span class="go"&gt;    100024    1   udp  32765  status&lt;/span&gt;
&lt;span class="go"&gt;    100024    1   tcp  32765  status&lt;/span&gt;
&lt;span class="go"&gt;    100005    1   udp   2086  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    1   tcp   3131  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    2   udp   2086  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    2   tcp   3131  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    3   udp   2086  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100005    3   tcp   3131  mountd&lt;/span&gt;
&lt;span class="go"&gt;    100003    2   udp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    3   udp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    4   udp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    2   tcp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    3   tcp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100003    4   tcp   2049  nfs&lt;/span&gt;
&lt;span class="go"&gt;    100021    1   udp   2158  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    3   udp   2158  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    4   udp   2158  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    1   tcp   4189  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    3   tcp   4189  nlockmgr&lt;/span&gt;
&lt;span class="go"&gt;    100021    4   tcp   4189  nlockmgr&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ok, &lt;span class="caps"&gt;NFS&lt;/span&gt; is now there. It all looks good, and re-running &lt;code&gt;mount -a&lt;/code&gt; on
the client successfully mounts the &lt;span class="caps"&gt;NFS&lt;/span&gt;&amp;nbsp;share.&lt;/p&gt;
&lt;p&gt;We&amp;#8217;ll see what happens next time I have to reboot the ReadyNAS. In the
mean time, I&amp;#8217;m going to try to bring this to the attention of Netgear
support and hope they do something about&amp;nbsp;it.&lt;/p&gt;</content><category term="appliance"></category><category term="embedded"></category><category term="linux"></category><category term="nas"></category><category term="netgear"></category><category term="nfs"></category><category term="readynas"></category></entry><entry><title>Using wireshark to capture packets from a remote host</title><link href="https://blog.jasonantman.com/2011/04/using-wireshark-to-capture-packets-from-a-remote-host/" rel="alternate"></link><published>2011-04-26T10:50:00-04:00</published><updated>2011-04-26T10:50:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-04-26:/2011/04/using-wireshark-to-capture-packets-from-a-remote-host/</id><summary type="html">&lt;p&gt;I spend a fair amount of my time debugging network and service problems
on a few racks of Linux servers. Of course, they&amp;#8217;re located in a data
center (yes, just downstairs, but still not quite as comfortable as my
office), and they&amp;#8217;re all command-line only - no sense in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I spend a fair amount of my time debugging network and service problems
on a few racks of Linux servers. Of course, they&amp;#8217;re located in a data
center (yes, just downstairs, but still not quite as comfortable as my
office), and they&amp;#8217;re all command-line only - no sense in using up &lt;span class="caps"&gt;RAM&lt;/span&gt;
and &lt;span class="caps"&gt;CPU&lt;/span&gt; to run a graphical &lt;span class="caps"&gt;UI&lt;/span&gt; on a box that should just be serving
remote clients. I used to go through the arduous task of running a
command line &lt;a href="http://www.tcpdump.org/"&gt;&lt;code&gt;tcpdump&lt;/code&gt;&lt;/a&gt; session on the server
until I thought I had enough packets, then SCPing it over to my
workstation and opening the file in
&lt;a href="http://www.wireshark.org/"&gt;wireshark&lt;/a&gt; (formerly Ethereal). Fortunately,
thanks to a
&lt;a href="http://linuxexplore.wordpress.com/2010/05/30/remote-packet-capture-using-wireshark-tcpdump/"&gt;post&lt;/a&gt;
on Rahul Panwar&amp;#8217;s &lt;a href="http://linuxexplore.wordpress.com/"&gt;Linux Explore
blog&lt;/a&gt; (which seems to be sadly
neglected), I found a much easier way to do it. I&amp;#8217;ve summarized that
post here, added a little explanation, and also made some useful
comments for people working on Red Hat/CentOS and&amp;nbsp;OpenSuSE.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What you&amp;nbsp;need:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Source system (the server you want to capture packets on) that you
    have &lt;span class="caps"&gt;SSH&lt;/span&gt; access to, with tcpdump installed, and available to your
    user (either directly, or via sudo without&amp;nbsp;password).&lt;/li&gt;
&lt;li&gt;Destination system (where you run graphical Wireshark) with
    wireshark installed and working, and &lt;code&gt;mkfifo&lt;/code&gt; available.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Procedure:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;On the destination system, if you haven&amp;#8217;t already done&amp;nbsp;so,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mkfifo /tmp/packet_capture
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This creates a &lt;a href="http://en.wikipedia.org/wiki/Named_pipe"&gt;named pipe&lt;/a&gt;
where the source packet data (via ssh) will be written and Wireshark
will read it from. You can use any name or location you want, but
&lt;code&gt;/tmp/packet_capture&lt;/code&gt; is pretty&amp;nbsp;logical.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On your destination system, open up Wireshark (we do this now, since
    on many systems it required the root password to start). In the
    &amp;#8220;Capture&amp;#8221; menu, select &amp;#8220;Options&amp;#8221;. In the &amp;#8220;Interface&amp;#8221; box, type in
    the path to the &lt;span class="caps"&gt;FIFO&lt;/span&gt; you created (&lt;code&gt;/tmp/packet_capture&lt;/code&gt;). You should
    press the Start button before running the next command - I recommend
    typing the command in a terminal window, pressing start, then
    hitting enter in the terminal to run the&amp;nbsp;command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the destination system,&amp;nbsp;run&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh user@source-hostname &lt;span class="s2"&gt;&amp;quot;sudo /usr/sbin/tcpdump -s 0 -U -n -w - -i eth0 not port 22&amp;quot;&lt;/span&gt; &amp;gt; /tmp/packet_capture
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will &lt;span class="caps"&gt;SSH&lt;/span&gt; to the source system (&lt;code&gt;source-hostname&lt;/code&gt;, either by
hostname or &lt;span class="caps"&gt;IP&lt;/span&gt;) as the specified user (&lt;code&gt;user&lt;/code&gt;) and execute
&lt;code&gt;sudo /usr/sbin/tcpdump&lt;/code&gt;. Omit the &amp;#8220;sudo&amp;#8221; if you don&amp;#8217;t need it,
though if you do, you&amp;#8217;ll need passwordless access. Options passed to
tcpdump are: &amp;#8220;-s 0&amp;#8221; snarf entire packets, no length limit; &amp;#8220;-U&amp;#8221;
packet-buffered output - write each complete packet to output once
it&amp;#8217;s captured, rather than waiting for a buffer to fill up; &amp;#8220;-n&amp;#8221;
don&amp;#8217;t convert addresses to hostnames; &amp;#8220;-w -&amp;#8221; write raw packets to
&lt;span class="caps"&gt;STDOUT&lt;/span&gt; (which will be passed through the &lt;span class="caps"&gt;SSH&lt;/span&gt; tunnel and become
&lt;span class="caps"&gt;STDOUT&lt;/span&gt; of the &amp;#8220;ssh&amp;#8221; command on the destination machine); &amp;#8220;-i eth0&amp;#8221;
capture on interface eth0; &amp;#8220;not port 22&amp;#8221; a tcpdump filter expression
to prevent capturing our own &lt;span class="caps"&gt;SSH&lt;/span&gt; packets (more on this below). The
final &amp;#8220;&gt; /tmp/packet_capture&amp;#8221; redirects the &lt;span class="caps"&gt;STDOUT&lt;/span&gt; of the ssh
program (the raw packets from tcpdump on the source machine) to the
&lt;code&gt;/tmp/packet_capture&lt;/code&gt; &lt;span class="caps"&gt;FIFO&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When you&amp;#8217;re ready to stop the capture, just Ctrl+C the &lt;span class="caps"&gt;SSH&lt;/span&gt; command
    in the terminal window. Wireshark will automatically stop capturing,
    and you can save the capture file or play around with it. To capture
    again, you&amp;#8217;ll need to restart the capture in Wireshark and then run
    the ssh command&amp;nbsp;again.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;A note on network usage and tcpdump&amp;nbsp;filters&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is a relatively bandwidth intensive procedure. If you use the &amp;#8220;not
port 22&amp;#8221; tcpdump filter (shown above) on the source machine, all traffic
over eth0 (other than &lt;span class="caps"&gt;SSH&lt;/span&gt;) on that machine will be duplicated within an
&lt;span class="caps"&gt;SSH&lt;/span&gt; tunnel. So you have double the traffic, plus the overhead of
tunneling all that within &lt;span class="caps"&gt;SSH&lt;/span&gt; to the destination machine. If you&amp;#8217;re
capturing data from a busy machine this way, you could easily saturate
the uplink and wreak all sorts of havoc. As a result, I&amp;#8217;d recommend
making the tcpdump filter as specific as you can while still retaining
the data you need. If you can replace it with a filter for specific
ports (i.e. &lt;code&gt;'(port 67 or port 68)'&lt;/code&gt; for &lt;span class="caps"&gt;DHCP&lt;/span&gt;) or specific hosts, that
should cut down on the amount of data you actually have to pass through
the&amp;nbsp;tunnel.&lt;/p&gt;</content><category term="ethereal"></category><category term="linux"></category><category term="sysadmin"></category><category term="tcpdump"></category><category term="troubleshooting"></category><category term="wireshark"></category></entry><entry><title>How to get actual login username when using sudo su</title><link href="https://blog.jasonantman.com/2011/01/how-to-get-actual-login-username-when-using-sudo-su/" rel="alternate"></link><published>2011-01-05T11:48:00-05:00</published><updated>2011-01-05T11:48:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-01-05:/2011/01/how-to-get-actual-login-username-when-using-sudo-su/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve had the need to find out the actual username of someone logged in
and working as root (via &lt;code&gt;sudo su -&lt;/code&gt;) to &lt;a href="/2011/01/client-side-subversion-commit-message-hooks/"&gt;put it into a subversion
commit message&lt;/a&gt;.
This quick little bash script does the trick, and just echos the&amp;nbsp;username.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;PID&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$$&lt;/span&gt; &lt;span class="c1"&gt;# get &lt;span class="caps"&gt;PID&lt;/span&gt; of current …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve had the need to find out the actual username of someone logged in
and working as root (via &lt;code&gt;sudo su -&lt;/code&gt;) to &lt;a href="/2011/01/client-side-subversion-commit-message-hooks/"&gt;put it into a subversion
commit message&lt;/a&gt;.
This quick little bash script does the trick, and just echos the&amp;nbsp;username.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;PID&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$$&lt;/span&gt; &lt;span class="c1"&gt;# get &lt;span class="caps"&gt;PID&lt;/span&gt; of current process&lt;/span&gt;
&lt;span class="nv"&gt;LogUID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;cat /proc/&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;PID&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;/loginuid&lt;span class="sb"&gt;`&lt;/span&gt; &lt;span class="c1"&gt;# get loginuid of current process&lt;/span&gt;
&lt;span class="nv"&gt;username&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;getent passwd &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LogUID&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; awk -F &lt;span class="s2"&gt;&amp;quot;:&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt; &lt;span class="c1"&gt;# translate loginuid to username&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$username&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="linux"></category><category term="login"></category><category term="sudo"></category><category term="username"></category></entry><entry><title>Client-side subversion commit message hooks</title><link href="https://blog.jasonantman.com/2011/01/client-side-subversion-commit-message-hooks/" rel="alternate"></link><published>2011-01-05T11:23:00-05:00</published><updated>2011-01-05T11:23:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2011-01-05:/2011/01/client-side-subversion-commit-message-hooks/</id><summary type="html">&lt;p&gt;While I know this isn&amp;#8217;t best practice, since we use &lt;span class="caps"&gt;LDAP&lt;/span&gt;-based auth for
our Linux boxes (including a sudoers file based on &lt;span class="caps"&gt;LDAP&lt;/span&gt; group
membership), we usually do work on some boxes as root (&lt;code&gt;sudo su -&lt;/code&gt;).
This includes our &lt;a href="http://www.puppetlabs.com/"&gt;puppetmaster&lt;/a&gt;, where
configs are kept in subversion and edited …&lt;/p&gt;</summary><content type="html">&lt;p&gt;While I know this isn&amp;#8217;t best practice, since we use &lt;span class="caps"&gt;LDAP&lt;/span&gt;-based auth for
our Linux boxes (including a sudoers file based on &lt;span class="caps"&gt;LDAP&lt;/span&gt; group
membership), we usually do work on some boxes as root (&lt;code&gt;sudo su -&lt;/code&gt;).
This includes our &lt;a href="http://www.puppetlabs.com/"&gt;puppetmaster&lt;/a&gt;, where
configs are kept in subversion and edited as root. The one problem with
this is how to get the username of the actual committer, not root, in
subversion&amp;nbsp;messages.&lt;/p&gt;
&lt;p&gt;The theory that I came up with is a &lt;a href="/2011/01/how-to-get-actual-login-username-when-using-sudo-su/"&gt;shell script that finds out who the
actual user
is&lt;/a&gt;, and
then tacking this onto the beginning of the subversion commit message
(since there&amp;#8217;s no real way to do client-side hooks in subversion). While
I struggled with subversion&amp;#8217;s lack of good client hooks, I came up with
a theory based on a script that preloads svn-commit.tmp and then calls
the text editor. It&amp;#8217;s actually quite&amp;nbsp;simple.&lt;/p&gt;
&lt;p&gt;First, in your .bashrc or wherever you setup environment variables,
&lt;code&gt;export SVN_EDITOR=/usr/local/bin/svnPreCommitClientHook.sh&lt;/code&gt;. This way,
every time you run &lt;code&gt;svn commit&lt;/code&gt;, instead of calling your text editor
with &lt;code&gt;svn-commit.tmp&lt;/code&gt; as an argument, the bash script will do what it
needs to (commit message preloading) with svn-commit.tmp and &lt;em&gt;then&lt;/em&gt; call
your editor to finish the&amp;nbsp;message.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/usr/local/bin/svnPreCommitClientHook.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;LOGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;/usr/local/bin/getLogname.py&lt;span class="sb"&gt;`&lt;/span&gt; &lt;span class="c1"&gt;# script to get user&amp;#39;s actual login name, even if using sudo su&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; -e &lt;span class="s2"&gt;&amp;quot;\nBY: &lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;LOGNAME&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &amp;gt; svn-commit.foo
cat svn-commit.tmp &amp;gt;&amp;gt; svn-commit.foo
mv svn-commit.foo svn-commit.tmp
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;EDITOR&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; svn-commit.tmp
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using this method, running &lt;code&gt;svn commit&lt;/code&gt; will pull up your text editor
with &amp;#8220;&lt;span class="caps"&gt;BY&lt;/span&gt;: username&amp;#8221; already inserted in the commit&amp;nbsp;message.&lt;/p&gt;</content><category term="linux"></category><category term="puppet"></category><category term="subversion"></category><category term="svn"></category></entry><entry><title>Ignoring SVN directories and save files with grep</title><link href="https://blog.jasonantman.com/2010/10/ignoring-svn-directories-and-save-files-with-grep/" rel="alternate"></link><published>2010-10-15T07:27:00-04:00</published><updated>2010-10-15T07:27:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2010-10-15:/2010/10/ignoring-svn-directories-and-save-files-with-grep/</id><summary type="html">&lt;p&gt;Yes, I know I haven&amp;#8217;t posted anything useful in a while. I&amp;#8217;ve been quite
busy at work, and hopefully I&amp;#8217;ll post some of my &lt;span class="caps"&gt;DHCP&lt;/span&gt; stuff. In the&amp;nbsp;meantime&amp;#8230;&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m starting a project for the &lt;a href="http://www.midlandparkambulance.com/"&gt;ambulance
corps&lt;/a&gt; migrating two Linux boxes
to a single new server …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Yes, I know I haven&amp;#8217;t posted anything useful in a while. I&amp;#8217;ve been quite
busy at work, and hopefully I&amp;#8217;ll post some of my &lt;span class="caps"&gt;DHCP&lt;/span&gt; stuff. In the&amp;nbsp;meantime&amp;#8230;&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m starting a project for the &lt;a href="http://www.midlandparkambulance.com/"&gt;ambulance
corps&lt;/a&gt; migrating two Linux boxes
to a single new server. One of them has been in production for about
five years, and (partially due to the &amp;#8220;we need it yesterday&amp;#8221; nature of
emergency services) has quite a bit of cruft laying around. Since almost
everything is web-based (well, browser-based, restricted to the &lt;span class="caps"&gt;LAN&lt;/span&gt;
only), there are a lot of web apps and &lt;span class="caps"&gt;PHP&lt;/span&gt; scripts that need to be
migrated. This is made even more complicated by the switch from SuSE
10.1 (yes, ancient) to CentOS 5.4, and therefore from &lt;code&gt;/srv/www/htdocs&lt;/code&gt;
to &lt;code&gt;/var/www/html&lt;/code&gt;. I could be lazy and symlink it, but I think it&amp;#8217;s
time to search down and destroy any absolute&amp;nbsp;includes.&lt;/p&gt;
&lt;p&gt;The problem with doing this is that, with any scripts in &lt;span class="caps"&gt;SVN&lt;/span&gt;, grepping
for a string could potentially return three hits for a file - the actual
file, the emacs save file (&lt;code&gt;filename~&lt;/code&gt;) and the text file in the &lt;code&gt;.svn&lt;/code&gt;
directory.&lt;/p&gt;
&lt;p&gt;The solution is actually pretty easy. To get rid of the .svn
directories, we add &lt;code&gt;--exclude=\*.svn\*&lt;/code&gt; to our grep command line (yes,
I know, it excludes everything with &amp;#8220;.svn&amp;#8221; in the path, but that&amp;#8217;s
acceptably imprecise for my purposes). To get rid of the tilde (save)
files, all we need is &lt;code&gt;--exclude=\*~&lt;/code&gt;. It&amp;#8217;s no problem to string them
together as &lt;code&gt;grep --exclude=\*~ --exclude=\*.svn\* -rin "foo bar" *&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To make this even easier, just add to your &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;GREP_OPTIONS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;--exclude=\*~ --exclude=\*.svn\*&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="grep"></category><category term="linux"></category></entry><entry><title>How to make software distribution secure</title><link href="https://blog.jasonantman.com/2010/09/how-to-make-software-distribution-secure/" rel="alternate"></link><published>2010-09-17T12:42:00-04:00</published><updated>2010-09-17T12:42:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2010-09-17:/2010/09/how-to-make-software-distribution-secure/</id><summary type="html">&lt;p&gt;We were seeing some strange behavior with Mac client machines on the
network lately, specifically with &lt;span class="caps"&gt;DNS&lt;/span&gt; queries (I&amp;#8217;d guess that a lot of
it has to do with
&lt;a href="http://en.wikipedia.org/wiki/Bonjour_(software)"&gt;Bonjour&lt;/a&gt;), but the
discussion touched on the &lt;a href="http://isc.sans.edu/diary.html?storyid=3595"&gt;&lt;span class="caps"&gt;DNS&lt;/span&gt;
Changer&lt;/a&gt;
&lt;a href="http://www.dnschanger.com/"&gt;trojan&lt;/a&gt; for Mac. I&amp;#8217;d really never heard
about it before …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We were seeing some strange behavior with Mac client machines on the
network lately, specifically with &lt;span class="caps"&gt;DNS&lt;/span&gt; queries (I&amp;#8217;d guess that a lot of
it has to do with
&lt;a href="http://en.wikipedia.org/wiki/Bonjour_(software)"&gt;Bonjour&lt;/a&gt;), but the
discussion touched on the &lt;a href="http://isc.sans.edu/diary.html?storyid=3595"&gt;&lt;span class="caps"&gt;DNS&lt;/span&gt;
Changer&lt;/a&gt;
&lt;a href="http://www.dnschanger.com/"&gt;trojan&lt;/a&gt; for Mac. I&amp;#8217;d really never heard
about it before, and after some basic reading, it really got me thinking
about the state of software packaging, updates, and distribution.
Granted, some of my observations would require sweeping changes to how
packaging is handled (even on the *nixes), and would require buy-in
from more than just the vendor and distributor (well, I guess &lt;span class="caps"&gt;MS&lt;/span&gt; can
probably pressure ISVs to do whatever they want), but seems to be the
only way to keep appliancization from becoming the solution to security
issues. I&amp;#8217;ve written about this
&lt;a href="/2009/12/book-comments-the-future-of-the-internet-and-how-to-stop-it-by-jonathan-zittrain/"&gt;before&lt;/a&gt;,
and a while ago in respect to
&lt;a href="/2008/10/my-biggest-problem-with-linux/"&gt;Linux&lt;/a&gt;, but here&amp;#8217;s my current
take on what needs to be done to software packaging to allow our
machines to stay secure, no matter what &lt;span class="caps"&gt;OS&lt;/span&gt; they&amp;nbsp;run.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Allow packages to be installed as a user.&lt;/strong&gt; This is a mammoth task
    under Windows or Mac, but still an issue under Linux. The &lt;span class="caps"&gt;DNS&lt;/span&gt;
    Changer trojan is a case in point - there&amp;#8217;s no reason a &amp;#8220;video
    codec&amp;#8221; would need to be installed system-wide, and if that were
    simply installed user-specific, the malicious installer would never
    have the privileges to change system-wide &lt;span class="caps"&gt;DNS&lt;/span&gt; settings. This is also
    a big issue under Linux. Yum, apt, rpm, etc. should (if run as a
    non-root user) install packages in a user-local path under &lt;code&gt;/home&lt;/code&gt;
    by default. Of course, this would mean many things would need to
    change in order to cope - perhaps even a change to the
    &lt;a href="http://www.linuxfoundation.org/collaborate/workgroups/lsb"&gt;&lt;span class="caps"&gt;LSB&lt;/span&gt;&lt;/a&gt;&amp;nbsp;spec.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Warn about inconsistencies on package installation.&lt;/strong&gt; The package
    installation program should warn a user (whether installing packages
    system-wide or local to a user) if the package is going to modify
    system-wide files, i.e. files not specifically placed by that
    package and that package&amp;nbsp;only.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Real package management for Windows and Mac&lt;/strong&gt; It&amp;#8217;s about time that
    Apple and Microsoft admit that people without billions in funding
    can come up with good ideas. Get rid of these Installer programs
    (the many many different ones). Each &lt;span class="caps"&gt;OS&lt;/span&gt; should pick a package
    format, develop a yum-like (or, even better, zypper-like) package
    management program that understands repositories. I don&amp;#8217;t know how
    they&amp;#8217;d cope with the pervasive license keys and &lt;span class="caps"&gt;DRM&lt;/span&gt; in the non-nix
    world, but I&amp;#8217;m sure they could figure out a way that still allowed
    sane package management. The idea here is that vendors run
    repositories and are responsible for their &lt;span class="caps"&gt;GPG&lt;/span&gt; keys, so trojans
    claiming to be an update to a given vendor&amp;#8217;s software would be
    rejected. Also, isn&amp;#8217;t it about time that you can update all your
    software on Windows or Mac through one&amp;nbsp;tool?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Filesystem-based &lt;span class="caps"&gt;IDS&lt;/span&gt; for Windows and Mac&lt;/strong&gt; Assuming it will take a
    while to get everyone onboard with the packaging idea, and noting
    that users of these OSes like installing applications from arbitrary
    sources, there should be an &lt;span class="caps"&gt;OS&lt;/span&gt;-level feature to audit all filesystem
    changes made by untrusted/unsigned applications, and a way to alert
    the user to these changes if they appear suspisious (essentially
    what &lt;a href="http://www.safer-networking.org"&gt;Spybot Search &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Destroy /
    TeaTimer&lt;/a&gt; do, but builtin to the&amp;nbsp;&lt;span class="caps"&gt;OS&lt;/span&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vendor support of packaging/repositories&lt;/strong&gt; - Along with the idea
    of repositories, vendors should have a trust or signing system for
    ISVs signing keys. If users are installing arbitrary software,
    making them trust an arbitrary key won&amp;#8217;t do anything to improve
    security. Microsoft and Apple need to run a &lt;span class="caps"&gt;CA&lt;/span&gt; that signs the
    package signing keys of their ISVs. The also - and here&amp;#8217;s the big
    one - need to have a parallel framework for &amp;#8220;independent
    developers&amp;#8221;. I.e. something that doesn&amp;#8217;t cost any money for the
    packagers, and allows them to at least give a &amp;#8220;this person is who
    they say they are&amp;#8221;&amp;nbsp;message.&lt;/li&gt;
&lt;li&gt;Finally, &lt;strong&gt;Make package management pervasive&lt;/strong&gt; - Have a real push to
    apply the packaging and signing keys standard to all software for
    the&amp;nbsp;&lt;span class="caps"&gt;OS&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;On a final note, applicable to both the current state of Linux packaging
and my ideas about Mac and Windows&amp;#8230; &lt;span class="caps"&gt;DNS&lt;/span&gt; is the ideal method of key
distribution (granted, yes, this just means that the security of the
packager&amp;#8217;s &lt;span class="caps"&gt;DNS&lt;/span&gt; records, and their servers and signing key, is just more
of an issue). But even with Yum and Zypper, it seems to me to be logical
that the packager&amp;#8217;s public key should be stored in a &lt;span class="caps"&gt;DNS&lt;/span&gt; record (or at a
&lt;span class="caps"&gt;URL&lt;/span&gt; stored in a &lt;span class="caps"&gt;DNS&lt;/span&gt; &lt;span class="caps"&gt;TXT&lt;/span&gt; record). That way, it wouldn&amp;#8217;t be up to an end
user to import and trust a key, they&amp;#8217;d just have to trust the repository
(i.e. software.adobe.com) and the package manager would pull down the
key and verify that package X in software.adobe.com is, in fact, signed
by the software.adobe.com&amp;nbsp;key.&lt;/p&gt;</content><category term="linux"></category><category term="mac"></category><category term="packaging"></category><category term="security"></category><category term="software"></category><category term="windows"></category></entry><entry><title>New MacBook Pro; Dual boot with Linux</title><link href="https://blog.jasonantman.com/2010/06/new-macbook-pro-dual-boot-with-linux/" rel="alternate"></link><published>2010-06-22T15:17:00-04:00</published><updated>2010-06-22T15:17:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2010-06-22:/2010/06/new-macbook-pro-dual-boot-with-linux/</id><summary type="html">&lt;p&gt;So in the first bit of good news lately, after four years as a
part-timer, this Monday I start my full-time position at Rutgers as a
Linux SysAdmin. Not really anything different - same office, same work,
just another day a week and a pay bump (plus benefits and all that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So in the first bit of good news lately, after four years as a
part-timer, this Monday I start my full-time position at Rutgers as a
Linux SysAdmin. Not really anything different - same office, same work,
just another day a week and a pay bump (plus benefits and all that). My
only real change on the first day will be a 3-hour &lt;span class="caps"&gt;HR&lt;/span&gt; orientation and
moving my workstation to public address space. But, on the positive
side, my new laptop just came in - a shiny new 13&amp;#8221; MacBook Pro, 2.4GHz
Core2 Duo, &lt;span class="caps"&gt;4GB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;, &lt;span class="caps"&gt;250GB&lt;/span&gt; &lt;span class="caps"&gt;HDD&lt;/span&gt;. Every time I see Mac packaging, I
remember why they cost so much - the box must be half the&amp;nbsp;price!&lt;/p&gt;
&lt;p&gt;&lt;img alt="MacBook Pro" src="/GFX/newMacBookPro.jpg"&gt;&lt;/p&gt;
&lt;p&gt;If all goes well, I&amp;#8217;ll have the machine setup to dual-boot &lt;span class="caps"&gt;OSX&lt;/span&gt; and Linux
(specifically &lt;a href="http://www.opensuse.org"&gt;OpenSuSE&lt;/a&gt; 11.2. I&amp;#8217;ll post notes
when I have it&amp;nbsp;done.&lt;/p&gt;
&lt;p&gt;The list of things I have to figure out beyond just getting both OSes&amp;nbsp;running:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do I want to use Mac for more than a select few apps that require it
    (i.e. possibly as another day-to-day &lt;span class="caps"&gt;OS&lt;/span&gt;)? If so, I need to figure
    out file sharing between the OSes, what I want unified from my
    profiles/homedirs, Firefox profile sharing,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;How to do a simple shared&amp;nbsp;partition?&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;FUSE&lt;/span&gt;/&lt;span class="caps"&gt;SSHFS&lt;/span&gt; on the Mac&amp;nbsp;side.&lt;/li&gt;
&lt;li&gt;Is there a way to select the boot &lt;span class="caps"&gt;OS&lt;/span&gt; (rEFIt) from&amp;nbsp;Linux?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Stay&amp;nbsp;tuned&amp;#8230;&lt;/p&gt;</content><category term="apple"></category><category term="dual boot"></category><category term="laptop"></category><category term="linux"></category><category term="mac"></category><category term="macbook"></category><category term="opensuse"></category></entry><entry><title>The Newest Generation of Hackers</title><link href="https://blog.jasonantman.com/2010/03/the-newest-generation-of-hackers/" rel="alternate"></link><published>2010-03-02T21:45:00-05:00</published><updated>2010-03-02T21:45:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2010-03-02:/2010/03/the-newest-generation-of-hackers/</id><summary type="html">&lt;p&gt;&lt;em&gt;Note for non-technical readers (not that I expect there to be many).
The title of this post includes the word &amp;#8220;hacker&amp;#8221;. If you think that has
anything to do with illegal acts or unethical behavior, you&amp;#8217;ve fallen
victim to what happens when the mainstream media latches on to a …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Note for non-technical readers (not that I expect there to be many).
The title of this post includes the word &amp;#8220;hacker&amp;#8221;. If you think that has
anything to do with illegal acts or unethical behavior, you&amp;#8217;ve fallen
victim to what happens when the mainstream media latches on to a term
they don&amp;#8217;t understand. The
&lt;a href="http://www.catb.org/jargon/html/H/hacker.html"&gt;definition&lt;/a&gt; of
this word is far from negative. Within the geek community, the title
&amp;#8220;hacker&amp;#8221; is the utmost compliment - something like Grand Master in the
martial arts, or perhaps whatever title is given to an eminent artist.
It both describes someone who is an expert in their field. Or, more
generally, someone who enjoys seeking knowledge simply for the sake of
knowledge - figuring out how things work, how to make them, and how to
make them better. If you&amp;#8217;re looking for a term that describes a
criminal, &amp;#8220;attacker&amp;#8221;, &amp;#8220;malicious user&amp;#8221; or &amp;#8220;computer criminal&amp;#8221; work fine.
While I wouldn&amp;#8217;t by any extent consider myself a hacker in the
super-genius-wizard sense of the term, I do definitely subscribe to the
hacker ethic - the burning need to figure out how things work and make
them&amp;nbsp;better.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Thanks to the snow at the end of last week, and a long weekend, I
actually got to do some reading that didn&amp;#8217;t involve man pages or books
strictly about software. I finally finished &lt;a href="http://www.amazon.com/Daemon-Gnu-Penguin-Peter-Salus/dp/097903423X"&gt;The Daemon, the Gnu, and
the
Penguin&lt;/a&gt;
by Peter H. Salus, a wonderful book (with a great foreword by maddog
Hall). I also &lt;em&gt;finally&lt;/em&gt; got a chance to start reading &lt;a href="http://www.amazon.com/Cathedral-Bazaar-Musings-Accidental-Revolutionary/dp/0596001088/"&gt;The Cathedral &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt;
the Bazaar: Musings on Linux and Open Source by an Accidental
Revolutionary&lt;/a&gt;
by Eric S. Raymond (&lt;span class="caps"&gt;ESR&lt;/span&gt;). I&amp;#8217;m only up to page 50 or so, but it&amp;#8217;s an
equally good book, and I&amp;#8217;ve been looking forward to reading it for&amp;nbsp;years.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve always been very interested in history (heck, I have a minor in
it), and specifically the history of my other interests. When
photography took up most of my time, I read every photo history book I
could get my hands on (including many primary sources on now-archaic
techniques). In the past few years, I&amp;#8217;ve been amassing books on
computing history (specifically &lt;span class="caps"&gt;ARPANET&lt;/span&gt;/the Internet and Unix/Linux/Free
software) at a near-alarming&amp;nbsp;rate.&lt;/p&gt;
&lt;p&gt;Through all of my reading, two main things have struck me: the utterly
amazing feats accomplished by previous generations, and how my own
generation takes them for granted. I was born in 1987 which, I feel,
makes me part of a very small group who were lucky enough to grow up
during the real rise of the Internet. I remember playing simple games on
my grandmother&amp;#8217;s (business) &lt;span class="caps"&gt;386DX&lt;/span&gt; long before I could read most of the
words on the screen. But I also remember my father dialing in to an &lt;span class="caps"&gt;ISP&lt;/span&gt;
(I honestly don&amp;#8217;t remember which one) on a 9600 baud serial modem, and
how unique that was at the time (at least among kids my age). By 13 or
so, I had a 10BaseT network in my house, sharing a 56k dial-up
connection between two computers. I feel that I&amp;#8217;m part of a short
historical period of kids who &amp;#8220;grew up&amp;#8221; with computers, used them in
middle school, are perfectly at home with them, but still remember
dial-up, the launch of Windows 98, and ordering Linux on CDs because you
just couldn&amp;#8217;t get it any other way (too young to have access to the
resources of a college, only&amp;nbsp;dial-up).&lt;/p&gt;
&lt;p&gt;Anyway, on to my&amp;nbsp;point&amp;#8230;&lt;/p&gt;
&lt;p&gt;As I read about those who stepped before me (and my generation), those
who thought up such amazing ideas as Unix, the Internet, networking and
most of the software and protocols we have today, I realize how big
their shoes are, and how difficult it will be for the next generation to
fill them. Sure, we have Facebook, &lt;span class="caps"&gt;RSS&lt;/span&gt; feeds, Web 2.0 and smartphones,
but will we be able to innovate on the level that those who came before
us did? And then it strikes me how much we young aspiring hackers take
for granted. How many aspects of technology today would be seemed
impossible 20 years ago, but we use without a second&amp;nbsp;thought.&lt;/p&gt;
&lt;p&gt;The last generation of hackers and programmers were raised on software
distribution tapes. Their idea of &amp;#8220;open&amp;#8221; was formed by what they were
used to - a Cathedral development model, with regular releases
(production, perhaps beta, perhaps even less) and accompanying source
code. However, in the pre-Internet days, they were still bound by
physical media. They were still bound to the Cathedral development
model, to a small and tight-knit group of sages determining when the
world was ready to see the fruits of their&amp;nbsp;labor.&lt;/p&gt;
&lt;p&gt;The current generation - those of us just out of college or grad school,
or even younger - think of Linux as the quintessential open source
project. For those of us who came into computing when Linux was already
around (I first ran Linux in 2001 when, at 14, I bought the
newly-released &lt;span class="caps"&gt;CD&lt;/span&gt; set of SuSE 7.3), Linux sets the bar. It&amp;#8217;s what we
were raised on (at least in terms of open source). Fixed releases - even
with source - seem antiquated, pre-Internet, our fathers&amp;#8217; open source.
To us, open means nightly builds, world-readable ticket/bug trackers,
anonymous Git or &lt;span class="caps"&gt;SVN&lt;/span&gt; access, and &lt;span class="caps"&gt;RSS&lt;/span&gt; feeds of every commit. It means
being able to see every line of code at every moment in time, even if
we&amp;#8217;ve never e-mailed one of the&amp;nbsp;developers.&lt;/p&gt;
&lt;p&gt;Even just a few years ago, the word &amp;#8220;open&amp;#8221; was used by vendors to mean
almost anything - everything from software based on Linux, to software
that included source (regardless of the license) to software that just
used (patent encumbered) documented protocols or formats. For the next
generation, even the generation entering the workforce now, open means
much more. It means transparency in development, in code, in
documentation, in&amp;nbsp;management.&lt;/p&gt;
&lt;p&gt;Many times, I&amp;#8217;ve found an &amp;#8220;open&amp;#8221; software project, and searched their
web site endlessly looking for links to Git or &lt;span class="caps"&gt;SVN&lt;/span&gt; or &lt;span class="caps"&gt;CVS&lt;/span&gt;. Or looked
endlessly for the (internal) bug tracker. Every time, I had to remind
myself that the world, even many of the open source projects, are still
far behind my expectations. Even Google&amp;#8217;s Android Open Source project
only has code merged in periodically from the production (closed) tree,
and maintains a separate bug tracker. Far from my expectation of just
having some parts of the tree unavailable on the Internet, and some
classes of bugs filtered out from public&amp;nbsp;view.&lt;/p&gt;
&lt;p&gt;Nobody - not even Microsoft - can deny that the world is moving more and
more to open source. It&amp;#8217;s already the de-facto standard on the Internet,
but it&amp;#8217;s moving more and more to the desktop every day. And, as this
happens, the expectations of what open means (increasingly more
transparent than just &amp;#8220;open&amp;#8221;) are also increasing. The software world -
both proprietary and open source - will have to keep up. And, hopefully,
as the generation raised on the Internet begins to fill the ranks of
geeks in the workforce, we&amp;#8217;ll see more and more open source&amp;nbsp;usage.&lt;/p&gt;
&lt;p&gt;As a side note, I&amp;#8217;d be very interested to see how open source use
compares to demographics. I know that Linux use (on student-owned
computers) at most colleges is way above the global average, and the
same goes for&amp;nbsp;Firefox.&lt;/p&gt;</content><category term="free"></category><category term="hacker"></category><category term="linux"></category><category term="open source"></category><category term="svn"></category></entry><entry><title>Apache2 - list Name-Based Virtual Hosts</title><link href="https://blog.jasonantman.com/2010/02/apache2-list-name-based-virtual-hosts/" rel="alternate"></link><published>2010-02-11T09:48:00-05:00</published><updated>2010-02-11T09:48:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2010-02-11:/2010/02/apache2-list-name-based-virtual-hosts/</id><summary type="html">&lt;p&gt;Here&amp;#8217;s a little tidbit that I never knew until I had an
&lt;a href="http://httpd.apache.org/"&gt;Apache2&lt;/a&gt; name-based virtual host problem:
&lt;code&gt;httpd -S&lt;/code&gt; lists the vhosts that are being served by Apache, and how
they were parsed from the config&amp;nbsp;files.&lt;/p&gt;
&lt;p&gt;The output on one of my servers looks something&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;[root@web2 …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Here&amp;#8217;s a little tidbit that I never knew until I had an
&lt;a href="http://httpd.apache.org/"&gt;Apache2&lt;/a&gt; name-based virtual host problem:
&lt;code&gt;httpd -S&lt;/code&gt; lists the vhosts that are being served by Apache, and how
they were parsed from the config&amp;nbsp;files.&lt;/p&gt;
&lt;p&gt;The output on one of my servers looks something&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;[root@web2 vhosts.d]#&lt;/span&gt; httpd -S
&lt;span class="go"&gt;VirtualHost configuration:&lt;/span&gt;
&lt;span class="go"&gt;wildcard NameVirtualHosts and _default_ servers:&lt;/span&gt;
&lt;span class="go"&gt;_default_:443          web2.jasonantman.com (/etc/httpd/vhosts.d/ssl-host.conf:7)&lt;/span&gt;
&lt;span class="go"&gt;*:80                   is a NameVirtualHost&lt;/span&gt;
&lt;span class="go"&gt;         default server www.jasonantman.com (/etc/httpd/vhosts.d/000-default.conf:1)&lt;/span&gt;
&lt;span class="go"&gt;         port 80 namevhost www.jasonantman.com (/etc/httpd/vhosts.d/000-default.conf:1)&lt;/span&gt;
&lt;span class="go"&gt;         port 80 namevhost rackman.jasonantman.com (/etc/httpd/vhosts.d/rackman.jasonantman.com.conf:1)&lt;/span&gt;
&lt;span class="go"&gt;         port 80 namevhost whatismyip.jasonantman.com (/etc/httpd/vhosts.d/whatismyip.jasonantman.com.conf:1)&lt;/span&gt;
&lt;span class="go"&gt;Syntax &lt;span class="caps"&gt;OK&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is quite useful in debugging vhost problems, especially those pesky
times when a request that should go to a specific vhost is being served
by the default (in my case at this time, I had two ServerName directives
instead of a ServerName and a&amp;nbsp;ServerAlias).&lt;/p&gt;</content><category term="apache"></category><category term="configuration"></category><category term="linux"></category></entry><entry><title>Running a script on USB drive insertion</title><link href="https://blog.jasonantman.com/2009/11/running-a-script-on-usb-drive-insertion/" rel="alternate"></link><published>2009-11-11T11:47:00-05:00</published><updated>2009-11-11T11:47:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2009-11-11:/2009/11/running-a-script-on-usb-drive-insertion/</id><summary type="html">&lt;p&gt;Before I even get into how to do this, &lt;strong&gt;be warned:&lt;/strong&gt; this is a &lt;em&gt;really&lt;/em&gt;
bad idea unless you can ensure total physical access control to the
machine. About the only place I&amp;#8217;d ever use it is in a non-networked
embedded system in a secure location. Its original intent …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Before I even get into how to do this, &lt;strong&gt;be warned:&lt;/strong&gt; this is a &lt;em&gt;really&lt;/em&gt;
bad idea unless you can ensure total physical access control to the
machine. About the only place I&amp;#8217;d ever use it is in a non-networked
embedded system in a secure location. Its original intent is to handle
loading of pictures onto a Linux-based digital photo&amp;nbsp;frame.&lt;/p&gt;
&lt;p&gt;So, you want to run a specific script on insertion of a &lt;span class="caps"&gt;USB&lt;/span&gt; drive.
Here&amp;#8217;s how to use udev to do&amp;nbsp;it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create &lt;code&gt;/etc/udev/rules.d/99-usbhook.rules&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="caps"&gt;ACTION&lt;/span&gt;==&amp;quot;add&amp;quot;,&lt;span class="caps"&gt;KERNEL&lt;/span&gt;==&amp;quot;sd*&amp;quot;, &lt;span class="caps"&gt;SUBSYSTEMS&lt;/span&gt;==&amp;quot;usb&amp;quot;, &lt;span class="caps"&gt;ATTRS&lt;/span&gt;{product}==&amp;quot;Mass Storage&amp;quot;, &lt;span class="caps"&gt;RUN&lt;/span&gt;+=&amp;quot;/root/bin/usbhook %k&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will run &amp;#8220;/root/bin/usbook&amp;#8221;, passing it the device name as an
argument, every time a &lt;span class="caps"&gt;USB&lt;/span&gt; Mass Storage device is plugged&amp;nbsp;in.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;run &lt;code&gt;udevcontrol reload_rules&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Create your usbhook&amp;nbsp;script.&lt;/li&gt;
&lt;li&gt;Enjoy&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here is my usbhook script to copy all files from a &lt;span class="caps"&gt;USB&lt;/span&gt; mass storage disk
to a specific location. It includes quite a bit of debugging, and also
checks for the presence of a file called &amp;#8220;foobarbaz.txt&amp;#8221; on the device
before copying the files&amp;nbsp;over.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="c1"&gt;# script to move over all files from a &lt;span class="caps"&gt;USB&lt;/span&gt; key&lt;/span&gt;
&lt;span class="c1"&gt;# when it is inserted into the system.&lt;/span&gt;

&lt;span class="c1"&gt;# should be called from a udev rule like:&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;span class="caps"&gt;ACTION&lt;/span&gt;==&amp;quot;add&amp;quot;,&lt;span class="caps"&gt;KERNEL&lt;/span&gt;==&amp;quot;sd*&amp;quot;, &lt;span class="caps"&gt;SUBSYSTEMS&lt;/span&gt;==&amp;quot;usb&amp;quot;, &lt;span class="caps"&gt;ATTRS&lt;/span&gt;{product}==&amp;quot;Mass Storage&amp;quot;, &lt;span class="caps"&gt;RUN&lt;/span&gt;+=&amp;quot;/root/bin/usbhook %k&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Copyright 2009 Jason Antman.  &lt;/span&gt;
&lt;span class="c1"&gt;# &lt;/span&gt;

&lt;span class="c1"&gt;# &lt;span class="caps"&gt;CONFIGURATION&lt;/span&gt;&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;DEBUG&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="c1"&gt;# set to 1 for debugging output&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;DEST&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/home/foo/&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;# destination for files&lt;/span&gt;


&lt;span class="nv"&gt;&lt;span class="caps"&gt;DEVICE&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;# the device name&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;LOGFACILITY&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;kernel.info&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;# for debugging output&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;DEBUG&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;:=0&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt; logger &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;LOGFACILITY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; usbhook called with arguments: &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;DEVICE&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;fi&lt;/span&gt;

sleep &lt;span class="m"&gt;5&lt;/span&gt; &lt;span class="c1"&gt;# delay 5 seconds to wait for mount&lt;/span&gt;

mount &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;DEVICE&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;FOO&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$?&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;FOO&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;DEBUG&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;:=0&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt; logger &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;LOGFACILITY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; usbhook device mounted: &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;DEVICE&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;DEBUG&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;:=0&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt; logger &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;LOGFACILITY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; usbhook device &lt;span class="caps"&gt;NOT&lt;/span&gt; mounted: &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;DEVICE&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; - exiting&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;fi&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;BAR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;mount &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;DEVICE&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;&amp;#39;{ print $3 }&amp;#39;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -e &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;BAR&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;/foobarbaz.txt&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;DEBUG&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;:=0&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt; logger &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;LOGFACILITY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; usbhook &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;BAR&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;/foobarbaz.txt found&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;DEBUG&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;:=0&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt; logger &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;LOGFACILITY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; usbhook &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;BAR&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;/foobarbaz.txt &lt;span class="caps"&gt;NOT&lt;/span&gt; found - exiting&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;fi&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

cp -R &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;DEVICE&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;/* &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;DEST&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This was tested on &lt;a href="http://www.opensuse.org"&gt;OpenSuSE&lt;/a&gt;&amp;nbsp;10.3.&lt;/p&gt;</content><category term="linux"></category><category term="script"></category><category term="udev"></category><category term="usb"></category></entry><entry><title>Microsoft submits driver code for Linux kernel</title><link href="https://blog.jasonantman.com/2009/07/microsoft-submits-driver-code-for-linux-kernel/" rel="alternate"></link><published>2009-07-23T09:32:00-04:00</published><updated>2009-07-23T09:32:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2009-07-23:/2009/07/microsoft-submits-driver-code-for-linux-kernel/</id><summary type="html">&lt;p&gt;I read a very interesting &lt;a href="http://www.linux-mag.com/cache/7439/1.html"&gt;article on
Linux-Mag.com&lt;/a&gt; today. The
gist of it is that Microsoft (as happily announced in a &lt;a href="http://www.microsoft.com/presspass/features/2009/Jul09/07-20LinuxQA.mspx"&gt;press
release&lt;/a&gt;)
has submitted 20,000 lines of code for inclusion into the kernel.
Specifically, the code is comprised of a number of drivers that will
enable Linux …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I read a very interesting &lt;a href="http://www.linux-mag.com/cache/7439/1.html"&gt;article on
Linux-Mag.com&lt;/a&gt; today. The
gist of it is that Microsoft (as happily announced in a &lt;a href="http://www.microsoft.com/presspass/features/2009/Jul09/07-20LinuxQA.mspx"&gt;press
release&lt;/a&gt;)
has submitted 20,000 lines of code for inclusion into the kernel.
Specifically, the code is comprised of a number of drivers that will
enable Linux to run better under Microsoft&amp;nbsp;Hyper-V.&lt;/p&gt;
&lt;p&gt;Yes, that&amp;#8217;s right, Microsoft released code under GPLv2 and is asking for
it to be put in Linux. They released it under the license that they call
&amp;#8220;cancer&amp;#8221;. And the entire purpose is, essentially, saying &amp;#8220;we want your
project to run well as a guest under our&amp;nbsp;hypervisor.&lt;/p&gt;
&lt;p&gt;The Linux Mag article did touch on some recent news, such as Microsoft&amp;#8217;s
&lt;a href="http://www.linux-mag.com/id/7325"&gt;lawsuit against TomTom&lt;/a&gt; (&lt;a href="http://arstechnica.com/microsoft/news/2009/03/microsoft-and-tomtom-settle-patent-dispute.ars"&gt;settled in
late
March&lt;/a&gt;)
claiming that the Linux kernel infringes their &lt;span class="caps"&gt;VFAT&lt;/span&gt; patents and the 2004
&lt;a href="http://ec.europa.eu/comm/competition/antitrust/cases/decisions/37792/en.pdf"&gt;&lt;span class="caps"&gt;EU&lt;/span&gt; antitrust case
(&lt;span class="caps"&gt;PDF&lt;/span&gt;)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A number of things are immediately apparent to&amp;nbsp;me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The only reason for this is so Linux will virtualize well under&amp;nbsp;Windows/Hyper-V.&lt;/li&gt;
&lt;li&gt;Microsoft doesn&amp;#8217;t seem to be making any similar effort to allow
    Windows to virtualize well under Xen (and it seems to me that many
    more people would want Windows on a reliable Linux host than the
    other way&amp;nbsp;around).&lt;/li&gt;
&lt;li&gt;Microsoft reached a settlement with TomTom, but never did anything
    to indemnify the Linux community at&amp;nbsp;large.&lt;/li&gt;
&lt;li&gt;This is &lt;strong&gt;not&lt;/strong&gt; a Microsoft endorsement (or even recognition) of the&amp;nbsp;&lt;span class="caps"&gt;GPL&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Microsoft &lt;a href="http://www.linux-watch.com/news/NS6670466370.html"&gt;made
    threats&lt;/a&gt; about
    Linux violating &amp;#8220;over 228&amp;#8221; of its patents in&amp;nbsp;2007.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There&amp;#8217;s a
&lt;a href="http://www.kroah.com/log/linux/microsoft-linux-hyper-v-drivers.html"&gt;post&lt;/a&gt;
on &lt;a href="http://www.kroah.com/log/"&gt;Greg Kroah-Hartman&amp;#8217;s blog&lt;/a&gt; (he&amp;#8217;s the
kernel maintainer who will - or will not - eventually be in charge of
the inclusion of the code). It should be noted that &lt;strong&gt;this all started&lt;/strong&gt;
due to a guy who I really admire, &lt;a href="http://linux-network-plumber.blogspot.com/"&gt;Stephen
Hemminger&lt;/a&gt;, the principal
engineer at Vyatta (whose router product I absolutely love, and their
mock advertisements are just as wonderful). Steve has a &lt;a href="http://linux-network-plumber.blogspot.com/2009/07/congratulations-microsoft.html"&gt;post on his
blog&lt;/a&gt;
giving the&amp;nbsp;background.&lt;/p&gt;
&lt;p&gt;So what do &lt;em&gt;I&lt;/em&gt; think should be done? Include the code. But first&amp;#8230; (I
know Microsoft doing all of this at once would be a dream, but maybe one
or two of them would be&amp;nbsp;nice)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If they haven&amp;#8217;t already done so, Microsoft should publicly recognize
    the &lt;span class="caps"&gt;GPL&lt;/span&gt; and all of its terms as being a legally binding&amp;nbsp;license.&lt;/li&gt;
&lt;li&gt;Prior to having any Microsoft code included in the Linux kernel,
    Microsoft publicly states that the Linux kernel, as of the time they
    submitted their code, does not infringe on any Microsoft
    intellectual&amp;nbsp;property.&lt;/li&gt;
&lt;li&gt;It would be nice of Microsoft would agree to some level of
    cooperation with the Linux&amp;nbsp;community.&lt;/li&gt;
&lt;li&gt;Microsoft pledges to allow, support, and actively develop for
    Windows as a guest under Xen and&amp;nbsp;&lt;span class="caps"&gt;KVM&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;</content><category term="gpl"></category><category term="kernel"></category><category term="linux"></category><category term="microsoft"></category></entry><entry><title>Building a Rebuild-able Site</title><link href="https://blog.jasonantman.com/2009/05/building-a-rebuild-able-site/" rel="alternate"></link><published>2009-05-06T08:42:00-04:00</published><updated>2009-05-06T08:42:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2009-05-06:/2009/05/building-a-rebuild-able-site/</id><summary type="html">&lt;p&gt;At $&lt;span class="caps"&gt;WORK&lt;/span&gt;, my group runs about two dozen servers that provide services
for over 60,000 users. They&amp;#8217;re a mix of Windows and Linux, with some old
Solaris stuff thrown in there. The one thing they have in common is
they&amp;#8217;re all hand-built, hand-configured, and old. They&amp;#8217;ve …&lt;/p&gt;</summary><content type="html">&lt;p&gt;At $&lt;span class="caps"&gt;WORK&lt;/span&gt;, my group runs about two dozen servers that provide services
for over 60,000 users. They&amp;#8217;re a mix of Windows and Linux, with some old
Solaris stuff thrown in there. The one thing they have in common is
they&amp;#8217;re all hand-built, hand-configured, and old. They&amp;#8217;ve been around
for a while. At the moment, we don&amp;#8217;t even have an adequate backup&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;So, being the closest thing to a SysAdmin we have (my official title is
still Student Systems Programmer), it&amp;#8217;s my job to build a new
installation, configuration and backup infrastructure. We&amp;#8217;ve already
standardized on &lt;a href="http://www.centos.org"&gt;CentOS&lt;/a&gt; as a University-wide
distro, and have a local full mirror, so I don&amp;#8217;t need to choose a
distro. I do, however, have to plan the installation and backup
architecture. The main requirements&amp;nbsp;are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Lowest overall time for bare-metal recovery to a working&amp;nbsp;system.&lt;/li&gt;
&lt;li&gt;Ease of use, as people other than myself will need to administer it
    (so they should be able to do so from a cheat sheet in the&amp;nbsp;wiki).&lt;/li&gt;
&lt;li&gt;Repeatability - it should be easy and intuitive to make an
    almost-exact-copy of a&amp;nbsp;machine.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I started a thread a few days ago on the &lt;span class="caps"&gt;SAGE&lt;/span&gt; mailing list, which you
can find
&lt;a href="http://mailman.sage.org/pipermail/sage-members/2009/msg00447.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At the moment, it looks like the general idea that I&amp;#8217;m going with is to
use &lt;a href="http://fedoraproject.org/wiki/Anaconda/Kickstart"&gt;Kickstart&lt;/a&gt; to
install the systems, using a basic and minimal Kickstart file. Basic
package selection (minimalist) with just what&amp;#8217;s needed to configure the
system with a hostname and network settings for the management &lt;span class="caps"&gt;VLAN&lt;/span&gt;.
I&amp;#8217;ll then have Kickstart install and configure a configuration
management package - I&amp;#8217;m leaning towards
&lt;a href="http://reductivelabs.com/products/puppet/"&gt;Puppet&lt;/a&gt; over
&lt;a href="http://www.cfengine.org/"&gt;Cfengine&lt;/a&gt; and am starting testing. The config
management software will handle all of the customization for the system
(everything different from the base generic Kickstart install) so it&amp;#8217;s
all kept under the control of config management from step&amp;nbsp;1.&lt;/p&gt;
&lt;p&gt;The final part is a backup system, mainly for whatever eventually -
whether out of human error or simple laziness - ends up out of the
config management system&amp;#8217;s control. Our previous &lt;span class="caps"&gt;SA&lt;/span&gt; had settled on
&lt;a href="http://www.zmanda.com/"&gt;Zmanda&lt;/a&gt;, the paid version of
&lt;a href="http://www.amanda.org/"&gt;Amanda&lt;/a&gt;, which comes with specific plugins for
MySQL and &lt;span class="caps"&gt;MSSQL&lt;/span&gt;. I&amp;#8217;m also looking at &lt;a href="http://www.bacula.org"&gt;Bacula&lt;/a&gt;,
mainly because of its&amp;#8217; advanced features, scheduling (especially the new
scheduling in Bacula 3) and&amp;nbsp;scalability.&lt;/p&gt;
&lt;p&gt;The beauty that I see in having Kickstart do something minimal and then
letting Puppet handle the rest is that (especially since we&amp;#8217;ve
standardized on SunFire X4100&amp;#8217;s with identical configurations) I can
kickstart and rack up a few spare machines, and to get them up and
running all I need to do is power them up (iLOM) and tell Puppet what to
make&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m currently starting testing of both Puppet itself and getting
Kickstart to start the puppet install and daemon (instructions from
&lt;a href="http://watzmann.net/blog/index.php?cat=21"&gt;David Lutterkort&amp;#8217;s blog (Red Hat software
engineer)&lt;/a&gt;). We&amp;#8217;ll see how
everything&amp;nbsp;goes&amp;#8230;&lt;/p&gt;</content><category term="backup"></category><category term="configuration"></category><category term="kickstart"></category><category term="linux"></category><category term="puppet"></category><category term="recovery"></category><category term="work"></category></entry><entry><title>My biggest problem with Linux</title><link href="https://blog.jasonantman.com/2008/10/my-biggest-problem-with-linux/" rel="alternate"></link><published>2008-10-27T15:27:00-04:00</published><updated>2008-10-27T15:27:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-10-27:/2008/10/my-biggest-problem-with-linux/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update / Notice:&lt;/strong&gt; This post was written in 2008. The world has
changed since then. A lot. We have good, easy configuration management
like Puppet, Chef, etc. (which, in fact, I
&lt;a href="https://github.com/jantman/workstation-bootstrap"&gt;use to manage my desktop and laptop&lt;/a&gt;)
and, more importantly, creating and destroying servers can be done in
&lt;a href="http://aws.amazon.com/cloudformation/"&gt;seconds&lt;/a&gt; rather …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Update / Notice:&lt;/strong&gt; This post was written in 2008. The world has
changed since then. A lot. We have good, easy configuration management
like Puppet, Chef, etc. (which, in fact, I
&lt;a href="https://github.com/jantman/workstation-bootstrap"&gt;use to manage my desktop and laptop&lt;/a&gt;)
and, more importantly, creating and destroying servers can be done in
&lt;a href="http://aws.amazon.com/cloudformation/"&gt;seconds&lt;/a&gt; rather than hours.
In short, in my opinion, this post is a rant about a problem that no longer
exists. If you&amp;#8217;re still thinking of things the way this post does, you&amp;#8217;re
doing it&amp;nbsp;wrong.&lt;/p&gt;
&lt;p&gt;For one of my wonderful classes, Internet Security, I&amp;#8217;m doing a
presentation on &amp;#8220;patch management&amp;#8221;. While I&amp;#8217;m obligated to cover Windows
- and, of course, will talk about MacOS - I&amp;#8217;ll obviously be spending a
good deal of time on the Unix/Linux side of things. This has gotten me
thinking about one of my biggest problems with Linux (and specifically
&lt;a href="http://www.opensuse.org"&gt;OpenSuSE&lt;/a&gt;, my usual default distro. Patch
management is utterly&amp;nbsp;awful.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s the problem: I have about a dozen machines under my control. I
need to keep them all up-to-date. Currently, I manually do patches and
upgrades via YaST or zypper. I thought about scripting this through
zypper, but that doesn&amp;#8217;t make any sense - the packages on the machines
are far from homogenous, so there&amp;#8217;s no clear way to make one script that
updates them all. I considered using Puppet or CFengine or something of
that sort, but that&amp;#8217;s too heavy-weight for me - for only a dozen
machines, many of which are personal or development only, that&amp;#8217;s a lot
to keep track of by hand, and a lot of work defining which patches
should be applied, and which machines shouldn&amp;#8217;t be&amp;nbsp;changed.&lt;/p&gt;
&lt;p&gt;My other peeve is distribution upgrades. About three of my machines are
still running OpenSuSE 10.0 or 10.1, both of which are unsupported, and
no longer even have downloads available. Why? Becuase I&amp;#8217;ve done major
OpenSuSE upgrades before, broken a &lt;span class="caps"&gt;LOT&lt;/span&gt; of stuff, and I simply can&amp;#8217;t risk
that on machines that can&amp;#8217;t stand extended downtime. This process
*needs* to be made easier. Bottom line - it should be made no more
difficult or unreliable than a kernel upgrade. &lt;span class="caps"&gt;IMHO&lt;/span&gt;, the biggest selling
point for Solaris is its&amp;#8217; ability to do a total upgrade to a second
partition, and switch-over at runtime. Why doesn&amp;#8217;t Linux (or SuSE) have
this&amp;nbsp;yet?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;What&amp;#8217;s my ideal solution?&lt;/em&gt; A curses application that uses text-file
backends (curses so I can run it over &lt;span class="caps"&gt;SSH&lt;/span&gt; even if I have a slow link or
high latency, like from a &lt;span class="caps"&gt;SSH&lt;/span&gt; session on my cell phone, if need be). The
app would allow me to list all of the machines I want managed. It would
connect to the machines over standard &lt;span class="caps"&gt;SSH&lt;/span&gt;, and would leave an extensive
audit trail of what&amp;#8217;s done, both on the management console and on the
machines (as well as running as a dedicated user). The application would
maintain an inventory of all of the packages on every machine. It would
check daily for new patches/updates to any of those packages, and e-mail
me a daily summary of what&amp;#8217;s new, including all dependency changes, and
which machines need the update. It would also allow me to define, on a
per-machine (or per-group-of-machines) basis, rules for packages that
must stay at their current version - i.e. I have a bunch of &lt;span class="caps"&gt;PHP4&lt;/span&gt; apps,
so machine X needs to stay at &lt;span class="caps"&gt;PHP4&lt;/span&gt;. The e-mail summary would include any
packages that aren&amp;#8217;t going to be updated for a specific machine because
of dependency/version rules, as well as warnings about any new packages
that have a dependency that has a rule set. I could then run the main
curses app on my admin machine and, starting from &lt;span class="caps"&gt;NO&lt;/span&gt; selections, select
which updates I want to apply and whether I want to ignore or create new
rules to keep something at its current version, on a per-machine or
per-group basis. This curses app would generate a file (&lt;span class="caps"&gt;XML&lt;/span&gt;?) of what to
do (which would also be generated or edited by hand, easily). The &lt;span class="caps"&gt;XML&lt;/span&gt;
file would then be fed into a script that downloads all of the needed
packages to a central (local) mirror (or, optionally, for remote
machines, has them download locally on the machine), checksums them, and
then installs them (running commands over &lt;span class="caps"&gt;SSH&lt;/span&gt;) on all applicable
machines. It would then keep a log of all changes, both on each machine
changed (in a master changelog file) and on the central administrative
machine. &lt;strong&gt;Most importantly&lt;/strong&gt;, the curses interface would have a simple,
quick way to back out any specific update or group of updates for all
machines, a group of machines, or one machine. All data needed to back
out a change would be kept on each machine (say, cleaned up at the next
update of that package and all of its&amp;#8217; dependencies) with
machine-readable instructions kept in a central file, allowing local
rollbacks - i.e. a machine goes down, I realize that it was because of
an update to package X, and on the local machine I can check the
changelog, see an entry like &amp;#8220;Package X updated 1.0.0 to 1.0.1 on
yyyy-mm-dd, Change &lt;span class="caps"&gt;ID&lt;/span&gt; 1234&amp;#8221; and then, to rollback, simply issue a
command like &amp;#8220;patchmgt rollback 1234&amp;#8221; on the effected&amp;nbsp;machine.&lt;/p&gt;
&lt;p&gt;Just some ideas, and a little&amp;nbsp;rant.&lt;/p&gt;</content><category term="linux"></category><category term="patch management"></category><category term="solaris"></category><category term="updates"></category><category term="upgrades"></category></entry><entry><title>eeePC stronger than ever</title><link href="https://blog.jasonantman.com/2008/09/eeepc-stronger-than-ever/" rel="alternate"></link><published>2008-09-10T23:55:00-04:00</published><updated>2008-09-10T23:55:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-09-10:/2008/09/eeepc-stronger-than-ever/</id><summary type="html">&lt;p&gt;It seems like every time I open up my &lt;a href="http://reader.google.com"&gt;Google
Reader&lt;/a&gt; account, there&amp;#8217;s news about another
company that released a knock-off of my beloved &lt;a href="http://eeepc.asus.com/global/700.htm"&gt;Asus eeePC 4G Surf
(701)&lt;/a&gt; (interestingly, it looks
like eeepc.asus.com is down at the moment of writing). Even Asus has
released numerous (I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It seems like every time I open up my &lt;a href="http://reader.google.com"&gt;Google
Reader&lt;/a&gt; account, there&amp;#8217;s news about another
company that released a knock-off of my beloved &lt;a href="http://eeepc.asus.com/global/700.htm"&gt;Asus eeePC 4G Surf
(701)&lt;/a&gt; (interestingly, it looks
like eeepc.asus.com is down at the moment of writing). Even Asus has
released numerous (I think the product like is now up to about 10
variations) follow-ups to the 7&amp;#8221; beauty, now up to 10&amp;#8221; in size (though,
admittedly, I&amp;#8217;m less-than-enthused about their Windows&amp;nbsp;models).&lt;/p&gt;
&lt;p&gt;With the new semester here, I am (unfortunately) back in class. And I&amp;#8217;m
very happy to report that I&amp;#8217;m starting to see eeePCs in more and more
hands. Granted, my classes are in the &lt;span class="caps"&gt;IT&lt;/span&gt; program, but I was quite
surprised last night to be sitting in my Internet Security class and
notice no less than four eeePCs in a class of about 25 people. While
I&amp;#8217;ve just relegated my own 4G to my server room bag, replacing it with a
(used, surplus from work) &lt;span class="caps"&gt;IBM&lt;/span&gt; ThinkPad T41 (14.1&amp;#8221; display, 1.4GHz
Pentium, &lt;span class="caps"&gt;768MB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;, and a &lt;span class="caps"&gt;DVD&lt;/span&gt; drive). Though my heart sank when I found
that half of the eeePCs were running Windows, it seems that in my
travels around campus, I&amp;#8217;m seeing more and more eeePCs, and more laptops
running&amp;nbsp;Linux.&lt;/p&gt;
&lt;p&gt;While the academic world has surely embraced new technologies, and
non-mainstream technologies, quicker than other sectors (specifically
considering Linux and the apparent popularity of the eeePC), it&amp;#8217;s
definitely a good omen. Seeing non-geek, and perhaps even non-&lt;span class="caps"&gt;CS&lt;/span&gt; and
non-Engineering, students using Linux speaks quite well for the
expansion of the Linux user base when these students graduate and enter
the &amp;#8220;real&amp;nbsp;world&amp;#8221;&lt;/p&gt;</content><category term="asus"></category><category term="eeepc"></category><category term="linux"></category></entry><entry><title>LIRC and Hauppauge PVR-150 on OpenSuSE 11.0</title><link href="https://blog.jasonantman.com/2008/09/lirc-and-hauppauge-pvr-150-on-opensuse-110/" rel="alternate"></link><published>2008-09-01T10:37:00-04:00</published><updated>2008-09-01T10:37:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-09-01:/2008/09/lirc-and-hauppauge-pvr-150-on-opensuse-110/</id><summary type="html">&lt;p&gt;Well, despite what&amp;#8217;s been said elsewhere, it &lt;em&gt;&lt;span class="caps"&gt;IS&lt;/span&gt;&lt;/em&gt; possible! It&amp;#8217;s a bit
error-ridden at first, but here is the procedure that I used to compile
and install the &lt;span class="caps"&gt;PVR&lt;/span&gt;-150 patched &lt;span class="caps"&gt;LIRC&lt;/span&gt;&amp;nbsp;0.8.3-&lt;span class="caps"&gt;CVS&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;First, Download the tarball mentioned in the &lt;a href="http://www.blushingpenguin.com/mark/blog/?p=24"&gt;Version 3 blog
post&lt;/a&gt; at …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Well, despite what&amp;#8217;s been said elsewhere, it &lt;em&gt;&lt;span class="caps"&gt;IS&lt;/span&gt;&lt;/em&gt; possible! It&amp;#8217;s a bit
error-ridden at first, but here is the procedure that I used to compile
and install the &lt;span class="caps"&gt;PVR&lt;/span&gt;-150 patched &lt;span class="caps"&gt;LIRC&lt;/span&gt;&amp;nbsp;0.8.3-&lt;span class="caps"&gt;CVS&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;First, Download the tarball mentioned in the &lt;a href="http://www.blushingpenguin.com/mark/blog/?p=24"&gt;Version 3 blog
post&lt;/a&gt; at &lt;a href="http://www.blushingpenguin.com/mark/blog/"&gt;Marks
Braindump&lt;/a&gt;. You can pretty
much follow his instructions on the installation in the blog post, with
some changes that are specific to getting it to compile on OpenSuSE&amp;nbsp;11.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First, remove all traces of the OpenSuSE &lt;span class="caps"&gt;LIRC&lt;/span&gt; from you system.
    Uninstall the &lt;span class="caps"&gt;RPMS&lt;/span&gt; and everything else that goes with them. Then
    unload all of the kernel modules, especially lirc_i2c (if you have
    it&amp;nbsp;loaded).&lt;/li&gt;
&lt;li&gt;In your kernel source directory, run
    &lt;code&gt;make oldconfig &amp;amp;&amp;amp; make prepare.&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In your kernel source directory, run &lt;code&gt;make prepare scripts&lt;/code&gt; which,
    among other things, compiles the required &lt;code&gt;genksyms&lt;/code&gt; scurript.&lt;/li&gt;
&lt;li&gt;I was getting a compile error like &amp;#8220;&lt;span class="caps"&gt;WARNING&lt;/span&gt;: Symbol version dump
    /usr/src/`uname -r`/Module.symvers is missing&amp;#8221;. Find out which
    kernel you&amp;#8217;re running (&lt;code&gt;uname -r&lt;/code&gt;). In yout kernel source directory,
    copy your Module.symvers file from /usr/src/linux-obj. I was running
    i386 architecture with the &amp;#8220;default&amp;#8221; kernel, so mine was located at
    &lt;code&gt;/usr/src/linux-obj/i386/debug/Module.symvers&lt;/code&gt;. Copy that into
    &lt;code&gt;/usr/src/linux&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;In the lirc (patched) directory, run &lt;code&gt;setup.sh&lt;/code&gt; as instructed. &lt;span class="caps"&gt;DO&lt;/span&gt;
    &lt;span class="caps"&gt;NOT&lt;/span&gt; tell it to run configure - just save settings and&amp;nbsp;exit.&lt;/li&gt;
&lt;li&gt;Edit the generated &lt;code&gt;configure.sh&lt;/code&gt; file, adding a
    &lt;code&gt;--with-kerneldir=/usr/src/KERNELDIR&lt;/code&gt;, replacing &lt;span class="caps"&gt;KERNELDIR&lt;/span&gt; with the
    actual path to your kernel soruce (i.e. /usr/src/`uname&amp;nbsp;-r`).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;make&lt;/code&gt;. If no errors, &lt;code&gt;make install&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;I decided to reboot at this point, and when I did, everything worked&amp;nbsp;perfectly.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Also, I found that I needed to explicitly specify &lt;code&gt;--device=/dev/lirc0&lt;/code&gt;
when starting &lt;span class="caps"&gt;LIRC&lt;/span&gt;, as well as not specifying a driver. I just took the
&lt;code&gt;/etc/init.d/lirc&lt;/code&gt; from the official OpenSuSE 11.0 package, commented
out line 108 in &lt;code&gt;makeargs()&lt;/code&gt; that adds the &lt;code&gt;-H $LIRC_DRIVER&lt;/code&gt; to the
args, and added &lt;code&gt;LIRC_DEVICE="/dev/lirc0"&lt;/code&gt; to the top after the &lt;span class="caps"&gt;INIT&lt;/span&gt;&amp;nbsp;info.&lt;/p&gt;
&lt;p&gt;Unfortunately, figuring out this process took me a long time. I&amp;#8217;ve
reconstructed these instructions from various post-it notes, the
whiteboard next to my desk, and some bash history files and terminal
dumps. If this doesn&amp;#8217;t seem to work for you, please drop an email to
jason &lt;span class="caps"&gt;AT&lt;/span&gt; jason antman &lt;span class="caps"&gt;DOT&lt;/span&gt; com, with as much information as you have, and
I&amp;#8217;ll figure it out and update the&amp;nbsp;instructions.&lt;/p&gt;
&lt;p&gt;Now, finally, an up-to-date system &lt;span class="caps"&gt;AND&lt;/span&gt; &lt;a href="http://www.mythtv.org"&gt;MythTV&lt;/a&gt;.&lt;/p&gt;</content><category term="hauppauge"></category><category term="linux"></category><category term="lirc"></category><category term="mythtv"></category><category term="opensuse"></category><category term="pvr-150"></category><category term="suse"></category></entry><entry><title>Linux, Choice, Updates, CitiBank issues</title><link href="https://blog.jasonantman.com/2008/08/linux-choice-updates-citibank-issues/" rel="alternate"></link><published>2008-08-25T12:37:00-04:00</published><updated>2008-08-25T12:37:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-08-25:/2008/08/linux-choice-updates-citibank-issues/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update July 11, 2011&lt;/strong&gt; - I &lt;a href="/2011/07/article-on-theinquirer-net/"&gt;just found
out&lt;/a&gt; that this post is heavily
quote in &lt;a href="http://www.theinquirer.net/inquirer/news/1026958/citibank-infuriating-customers-linux-hostile-site"&gt;an article on
theinquirer.net&lt;/a&gt;
about this issue. Luckily (I don&amp;#8217;t know whether I made a difference or
not, certainly CitiBank never contacted me back), citicards.com now
works with Firefox on Linux. I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Update July 11, 2011&lt;/strong&gt; - I &lt;a href="/2011/07/article-on-theinquirer-net/"&gt;just found
out&lt;/a&gt; that this post is heavily
quote in &lt;a href="http://www.theinquirer.net/inquirer/news/1026958/citibank-infuriating-customers-linux-hostile-site"&gt;an article on
theinquirer.net&lt;/a&gt;
about this issue. Luckily (I don&amp;#8217;t know whether I made a difference or
not, certainly CitiBank never contacted me back), citicards.com now
works with Firefox on Linux. I have no idea if it was a change made by
Citi, or a change with Firefox or Flash&amp;nbsp;Player.&lt;/p&gt;
&lt;p&gt;I know this blog has been less-than-active lately. Life has been pretty
busy, between a massive network upgrade at the &lt;a href="http://www.midlandparkambulance.com"&gt;ambulance
corps&lt;/a&gt; that I volunteer with, the
impending doom of a new semester at work, scheduling courses, and a few
personal projects. I do, however, have a long list of things to post,
including some notes on my upgrade to &lt;a href="http://www.nagios.org"&gt;Nagios 3&lt;/a&gt;,
my recent experience with the &lt;a href="http://www.pcengines.ch/alix.htm"&gt;&lt;span class="caps"&gt;PC&lt;/span&gt; Engines
&lt;span class="caps"&gt;ALIX&lt;/span&gt;&lt;/a&gt; board, some changes to
&lt;a href="http://tuxostat.jasonantman.com"&gt;tuxOstat&lt;/a&gt;, and my plans to upgrade to
Optimum Business cable with 5 static IPs - finally a real home for
&lt;a href="http://www.jasonantman.com"&gt;JasonAntman.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CitiCards Problems -&lt;/strong&gt; I had a somewhat unnerving experience this
morning. Having just gotten a Citibank credit card, and made my first
few purchases on it, I browsed to
&lt;a href="https://www.citicards.com"&gt;CitiCards.com&lt;/a&gt; to check my account summary.
I happened to be using a just-purchased &lt;span class="caps"&gt;IBM&lt;/span&gt; T41 laptop, running
&lt;a href="http://www.opensuse.org"&gt;OpenSuSE 11.0&lt;/a&gt; and
&lt;a href="http://www.getfirefox.com"&gt;FireFox3&lt;/a&gt;, so when I saw the page display
and then go completely blank, I suspected a problem with my Flash
plugin. Little did I know, but I tried the same page on 3 other
Linux/Firefox machines, with the same result. I put in a call to the
tech support line, and was gruffly informed by the representative that
Firefox was not supported, they were unable to support it, and, to
paraphrase, I should get another browser or f*** off. She was &lt;em&gt;very
well-aware&lt;/em&gt; of the issue, and stated that Citi would not fix it. At this
point, I stated that I thought I would cancel my card, and she told me
to have a nice day and hung&amp;nbsp;up.&lt;/p&gt;
&lt;p&gt;I decided to go to step 2 of the Generic Problem Solving
Method,
and found &lt;a href="http://www.google.com/search?hl=en&amp;amp;q=citicards.com+linux&amp;amp;btnG=Google+Search"&gt;hundreds of references to a problem with CitiCards.com on
Linux&lt;/a&gt;.
I read through a lot of conspiracy theory, but decided to test one of
the theories (and fixes). Sure enough, when I right-clicked on the blank
white screen, I got a Flash context menu. Clicking &amp;#8220;Play&amp;#8221; showed the ad,
and I was able to click the little &amp;#8220;X&amp;#8221; in the top right and bypass it,
gaining access to the normal main page. Never to be one to ignore a
conspiracy (or anti-Linux) theory, I pulled up the same page on a Mac.
Sure enough, that particular ad (set not to play and with an opaque
full-screen background) didn&amp;#8217;t show up. Hmm&amp;#8230; maybe there&amp;#8217;s something
to the theory put forth by the &lt;a href="http://stealcode.blogspot.com/2008/07/citibank-doesnt-like-linuxubuntu_27.html"&gt;guy who said CitiBank is blocking Linux
users&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I decided to call back, and this time spoke with Susan at CitiCards tech
support. She was very understanding, and apologized for both the
inconvenience and the previous representative&amp;#8217;s attitude. She said that
she was aware of some issues with Firefox and Linux, but stated that
they are only unsupported so far as Tech Support won&amp;#8217;t walk a customer
using Linux or FireFox through any issue resolution, but that both the
browser and architecture should, theoretically, work. She didn&amp;#8217;t know
anything about a policy against Linux, or intentional blocking/sabotage.
She did say, however, that they are &amp;#8220;working on it&amp;#8221;. I did inform her
that the problem could probably be resolved by simply editing the Flash
ad to be properly transparent, or suppressing it for Linux
architectures, though I doubt that the information will make its&amp;#8217; way up
the food chain. Unfortunately, I can&amp;#8217;t seem to find a contact email for
anything site-related on&amp;nbsp;CitiCards.com.&lt;/p&gt;
&lt;p&gt;If this is really a case of intentional blocking, it would be quite
infuriating - I filled out the application for the card on
FireFox3/Linux&amp;#8230; but then they block account&amp;nbsp;access?&lt;/p&gt;
&lt;p&gt;Hopefully more of an update&amp;nbsp;tonight&amp;#8230;&lt;/p&gt;</content><category term="citibank"></category><category term="citicards"></category><category term="firefox"></category><category term="flash"></category><category term="linux"></category></entry><entry><title>Practical PHP and MySQL</title><link href="https://blog.jasonantman.com/2008/06/practical-php-and-mysql/" rel="alternate"></link><published>2008-06-26T14:29:00-04:00</published><updated>2008-06-26T14:29:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-06-26:/2008/06/practical-php-and-mysql/</id><summary type="html">&lt;p&gt;I&amp;#8217;m taking a summer course in Building Data Driven Websites - not that I
thought I&amp;#8217;d learn much in such a course at
&lt;a href="http://scils.rutgers.edu"&gt;&lt;span class="caps"&gt;SCILS&lt;/span&gt;&lt;/a&gt;, but I&amp;#8217;d like to graduate on time, and
need the credits, and Bill Crosbie is just the type of rare teacher that
can keep …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;m taking a summer course in Building Data Driven Websites - not that I
thought I&amp;#8217;d learn much in such a course at
&lt;a href="http://scils.rutgers.edu"&gt;&lt;span class="caps"&gt;SCILS&lt;/span&gt;&lt;/a&gt;, but I&amp;#8217;d like to graduate on time, and
need the credits, and Bill Crosbie is just the type of rare teacher that
can keep even me awake and interested. Our book is &lt;a href="http://www.informit.com/store/product.aspx?isbn=0132239973"&gt;Practical &lt;span class="caps"&gt;PHP&lt;/span&gt; and
MySQL: Building Eight Dynamic Web
Applications&lt;/a&gt;
(&lt;a href="http://www.amazon.com/Practical-PHP-MySQL-Building-Applications/dp/0132239973"&gt;Amazon&lt;/a&gt;)
by &lt;a href="http://www.jonobacon.org/"&gt;Jono Bacon&lt;/a&gt;. Now, I know it&amp;#8217;s not a
&lt;em&gt;real&lt;/em&gt; book like, say, &lt;a href="http://oreilly.com/catalog/9780596003432/"&gt;&lt;span class="caps"&gt;ESA3&lt;/span&gt; by
Frisch&lt;/a&gt;, which has a healthy
&lt;a href="http://www.aeleen.com/home.htm"&gt;web presense&lt;/a&gt;. But this thing is all
code and doesn&amp;#8217;t even have a web site, let alone easy code&amp;nbsp;downloads!&lt;/p&gt;
&lt;p&gt;The book does come with a heavily customized Ubuntu LiveCD. However,
when I popped it in my &lt;a href="http://www.opensuse.org"&gt;OpenSuSE workstation&lt;/a&gt;,
I couldn&amp;#8217;t really make much out of the &lt;span class="caps"&gt;CD&lt;/span&gt; - there was certainly no
easy-to-find &amp;#8220;this is the code&amp;#8221; directory. Well, after some exploring, I
mounted the &lt;a href="http://squashfs.sourceforge.net/"&gt;SquashFS&lt;/a&gt; filesystem and
poked around a bit. Strange&amp;#8230; seems to only have one real user (root)
and, though they claim this is a fully-functional &lt;span class="caps"&gt;LAMP&lt;/span&gt; server, no Apache
or MySQL. Really weird. Well, after poking for a few minutes, I found
the holy grail - &lt;code&gt;/root/.bash_history&lt;/code&gt; was intact! Just a quick look
through it with &lt;code&gt;less&lt;/code&gt; and I found what I was looking for: &lt;code&gt;/opt/lampp&lt;/code&gt;.
It appears that the install is actually ApacheFriends&amp;#8217;
&lt;a href="http://www.apachefriends.org/en/xampp-linux.html"&gt;&lt;span class="caps"&gt;LAMPP&lt;/span&gt;&lt;/a&gt;, or &lt;span class="caps"&gt;XAMPP&lt;/span&gt; for
Linux (gotta wonder if the guy writing this book doesn&amp;#8217;t even know how
to install Apache&amp;#8230; I&amp;#8217;m sure &lt;span class="caps"&gt;XAMPP&lt;/span&gt; for Linux is more bloated than a
customized build of Apache/MySQL/&lt;span class="caps"&gt;PHP&lt;/span&gt; from source, especially since it&amp;#8217;s
only being used to host 8 sample projects, so a lot could be left&amp;nbsp;out).&lt;/p&gt;
&lt;p&gt;Anyway, it appears that &lt;span class="caps"&gt;LAMPP&lt;/span&gt; is running in a chroot&amp;#8217;ed environment. The
actual sample code is rooted at &lt;code&gt;/opt/lampp/htdocs/sites&lt;/code&gt;. It seems that
&lt;em&gt;all&lt;/em&gt; of the &lt;span class="caps"&gt;PHP&lt;/span&gt; files are also owned by root and chmod&amp;#8217;ed 777! And
the top-level &lt;code&gt;index.php&lt;/code&gt; file makes use of absolute links, so obviously
he never thought that someone may want to copy the sample code and use
it on a &lt;em&gt;real&lt;/em&gt;&amp;nbsp;box.&lt;/p&gt;
&lt;p&gt;I just can&amp;#8217;t imagine someone who&amp;#8217;s a beginner with Linux, let alone a
Windows person, trying to get this source code onto a machine where they
can actually play with it. And&amp;#8230; to make the situation worse&amp;#8230; the
LiveCD has vi and vim, but no Emacs!!!!&amp;nbsp;Eeeek!!&lt;/p&gt;</content><category term="books"></category><category term="linux"></category><category term="PHP"></category><category term="programming"></category><category term="rutgers"></category></entry><entry><title>Update</title><link href="https://blog.jasonantman.com/2008/06/update-2/" rel="alternate"></link><published>2008-06-15T11:03:00-04:00</published><updated>2008-06-15T11:03:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-06-15:/2008/06/update-2/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been incredibly busy lately. But I have 2 quick&amp;nbsp;updates-&lt;/p&gt;
&lt;p&gt;tuxOstat, my thermostat project, isn&amp;#8217;t totally finished, but is up
and running. There&amp;#8217;s still some work to do, but the code is largely
complete. There&amp;#8217;s
also a web interface with temperature
graphs, system status, and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been incredibly busy lately. But I have 2 quick&amp;nbsp;updates-&lt;/p&gt;
&lt;p&gt;tuxOstat, my thermostat project, isn&amp;#8217;t totally finished, but is up
and running. There&amp;#8217;s still some work to do, but the code is largely
complete. There&amp;#8217;s
also a web interface with temperature
graphs, system status, and a (horrible) webcam view of the &lt;span class="caps"&gt;LCD&lt;/span&gt; control
panel. I&amp;#8217;ll probably be finishing up a first version this week,
finishing the documentation next week, and releasing what I have&amp;nbsp;soon.&lt;/p&gt;
&lt;p&gt;I got an e-mail today about one of my older projects, &lt;a href="http://www.php-ems-tools.com"&gt;&lt;span class="caps"&gt;PHP&lt;/span&gt; &lt;span class="caps"&gt;EMS&lt;/span&gt;
Tools&lt;/a&gt;, a &lt;span class="caps"&gt;PHP&lt;/span&gt;/MySQL based application for
fire/&lt;span class="caps"&gt;EMS&lt;/span&gt; agencies to handle scheduling, membership rosters, equipment
checks, etc. The potential user was asking about running the software on
Windows - which, of course, I have no experience with. I&amp;#8217;m pretty sure
there aren&amp;#8217;t many, if any, Unix-specific calls hidden in the code, and
advised him to try &lt;span class="caps"&gt;XAMPP&lt;/span&gt; (Apache/MySQL on Windows). But I did take a
moment to comment on why I chose Linux. My pilot installation of &lt;span class="caps"&gt;PHP&lt;/span&gt; &lt;span class="caps"&gt;EMS&lt;/span&gt;
Tools, at the Midland Park Volunteer Ambulance Corps, where I&amp;#8217;ve been a
member since 2005, has been handling our scheduling, roster, and
equipment checks since June 2006. It&amp;#8217;s running on a generation 1 Compaq
Proliant &lt;span class="caps"&gt;DL380&lt;/span&gt;, running dual Pentium &lt;span class="caps"&gt;III&lt;/span&gt; 733MHz processors and &lt;span class="caps"&gt;1GB&lt;/span&gt;
memory - and even with a number of other programs on it, including
ieilogd which is reading from the
serial port 24x7 - the load average has never passed 1.2 and the memory
usage is well under 50%. More importantly, the system has been up for
442 days without a&amp;nbsp;hiccup!&lt;/p&gt;</content><category term="ieilogd"></category><category term="linux"></category><category term="php ems tools"></category><category term="tuxostat"></category></entry><entry><title>New Project</title><link href="https://blog.jasonantman.com/2008/06/new-project/" rel="alternate"></link><published>2008-06-04T10:34:00-04:00</published><updated>2008-06-04T10:34:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-06-04:/2008/06/new-project/</id><summary type="html">&lt;p&gt;Well, TuxTruck has been temporarily put on the back burner. I priced out
the hardware, and it looks like a minimum of $1000, more like $1000 if I
get what I had originally wanted. This is complicated by the fact that
my roommates and I were just hit with a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Well, TuxTruck has been temporarily put on the back burner. I priced out
the hardware, and it looks like a minimum of $1000, more like $1000 if I
get what I had originally wanted. This is complicated by the fact that
my roommates and I were just hit with a $220 electric bill. Mostly,
that&amp;#8217;s due to the central air conditioning in our apartment, and the
horrible inefficiencies with&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Inefficient? Yes. At the moment, I&amp;#8217;m the only person in the apartment.
I&amp;#8217;m home for the weekend from 18:00 Friday through about 15:00 Monday. I
have class Monday-Thursday night 18:00-21:45. I work Tuesday-Friday
0900-1700. Even though the thermostat we have is &amp;#8220;programmable&amp;#8221;, it can
only be set for 4 time periods per day, weekdays and weekends. So, I
figured that a little added efficiency in calculating when the A/C
should run would go a long way towards energy&amp;nbsp;savings.&lt;/p&gt;
&lt;p&gt;My idea - tuxOstat - is to have a Linux box that has temperature sensors
placed around the apartment, and a bank of relays to control the
heating/cooling systems. So, even though I only got the idea last
Thursday, version 1 should be up and running next&amp;nbsp;week.&lt;/p&gt;
&lt;p&gt;In terms of&amp;nbsp;hardware:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Originally I had planned on using a &lt;a href="http://www.soekris.com/net4526.htm"&gt;Soekris
    net4526&lt;/a&gt; that I had lying
    around. However, the added cost of a MiniPCI &lt;span class="caps"&gt;USB&lt;/span&gt; card seemed
    prohibitive for a one-off project. Instead, I&amp;#8217;m using an old &lt;span class="caps"&gt;HP&lt;/span&gt;
    OmniBook laptop that was already lying behind my servers. It&amp;#8217;s
    running Debian&amp;nbsp;4.0.&lt;/li&gt;
&lt;li&gt;I&amp;#8217;ve ordered (just 15 minutes ago) a &lt;a href="http://www.phidgets.com/products.php?product_id=1014"&gt;Phidgets InterfaceKit
    0/0/4&lt;/a&gt;, which
    connects via &lt;span class="caps"&gt;USB&lt;/span&gt; and provides 4 relays. One will control the fan,
    one for the A/C compressor, one for the heat, and one unused (for&amp;nbsp;now).&lt;/li&gt;
&lt;li&gt;I already had a
    &lt;a href="http://www.hobby-boards.com/catalog/product_info.php?cPath=23&amp;amp;products_id=1503"&gt;&lt;span class="caps"&gt;DS9490&lt;/span&gt;&lt;/a&gt;
    Dallas 1-wire &lt;span class="caps"&gt;USB&lt;/span&gt; adapter from
    &lt;a href="http://www.hobby-boards.com/"&gt;Hobby-Boards.com&lt;/a&gt; along with five
    &lt;a href="http://www.hobby-boards.com/catalog/product_info.php?products_id=93"&gt;&lt;span class="caps"&gt;DS18S20P&lt;/span&gt;&lt;/a&gt;
    1-wire parasite power temperature sensors. I&amp;#8217;ve wired those up with
    one in the living room near the existing thermostat, one in my
    bedroom, and one stuck about five feet up one of the A/C conduits,
    to sense when the system is actually putting out cold air. I&amp;#8217;ve had
    them logging to MySQL since 0200&amp;nbsp;today.&lt;/li&gt;
&lt;li&gt;I decided to bite the bullet and order a beautiful &lt;a href="http://www.crystalfontz.com/products/635xes/index.html"&gt;CrystalFontz
    &lt;span class="caps"&gt;XES635BK&lt;/span&gt;-&lt;span class="caps"&gt;TMF&lt;/span&gt;-&lt;span class="caps"&gt;KU&lt;/span&gt;&lt;/a&gt;
    for the physical interface. It&amp;#8217;s a little backlit &lt;span class="caps"&gt;LCD&lt;/span&gt; display, in a
    surface-mount box, along with four bi-color LEDs and a 6-button
    keypad. That should handle the interface for anyone who doesn&amp;#8217;t want
    to grab a&amp;nbsp;console.&lt;/li&gt;
&lt;li&gt;I&amp;#8217;ll be looking for a eight-pin header so that the relays will plug
    right in to the screw-terminal block that the thermostat uses, to
    make for easy switching to the original thermostat if needed (or
    when moving out in a&amp;nbsp;year).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, in terms of&amp;nbsp;software:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A Python text-based configuration/administration program. Will be
    accessed via &lt;span class="caps"&gt;SSH&lt;/span&gt; or &lt;span class="caps"&gt;KVM&lt;/span&gt; for the actual&amp;nbsp;machine.&lt;/li&gt;
&lt;li&gt;Lots of state data stored in files under&amp;nbsp;/var.&lt;/li&gt;
&lt;li&gt;A python script, run via cron every 2 minutes, that checks
    temperatures from the 1-wire bus, logs them to MySQL (on a remote
    host) and updates the temperature files in&amp;nbsp;/var.&lt;/li&gt;
&lt;li&gt;A master control script, run via cron every minute, that looks at
    the temperatures, the current system state, any manual overrides
    that exist, and decides what relays should be on or&amp;nbsp;off.&lt;/li&gt;
&lt;li&gt;A daemon to handle relay&amp;nbsp;control.&lt;/li&gt;
&lt;li&gt;A daemon to handle the &lt;span class="caps"&gt;LCD&lt;/span&gt; display output and keypad input
    (including immediate manual&amp;nbsp;overrides).&lt;/li&gt;
&lt;li&gt;A method of providing overrides of the programmed schedule on a
    single-instance basis, i.e. &amp;#8220;system completely off from 2008-06-06
    18:00 to 2008-06-08&amp;nbsp;15:00&amp;#8221;.&lt;/li&gt;
&lt;/ol&gt;</content><category term="1wire"></category><category term="automation"></category><category term="home control"></category><category term="linux"></category><category term="thermostat"></category></entry><entry><title>Getting SunSPOTs working under OpenSuSE 10.1</title><link href="https://blog.jasonantman.com/2008/05/getting-sunspots-working-under-opensuse-101/" rel="alternate"></link><published>2008-05-13T13:09:00-04:00</published><updated>2008-05-13T13:09:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-05-13:/2008/05/getting-sunspots-working-under-opensuse-101/</id><summary type="html">&lt;p&gt;So I&amp;#8217;ve been playing around with&lt;a href="http://www.sunspotworld.com"&gt;SunSPOT&lt;/a&gt;s
lately. Or trying to. My only x86 (32-bit) machines are an old desktop
running OpenSuSE 10.1 and my eeePC. It looks like I just killed my new
install on the &lt;span class="caps"&gt;8GB&lt;/span&gt; &lt;span class="caps"&gt;SDHC&lt;/span&gt; card, so I gave the desktop a try …&lt;/p&gt;</summary><content type="html">&lt;p&gt;So I&amp;#8217;ve been playing around with&lt;a href="http://www.sunspotworld.com"&gt;SunSPOT&lt;/a&gt;s
lately. Or trying to. My only x86 (32-bit) machines are an old desktop
running OpenSuSE 10.1 and my eeePC. It looks like I just killed my new
install on the &lt;span class="caps"&gt;8GB&lt;/span&gt; &lt;span class="caps"&gt;SDHC&lt;/span&gt; card, so I gave the desktop a try. I&amp;#8217;d already
tried once with the install of Orange from the &lt;span class="caps"&gt;CD&lt;/span&gt; that came with them,
and had NetBeans 6 installed, so I had to do some recovery. The
procedure was as&amp;nbsp;follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install all of the Java6 java-sun packages (specifically the base as&amp;nbsp;devel).&lt;/li&gt;
&lt;li&gt;Download the Java 6 &lt;span class="caps"&gt;JDK&lt;/span&gt; from Sun, and install all of the&amp;nbsp;RPMs.&lt;/li&gt;
&lt;li&gt;Screw with /usr/lib/jvm and get it sane - specifically, replace all
    of the symlinks that point to /etc/alternatives with new ones
    pointing to the Java6 install in&amp;nbsp;/usr/lib/jvm/java-1.6.0-sun-1.6.0&lt;/li&gt;
&lt;li&gt;Delete your entire .netbeans directory (I was having serious issues
    with&amp;nbsp;NetBeans).&lt;/li&gt;
&lt;li&gt;Start NetBeans from the command line with an explicitly set jdkhome:
    &amp;#8220;netbeans &amp;#8212;jdkhome&amp;nbsp;/usr/lib/jvm/java-1.6.0-sun-1.6.0&lt;/li&gt;
&lt;li&gt;Download the &lt;span class="caps"&gt;SPOT&lt;/span&gt; plugin for NetBeans, following the instructions on
    &lt;a href="http://weblogs.java.net/blog/brunogh/archive/2008/04/starting_with_s.html"&gt;Bruno Ghisi&amp;#8217;s
    blog&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Once installed, you should have a little &lt;span class="caps"&gt;SPOT&lt;/span&gt;-looking icon on the
    toolbar below &amp;#8220;Navigate&amp;#8221;. Click on it, and launch SPOTManager from
    the link in the right panel (&amp;#8220;Sun SPOTs Info&amp;#8221;, the link is an icon
    not text). Go through whatever configuration is&amp;nbsp;needed.&lt;/li&gt;
&lt;li&gt;Upgrade local &lt;span class="caps"&gt;SDK&lt;/span&gt; to Purple (Click the &lt;span class="caps"&gt;SDK&lt;/span&gt; tab, select &amp;#8220;v3.0 Purple&amp;#8221;
    from the right panel, click the Upgrade button near the&amp;nbsp;bottom).&lt;/li&gt;
&lt;li&gt;Upgrade your demos following davidgs&amp;#8217;s &lt;a href="http://blogs.sun.com/davidgs/entry/beta_follow_up"&gt;blog
    posting&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Upgrade all of the SPOTs to Purple (plug them in one at a time, on
    the SPOTManager SunSPOTs tab, click&amp;nbsp;&amp;#8220;Upgrade&amp;#8221;).&lt;/li&gt;
&lt;li&gt;I&amp;#8217;m still having some minor issues here. I&amp;#8217;ll update when I have
    everything figured&amp;nbsp;out&amp;#8230;&lt;/li&gt;
&lt;/ol&gt;</content><category term="java"></category><category term="linux"></category><category term="netbeans"></category><category term="sun"></category><category term="sunspot"></category></entry><entry><title>SunSPOT; CarPC; MediaWiki Logging</title><link href="https://blog.jasonantman.com/2008/05/sunspot-carpc-mediawiki-logging/" rel="alternate"></link><published>2008-05-07T10:03:00-04:00</published><updated>2008-05-07T10:03:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-05-07:/2008/05/sunspot-carpc-mediawiki-logging/</id><summary type="html">&lt;p&gt;Well, finals season is upon me. That&amp;#8217;s probably why I haven&amp;#8217;t been
posting much lately (I haven&amp;#8217;t even been checking &lt;a href="http://reader.google.com/"&gt;Google
Reader&lt;/a&gt; - I&amp;#8217;ll have to delete a few thousand
entries when I get back into the swing of things). I&amp;#8217;ve been pretty
busy, between studying …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Well, finals season is upon me. That&amp;#8217;s probably why I haven&amp;#8217;t been
posting much lately (I haven&amp;#8217;t even been checking &lt;a href="http://reader.google.com/"&gt;Google
Reader&lt;/a&gt; - I&amp;#8217;ll have to delete a few thousand
entries when I get back into the swing of things). I&amp;#8217;ve been pretty
busy, between studying, projects, and work. I&amp;#8217;ll be working 4 days a
week through June 20th, as well as taking night classes 4 nigths a week
(unfortunately not the same 4 days) through July 3, in an effort to
graduate Rutgers on time (after transferring in and also switching
majors). Work after June 20th is up in the air - who knows how hard the
budget cuts will&amp;nbsp;hit.&lt;/p&gt;
&lt;p&gt;My internship as the Sun Microsystems Campus Ambassador to Rutgers is
over on May 12th. I got a chance to do the Rutgers &lt;span class="caps"&gt;IT&lt;/span&gt; Vendor Fair with
Sun, and met a few cool people - especially including Matt McGrath of
&lt;a href="http://www.conres.com/"&gt;Continental Resources&lt;/a&gt;, a Sun Strategic iForce
Partner, who&amp;#8217;s doing some wonderful things with the &lt;a href="http://www.sun.com/solutions/landing/industry/education/edu_essentials.jsp"&gt;Sun Education
Essentials Matching Grant
Program&lt;/a&gt;,
and &lt;a href="http://opsamericas.com/"&gt;Skip Paul&lt;/a&gt;, a Linux Systems Engineer for
Novell&amp;#8217;s Open Platform Solutions group. I also finally cracked open my
demo set of &lt;a href="http://www.sunspotworld.com/"&gt;SunSPOT&lt;/a&gt;s. Wonderful little
devices, radio, run Java on the bare metal, and have temperature
sensors, accelerometers, and liberal I/O. My first development exereice
will probably be making a temperature and acceleration data logger for
my truck, but there&amp;#8217;s surely more to come. They&amp;#8217;re&amp;nbsp;great!&lt;/p&gt;
&lt;p&gt;My newest project - which I&amp;#8217;m hoping to spend nearly the whole summer on
- is the &lt;a href="http://www.jasonantman.com/tuxtruck/"&gt;TuxTruck&lt;/a&gt;. I&amp;#8217;ve been
frustrated with the lack of &amp;#8220;smartness&amp;#8221; in my truck (an 06 Ford F-250),
not to mention having to remember my &lt;span class="caps"&gt;MP3&lt;/span&gt; player so I can listen to
podcasts on the way to work, and having so many gadgets in my truck. So,
the solution is obvious: a Linux-based
&lt;a href="http://en.wikipedia.org/wiki/Carpc"&gt;CarPC&lt;/a&gt;. A nice little Mini-&lt;span class="caps"&gt;ATX&lt;/span&gt; box
under a seat, with a 7&amp;#8221; pull-out touchscreen in the dash (replacing the
factory radio). It&amp;#8217;s a big, complicated, and expensive project - but I
want one, and I could use some experience with smaller systems.&lt;br&gt;
The major features I have&amp;nbsp;planned:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Realtime &lt;span class="caps"&gt;GPS&lt;/span&gt;&amp;nbsp;navigation&lt;/li&gt;
&lt;li&gt;Hands-free bluetooth calls from my cell, with address book, routing
    to contact address, possibly voice&amp;nbsp;dialing.&lt;/li&gt;
&lt;li&gt;Realtime&amp;nbsp;weather&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;OBD&lt;/span&gt;-&lt;span class="caps"&gt;II&lt;/span&gt; interface, for vehicle diagnostics and fuel
    efficiency/performance&amp;nbsp;profiling&lt;/li&gt;
&lt;li&gt;Audio - at a minimum searching and playing MP3s, and automatically
    downloading podcasts and throwing them in a playlist. Perhaps also
    an &lt;span class="caps"&gt;AM&lt;/span&gt;/&lt;span class="caps"&gt;FM&lt;/span&gt;&amp;nbsp;tuner&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It&amp;#8217;s not an easy project. So far, the major challenges seem to&amp;nbsp;be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No full-featured &lt;span class="caps"&gt;GPS&lt;/span&gt; navigation package available. The ones that are
    available don&amp;#8217;t seem to be too easy to integrate into my planned
    &lt;span class="caps"&gt;GUI&lt;/span&gt;, which will allot them 800x420 pixels (on an 800x480 screen) and
    requre the bottom toolbar to be always&amp;nbsp;available.&lt;/li&gt;
&lt;li&gt;How to handle processing of multiple data streams that require
    near-real-time processing - specifically, &lt;span class="caps"&gt;GPS&lt;/span&gt; with text-to-speech,
    turn-by-turn directions, plus playing audio, plus responding to an
    incoming phone call in a timely manner, pausing the audio, and
    stopping &lt;span class="caps"&gt;GPS&lt;/span&gt; audio but continuing&amp;nbsp;navigation.&lt;/li&gt;
&lt;li&gt;Whether to install a smaller stereo and use aux input for audio, or
    totally rip out the stereo, use an amp with the computer as its only
    input, and then how to control&amp;nbsp;volume?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There will be more to come in the future. For now, take a look at &lt;a href="https://github.com/jantman/tuxtruck"&gt;the
TuxTruck github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update Saturday, March 2, 2013&lt;/strong&gt; - I&amp;#8217;m in the process of migrating my
legacy &lt;span class="caps"&gt;CVS&lt;/span&gt; and Subversion repositories to
&lt;a href="http://github.com/jantman/"&gt;github.com&lt;/a&gt;. The forgotten &lt;span class="caps"&gt;SVN&lt;/span&gt; repository
for TuxTruck has been migrated there, and the &lt;span class="caps"&gt;CVS&lt;/span&gt; repository will soon
be moved there as well. Tuxtruck.org has been permanently taken offline
and redirected to the GitHub&amp;nbsp;repository.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mediawiki Logging&lt;/strong&gt; - I recently
had a situation where I had to confirm how much work someone had done on
a MediaWiki-based project. The Recent Changes page only goes back 30
days, and walking through the History of each page is a pain. After
looking around in the database a bit, I found a few tables of&amp;nbsp;interest:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Table &amp;#8220;users&amp;#8221; includes fields &amp;#8220;user_touched&amp;#8221; (last time the user
    was updated) and &amp;#8220;user_editcount&amp;#8221; (a really simple count of the
    users&amp;#8217; number of&amp;nbsp;edits).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Table &amp;#8220;recentchanges&amp;#8221; holds a lot of data&amp;#8230; seemingly the entire
    life of the&amp;nbsp;wiki&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="bluetooth"></category><category term="car"></category><category term="carpc"></category><category term="conres"></category><category term="gps"></category><category term="linux"></category><category term="mediawiki"></category><category term="novell"></category><category term="obd"></category><category term="rutgers"></category><category term="sun"></category><category term="sunspot"></category><category term="suse"></category><category term="tuxtruck"></category></entry><entry><title>Asus eeePC Update</title><link href="https://blog.jasonantman.com/2008/02/asus-eeepc-update/" rel="alternate"></link><published>2008-02-04T19:12:00-05:00</published><updated>2008-02-04T19:12:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2008-02-04:/2008/02/asus-eeepc-update/</id><summary type="html">&lt;p&gt;More to come sometime this week, when I have enough sanity and time to&amp;nbsp;write.&lt;/p&gt;
&lt;p&gt;In the mean&amp;nbsp;time&amp;#8230;&lt;/p&gt;
&lt;p&gt;So it&amp;#8217;s been two weeks since classes started again, and that means two
weeks using my now-beloved eeePC 4G Surf (details in a &lt;a href="/2008/01/eeepc-solaris-other-updates.html"&gt;previous
post&lt;/a&gt;).
Granted, I have my &amp;#8220;desktop …&lt;/p&gt;</summary><content type="html">&lt;p&gt;More to come sometime this week, when I have enough sanity and time to&amp;nbsp;write.&lt;/p&gt;
&lt;p&gt;In the mean&amp;nbsp;time&amp;#8230;&lt;/p&gt;
&lt;p&gt;So it&amp;#8217;s been two weeks since classes started again, and that means two
weeks using my now-beloved eeePC 4G Surf (details in a &lt;a href="/2008/01/eeepc-solaris-other-updates.html"&gt;previous
post&lt;/a&gt;).
Granted, I have my &amp;#8220;desktop replacement&amp;#8221; laptop (&lt;a href="http://www.linuxcertified.com/linux-laptop-lc2464.html"&gt;a Linux Certified
&lt;span class="caps"&gt;LC2464&lt;/span&gt;&lt;/a&gt;) to use
at my desk at home or at my apartment - though the &amp;#8220;desktop replacement&amp;#8221;
really means that it&amp;#8217;s easy to move from one desk to&amp;nbsp;another.&lt;/p&gt;
&lt;p&gt;So far, I really love it, but I have a few&amp;nbsp;issues:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I should have bought an &lt;span class="caps"&gt;8GB&lt;/span&gt; &lt;span class="caps"&gt;SDHC&lt;/span&gt; card instead of the &lt;span class="caps"&gt;4GB&lt;/span&gt; that I got&lt;ul&gt;
&lt;li&gt;especially with a full install of OpenSuSE with Sun&amp;#8217;s &lt;span class="caps"&gt;JDK&lt;/span&gt; and
OpenOffice, the &lt;span class="caps"&gt;2GB&lt;/span&gt; root partition is 99%&amp;nbsp;full!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;After using a desktop for hours, it takes a few lines of text for my
    fingers to re-adjust to the small keyboard. Hopefully it&amp;#8217;ll get
    easier with&amp;nbsp;time.&lt;/li&gt;
&lt;li&gt;Unfortunately, I don&amp;#8217;t have space for kernel headers or source, so I
    can&amp;#8217;t compile the customized version of asus_acpi. I can&amp;#8217;t find any
    binary packges, or binary kernel modules for my kernel version. That
    prevents me from using sleep/hibernate/suspend, and also means I
    don&amp;#8217;t get accurate battery calculations. I&amp;#8217;ve found from usage that
    the battery lasts 2-3 hours with wireless on and minimal screen
    brightness. Also, unfortunately, (maybe because of the &lt;span class="caps"&gt;ACPI&lt;/span&gt; issue?)
    if I dim the screen and then the screensaver comes on, when I log
    back in it resets to full&amp;nbsp;brightness.&lt;/li&gt;
&lt;li&gt;As of this week, there&amp;#8217;s still no MadWifi driver for the Atheros
    card in the 4G. I have to run it under Ndiswrapper. As a result, I
    can&amp;#8217;t get monitor mode, so the eee is effectively useless for
    wireless site surveys and security work. There&amp;#8217;s talk of a
    forthcoming MadWifi, but if nothing shows up, I may have to go with
    a &lt;span class="caps"&gt;USB&lt;/span&gt; adapter (I don&amp;#8217;t want to void the warranty by swapping out the
    internal Mini-&lt;span class="caps"&gt;PCI&lt;/span&gt;&amp;nbsp;adapter).&lt;/li&gt;
&lt;li&gt;Not a problem with the eeePC, but it seems like quite a few web
    sites that I&amp;#8217;ve visited are horribly coded - with static screen
    sizes assumed. On the small screen on the eee, the biggest issue is
    when the first few characters of every line on some sites are cut
    off, thereby rendering the content illegible. This is an issue out
    of Asus&amp;#8217; control, but can be a hindrance to full use. I have,
    however, found that for many sites, switching &lt;span class="caps"&gt;FF&lt;/span&gt; to &amp;#8220;full screen&amp;#8221;
    mode (F11)&amp;nbsp;helps.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Stay tuned for more, and some new scripts to automate wireless surveys,
rogue &lt;span class="caps"&gt;AP&lt;/span&gt; detection, etc. And maybe even some work with autonomics and or
configuration&amp;nbsp;tools.&lt;/p&gt;</content><category term="eeepc"></category><category term="linux"></category></entry><entry><title>*nix</title><link href="https://blog.jasonantman.com/2007/09/nix/" rel="alternate"></link><published>2007-09-28T13:22:00-04:00</published><updated>2007-09-28T13:22:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2007-09-28:/2007/09/nix/</id><summary type="html">&lt;p&gt;First off, my Sun blog should be coming sometime this weekend/early next
week. If I post anything interesting there, I&amp;#8217;ll be sure to cross-post&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;This morning at work, while reading &lt;a href="http://digg.com"&gt;Digg&lt;/a&gt;, I came by
two interesting links that got me thinking:
&lt;a href="http://www.foogazi.com/2007/09/27/5-reasons-your-parents-should-use-linux/"&gt;5 Reasons Your Parents Should Use …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;First off, my Sun blog should be coming sometime this weekend/early next
week. If I post anything interesting there, I&amp;#8217;ll be sure to cross-post&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;This morning at work, while reading &lt;a href="http://digg.com"&gt;Digg&lt;/a&gt;, I came by
two interesting links that got me thinking:
&lt;a href="http://www.foogazi.com/2007/09/27/5-reasons-your-parents-should-use-linux/"&gt;5 Reasons Your Parents Should Use
Linux&lt;/a&gt;
and &lt;a href="http://warpedvisions.org/2006/12/30/ten-things-linux-distros-get-right-that-ms-doesnt/"&gt;Ten Things Linux Distros Get Right (That &lt;span class="caps"&gt;MS&lt;/span&gt;
Doesn&amp;#8217;t)&lt;/a&gt;.
Now, I&amp;#8217;ll admit, my *nix experience is pretty much limited to Linux.
I&amp;#8217;ve used &lt;span class="caps"&gt;BSD&lt;/span&gt; a few times, but only as pre-built images for embedded
systems like my &lt;a href="http://www.soekris.com"&gt;Soekris&lt;/a&gt; boxen. I&amp;#8217;ve used
Solaris mainly just as a user/web developer in &lt;span class="caps"&gt;SSH&lt;/span&gt; at work. And while I
now have a work computer running Solaris 10 and a &lt;span class="caps"&gt;SXDE&lt;/span&gt; image on my
laptop, I&amp;#8217;m still relatively new - and, given that I&amp;#8217;m now doing
hardware support and wireless work, I don&amp;#8217;t even know what I need
another machine in the office&amp;nbsp;for.&lt;/p&gt;
&lt;p&gt;That being said, the second link got me thinking. Specifically, about
something I read in &lt;a href="http://www.catb.org/~esr/writings/taoup/"&gt;The Art of Unix
Programming&lt;/a&gt; [Wikipedia] by
Eric S. Raymond (available online
&lt;a href="http://www.catb.org/~esr/writings/taoup/html/"&gt;here&lt;/a&gt;) with regards to
interface design. One quote that I was able to find in the online
version, comes from Chapter 11, under the subtitle &amp;#8220;Tradeoffs between
&lt;span class="caps"&gt;CLI&lt;/span&gt; and Visual Interfaces&amp;#8221;, &amp;#8220;Resistance to &lt;span class="caps"&gt;CLI&lt;/span&gt; interfaces tends to
decrease as users become more expert. In many problem domains, users
(especially frequent
users) reach a crossover point at which the concision and expressiveness
of &lt;span class="caps"&gt;CLI&lt;/span&gt; becomes more valuable than avoiding its mnemonic load. Thus, for
example, computing novices prefer the ease of &lt;span class="caps"&gt;GUI&lt;/span&gt; desktops, but
experienced users often gradually discover that they prefer typing
commands to a&amp;nbsp;shell.&amp;#8221;&lt;/p&gt;
&lt;p&gt;There is another similar
quote in the book, mentioning how resistance to the &lt;span class="caps"&gt;CLI&lt;/span&gt; drops as
&lt;em&gt;typing speed&lt;/em&gt;&amp;nbsp;increases.&lt;/p&gt;
&lt;p&gt;Unfortunately, in some areas I&amp;#8217;m still bound to Windows. Though my only
personal use for it is to control an ancient Umax Mirage IIse &lt;span class="caps"&gt;SCSI&lt;/span&gt;
scanner (with only Windows and Mac drivers), I ultimately need to touch
it now and then - whether on my mother&amp;#8217;s box (she claims she has to have
Windows and &lt;span class="caps"&gt;MS&lt;/span&gt; Office because &amp;#8220;that&amp;#8217;s what businesses use&amp;#8221;) or as admin
of the four boxes at the &lt;a href="http://www.midlandparkambulance.com"&gt;Ambulance
Corps&lt;/a&gt; where I&amp;nbsp;volunteer.&lt;/p&gt;
&lt;p&gt;However, whenever I am (unfortunately) pushed into the task of working
on a Windows box, I always feel something lacking. To be blunt, I don&amp;#8217;t
see how experienced users can deal with it. And this isn&amp;#8217;t just an issue
of multiple desktops, or reliability (I expect my desktop to have months
of uptime, and my servers to have years). This isn&amp;#8217;t just pro-Linux,
it&amp;#8217;s anti-Windows. Linux is great. Solaris seems wonderful, and I can&amp;#8217;t
want to move my servers over. And, believe it or not, due to playing
around with the Solaris Management Console, for the first time in 5
years, I plan on running X on my servers.
What this is, is a talk about total workflow. Years ago, I reached the
point where I am more comfortable at the command line, or in an
Ncurses-style &lt;span class="caps"&gt;GUI&lt;/span&gt;, than in&amp;nbsp;X.&lt;/p&gt;
&lt;p&gt;I an attribute this to two factors - verbosity and speed. The &lt;span class="caps"&gt;CLI&lt;/span&gt; is as
verbose as anything can get. I remember setting a static &lt;span class="caps"&gt;IP&lt;/span&gt; on a Windows
box. I had to navigate the Start menu, open up the control panel, the
network thingy, click on the network card, and work through a series of
dialogs. In Linux, I clicked on the terminal icon, typed &amp;#8220;sudo ifconfig
eth0 up 192.168.0.211&amp;#8221; and then a password. Done. Likewise, refreshing a
&lt;span class="caps"&gt;DHCP&lt;/span&gt; lease on Windows requires a whole bunch of &amp;#8220;repair connection&amp;#8221;
nonsense, whereas in Linux all it requires is &amp;#8220;dhclient eth0&amp;#8221;. The
bottom line I know what I&amp;#8217;m doing. Windows should have an option to let
me quickly do&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Speed is a related issue. Click, click-click, drag, click, click&amp;#8230;.
what about just typing? Even for people who aren&amp;#8217;t &lt;span class="caps"&gt;CLI&lt;/span&gt;-friendly, there&amp;#8217;s
Ncurses. YaST2, the SuSE/openSuSE administration tool, has both &lt;span class="caps"&gt;GUI&lt;/span&gt; and
Ncurses interfaces. I always use the Ncurses interface. Why? Because
I&amp;#8217;ve been using it for years. I know that if I want to add a user
through YaST, I hit the down arrow 7 times, tab once, down 5, enter. Tab
once more to bring up the add user dialog. I can do this in well under a
second. What&amp;#8217;s the bottom line? Well, first of all, my hands are already
on the keyboard. That&amp;#8217;s where they like to stay. That&amp;#8217;s where they&amp;#8217;re
comfortable. My fingers need to move a *lot* less to navigate with the
arrow keys, tab, and enter than they do to use a mouse. If you know what
you&amp;#8217;re doing, if you already know what you&amp;#8217;re looking for, then a mouse
is slower than the speed of thought (or&amp;nbsp;reaction).&lt;/p&gt;
&lt;p&gt;So where&amp;#8217;s the Windows bashing? Simple. How do people at Microsoft deal
with this? How does the guy who *wrote* that network settings dialog
deal with navigating the &lt;span class="caps"&gt;GUI&lt;/span&gt; every time, even though he already knows
exactly what he wants to do - and probably the system calls to do&amp;nbsp;it?&lt;/p&gt;
&lt;p&gt;The bottom line is that every time I sit down at a Windows machine, I
wonder how the most popular &lt;span class="caps"&gt;OS&lt;/span&gt; is one that doesn&amp;#8217;t give any thought to
advanced users. I know that I can type faster than I can move a mouse,
why don&amp;#8217;t you let me use that? More importantly, why didn&amp;#8217;t Microsoft
ever think that people would use computers on a network? When I
installed Solaris, I wanted to edit a config file. I hadn&amp;#8217;t customized
&lt;em&gt;anything&lt;/em&gt; yet, hadn&amp;#8217;t installed any other software, nothing. Yet, I
was able to open up a terminal and grab my .emacs file from my laptop in
one line&amp;nbsp;(scp).&lt;/p&gt;
&lt;p&gt;To be totally honest, the question running through my mind is something
like &amp;#8220;everything is so much quicker on Linux. How do experts deal with&amp;nbsp;Windows?&amp;#8221;&lt;/p&gt;</content><category term="Digg"></category><category term="Eric S Raymond"></category><category term="linux"></category><category term="solaris"></category><category term="sun"></category><category term="Unix"></category></entry><entry><title>Update</title><link href="https://blog.jasonantman.com/2007/07/update/" rel="alternate"></link><published>2007-07-14T01:14:00-04:00</published><updated>2007-07-14T01:14:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2007-07-14:/2007/07/update/</id><summary type="html">&lt;p&gt;I haven&amp;#8217;t been too active on here lately, mainly due to spending my
summer as a paid transport &lt;span class="caps"&gt;EMT&lt;/span&gt;, working 50 hours a week or so, and still
trying to keep up on&amp;nbsp;&amp;#8220;life&amp;#8221;.&lt;/p&gt;
&lt;p&gt;I have a few things planned for the next month or so of summer, so …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I haven&amp;#8217;t been too active on here lately, mainly due to spending my
summer as a paid transport &lt;span class="caps"&gt;EMT&lt;/span&gt;, working 50 hours a week or so, and still
trying to keep up on&amp;nbsp;&amp;#8220;life&amp;#8221;.&lt;/p&gt;
&lt;p&gt;I have a few things planned for the next month or so of summer, so stay
tuned. Some of them&amp;nbsp;include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Redesign of my site including lots of information that&amp;#8217;s been stored
    away in text files, and a new wiki for technical&amp;nbsp;information.&lt;/li&gt;
&lt;li&gt;Some embedded development work, and notes on&amp;nbsp;that.&lt;/li&gt;
&lt;li&gt;Converting some sort of low-cost handheld computer, tablet, or eBook
    reader for use as a Linux-based &lt;span class="caps"&gt;RSS&lt;/span&gt; reader (updated over &lt;span class="caps"&gt;LAN&lt;/span&gt; nightly
    and cached locally), hopefully including an image of my software as
    well as some conduit to an &lt;span class="caps"&gt;RSS&lt;/span&gt; reader program, and ability to email
    a list of &amp;#8220;flagged&amp;#8221; articles on sync (&lt;span class="caps"&gt;RSS&lt;/span&gt; update over&amp;nbsp;network).&lt;/li&gt;
&lt;li&gt;A vast update of my &lt;a href="http://repo.jasonantman.com"&gt;Code Repo&lt;/a&gt; with
    most of my home-grown F/&lt;span class="caps"&gt;OSS&lt;/span&gt; programs, including my (very basic)
    web-based budget/finance&amp;nbsp;program.&lt;/li&gt;
&lt;li&gt;An update to &lt;a href="http://php-ems-tools.com"&gt;&lt;span class="caps"&gt;PHP&lt;/span&gt; &lt;span class="caps"&gt;EMS&lt;/span&gt;&amp;nbsp;Tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Notes on my experience with MythTV, an integrating it with &lt;span class="caps"&gt;IR&lt;/span&gt;
    controls, Cablevision &lt;span class="caps"&gt;SA&lt;/span&gt; set-top box, and ultimately a &amp;#8220;smart&amp;nbsp;room&amp;#8221;.&lt;/li&gt;
&lt;li&gt;My never-ending quest to find a way to interface a &lt;span class="caps"&gt;CDMA&lt;/span&gt; handset to a
    computer for purposes of sending &lt;span class="caps"&gt;SMS&lt;/span&gt; from the command line (Nagios
    out-of-band alerts on a&amp;nbsp;budget).&lt;/li&gt;
&lt;li&gt;A trial run of Asterisk and VoIP from the house to the&amp;nbsp;dorm.&lt;/li&gt;
&lt;li&gt;Some more projects including:&lt;ul&gt;
&lt;li&gt;Finding and implementing a hardware/software trouble- and
    change-tracking system, which will also integrate with my&amp;nbsp;Wiki.&lt;/li&gt;
&lt;li&gt;Choosing bug tracking software for my internal&amp;nbsp;projects.&lt;/li&gt;
&lt;li&gt;Choosing and implementing a network-wide backup system to handle
    *nix, Windows, and my remote *nix&amp;nbsp;machines.&lt;/li&gt;
&lt;li&gt;OpenSolaris.&lt;/li&gt;
&lt;li&gt;Figuring out a system to handle automated nightly/weekly tasks
    on my diverse machines including log analysis, backups, software
    updates, and the usual stuff (SpamAssassin updates and training
    and other routine&amp;nbsp;tasks).&lt;/li&gt;
&lt;li&gt;A status tracker/to-do list of my numerous&amp;nbsp;projects.&lt;/li&gt;
&lt;li&gt;Releasing most of my web-based kludges under &lt;span class="caps"&gt;GPL&lt;/span&gt; for anyone who
    may be&amp;nbsp;interested.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="emergency medical"></category><category term="linux"></category><category term="mythtv"></category><category term="php ems tools"></category><category term="tablet"></category><category term="update"></category></entry><entry><title>Managing G1 Proliant Servers with modern Linux</title><link href="https://blog.jasonantman.com/2007/03/managing-g1-proliant-servers-with-modern-linux/" rel="alternate"></link><published>2007-03-01T16:27:00-05:00</published><updated>2007-03-01T16:27:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2007-03-01:/2007/03/managing-g1-proliant-servers-with-modern-linux/</id><summary type="html">&lt;p&gt;Not much of an &amp;#8220;upgrade&amp;#8221; for anyone who&amp;#8217;s in &lt;span class="caps"&gt;IT&lt;/span&gt;, but jasonantman.com is
currently being upgraded from old desktops used as servers to a pile of
generation-1 (G1) &lt;span class="caps"&gt;HP&lt;/span&gt;/Compaq Proliants. I know that there are utilities
for Linux to manage the servers, specifically control fan speed and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Not much of an &amp;#8220;upgrade&amp;#8221; for anyone who&amp;#8217;s in &lt;span class="caps"&gt;IT&lt;/span&gt;, but jasonantman.com is
currently being upgraded from old desktops used as servers to a pile of
generation-1 (G1) &lt;span class="caps"&gt;HP&lt;/span&gt;/Compaq Proliants. I know that there are utilities
for Linux to manage the servers, specifically control fan speed and
monitor hardware-level health for Linux. However, the most recent
download on &lt;span class="caps"&gt;HP&lt;/span&gt;&amp;#8217;s site is for &lt;span class="caps"&gt;SLES9&lt;/span&gt;. All of my boxes will be running
openSuSE 10.2, and the &lt;span class="caps"&gt;SLES9&lt;/span&gt; version wouldn&amp;#8217;t install on&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;After an hour long phone call to &lt;span class="caps"&gt;HP&lt;/span&gt; support, I ended up speaking with
Paulo, the third support person I was transferred to. #1 read off the
web site, #2 knew what Linux was, but Paulo (#3) actually told me that
he was experimenting with installing &lt;span class="caps"&gt;HPASM&lt;/span&gt; (&lt;span class="caps"&gt;HP&lt;/span&gt;&amp;#8217;s server
administration/management utility) on an older Proliant as well. He
spent about half an hour walking me through it. Here&amp;#8217;s what I&amp;nbsp;found:&lt;/p&gt;
&lt;p&gt;The most compatible version of &lt;span class="caps"&gt;HPASM&lt;/span&gt; (I guess it&amp;#8217;s some hidden feature
for people who know it) is the version for the &lt;span class="caps"&gt;DL380&lt;/span&gt; G4. Paulo
instructed me to download this &lt;span class="caps"&gt;RPM&lt;/span&gt; from their site. I did, choosing the
&lt;span class="caps"&gt;SLES10&lt;/span&gt; (x86) download (hpasm-7.7.0-115.sles10.i586.rpm). This installed
fine. Running &lt;code&gt;hpasm status&lt;/code&gt; from the command line asks us to activate
it first. Do the activation. Now, running &lt;code&gt;hpasm status&lt;/code&gt; still asks us
to activate. Paulo confirmed this as happening on his machine too. Try
&lt;code&gt;/etc/init.d/hpasm status&lt;/code&gt; and you should see that all of the modules
are&amp;nbsp;working.&lt;/p&gt;
&lt;p&gt;Now, the install is complete. I&amp;#8217;m not sure if the &lt;span class="caps"&gt;SNMP&lt;/span&gt; works, but it
should as long as your snmpd is running. The &lt;code&gt;hpasm activate&lt;/code&gt; command
modifies snmpd.conf appropriately. and you will be queried for the
currect configuration&amp;nbsp;information.&lt;/p&gt;
&lt;p&gt;To give it a test, run &lt;code&gt;hplog -f&lt;/code&gt; or &lt;code&gt;hplog -p&lt;/code&gt; and you should see fan
and power status,&amp;nbsp;respectively.&lt;/p&gt;
&lt;p&gt;Paulo also told me that I could download the hpadu package (also &lt;span class="caps"&gt;DL380&lt;/span&gt;
G4 / &lt;span class="caps"&gt;SLES10&lt;/span&gt;) to get array diagnostics, He warned me that some of the
install scripts in &lt;span class="caps"&gt;HPADU&lt;/span&gt; look for the web management homepage, which we
haven&amp;#8217;t installed. To get around this, install the &lt;span class="caps"&gt;HPADU&lt;/span&gt; &lt;span class="caps"&gt;RPM&lt;/span&gt; file
(hpadu-7.70-12.linux.rpm)
&lt;code&gt;rpm -ivh --force --nodeps --noscripts hpadu-7.70-12.linux.rpm&lt;/code&gt;. Be
aware, though, that this package is supposed to be web-based. It
installs to&amp;nbsp;/opt/hp/hpadu.&lt;/p&gt;
&lt;p&gt;The web interface, luckily for me, is written in &lt;span class="caps"&gt;PHP&lt;/span&gt;. It is pretty
complex so it might take me a while to figure out the workings, but when
I do, I&amp;#8217;ll post as much info as I can on how to make a &lt;span class="caps"&gt;CLI&lt;/span&gt; interface, or
where one exists if I can find&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Also, I&amp;#8217;ll most likely develop a Python check script to use with
&lt;a href="http://www.nagios.org"&gt;Nagios&lt;/a&gt; to monitor most of the hpasm-enabled&amp;nbsp;components.&lt;/p&gt;
&lt;p&gt;For the use of anyone else, here are some of the links that &lt;span class="caps"&gt;HP&lt;/span&gt; Support
sent me after the&amp;nbsp;call:&lt;/p&gt;
&lt;p&gt;Link for users guide for Proliant Support Pack, which includes
documentation on &lt;span class="caps"&gt;HPASM&lt;/span&gt; from the&amp;nbsp;&lt;span class="caps"&gt;CLI&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://h18000.www1.hp.com/support/files/server/us/WebDoc/720/psp-users-guide.pdf"&gt;http://h18000.www1.hp.com/support/files/server/us/WebDoc/720/psp-users-guide.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Product&amp;nbsp;manuals:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://h20180.www2.hp.com/apps/Nav?h_pagetype=s-003&amp;amp;h_lang=en&amp;amp;h_cc=us&amp;amp;h_product=241435&amp;amp;h_page=hpcom&amp;amp;h_client=z-a-r1002-3&amp;amp;cc=us〈=en"&gt;http://h20180.www2.hp.com/apps/Nav?h_pagetype=s-003&amp;amp;h_lang=en&amp;amp;h_cc=us&amp;amp;h_product=241435&amp;amp;h_page=hpcom&amp;amp;h_client=z-a-r1002-3&amp;amp;cc=us〈=en&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;ML370&lt;/span&gt;&amp;nbsp;G1&lt;/p&gt;
&lt;p&gt;&lt;a href="http://h20000.www2.hp.com/bc/docs/support/UCR/SupportManual/TPM_143091-004/TPM_143091-004.pdf"&gt;http://h20000.www2.hp.com/bc/docs/support/&lt;span class="caps"&gt;UCR&lt;/span&gt;/SupportManual/TPM_143091-004/TPM_143091-004.pdf&lt;/a&gt;&lt;/p&gt;</content><category term="compaq"></category><category term="hp"></category><category term="hpadu"></category><category term="hpasm"></category><category term="linux"></category><category term="management"></category><category term="proliant"></category><category term="psp"></category></entry><entry><title>Why hasn’t Linux caught up to Windows?</title><link href="https://blog.jasonantman.com/2007/02/why-hasnt-linux-caught-up-to-windows/" rel="alternate"></link><published>2007-02-19T17:20:00-05:00</published><updated>2007-02-19T17:20:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2007-02-19:/2007/02/why-hasnt-linux-caught-up-to-windows/</id><summary type="html">&lt;p&gt;Those of us who are involved in the Linux community are often frustrated
by the lack of widespread acceptance of Linux. Granted, I haven&amp;#8217;t used
all of the newest &amp;#8220;desktop&amp;#8221; distributions (&amp;#8216;distros&amp;#8217;), but I know that
my choice - openSuSE - is far from being ready to compete with Windows
for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Those of us who are involved in the Linux community are often frustrated
by the lack of widespread acceptance of Linux. Granted, I haven&amp;#8217;t used
all of the newest &amp;#8220;desktop&amp;#8221; distributions (&amp;#8216;distros&amp;#8217;), but I know that
my choice - openSuSE - is far from being ready to compete with Windows
for the novice user market. From the first few screens of the
installation, it&amp;#8217;s clear that this isn&amp;#8217;t something for the uninitiated.
However, to get off on a short tangent, openSuSE has also severely
hampered access to the command-line-only, text-mode installation, which
I need in order to install on many of my&amp;nbsp;servers.&lt;/p&gt;
&lt;p&gt;Granted, it will take a lot of work to get Linux to retain its&amp;#8217; strong
points, and still be user-friendly for the non-technical user. However,
there are three main points that I see as being the biggest problems for
new users. All of which, coincidentally, are ones which some people
would bill as strong points of Linux. And they all have to do directly
with some of the founding principles of Linux - interoperability and&amp;nbsp;choice.&lt;/p&gt;
&lt;h2 id="packaging"&gt;&lt;a class="toclink" href="#packaging"&gt;Packaging.&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Searching for a package for a linux system goes something like this:
figure out what package format your distro uses, figure out the distro
version and architecture, and then start checking the online
repositories. If it&amp;#8217;s something simple, you may be able to use a you
distro-specific maintenance program to automatically upgrade it. If not,
you can sift through the myriad online repositories for packages that
fit your package manager (&lt;span class="caps"&gt;RPM&lt;/span&gt;, Apt, etc.) and your distro/architecture.
If you have no luck there, find the package&amp;#8217;s homepage, and hope someone
has contributed packages for your distro and architecture - usually a
hit-or-miss situation. Last but not least, when all else has failed, you
choose either to compile from source yourself, or give up. Compiling
from source not only requires some knowledge of your system, Linux, and
the compilation sequence used by the software - hopefully the generic
&lt;span class="caps"&gt;GNU&lt;/span&gt;-style ./configure, make, make install and not some more esoteric
scheme. Furthermore, compilation requires a whole slew of tools to be
installed on your system - make, gcc, autoconf, and may others,
depending on package. While it&amp;#8217;s not practical for people with limited
resources, homogenous environments, or novice users, I operate in a
largely heterogeneous environment - i586/compatible systems running SuSE
9.3-10.2 - and therefore maintain a dedicated system for compilation, if&amp;nbsp;merited.&lt;/p&gt;
&lt;p&gt;All of this complexity just enforces the novice&amp;#8217;s idea that there is not
much software available for Linux, as many novices are limited (due to
technical knowledge) to the packages that come with their&amp;nbsp;&lt;span class="caps"&gt;OS&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;While there are a few schemes to standardize all of this, the real
solution is quite complex, and would be based on a single package system
to be adopted by all distros (beginning with the main ones). Such a
system should have the following&amp;nbsp;features:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ability to work easily with all&amp;nbsp;distros&lt;/li&gt;
&lt;li&gt;I main configuration file which can define which directories to use -
i.e. /etc, /bin,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;Support for both simple, novice-oriented interfaces and expert-level&amp;nbsp;configuration&lt;/li&gt;
&lt;li&gt;Multiple interfaces, including command-line, text/ncurses, &lt;span class="caps"&gt;GTK&lt;/span&gt;, and
other graphical&amp;nbsp;subsystems&lt;/li&gt;
&lt;li&gt;A generalized package format that is&amp;nbsp;non-distro-specific&lt;/li&gt;
&lt;li&gt;Integration with an online master-list of&amp;nbsp;repositories&lt;/li&gt;
&lt;li&gt;Ability to search, download, and install packages from these&amp;nbsp;repositories&lt;/li&gt;
&lt;li&gt;Automatic update&amp;nbsp;ability&lt;/li&gt;
&lt;li&gt;Ability to mine the repositories for updates, and display a list on
screen or emailed to a user&amp;nbsp;account&lt;/li&gt;
&lt;li&gt;Very good tools for easy compilation from&amp;nbsp;source.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Some of these ideas would be incorporated in the tool itself, and some
as add-on&amp;nbsp;modules.&lt;/p&gt;
&lt;p&gt;The features that I, as administrator of a largely heterogeneous network
of about 10 machines, would most like to see&amp;nbsp;are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Truly automatic updates via list - select which packages can be
automatically updated, and run a cron job nightly to check for any
updates for those packages and automatically get and install&amp;nbsp;them.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;LAN&lt;/span&gt;-based updating - A single server on the &lt;span class="caps"&gt;LAN&lt;/span&gt; maintains a list
(perhaps gathered via an automatic tool) of &lt;span class="caps"&gt;ALL&lt;/span&gt; packages installed on
&lt;span class="caps"&gt;ALL&lt;/span&gt; &lt;span class="caps"&gt;LAN&lt;/span&gt; machines. Each night the configured clients will update this
list over the network, and then the master server will download all
available updates for all packages. Once this is complete, it will send
a message to all &lt;span class="caps"&gt;LAN&lt;/span&gt; machines, which will then update their software
from the central repository on the &lt;span class="caps"&gt;LAN&lt;/span&gt;. This would, in effect,
automatically keep all &lt;span class="caps"&gt;LAN&lt;/span&gt; machines on the same version of each
package and totally&amp;nbsp;up-to-date.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Kernel updates would be done manually, but should have an option for the
administrator to push the update to all&amp;nbsp;machines.&lt;/p&gt;
&lt;h2 id="distro-specific-tools-filesystem-layout-etc"&gt;&lt;a class="toclink" href="#distro-specific-tools-filesystem-layout-etc"&gt;Distro-specific tools, filesystem layout,&amp;nbsp;etc.&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This is not only a barrier for novice users, but experienced users as
well. If you do a search online for Linux training, you will surely come
by a nubmer of certifications - &lt;span class="caps"&gt;NCLE&lt;/span&gt;, &lt;span class="caps"&gt;RHCE&lt;/span&gt;, etc. The many distinct
certifications - offered by each Linux vendor and independent training
companies - underscore the inherent differences in Linux distributions.
While I&amp;#8217;m perfectly comfortable working with SuSE Linux (by Novell), if
I was to sit down in front of a Gentoo system, I would probably be
totally&amp;nbsp;lost.&lt;/p&gt;
&lt;p&gt;While the &lt;span class="caps"&gt;LSB&lt;/span&gt; project (http://www.linux-foundation.org/en/&lt;span class="caps"&gt;LSB&lt;/span&gt;) has aimed
to provide compatibility between distros, there are three main points
which must still be&amp;nbsp;addressed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The organization of filesystems on different distros, specifically
the directory tree and default locations for certain components, still
differs. In the interest of usability, the Linux directory tree should
be standardized, so that locations of programs, files, etc. will be
identical across&amp;nbsp;distributions.&lt;/li&gt;
&lt;li&gt;An effort needs to be made to make administration as similar as
possible across all distros. This means that program names,
functionality, location, etc. should be standardized as much as&amp;nbsp;possible.&lt;/li&gt;
&lt;li&gt;It seems that each distro has its&amp;#8217; own administration tool - YaST for
SuSE, and others for other distros. An effort needs to be made to
develop a tool encompassing all of the features in one, distro-neutral
form. Webmin (www.webmin.com) has done this wonderfully in a web-based
interface, but attention should be focused on a text-mode console
version as&amp;nbsp;well.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="gui"&gt;&lt;a class="toclink" href="#gui"&gt;&lt;span class="caps"&gt;GUI&lt;/span&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Perhaps the biggest hurdle for novices using Linux, and the biggest
development challenge, is general ease of use. While the above two
points may fall into this category, I am specifically referring to the
general, day-to-day use of the operating&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;While I will not begin to suggest solutions, the main problems that I
see are as&amp;nbsp;follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The stability and security of Linux must be kept intact, unlike
distros such as&amp;nbsp;Lindows.&lt;/li&gt;
&lt;li&gt;There must remain a way for advanced users to perform advanced&amp;nbsp;tasks.&lt;/li&gt;
&lt;li&gt;As much of the inner workings should be hidden from the end-user as
possible, unless specifically&amp;nbsp;requested.&lt;/li&gt;
&lt;li&gt;I good system would have a field added to a users&amp;#8217; &lt;span class="caps"&gt;GECOS&lt;/span&gt; data
specifying their level of &amp;#8220;novice-ness&amp;#8221; - i.e. allowing a dumbed-down
interface for users while retaining a full interface with Expert
features for those who want&amp;nbsp;it.&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Mysterious&amp;#8221; things such as file permissions should be hidden from
novice-level users when not absolutely&amp;nbsp;needed.&lt;/li&gt;
&lt;li&gt;There must be a strong integration with &amp;#8220;anti-mistake&amp;#8221; tools and &lt;span class="caps"&gt;DWIM&lt;/span&gt;
technology. The system itself should manage file permissions in a way
that grants only the minimum needed&amp;nbsp;access.&lt;/li&gt;
&lt;li&gt;There should be good, strong mistake detection, specifically in terms
of catching a user&amp;#8217;s inadvertent changing of file permissions, deleting
required files,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;Tools should be built so that the novice user is never required to
login as root or run a root&amp;nbsp;shell.&lt;/li&gt;
&lt;li&gt;Perhaps, and I&amp;#8217;m sure this is controversial, the root account should
be given either &lt;span class="caps"&gt;CLI&lt;/span&gt;-only access, or should not have X running by
default, so as to discourage novice users from running day-to-day tasks
as&amp;nbsp;root.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I&amp;#8217;m sure I&amp;#8217;ve missed a lot, and have also probably mentioned a number of
things that are already in place. However, the bottom line is that Linux
has to be able to achieve the easy of use and interoperability (between
distros) that Windows currently has, while retaining the extensibility,
advanced features, security, and stability that make Linux what it&amp;nbsp;is.&lt;/p&gt;</content><category term="compatibility"></category><category term="development"></category><category term="distribution"></category><category term="linux"></category><category term="novice"></category><category term="windows"></category></entry></feed>