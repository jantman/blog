<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jason Antman's Blog</title><link>http://blog.jasonantman.com/</link><description></description><atom:link href="http://blog.jasonantman.com/feeds/tags/beaker.rss.xml" rel="self"></atom:link><lastBuildDate>Tue, 05 May 2015 06:45:00 -0400</lastBuildDate><item><title>Local S3 Server to Acceptance Test Netflix Ice Installation In Isolation</title><link>http://blog.jasonantman.com/2015/05/local-s3-server-to-acceptance-test-netflix-ice-installation-in-isolation/</link><description>&lt;p&gt;At work, we recently started using &lt;a href="http://netflix.github.io/"&gt;Netflix &lt;span class="caps"&gt;OSS&lt;/span&gt;&lt;/a&gt;&amp;#8216;s &lt;a href="https://github.com/Netflix/ice"&gt;Ice&lt;/a&gt; &lt;span class="caps"&gt;AWS&lt;/span&gt; cost analysis tool.
It provides a Java daemon to read and parse &lt;span class="caps"&gt;AWS&lt;/span&gt;&amp;#8217; &lt;a href="http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/detailed-billing-reports.html"&gt;detailed billing reports&lt;/a&gt;
and a web interface to the data (&lt;a href="https://github.com/Netflix/ice/blob/master/README.md#screenshots"&gt;screenshots&lt;/a&gt;). The single biggest feature for us
is the ability to do cost breakdowns (by hour/day/week/month) based on Cost Allocation tags in the detailed billing reports. We tag every billable &lt;span class="caps"&gt;AWS&lt;/span&gt;
resource with the Application Name, Service Class (environment; dev/test/prod) and Responsible Party. Ice lets us configure &amp;#8220;Application Groups&amp;#8221;
based on applications as seen from a business/budgetary standpoint and allow up-to-the-hour data on that available to anyone who needs&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;We spun up the development install of Ice for a few weeks to give it a spin, but once people started complaining that my screen session died and took
Ice with it, it was clear we needed a real, permanent installation. While there is &lt;a href="https://github.com/mdsol/ice_cookbook"&gt;chef&lt;/a&gt; and &lt;a href="https://github.com/Answers4AWS/netflixoss-ansible"&gt;ansible&lt;/a&gt;
code to install and configure Ice, we&amp;#8217;re a Puppet shop, and there wasn&amp;#8217;t anything available that I could find for Puppet. So, I set about writing a
module to install and configure Ice, running in Tomcat behind an Nginx proxy. Like any good modern module, I wanted not only &lt;a href="http://rspec-puppet.com/"&gt;rspec-puppet&lt;/a&gt;
unit tests but also &lt;a href="https://github.com/puppetlabs/beaker"&gt;beaker&lt;/a&gt; acceptance tests. For those unfamiliar, Beaker is an acceptance testing framework for Puppet
that&amp;#8217;s similar to Test Kitchen; it spins up Vagrant machines, runs some code in them, and then uses &lt;a href="http://serverspec.org/"&gt;serverspec&lt;/a&gt; to make assertions about
the state of the system (file contents, running processes, command output, etc.) (side note: if you used Beaker prior to the
&lt;a href="https://github.com/puppetlabs/beaker/blob/master/HISTORY.md#beaker2.0.0"&gt;2.0 release&lt;/a&gt; in December 2014, you should really try it again; they&amp;#8217;ve made some great&amp;nbsp;improvements).&lt;/p&gt;
&lt;h2 id="the-problem"&gt;The&amp;nbsp;Problem&lt;/h2&gt;
&lt;p&gt;This posed a bit of a challenge, as Ice (in addition to being pretty poorly documented) is really designed to run in &lt;span class="caps"&gt;AWS&lt;/span&gt;. Firstly, the very reason we started running Ice was
to get a handle on our fast-growing &lt;span class="caps"&gt;AWS&lt;/span&gt; spend; as a result, we&amp;#8217;re trying hard not to use &lt;span class="caps"&gt;AWS&lt;/span&gt; for small-scale projects that could use existing resources. Second, while our
company very unfortunately doesn&amp;#8217;t have an open source policy and isn&amp;#8217;t releasing anything (hopefully this may be changing soon), we try hard to write generic, forge-quality&amp;nbsp;modules.&lt;/p&gt;
&lt;p&gt;As a result, I wanted to use the default Vagrant/VirtualBox provider for Beaker. To make matters worse, in keeping with the spirit of a community module, I didn&amp;#8217;t
want the acceptance tests to require anything specific to my company, such as an S3 bucket preseeded with our billing data. Ice both reads the detailed billing reports
(one of its three inputs; &lt;span class="caps"&gt;EC2&lt;/span&gt; pricing data and your accounts&amp;#8217; reservation pricing/capacity being the others) and writes state from and to S3. So, this was a bit difficult.
As we don&amp;#8217;t plan on upgrading Ice terribly often, and we wanted to install from the &lt;a href="https://netflixoss.ci.cloudbees.com/job/ice-master/"&gt;cloudbees master builds&lt;/a&gt;, we wanted
acceptance testing of not just the provisioning tooling, but also some basic smoke tests for the application&amp;nbsp;itself.&lt;/p&gt;
&lt;h2 id="the-solution"&gt;The&amp;nbsp;Solution&lt;/h2&gt;
&lt;p&gt;I managed to come up with a working, albeit somewhat Rube Goldberg, method of getting isolated acceptance tests to work. What follows is the gist of how I got Ice
working in complete isolation. The majority of this happens in &lt;code&gt;spec/acceptance/0prerequisite_spec.rb&lt;/code&gt; which runs first and both does the prerequisite setup
and validates that everything is setup right and working for the tests. The following solution is based on the amazingly helpful &lt;a href="https://github.com/jubos/fake-s3"&gt;fakes3&lt;/a&gt;
Ruby gem, the &lt;a href="http://www.apsis.ch/pound/"&gt;Pound&lt;/a&gt; reverse proxy, and some &lt;span class="caps"&gt;SSL&lt;/span&gt; certificate trickery. While my code was specific to Beaker, this should be generic
enough to use with any system acceptance testing&amp;nbsp;tool.&lt;/p&gt;
&lt;h2 id="prerequisites"&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;First, we obtain or create some files that we&amp;#8217;ll need on the test&amp;nbsp;instance:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Grab a relatively recent Detailed Billing With Resources and Tags zipped &lt;span class="caps"&gt;CSV&lt;/span&gt; report from an &lt;span class="caps"&gt;AWS&lt;/span&gt; account of yours (the filename is in the format
    &lt;code&gt;&amp;lt;ACCOUNT NUMBER&amp;gt;-aws-billing-detailed-line-items-with-resources-and-tags-&amp;lt;YYYY&amp;gt;-&amp;lt;MM&amp;gt;.csv&lt;/code&gt;). Manually trim it down to a sufficient sample of data;
    I took a few hours&amp;#8217; worth of data from one day and trimmed it down to just that referencing a few randomly chosen &lt;span class="caps"&gt;RDS&lt;/span&gt; instances, ELBs, on-demand &lt;span class="caps"&gt;EC2&lt;/span&gt;
    instances and reserved &lt;span class="caps"&gt;EC2&lt;/span&gt; instances. I then anonymized the account number, resource IDs, tag values, and anything else identifying. Ice needs billing
    data in order to do anything, so this will serve as our test&amp;nbsp;data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When Ice runs, it attempts to retrieve reserved instance pricing. It appears (I&amp;#8217;ve lost the mailing list or GitHub issue reference) that it&amp;#8217;s typical for
    the first Ice run on an empty S3 work directory to die because these files are missing. As a result, grab the &lt;code&gt;reservation_prices.oneyear.*&lt;/code&gt; files from
    the S3 work bucket of a running/working Ice installation. This will prevent a time-consuming shutdown of Ice on the first&amp;nbsp;run.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generate a self-signed &lt;span class="caps"&gt;SSL&lt;/span&gt; key and certificate for &lt;code&gt;fakebucket.s3.amazonaws.com&lt;/code&gt;. Package them together in a &lt;span class="caps"&gt;PEM&lt;/span&gt; file suitable for use in web servers.
    (Note that most modern S3 &lt;span class="caps"&gt;API&lt;/span&gt; clients accept a full &lt;span class="caps"&gt;URL&lt;/span&gt; to a bucket, as there are now third parties that implement the S3 &lt;span class="caps"&gt;API&lt;/span&gt;. Ice does not; it connects
    to https://&lt;span class="caps"&gt;BUCKETNAME&lt;/span&gt;.s3amazonaws.com. As a result, this &lt;span class="caps"&gt;SSL&lt;/span&gt; foolery is&amp;nbsp;required.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="setup"&gt;Setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install the &lt;a href="https://rubygems.org/gems/fakes3"&gt;fakes3&lt;/a&gt; rubygem; this provides an s3-compliant &lt;span class="caps"&gt;API&lt;/span&gt; backed by local filesystem storage.
    Configure it to run during your tests (I set it up as a systemd service, but there are certainly other ways to do this). Note that
    while fakes3 stores the uploaded data on the local filesystem, it maintains a mapping of known objects in memory; as such, the process
    always starts completely empty, regardless of what&amp;#8217;s in the backing directory on the filesystem. fakes3 allows all &lt;span class="caps"&gt;IAM&lt;/span&gt; credentials,
    so fake ones are fine. It also automatically creates buckets the first time they&amp;#8217;re&amp;nbsp;accessed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the &lt;a href="http://www.apsis.ch/pound/"&gt;pound&lt;/a&gt; reverse proxy and configure it to listen on port 443 with the &lt;span class="caps"&gt;PEM&lt;/span&gt; file you generated
    earlier, and proxy to fakes3 (which listens by default on port 10000). The &lt;code&gt;ListenHTTPS&lt;/code&gt;section of &lt;code&gt;pound.cfg&lt;/code&gt; will need the
    &lt;code&gt;xHTTP 1&lt;/code&gt; directive in order to enable &lt;span class="caps"&gt;HTTP&lt;/span&gt; verbs other than&amp;nbsp;&lt;span class="caps"&gt;GET&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Setup a local hosts file entry pointing &lt;code&gt;fakebucket.s3.amazonaws.com&lt;/code&gt; at &lt;code&gt;127.0.0.1&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After fakes3 starts, upload your sample billing data file and your reserved instance pricing files to the appropriate paths under a
    bucket called &amp;#8220;fakebucket&amp;#8221;. You can use a tool such as &lt;a href="http://s3tools.org/s3cmd"&gt;s3cmd&lt;/a&gt; to manipulate its contents, and other
    supported tools are listed in &lt;a href="https://github.com/jubos/fake-s3/wiki/Supported-Clients"&gt;the documentation&lt;/a&gt;. This step also serves
    to validate your Pound configuration, which should pass &lt;span class="caps"&gt;HTTPS&lt;/span&gt; port 443 traffic through to fakes3 and allow you to store and
    retrieve&amp;nbsp;objects.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Figure out the path to the trusted keystore for the version of Java that you&amp;#8217;re running Ice under. On CentOS 7 with OpenJDK 1.7.0,
    this was (after a lot of symlinks) &lt;code&gt;/usr/lib/jvm/jre/lib/security/cacerts&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Import your self-signed certificate into the Java keystore as a trusted certificate. This will allow &lt;span class="caps"&gt;SSL&lt;/span&gt; verification to succeed even
    with a self-signed&amp;nbsp;certificate:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;/bin/keytool -importcert -alias fakebucket -file fakebucket.s3.amazonaws.com.crt -keystore /usr/lib/jvm/jre/lib/security/cacerts -storepass changeit -trustcacerts -noprompt
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configure &lt;code&gt;ice.properties&lt;/code&gt; for the above. The important and unintuitive parts that I found&amp;nbsp;are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Going by the above examples, your billing and work S3 bucket names should both be&amp;nbsp;&amp;#8220;fakebucket&amp;#8221;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unless you want to mock out bigger parts of the &lt;span class="caps"&gt;AWS&lt;/span&gt; metadata service, run Ice with
   &lt;code&gt;-Dice.s3AccessKeyId=NotAValidAccessKeyId -Dice.s3SecretKey=NotAValidAwsSecretKeyXxxxxxxxxxxxxxxxxxx&lt;/code&gt;
   in the &lt;code&gt;JAVA_OPTS&lt;/code&gt;. If Ice can&amp;#8217;t retrieve an instance&amp;#8217;s &lt;span class="caps"&gt;IAM&lt;/span&gt; role from the metadata service
   (http://169.254.169.254/latest/meta-data/iam/security-credentials/) and doesn&amp;#8217;t have the
   access and secret keys defined, it won&amp;#8217;t run. Also note that while the documentation is &lt;strong&gt;very&lt;/strong&gt;
   unclear on this, a number of &lt;a href="https://github.com/Netflix/ice/issues/49#issuecomment-23497701"&gt;github issues&lt;/a&gt;
   clarify that these need to be passed in as Java runtime options; they can&amp;#8217;t be put in the properties&amp;nbsp;file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Disable the Reservation Capacity Poller (&lt;code&gt;ice.reservationCapacityPoller=false&lt;/code&gt;). This service
   needs to connect to the &lt;span class="caps"&gt;EC2&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;, and will cause Ice to die if it&amp;nbsp;can&amp;#8217;t.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For testing purposes, it&amp;#8217;s a lot simpler and less error-prone (as well as being a lot faster) to
   test the processor and reader separately - at least in serial instead of simultaneously in the same&amp;nbsp;instance.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once all this is done, running the Ice Processor should retrieve the billing file, process it, and write the processed data to the
fakes3 bucket. Running the Reader should display the data properly. So far I&amp;#8217;ve been unable to find any features (other than the
Reservation Capacity Poller, noted above) that don&amp;#8217;t work with this&amp;nbsp;setup.&lt;/p&gt;
&lt;p&gt;Whether it&amp;#8217;s related to Ice itself or ideas for acceptance testing isolated applications, I hope this can be of use to&amp;nbsp;someone&amp;#8230;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Antman</dc:creator><pubDate>Tue, 05 May 2015 06:45:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2015-05-05:2015/05/local-s3-server-to-acceptance-test-netflix-ice-installation-in-isolation/</guid><category>netflix</category><category>ice</category><category>puppet</category><category>beaker</category><category>acceptance testing</category><category>aws</category><category>s3</category><category>fakes3</category><category>testing</category></item><item><title>Some Additional Serverspec Types</title><link>http://blog.jasonantman.com/2015/03/some-additional-serverspec-types/</link><description>&lt;p&gt;&lt;a href="http://serverspec.org/"&gt;Serverspec&lt;/a&gt; is an rspec-based framework for testing live machines,
and making assertions about things like the output of commands, installed packages, running
services, file content, etc. However, it has a relatively limited and basic set of
&lt;a href="http://serverspec.org/resource_types.html"&gt;Resource Types&lt;/a&gt; that it can test&amp;nbsp;for.&lt;/p&gt;
&lt;p&gt;Before Serverspec completely disabled their GitHub issue tracker (they now seem to have no
issue tracker at all), I&amp;#8217;d suggested some improvements for more advanced resource types,
such as one that can perform an &lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;GET&lt;/span&gt; against an application and check the status code
and/or output. I was told in no uncertain terms that this is a task for application integration
testing, and that it&amp;#8217;s &amp;#8220;not what Serverspec is&amp;nbsp;for.&amp;#8221;&lt;/p&gt;
&lt;p&gt;I humbly disagree. I&amp;#8217;ve begun migrating my &lt;a href="https://www.linode.com/"&gt;Linode&lt;/a&gt; to an &lt;span class="caps"&gt;EC2&lt;/span&gt; machine,
using some technology that I&amp;#8217;ve been using at my day job; specifically, Puppet to configure the
machine and &lt;a href="https://packer.io/"&gt;Packer&lt;/a&gt; to build an &lt;span class="caps"&gt;AMI&lt;/span&gt;. Instead of using &lt;a href="http://aws.amazon.com/cloudformation/"&gt;Cloudformation&lt;/a&gt;
to spin up an entire stack, I just use a Rakefile to spin up a new &lt;span class="caps"&gt;EC2&lt;/span&gt; instance, test it, and
swap an &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html"&gt;Elastic &lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/a&gt;
if all the tests pass. Of course, this requires that I have relatively complete automated testing
of the &lt;span class="caps"&gt;EC2&lt;/span&gt; instance. Stock Serverspec can handle 95% of what I want to test, but there are a few
other, more complex, things that it can&amp;#8217;t. So, I wrote some code to fix&amp;nbsp;that.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ll admit right off the bat that this code doesn&amp;#8217;t really work the way Serverspec is intended to,
but it works and it&amp;#8217;s relatively simple. This largely breaks the abstraction of serverspec using
&lt;a href="https://github.com/serverspec/specinfra"&gt;specinfra&lt;/a&gt; under the hood, but I&amp;#8217;m not sure if that&amp;#8217;s even
a concern (since specinfra seems to be all about testing a running machine via some local command
execution mechanism, and two of the types that I wrote use network &lt;span class="caps"&gt;IO&lt;/span&gt;&amp;nbsp;instead).&lt;/p&gt;
&lt;p&gt;For the time being, I&amp;#8217;ve written three additional &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/#Types"&gt;types&lt;/a&gt;
that solve some specific use cases for&amp;nbsp;me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/#bitlbee"&gt;bitlbee&lt;/a&gt;
type that connects to a &lt;a href="http://www.bitlbee.org/"&gt;Bitlbee&lt;/a&gt; &lt;span class="caps"&gt;IRC&lt;/span&gt; gateway, authenticates,
and checks the running bitlbee version. It has matchers to check whether or not the connection and
authentication was successful, whether or not it timed out, and the bitlbee version. Parameters for
the type include login nick and password, bitlbee port, and whether or not to connect with&amp;nbsp;&lt;span class="caps"&gt;SSL&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;A &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/#http_get"&gt;http_get&lt;/a&gt;
type which connects to the system under test (with a specified port) and issues a
&lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;GET&lt;/span&gt; request for a specified path, with a specified &lt;code&gt;Host&lt;/code&gt; header and a timeout (default
10 seconds). Matchers are provided for the response content body (string), response headers
(hash), &lt;span class="caps"&gt;HTTP&lt;/span&gt; status code, and whether or not the request timed out (which also sets a status of&amp;nbsp;0).&lt;/li&gt;
&lt;li&gt;A &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/#virtualenv"&gt;virtualenv&lt;/a&gt; type for testing
python &lt;a href="https://virtualenv.pypa.io/en/latest/"&gt;virtualenv&lt;/a&gt;s. It takes the absolute path to the venv
on the filesystem, and uses serverspec&amp;#8217;s built-in file and command execution features to ensure that
the path &amp;#8220;looks like&amp;#8221; a virtualenv, and has matchers for the pip and python versions used in the venv
as well as the &lt;code&gt;pip freeze&lt;/code&gt; output as a hash of requirements and their&amp;nbsp;versions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hopefully this will be of use to someone else as well. As I continue using serverspec, I plan on
adding to the&amp;nbsp;types.&lt;/p&gt;
&lt;p&gt;The code for serverspec-extended-types is on &lt;a href="https://github.com/jantman/serverspec-extended-types/tree/master"&gt;GitHub&lt;/a&gt;
(pull requests and issues welcome) and it&amp;#8217;s packaged and hosted as a &lt;a href="https://rubygems.org/gems/serverspec-extended-types"&gt;ruby gem&lt;/a&gt;.
&lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/0.0.2#Installation"&gt;Installation&lt;/a&gt; and usage is as simple
as adding it to your Gemfile and &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/0.0.2#Usage"&gt;spec_helper&lt;/a&gt;
and then using the types and matchers in your&amp;nbsp;specs.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Antman</dc:creator><pubDate>Sat, 14 Mar 2015 11:58:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2015-03-14:2015/03/some-additional-serverspec-types/</guid><category>serverspec</category><category>specinfra</category><category>testing</category><category>beaker</category><category>ruby</category><category>rspec</category><category>gem</category></item></channel></rss>