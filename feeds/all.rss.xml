<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jason Antman's Blog</title><link>http://blog.jasonantman.com/</link><description></description><atom:link href="http://blog.jasonantman.com/feeds/all.rss.xml" rel="self"></atom:link><lastBuildDate>Sat, 22 Mar 2014 09:38:00 -0400</lastBuildDate><item><title>NSA Targeting SysAdmins</title><link>http://blog.jasonantman.com/2014/03/nsa-targeting-sysadmins/</link><description>&lt;p&gt;I try not to rant too much, but I feel that this one was needed. If you&amp;#8217;re looking for
objective, technical information, skip this&amp;nbsp;one.&lt;/p&gt;
&lt;p&gt;When I was younger and more naive, I had near complete trust in the &lt;span class="caps"&gt;US&lt;/span&gt; government. There&amp;#8217;s a Constitution,
and they abide by it, and so do I. Since 2001, that feeling has eroded a bit. Since 2008, it&amp;#8217;s eroded even
more. But the documents leaked by &lt;a href="http://en.wikipedia.org/wiki/Edward_Snowden"&gt;Edward Snowden&lt;/a&gt; have been
the &amp;#8216;icing on the cake&amp;#8217;. I know there&amp;#8217;s disagreement about whether what he did was right or not - I&amp;#8217;m pretty
decided on how I feel, but I know many others who feel that he should be taken out and shot - but one thing
that&amp;#8217;s no longer deniable is, since he released those documents, it&amp;#8217;s come to light that the &lt;span class="caps"&gt;US&lt;/span&gt; government
is routinely performing unconstitutional acts in the furtherance of &amp;#8220;national&amp;nbsp;security.&amp;#8221;&lt;/p&gt;
&lt;p&gt;I feel like many people, who said over and over again that it could never get to this point, that the
Government might cut some corners but they&amp;#8217;d never blatantly do things like &lt;a href="http://www.washingtonpost.com/world/national-security/agencies-collected-data-on-americans-cellphone-use-in-thousands-of-tower-dumps/2013/12/08/20549190-5e80-11e3-be07-006c776266ed_story.html"&gt;mass collection of cellular data&lt;/a&gt;,
&lt;a href="http://www.washingtonpost.com/world/national-security/nsa-tracking-cellphone-locations-worldwide-snowden-documents-show/2013/12/04/5492873a-5cf2-11e3-bc56-c6ca94801fac_story.html"&gt;tracking the physical location of cell phones worldwide&lt;/a&gt;, or &lt;a href="http://www.washingtonpost.com/world/national-security/nsa-infiltrates-links-to-yahoo-google-data-centers-worldwide-snowden-documents-say/2013/10/30/e51d661e-4166-11e3-8b74-d89d714ca4dd_story.html"&gt;tapping into the networks of private companies like Google and Yahoo&lt;/a&gt;. It seems that
every new document leaked is worse than the last. I refuse to accept the arguments that this is all &amp;#8220;legal&amp;#8221;,
they simply don&amp;#8217;t keep up with the times. I couldn&amp;#8217;t care less if the government reads my postal mail (which
they still need an actual warrant for, &lt;span class="caps"&gt;AFAIK&lt;/span&gt;) - they probably get the same credit card and siding offers anyway.
I do, however, care that the government - out of their own self-interest and excitement at near-effortless surveillance -
refuses to extend the same protections that wireline phone calls and postal mail get to their electronic and
wireless&amp;nbsp;equivalents.&lt;/p&gt;
&lt;p&gt;When it came to light that the &lt;span class="caps"&gt;NSA&lt;/span&gt; &lt;a href="http://www.reuters.com/article/2013/12/20/us-usa-security-rsa-idUSBRE9BJ1C220131220"&gt;paid $10M to put a backdoor in &lt;span class="caps"&gt;RSA&lt;/span&gt; encryption&lt;/a&gt;
I was astonished. Late last year a number of other deals came to light, where the &lt;span class="caps"&gt;NSA&lt;/span&gt; paid or extorted software
and hardware manufacturers to intentionally introduce flaws in security to make it easier for the &lt;span class="caps"&gt;NSA&lt;/span&gt;
to gain access. The worst part is these weren&amp;#8217;t &amp;#8220;master passwords&amp;#8221; available only to the &lt;span class="caps"&gt;NSA&lt;/span&gt;; for the most
part, they appear to be mathematical flaws known to the &lt;span class="caps"&gt;NSA&lt;/span&gt;, but just as easily discovered by our enemies.
This part seems to have been glossed over by the media&amp;#8230; the consequences of some mathematician
or security researcher discovering those flaws and selling them to a national enemy or terrorist
would be flat-out devastating to the country and economy. Our government deliberately put a flaw in
an encryption standard, and then used its&amp;#8217; influence via &lt;span class="caps"&gt;NIST&lt;/span&gt;, the National Institute of Standards
and Technology, to &lt;a href="http://arstechnica.com/security/2013/09/the-nsas-work-to-make-crypto-worse-and-better/"&gt;recommend that standard for use&lt;/a&gt;
including by banks, e-commerce sites and financial&amp;nbsp;institutions.&lt;/p&gt;
&lt;p&gt;What has me even more upset, though, is the recent revelation that the &lt;span class="caps"&gt;NSA&lt;/span&gt; is &lt;a href="https://firstlook.org/theintercept/article/2014/03/20/inside-nsa-secret-efforts-hunt-hack-system-administrators/"&gt;systematically targeting
the private, personal accounts of system administrators to gain access to their employers&amp;#8217; networks&lt;/a&gt;. The bulk of the information came from an internal classified blog entry of an &lt;span class="caps"&gt;NSA&lt;/span&gt; employee,
&lt;a href="https://s3.amazonaws.com/s3.documentcloud.org/documents/1094387/i-hunt-sys-admins.pdf"&gt;available as a &lt;span class="caps"&gt;PDF&lt;/span&gt;&lt;/a&gt;
(or &lt;a href="/GFX/i-hunt-sys-admins.pdf"&gt;local copy&lt;/a&gt;). It&amp;#8217;s pretty technical, but it&amp;#8217;s also a startling view into
both the mindsets of &lt;em&gt;individuals&lt;/em&gt; within the &lt;span class="caps"&gt;NSA&lt;/span&gt;, and the organization&amp;#8217;s overall goals. Just two of the many
worthy&amp;nbsp;excerpts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;(S/&lt;span class="caps"&gt;SI&lt;/span&gt;//&lt;span class="caps"&gt;REL&lt;/span&gt;) One of the coolest things about it is &lt;strong&gt;how much&lt;/strong&gt; data we have at our fingertips. If we
&lt;em&gt;only&lt;/em&gt; collected the data we knew we wanted&amp;#8230; yeah, we&amp;#8217;d fill some of our requirements, but it is
a whole world of possibilities we&amp;#8217;d be missing! It would be like going on a road-trip, but wearing a
blindfold the entire time, and only removing it when you&amp;#8217;re at one of your destinations&amp;#8230; yeah,
you&amp;#8217;ll still see stuff, but you&amp;#8217;ll be missing out on the entire&amp;nbsp;journey!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So&amp;#8230; ok, they&amp;#8217;re admitting that they collect more data than they want (or legally can?). This person&amp;#8217;s
blog series is about &amp;#8220;using passive collect to identify/enable &lt;span class="caps"&gt;CNE&lt;/span&gt; efforts&amp;#8221; (&lt;span class="caps"&gt;CNE&lt;/span&gt; being Computer Network
Exploitation), which is also implying that they have access to massive amounts of data from non-target
persons, including American&amp;nbsp;citizens.&lt;/p&gt;
&lt;p&gt;Within the document, multiple references are made to the &lt;a href="https://firstlook.org/theintercept/article/2014/03/12/nsa-plans-infect-millions-computers-malware/"&gt;&lt;span class="caps"&gt;QUANTUM&lt;/span&gt;&lt;/a&gt;
program which seems to be viewed as, in short, a tool that lets the &lt;span class="caps"&gt;NSA&lt;/span&gt; input someone&amp;#8217;s Facebook,
webmail, or other online service account, and take control of the computers they use to access&amp;nbsp;it&amp;#8230;&lt;/p&gt;
&lt;p&gt;Now, for people in my line of work, the more troubling&amp;nbsp;part:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Now, fade off with me into dream-land. Pretend that we had some master list. This master list
contained tons of networks around the world, and the personal accounts of admins of each of
those networks. And any time you wanted to target a new network, you could just find the admin
associated with it, queue his accounts up for &lt;span class="caps"&gt;QUANTUM&lt;/span&gt;, get access to his box and proceed to pwn
the network. Wouldn&amp;#8217;t that be&amp;nbsp;swell?&lt;/p&gt;
&lt;p&gt;(S/&lt;span class="caps"&gt;SI&lt;/span&gt;//&lt;span class="caps"&gt;REL&lt;/span&gt;) Well, you can stop dreaming my friends, I think it&amp;#8217;s possible (at least kinda&amp;nbsp;partially).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So&amp;#8230; we&amp;#8217;re talking about deliberately targeting the personal accounts of innocent third parties,
in order to compromise their credentials to also innocent networks, in order to eventually
gain access to the information of a target. This seems so horribly illegal I can barely
explain. It&amp;#8217;s also a direct affront to the people in my industry who have an ethical obligation
to protect the data of their employers, customers and users against illegal disclosure. And,
maybe even more troubling, it&amp;#8217;s being perpetrated by other people &amp;#8220;in our industry&amp;#8221;, other
technical people, who obviously have a very clear picture of exactly what they&amp;#8217;re&amp;nbsp;doing.&lt;/p&gt;
&lt;p&gt;My first thought was to make an analogy between our resposibility as those &amp;#8220;with the keys to
the kingdom&amp;#8221; to a more legally entrenched privacy, like that between a doctor and their patient,
or between a lawyer and their client, that would be much more obviously illegal for the government
to breach. But, apparently that&amp;#8217;s an all-too-correct analogy, since it came to light last month
that the &lt;a href="http://www.nytimes.com/2014/02/16/us/eavesdropping-ensnared-american-law-firm.html"&gt;&lt;span class="caps"&gt;NSA&lt;/span&gt; was intercepting privileged lawyer-client communications through the use of a
foreign intermediary, namely Australia&lt;/a&gt;.
Given the intelligence allicances between the &lt;span class="caps"&gt;US&lt;/span&gt;, the &lt;span class="caps"&gt;UK&lt;/span&gt; and Australia, and the scope of what
has been already disclosed, I find it entirely probable that in all of these leaked documents
that discuss doing this to &amp;#8220;foreign&amp;#8221; entities only, the reality is that to do the same to &lt;span class="caps"&gt;US&lt;/span&gt;
citizens, it&amp;#8217;s as simple as logging in to the Australian or &lt;span class="caps"&gt;UK&lt;/span&gt; equivalent&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;This is truly disturbing to me. I continue to feel that (1) if the &lt;span class="caps"&gt;NSA&lt;/span&gt; had provable cause to
collect this information, they&amp;#8217;d obtain a warrant like the Constitution says they have to,
and (2) their electronic data collection is the equivalent of wiretapping every phone in the
country and hoping for something useful - which has been continually held to be unconstitutional,
but because of the nature (already digital) of electronic communications, it&amp;#8217;s actually feasible
to&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;On a related note, a while ago I enabled &lt;a href="http://en.wikipedia.org/wiki/Time-based_One-time_Password_Algorithm"&gt;&lt;span class="caps"&gt;TOTP&lt;/span&gt;&lt;/a&gt;-based
two factor authentication on a number of my accounts (Google, GitHub, &lt;span class="caps"&gt;AWS&lt;/span&gt;, etc.) to try
and keep them more secure against the possibility of a password compromise. Yes, that still works
to keep an unscrupulous person out of them. However, if &lt;a href="http://www.washingtonpost.com/blogs/the-switch/wp/2013/08/24/loveint-when-nsa-officers-use-their-spying-power-on-love-interests/"&gt;&lt;span class="caps"&gt;NSA&lt;/span&gt; officials use classified systems to
spy on love interests&lt;/a&gt;,
it&amp;#8217;s entirely possible that an unscrupulous &lt;span class="caps"&gt;NSA&lt;/span&gt; employee (or even worse, someone who manages to
compromise the &lt;span class="caps"&gt;NSA&lt;/span&gt;&amp;#8217;s systems? Though I imagine they only use in-house-developed security for now-obvious reasons)
could decide to compromise an individual&amp;#8217;s accounts for personal gain. Given all this news, I
find it highly unlikely that such an event would ever be reported to the proper oversight authorities,
let alone become public knowledge or known to the&amp;nbsp;victim.&lt;/p&gt;
&lt;p&gt;However, if we look at some of the information about what the &lt;span class="caps"&gt;NSA&lt;/span&gt; is doing, like their
&lt;a href="http://www.wired.com/threatlevel/2012/03/ff_nsadatacenter/all/"&gt;&lt;span class="caps"&gt;NSA&lt;/span&gt;&amp;#8217;s Utah Data Center&lt;/a&gt;
and their plans for an &lt;a href="http://www.theregister.co.uk/2014/01/03/snowden_docs_show_nsa_building_encryptioncracking_quantum_system/"&gt;encryption-cracking quantum computer&lt;/a&gt;,
and assume that they probably have a datacenter full of FPGAs, it&amp;#8217;s entirely conceivable
that they can calculate this faster than most people think possible. On the other hand,
if they have passive taps on backbone providers, it&amp;#8217;s also possible they can just hijack
a session with the click of a&amp;nbsp;mouse.&lt;/p&gt;
&lt;p&gt;I don&amp;#8217;t want to sound like too much of a nut. I&amp;#8217;ve never been terribly concerned about the
government snooping on my data because, well, I&amp;#8217;m not doing anything illegal. And aside from
my stance in favor of tighter controls and more electronic freedom, I&amp;#8217;m not in many groups
that I think would be targeted. However, I do feel very strongly about what&amp;#8217;s going on in general
(we already &lt;a href="http://www.marquette.edu/library/archives/Mss/JRM/JRM-main.shtml"&gt;learned&lt;/a&gt; that
government records on individuals&amp;#8217; activities can be horribly misused). Even more so, I&amp;#8217;m
deeply disturbed that &lt;em&gt;my&lt;/em&gt; personal data and accounts could be compromised simply as a way
for a government employee to gain access to my employer&amp;#8217;s computer systems, and then to
those of our employees and&amp;nbsp;customers.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Antman</dc:creator><pubDate>Sat, 22 Mar 2014 09:38:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2014-03-22:2014/03/nsa-targeting-sysadmins/</guid><category>nsa</category><category>government</category><category>privacy</category><category>security</category></item><item><title>Python script to backup Disqus comments</title><link>http://blog.jasonantman.com/2014/03/python-script-to-backup-disqus-comments/</link><description>&lt;p&gt;Since I just &lt;a href="/2014/03/wordpress-to-pelican-with-disqus-comments"&gt;switched this blog to using Disqus for commenting&lt;/a&gt;,
I wanted a way to back up comments in case something goes wrong (like,
Disqus going the way of del.icio.us&amp;nbsp;bookmarking).&lt;/p&gt;
&lt;p&gt;I whipped up a quick &lt;a href="https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py"&gt;Python script&lt;/a&gt;
using the official &lt;a href="https://github.com/disqus/disqus-python"&gt;Disqus Python &lt;span class="caps"&gt;API&lt;/span&gt; client&lt;/a&gt;. It grabs the forum details,
threads list and posts (comments) list, and writes them out to a &lt;span class="caps"&gt;JSON&lt;/span&gt;&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;It doesn&amp;#8217;t have any restore feature, but it captures all of the&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;My first test made it look like there &lt;em&gt;may&lt;/em&gt; be some posts and theads missing (my import from
wordpress showed 56 threads and 146 comments, but this script only grabbed 52 and 125 respectively),
so exercise some caution until I verify what the problem is. If you happen to figure it out,
please submit a&amp;nbsp;&lt;span class="caps"&gt;PR&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The script is available on GitHub at &lt;a href="https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py"&gt;https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Antman</dc:creator><pubDate>Sat, 01 Mar 2014 19:01:00 -0500</pubDate><guid>tag:blog.jasonantman.com,2014-03-01:2014/03/python-script-to-backup-disqus-comments/</guid><category>pelican</category><category>disqus</category><category>python</category></item><item><title>Blog Moved from Self-hosted WordPress to Pelican on GitHub Pages</title><link>http://blog.jasonantman.com/2014/03/blog-moved-from-self-hosted-wordpress-to-pelican-on-github-pages/</link><description>&lt;p&gt;I just finally finished my migration from self-hosted WordPress to &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt;, a Python-based
static site generator, hosted on &lt;a href="http://pages.github.com/"&gt;GitHub Pages&lt;/a&gt;. It&amp;#8217;s not only easier and free, but also the
first step in my plan to migrate off of my &lt;a href="http://linode.com"&gt;Linode&lt;/a&gt; &lt;span class="caps"&gt;VM&lt;/span&gt; and onto a mix of &lt;span class="caps"&gt;EC2&lt;/span&gt; and free&amp;nbsp;services.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m sure this post will be &lt;a href="/2009/02/wordpress-installation-finished/"&gt;around in five years&lt;/a&gt; when there&amp;#8217;s a smarter way
to do all this, but until then&amp;#8230;&amp;nbsp;yay!&lt;/p&gt;
&lt;p&gt;I hit a number of bumps during the migration, mainly around &lt;a href="/2014/02/converting-wordpress-posts-to-pelican-markdown/"&gt;Migrating &lt;span class="caps"&gt;HTML&lt;/span&gt; posts from WordPress to Markdown in Pelican&lt;/a&gt;
and migrating &lt;a href="/2014/03/wordpress-to-pelican-with-disqus-comments/"&gt;WordPress comments to Disqus&lt;/a&gt;, but in the end everything
seems to be working. Hopefully someone will find this and save a few hours or days of work if they try the same&amp;nbsp;thing.&lt;/p&gt;
&lt;p&gt;Post-go-live I still had some issues - Disqus was displaying an&amp;nbsp;error:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We were unable to load Disqus. If you are a moderator please see our troubleshooting&amp;nbsp;guide.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;on all posts created after the WordPress migration, and FeedBurner rejected my attempts to change the &lt;span class="caps"&gt;RSS&lt;/span&gt; feed &lt;span class="caps"&gt;URL&lt;/span&gt; to
its new value (though I&amp;#8217;m pretty sure that&amp;#8217;s because I neglected to drop the &lt;span class="caps"&gt;TTL&lt;/span&gt; on the &lt;span class="caps"&gt;DNS&lt;/span&gt; record, and I can&amp;#8217;t
find a way to tell Feedburner to purge it from&amp;nbsp;cache).&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Antman</dc:creator><pubDate>Sat, 01 Mar 2014 14:14:00 -0500</pubDate><guid>tag:blog.jasonantman.com,2014-03-01:2014/03/blog-moved-from-self-hosted-wordpress-to-pelican-on-github-pages/</guid><category>blog</category><category>wordpress</category><category>pelican</category><category>github</category></item><item><title>Wordpress to Pelican with Disqus comments</title><link>http://blog.jasonantman.com/2014/03/wordpress-to-pelican-with-disqus-comments/</link><description>&lt;p&gt;This is the second part of my WordPress to &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt; conversion saga.
In the &lt;a href="/2014/03/converting-wordpress-posts-to-pelican-markdown/"&gt;last post&lt;/a&gt; I ran through some
of the issues that I faced when converting the posts themselves, setting up my theme and settings,
etc. In this post, I&amp;#8217;ll discuss the saga of moving from WordPress comments to Disqus&amp;nbsp;comments.&lt;/p&gt;
&lt;p&gt;Be sure to read &lt;strong&gt;all&lt;/strong&gt; of this before trying it yourself, as I had some serious problems with my
first&amp;nbsp;attempt.&lt;/p&gt;
&lt;h2 id="initial-import-to-disqus"&gt;Initial Import to&amp;nbsp;Disqus&lt;/h2&gt;
&lt;p&gt;Initially, I installed the Disqus WordPress plugin as instructed in
&lt;a href="http://help.disqus.com/customer/portal/articles/466255-importing-comments-from-wordpress"&gt;Disqus&amp;#8217; Import from WordPress documentation&lt;/a&gt;.
The automatic import imported three of 134 comments, and froze there,
even though the status said it was 100% complete. I emailed Disqus&amp;#8217; support,
and was told that this meant the import failed (even though there was no explicit
notification, their admin &lt;span class="caps"&gt;UI&lt;/span&gt; said the import was successful) and I had to manually
import my comments. I did this, as instructed in the same docs, by disabling all
plugins except for Disqus and generating an &lt;span class="caps"&gt;XML&lt;/span&gt; export from WordPress, then re-enabling
the plugins, and uploading the export to Disqus. This time, I ended up with all 134
comments in Disqus, so I assumed that all went&amp;nbsp;well.&lt;/p&gt;
&lt;h2 id="previewing-comments-in-pelican"&gt;Previewing Comments in&amp;nbsp;Pelican&lt;/h2&gt;
&lt;p&gt;I added my Disqus &lt;code&gt;shortname&lt;/code&gt; to the &lt;code&gt;DISQUS_SITENAME&lt;/code&gt; field in &lt;code&gt;pelicanconf.py&lt;/code&gt; and
re-built. I ended up having an issue with &lt;code&gt;SITE_URL&lt;/code&gt; being set incorrectly for some testing
that I did, so that killed 10 minutes. I rebuilt locally with &lt;code&gt;SITE_URL&lt;/code&gt; not defined, and
then used &lt;code&gt;fab serve&lt;/code&gt; to serve locally. I was using my
&lt;a href="/2014/01/planning-migration-from-wordpress-to-static-site/"&gt;Planning Migration from Wordpress to Static Site&lt;/a&gt;
post to test, as it was both the most recent post, and had a five comments in WordPress, which imported
correctly into Disqus and were visible both in the Disqus moderation tool and on the now-Disqus-powered
WordPress&amp;nbsp;blog.&lt;/p&gt;
&lt;p&gt;Once I rebuilt with &lt;code&gt;DISQUS_SITENAME&lt;/code&gt; set and served locally with SimpleHTTPServer (&lt;code&gt;fab serve&lt;/code&gt;),
I checked the post and saw only a &amp;#8220;We were unable to load Disqus&amp;#8221; message below the post. It contained
a &lt;a href="http://help.disqus.com/customer/portal/articles/472007-i-m-receiving-the-message-%22we-were-unable-to-load-disqus-%22"&gt;link to their help article for that problem&lt;/a&gt;,
which pointed me at a domain mismatch/different origin problem. As indicated on that page,
I went to Settings -&amp;gt; Advanced in the Disqus admin, found the &amp;#8220;Trusted Domains&amp;#8221; box, and added
both my test domain (newblog.jasonantman.com - pointing at GitHub pages until I was ready to
shut WordPress down and actually move the live site) and &amp;#8220;localhost&amp;#8221; for testing, and&amp;nbsp;saved.&lt;/p&gt;
&lt;p&gt;I refreshed the page I was looking at, and now could see the Disqus commenting below my post,
but it wasn&amp;#8217;t showing any of the comments&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Disqus commenting with no comments" src="/GFX/disqus_wrong_url.png" /&gt;&lt;/p&gt;
&lt;p&gt;I pulled up the source of the page, and saw in the Disqus javascript just below the post&amp;nbsp;content:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_shortname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;jasonantman&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// required: replace example with your forum shortname&lt;/span&gt;
            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_identifier&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;planning-migration-from-wordpress-to-static-site&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;../../../2014/01/planning-migration-from-wordpress-to-static-site/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Everything looked &lt;span class="caps"&gt;OK&lt;/span&gt; to me except for &lt;code&gt;disqus_url&lt;/code&gt;, which I&amp;#8217;d seen mention of on the
&lt;a href="http://help.disqus.com/customer/portal/articles/472007-i-m-receiving-the-message-%22we-were-unable-to-load-disqus-%22"&gt;help page&lt;/a&gt;
I&amp;#8217;d just been looking at. Sure enough, it indicated that the &lt;code&gt;disqus_url&lt;/code&gt; var must be
an absolute &lt;span class="caps"&gt;URL&lt;/span&gt; to the post, not a relative path. I assume this was because I&amp;#8217;d generated
the content without having &lt;code&gt;SITE_URL&lt;/code&gt; set, so I hand-edited the generated page to change this
to the correct &lt;span class="caps"&gt;URL&lt;/span&gt;, http://blog.jasonantman.com/2014/01/planning-migration-from-wordpress-to-static-site/,
and tested again. Unfortunately, still zero&amp;nbsp;comments.&lt;/p&gt;
&lt;h2 id="wordpress-disqus-plugin-permalinks"&gt;WordPress Disqus Plugin&amp;nbsp;Permalinks&lt;/h2&gt;
&lt;p&gt;Fearing the worst, I pulled up the same post on my now-Disqus-powered WordPress blog,
and took a peek at the source. The javascript over there revealed a&amp;nbsp;problem:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://blog.jasonantman.com/2014/01/planning-migration-from-wordpress-to-static-site/&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_identifier&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;1546 http://blog.jasonantman.com/?p=1546&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_container_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;disqus_thread&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_domain&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;disqus.com&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_shortname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;jasonantman&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;disqus_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Planning Migration from WordPress to Static Site&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;While the &lt;span class="caps"&gt;URL&lt;/span&gt; is correct, the Disqus WordPress plugin uses the WordPress
post &lt;span class="caps"&gt;ID&lt;/span&gt; and permalink for the &amp;#8220;identifier&amp;#8221;, but the Pelican plugin uses the slug.
That&amp;#8217;s a problem, as my Pelican site will have the same URLs, but the WordPress
post-&lt;span class="caps"&gt;ID&lt;/span&gt;-based permalinks are gone (since it&amp;#8217;s a static site, and there&amp;#8217;s no easy
way of replicating things that are query param based). The WordPress post IDs
are thrown out by Pelican, so there&amp;#8217;s no way to connect the&amp;nbsp;two.&lt;/p&gt;
&lt;p&gt;Even worse, I remembered that Disqus&amp;#8217;
&lt;a href="http://help.disqus.com/customer/portal/articles/466255-importing-comments-from-wordpress"&gt;Importing Comments from WordPress help page&lt;/a&gt;
clearly&amp;nbsp;stated:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Imported comments can&amp;#8217;t be permanently deleted. Consider following our &lt;a href="http://help.disqus.com/customer/portal/articles/1053796-best-practices-for-staging-development-and-preview-sites"&gt;guidelines for development sites&lt;/a&gt; to make sure the data you&amp;#8217;re importing is correct. You can &lt;a href="http://disqus.com/register"&gt;register a new forum&lt;/a&gt; if you have imported the wrong&amp;nbsp;comments.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="solution-to-permalink-issue"&gt;Solution to Permalink&amp;nbsp;Issue&lt;/h2&gt;
&lt;p&gt;Not seeing any way around it, I figured it was time to &amp;#8220;bite the bullet&amp;#8221;. I disabled the Disqus plugin
in WordPress and then installed and activated the
&lt;a href="http://wordpress.org/extend/plugins/code-freeze/"&gt;WordPress Code Freeze Plugin&lt;/a&gt;
to disable comments. (&lt;em&gt;Note&lt;/em&gt; ironically, this plugin also uses JavaScript to disable your ability to
deactivate plugins, including itself. So before you activate it, copy the &amp;#8220;Activate&amp;#8221; link and save it
somewhere; changing &lt;code&gt;action=activate&lt;/code&gt; to &lt;code&gt;action=deactivate&lt;/code&gt; will let you get rid of it if you&amp;nbsp;want).&lt;/p&gt;
&lt;p&gt;Disqus has some documentation on &lt;a href="http://help.disqus.com/customer/portal/articles/1104797-importing-exporting"&gt;Importing and Exporting&lt;/a&gt;
which includes &lt;a href="http://help.disqus.com/customer/portal/articles/472150"&gt;Custom &lt;span class="caps"&gt;XML&lt;/span&gt; Imports&lt;/a&gt; based on the
WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; export format. So, I figured that I just had to decide that WordPress commenting would be
turned off, and do a point-in-time migration to Disqus (maybe circling back to hack the Disqus &lt;span class="caps"&gt;WP&lt;/span&gt; plugin
to keep comments working there for the time&amp;nbsp;being).&lt;/p&gt;
&lt;p&gt;Before anything else, I decided to actually set up a test forum/site in Disqus like they suggested.
I updated the &lt;code&gt;DISQUS_SITENAME&lt;/code&gt; in &lt;code&gt;pelicanconf.py&lt;/code&gt;, and then started in on the &lt;span class="caps"&gt;XML&lt;/span&gt; munging. The
&lt;a href="http://help.disqus.com/customer/portal/articles/472150"&gt;Custom &lt;span class="caps"&gt;XML&lt;/span&gt; Imports&lt;/a&gt; documentation implies
that the import engine recognizes a &lt;code&gt;dsq:thread_identifier&lt;/code&gt; &lt;span class="caps"&gt;XML&lt;/span&gt; element that holds the thread identifier,
but that element wasn&amp;#8217;t present in my WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; export. It appeared that Disqus was concatenating the
&lt;code&gt;wp:post_id&lt;/code&gt; and &lt;code&gt;guid&lt;/code&gt; fields (with a space in between) to come up with the&amp;nbsp;identifier.&lt;/p&gt;
&lt;p&gt;So, I wrote a script (&lt;a href="https://github.com/jantman/blog/blob/master/dev/wp-move/wp_comment_xml_munge.py"&gt;wp_comment_xml_munge.py&lt;/a&gt;)
using &lt;a href="http://lxml.de/"&gt;lxml&lt;/a&gt; that adds the &lt;code&gt;dsq:&lt;/code&gt; namespace to the WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; export (unfortunately using
string replacement and a temp file, due to a &lt;a href="https://bugs.launchpad.net/lxml/+bug/555602"&gt;bug in lxml&lt;/a&gt;)
and then adds the &lt;code&gt;dsq:thread_identifier&lt;/code&gt; tag to each post item, setting its value to the same
string as &lt;code&gt;wp:post_name&lt;/code&gt;, the &lt;span class="caps"&gt;URL&lt;/span&gt; slug (and post identifier in&amp;nbsp;Pelican).&lt;/p&gt;
&lt;p&gt;I imported the &lt;span class="caps"&gt;XML&lt;/span&gt; written by the script into my test forum in Disqus and rebuilt the Pelican content.
Magically, the first time I looked, the comments were&amp;nbsp;there.&lt;/p&gt;
&lt;p&gt;Now, time to see if I could get the same effect with the existing Disqus&amp;nbsp;site/forum:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In the Disqus moderation interface, delete all comments. You&amp;#8217;ll have to do this in batches of 10, as that&amp;#8217;s
   how they&amp;#8217;re paged in the interface. The comments don&amp;#8217;t seem to be permanently deleted, but do show as&amp;nbsp;&amp;#8220;deleted&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Go to &lt;a href="http://import.disqus.com"&gt;import.disqus.com&lt;/a&gt; and select your &amp;#8220;forum&amp;#8221; (site). You should see your existing
   (previous) import, as 100% complete, with the correct count of threads and comments. Do another import with the
   &lt;code&gt;_disqus.xml&lt;/code&gt; munged &lt;span class="caps"&gt;XML&lt;/span&gt;&amp;nbsp;export.&lt;/li&gt;
&lt;li&gt;Comments should now be linked to the correct post in&amp;nbsp;Pelican.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, Pelican seemed to be working, but WordPress was still left with only the old internal commenting,
and that was disabled by the Code Freeze plugin. I probably could have manually patched the Disqus plugin to
reflect the new thread identifiers, but instead, I chose to just push forward with the switch from WordPress to&amp;nbsp;Pelican.&lt;/p&gt;
&lt;p&gt;That only took a few hours, and I&amp;#8217;m happy to say that I&amp;#8217;m now up and running with a Pelican blog, hosted for free
by GitHub&amp;nbsp;Pages.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Antman</dc:creator><pubDate>Sat, 01 Mar 2014 09:09:00 -0500</pubDate><guid>tag:blog.jasonantman.com,2014-03-01:2014/03/wordpress-to-pelican-with-disqus-comments/</guid><category>wordpress</category><category>pelican</category><category>blog</category><category>disqus</category><category>comments</category></item><item><title>Converting WordPress Posts to Pelican MarkDown</title><link>http://blog.jasonantman.com/2014/02/converting-wordpress-posts-to-pelican-markdown/</link><description>&lt;p&gt;A few weeks ago, I
&lt;a href="/2014/01/planning-migration-from-wordpress-to-static-site/"&gt;posted&lt;/a&gt; about my
plans to convert my self-hosted WordPress blog to a static site using a static
blog generator. Since then, I&amp;#8217;ve decided to stop working on my exhaustive
&lt;a href="https://docs.google.com/spreadsheet/ccc?key=0AnHh-ye5DNiNdF9DWkJrT2kzSkNsNVp6cjMzLXJ6VEE&amp;amp;usp=sharing"&gt;static blog generator comparison spreadsheet&lt;/a&gt;
and just try &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt; - mainly because it&amp;#8217;s written in
Python which is my current strongest language, comes highly recommended, seems
to have most of the features I want, and seems to be easily&amp;nbsp;extensible.&lt;/p&gt;
&lt;p&gt;So, I walked through the documentation for the latest version (3.3.0), started
a &lt;a href="https://github.com/jantman/blog"&gt;GitHub repo&lt;/a&gt;, and tweaked a bunch of
settings. The repo is public, so if you want to take a look behind the scenes,
see my &lt;a href="https://github.com/jantman/blog/blob/master/fabfile.py"&gt;fabfile&lt;/a&gt;,
etc. feel&amp;nbsp;free. &lt;/p&gt;
&lt;h2 id="initial-wordpress-import-attempt"&gt;Initial WordPress Import&amp;nbsp;Attempt&lt;/h2&gt;
&lt;p&gt;I used the WordPress &lt;span class="caps"&gt;XML&lt;/span&gt; Export tool, as instructed in the &lt;a href="http://docs.getpelican.com/en/latest/importer.html"&gt;Pelican Importer documentation&lt;/a&gt;.
At first, I attempted to do a more-or-less default import from WordPress using
the &lt;code&gt;pelican-import&lt;/code&gt; tool, which writes rST, and then build the blog. What I
ended up with was thousands of errors complaining about &amp;#8220;Inline interpreted
text or phrase reference start-string without end-string&amp;#8221;, &amp;#8220;Explicit markup
ends without a blank line; unexpected uninden&amp;#8221;, &amp;#8220;malformed hyperlink target&amp;#8221;,
&amp;#8220;Unknown target name&amp;#8221; on all of my links, and a bevy of other Docutils
errors. It was so utterly awful that I gave&amp;nbsp;up.&lt;/p&gt;
&lt;h2 id="wordpress-import-as-markdown"&gt;WordPress Import as&amp;nbsp;MarkDown&lt;/h2&gt;
&lt;p&gt;Next I tried importing as MarkDown instead of rST,&amp;nbsp;using:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;pelican-import --markup markdown --wpfile -o content/ --dir-page jasonantman039sblog.wordpress.2014-01-11.xml
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That built without errors, and the posts looked somewhat right out of the
box, without any of the previous thousands of errors. And the links looked
mostly right - even the captions for images. Though I&amp;#8217;m working at a Python
shop and writing a lot of Python these days, my knowledge of MarkDown is still
much better than rST, so this is fine for me. (I even wrote a &lt;code&gt;fab post&lt;/code&gt; task
that prompts for a title, generates all of the post metadata, writes it to the
right file, and opens up an editor on&amp;nbsp;it.)&lt;/p&gt;
&lt;p&gt;The first problem was that the import script gave me one &amp;#8220;content&amp;#8221; directory
with 346 &amp;#8220;.md&amp;#8221; files in it - not exactly easy to work with. Luckily the
metadata was right, so a quick little
&lt;a href="https://github.com/jantman/blog/blob/master/move_wordpress.sh"&gt;bash script&lt;/a&gt;
moved the posts into a &lt;span class="caps"&gt;YYYY&lt;/span&gt;/&lt;span class="caps"&gt;MM&lt;/span&gt; directory&amp;nbsp;hierarchy.&lt;/p&gt;
&lt;h2 id="obvious-problems-with-imported-posts"&gt;Obvious Problems with Imported&amp;nbsp;Posts&lt;/h2&gt;
&lt;p&gt;After getting the MarkDown import working, and the posts moved to the proper
paths, I was still having some&amp;nbsp;issues&amp;#8230;&lt;/p&gt;
&lt;h3 id="syntax-hilighting-gone"&gt;Syntax Hilighting&amp;nbsp;Gone&lt;/h3&gt;
&lt;p&gt;In WordPress, I was using the
&lt;a href="http://wordpress.org/extend/plugins/wp-syntax/"&gt;&lt;span class="caps"&gt;WP&lt;/span&gt;-Syntax&lt;/a&gt; plugin to perform
syntax hilighting via &lt;a href="http://qbnz.com/highlighter/"&gt;GeSHi&lt;/a&gt;. The plugin uses
pre tags with a &lt;code&gt;lang=&lt;/code&gt; attribute to specify the language,&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&amp;lt;pre lang=&amp;quot;bash&amp;quot;&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, these translated to some really ugly MarkDown fenced blocks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;~~~~ {lang=&amp;quot;bash&amp;quot;}
cp /boot/efi/EFI/fedora/grub.cfg /boot/efi/EFI/fedora/grub.cfg.bak
echo &amp;#39;GRUB_DISABLE_OS_PROBER=&amp;quot;true&amp;quot;&amp;#39; &amp;gt;&amp;gt; /etc/default/grub
grub2-mkconfig &amp;gt; /boot/efi/EFI/fedora/grub.cfg
~~~~
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;that seem to be just a bit off from what MarkDown/Pygments can handle. The
places where I just used bare &lt;code&gt;&amp;lt;pre&amp;gt;&lt;/code&gt; blocks translated&amp;nbsp;fine.&lt;/p&gt;
&lt;p&gt;http://blog.gastove.com/2013-09-17_enabling_line_numbers_for_pygments.html&lt;/p&gt;
&lt;p&gt;Fixed this by using fenced blocks with the &amp;#8216;lang=&amp;#8217; stuff removed, and in class
syntax like the MarkDown docs suggest. Some four-tab-indents with
:::identifier&amp;nbsp;work.&lt;/p&gt;
&lt;h3 id="broken-links"&gt;Broken&amp;nbsp;Links&lt;/h3&gt;
&lt;p&gt;It seems that something in the conversion process introduced line wraps (could
it really be Pandoc itself???) Unfortunately, this wreaks havoc with any
explicit reference links
that use long (long enough to break across lines) titles, depending on where
they are in the line. It seems that in some places they end up breaking
differently in the link in the text and in the link definition, which MarkDown misses, and
then renders broken links and plain text of the link table at the bottom of
the page. Manually removing the line breaks and any extraneous spaces seems to
fix&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;So, yes, Pandoc was doing this because of the &lt;code&gt;--reference-links&lt;/code&gt; parameter
that &lt;code&gt;pelican-import&lt;/code&gt; was calling it with. There was an
&lt;a href="https://github.com/getpelican/pelican/issues/348"&gt;issue&lt;/a&gt; and
&lt;a href="https://github.com/getpelican/pelican/pull/642"&gt;pull request&lt;/a&gt; to fix this,
but when I started with Pelican the last release was 3.3.0 (4 months ago) and
the &lt;span class="caps"&gt;PR&lt;/span&gt; was merged after that. So, if you&amp;#8217;re having the same problem and the
latest release of Pelican is still 3.3.0, you might as well just apply
&lt;a href="https://github.com/getpelican/pelican/commit/83e4d35b44a422ee8d4b077f505970d03e555f45"&gt;the patch&lt;/a&gt;
yourself - it&amp;#8217;s just a very simple removal of a parameter in
&lt;code&gt;pelican_import.py&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="overall-results"&gt;Overall&amp;nbsp;Results&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m quite happy with the overall results. I also spent a &lt;em&gt;lot&lt;/em&gt; of time manually fixing
markup issues that didn&amp;#8217;t translate well through Pandoc, but I suppose that&amp;#8217;s to be
expected given that many of my older blog posts had &lt;span class="caps"&gt;HTML&lt;/span&gt;&amp;nbsp;issues.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Antman</dc:creator><pubDate>Fri, 28 Feb 2014 22:21:00 -0500</pubDate><guid>tag:blog.jasonantman.com,2014-02-28:2014/02/converting-wordpress-posts-to-pelican-markdown/</guid><category>pelican</category><category>wordpress</category><category>blog</category><category>markdown</category></item><item><title>Planning Migration from WordPress to Static Site</title><link>http://blog.jasonantman.com/2014/01/planning-migration-from-wordpress-to-static-site/</link><description>&lt;p&gt;Right now, this blog, my email, and a whole bunch of other services are
hosted on a &lt;a href="http://linode.com"&gt;Linode&lt;/a&gt; Xen &lt;span class="caps"&gt;VM&lt;/span&gt;. I don&amp;#8217;t really keep up
to date with administration and upgrades the way I used to, and
honestly, I&amp;#8217;d rather spend my time working on other things (like
actually writing all of the blog posts that I&amp;#8217;ve been planning to. The
first thing I&amp;#8217;ve identified for migration is this blog itself. It&amp;#8217;s
currently on WordPress and, frankly, I don&amp;#8217;t either need nor like it.
But there are some features I like. I&amp;#8217;d like to end up with a static
site generator, hosted from either S3 or GitHub Pages. I know that means
I&amp;#8217;ll lost comments (unless I move to a third-party, &lt;span class="caps"&gt;JS&lt;/span&gt;-based comment
system like &lt;a href="http://disqus.com/"&gt;Disqus&lt;/a&gt;, which means I&amp;#8217;ll lose
&lt;em&gt;control&lt;/em&gt; over my comments) but I suppose I can live with that. What I
really want is something simple, static, cheap or free (that I&amp;#8217;ll likely
put behind a small ec2 instance running nginx for&amp;nbsp;redirects/rewrites).&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m still in the planning phase, and trying to come up with a
feature-by-feature comparison of my options. I&amp;#8217;ll likely post that when
I finally have it done (at the moment it&amp;#8217;s in a very rough &lt;a href="https://docs.google.com/spreadsheet/ccc?key=0AnHh-ye5DNiNdF9DWkJrT2kzSkNsNVp6cjMzLXJ6VEE&amp;amp;usp=sharing"&gt;Google Docs
spreadsheet&lt;/a&gt;).
I&amp;#8217;m trying to round up my static site generator options and see which
ones will do most, if not all, of what I want (though I still haven&amp;#8217;t
discounted using hosted wordpress if it comes down to it). Here are the
features I currently &amp;#8220;use&amp;#8221; (have) on my WordPress&amp;nbsp;blog:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User-defined permalinks to&amp;nbsp;posts&lt;/li&gt;
&lt;li&gt;Overall &lt;span class="caps"&gt;RSS&lt;/span&gt; feed of blog (currently powered by FeedBurner) and of&amp;nbsp;comments)&lt;/li&gt;
&lt;li&gt;Categories (a post can be in multiple&amp;nbsp;categories)&lt;/li&gt;
&lt;li&gt;Tags&lt;/li&gt;
&lt;li&gt;Category and Tag&amp;nbsp;pages&lt;/li&gt;
&lt;li&gt;per-Category and per-Tag feeds&amp;nbsp;(&lt;span class="caps"&gt;RSS&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;Tag cloud &amp;#8220;widget&amp;#8221; in&amp;nbsp;sidebar&lt;/li&gt;
&lt;li&gt;Themes. I actually like my current &lt;span class="caps"&gt;WP&lt;/span&gt;&amp;nbsp;theme&amp;#8230;&lt;/li&gt;
&lt;li&gt;Visitor statistics (currently self-hosted
    &lt;a href="http://piwik.org/"&gt;Piwik&lt;/a&gt;, formerly Google&amp;nbsp;Analytics)&lt;/li&gt;
&lt;li&gt;Post publishing via cron&amp;#8217;ed script (&lt;em&gt;see below&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Draft/Pending status (i.e. let me save a partial post, and let me
    save a complete post but mark it &amp;#8220;pending&amp;#8221; so I can just publish it&amp;nbsp;later)&lt;/li&gt;
&lt;li&gt;Commenting (this will probably be the big sticking&amp;nbsp;point)&lt;/li&gt;
&lt;li&gt;Syntax&amp;nbsp;hilighting&lt;/li&gt;
&lt;li&gt;As &amp;#8220;weird&amp;#8221; as this is, I write all my posts in raw &lt;span class="caps"&gt;HTML&lt;/span&gt;, and am
    perfectly happy doing&amp;nbsp;that.&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Subscribe via Email&amp;#8221; FeedBurner&amp;nbsp;widget&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;XML&lt;/span&gt;&amp;nbsp;Sitemap&lt;/li&gt;
&lt;li&gt;Twitter&amp;nbsp;box/widget&lt;/li&gt;
&lt;li&gt;Pingbacks (not that these are really useful for anything other than
    spam these&amp;nbsp;days)&lt;/li&gt;
&lt;li&gt;Automatic or manual post excerpts for feeds,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;Remote publishing via &lt;span class="caps"&gt;XML&lt;/span&gt;-&lt;span class="caps"&gt;RPC&lt;/span&gt;/Android app (not that I&amp;#8217;ve used it
    more than once or&amp;nbsp;twice)&lt;/li&gt;
&lt;li&gt;Advertising - I currently use Google AdSense on my blog. The revenue
    from my tiny hit count isn&amp;#8217;t enough to offset the cost of a Linode,
    but if I moved to a much less expensive hosting service, it might be
    worth considering (you can&amp;#8217;t run ads on the free hosted WordPress,
    and I doubt you can on GitHub Pages&amp;nbsp;either).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I should be updating this post when I do some more research and have a
comparison of the&amp;nbsp;options.&lt;/p&gt;
&lt;p&gt;Note on &amp;#8220;Post publishing via cron&amp;#8217;ed script&amp;#8221; - sometimes I sit down and
write half a dozen or so blog posts at a time. But I don&amp;#8217;t want them all
to show up immediately, and spam the few people who still use &lt;span class="caps"&gt;RSS&lt;/span&gt;
readers after the death of Google Reader. So I set the posts to
&amp;#8220;Pending&amp;#8221; status, and I have a cron&amp;#8217;ed script that runs every weekday
morning and publishes the one oldest &amp;#8220;pending&amp;#8221; post. Who knows if this
actually does any good or&amp;nbsp;not&amp;#8230;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Wed, 01 Jan 2014 15:15:00 -0500</pubDate><guid>tag:blog.jasonantman.com,2014-01-01:2014/01/planning-migration-from-wordpress-to-static-site/</guid><category>blog</category><category>jekyll</category><category>pelican</category><category>python</category><category>static site</category><category>wordpress</category></item><item><title>Testing GPG Key Passphrases</title><link>http://blog.jasonantman.com/2013/08/testing-gpg-key-passphrases/</link><description>&lt;p&gt;So hypothetically, you have a &lt;span class="caps"&gt;GPG&lt;/span&gt; public/private keypair (from a backup
or old computer), but you don&amp;#8217;t remember the passphrase. Here&amp;#8217;s a
relatively simple way to find it from a number of possible options. This
&lt;em&gt;requires&lt;/em&gt; that you have a computer secure enough to store the possible
options in a text file. I&amp;#8217;d recommend storing that file on a
ramdisk/tmpfs, and using a temporary &lt;span class="caps"&gt;VM&lt;/span&gt; for this, which you&amp;#8217;ll wipe away
when you&amp;#8217;re&amp;nbsp;done.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preparation:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You have an appropriately secure place to do this with &lt;span class="caps"&gt;GPG&lt;/span&gt;
    installed, and a safe place to store a text file of sample
    passphrases (i.e. a&amp;nbsp;ramdisk).&lt;/li&gt;
&lt;li&gt;Copy your backed up public and private keys to &lt;code&gt;~/.gnupg&lt;/code&gt; on that
    host. Let&amp;#8217;s assume they&amp;#8217;re called &lt;code&gt;TestUser_public.key&lt;/code&gt; and
    &lt;code&gt;TestUser_private.key&lt;/code&gt;. We&amp;#8217;re assuming that you &lt;span class="caps"&gt;KNOW&lt;/span&gt;, &lt;span class="caps"&gt;BEYOND&lt;/span&gt; A &lt;span class="caps"&gt;DOUBT&lt;/span&gt;
    that these are your keys (i.e. you got them from a secure offline
    backup medium, you&amp;#8217;ve verified against a printed key fingerprint,
    you&amp;#8217;ve verified the fingerprints against a
    &lt;a href="http://pgp.mit.edu/"&gt;keyserver&lt;/a&gt; that you know is authoritative for
    your keys,&amp;nbsp;etc.).&lt;/li&gt;
&lt;li&gt;First, we import the public and private keys to&amp;nbsp;&lt;span class="caps"&gt;GPG&lt;/span&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~$&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; .gnupg
&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --import TestUser_public.key 
&lt;span class="go"&gt;gpg: keyring `/home/testuser/.gnupg/secring.gpg` created&lt;/span&gt;
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: public key &amp;quot;Test User (Test User) &amp;quot; imported&lt;/span&gt;
&lt;span class="go"&gt;gpg: Total number processed: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:               imported: 1  (&lt;span class="caps"&gt;RSA&lt;/span&gt;: 1)&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --allow-secret-key-import --import TestUser_secret.key 
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: secret key imported&lt;/span&gt;
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: &amp;quot;Test User (Test User) &amp;quot; not changed&lt;/span&gt;
&lt;span class="go"&gt;gpg: Total number processed: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:              unchanged: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:       secret keys read: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:   secret keys imported: 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Check that the keys are&amp;nbsp;there:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --list-keys
&lt;span class="go"&gt;/home/testuser/.gnupg/pubring.gpg&lt;/span&gt;
&lt;span class="go"&gt;--------------------------------&lt;/span&gt;
&lt;span class="go"&gt;pub   2048R/&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; 2013-08-24&lt;/span&gt;
&lt;span class="go"&gt;uid                  Test User (Test User) &lt;/span&gt;
&lt;span class="go"&gt;sub   2048R/&lt;span class="caps"&gt;40D9F35E&lt;/span&gt; 2013-08-24&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --list-secret-keys
&lt;span class="go"&gt;/home/testuser/.gnupg/secring.gpg&lt;/span&gt;
&lt;span class="go"&gt;--------------------------------&lt;/span&gt;
&lt;span class="go"&gt;sec   2048R/&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; 2013-08-24&lt;/span&gt;
&lt;span class="go"&gt;uid                  Test User (Test User) &lt;/span&gt;
&lt;span class="go"&gt;ssb   2048R/&lt;span class="caps"&gt;40D9F35E&lt;/span&gt; 2013-08-24&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Note the fingerprint of the key which is, in this case, &lt;code&gt;17AD8D3D&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Testing&amp;nbsp;Passphrases:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Now that we have the keys imported, we&amp;#8217;re ready to test some
    passphrases. Enter your passphrases, one per line, in a text file.
    We&amp;#8217;re assuming that we&amp;#8217;re working on a totally secured host
    (ideally, a &lt;span class="caps"&gt;VM&lt;/span&gt; running on a standalone, non-networked machine) that
    will be destroyed when we&amp;#8217;re done. For added security, I&amp;#8217;d put this
    file on a ramdisk. In this example, the actual passphrase for the
    key is &amp;#8220;test&amp;#8221;. Here&amp;#8217;s our text&amp;nbsp;file:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; cat /tmp/passphrases 
&lt;span class="go"&gt;bad&lt;/span&gt;
&lt;span class="go"&gt;notgood&lt;/span&gt;
&lt;span class="go"&gt;notright&lt;/span&gt;
&lt;span class="go"&gt;test&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Next, create a test data file to try to&amp;nbsp;sign/encrypt:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;test input&amp;quot;&lt;/span&gt; &amp;gt; /tmp/test.in
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Now we run the actual test (see below for more&amp;nbsp;information&amp;#8230;)&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; &lt;span class="k"&gt;for &lt;/span&gt;p in &lt;span class="sb"&gt;`&lt;/span&gt;cat /tmp/passphrases&lt;span class="sb"&gt;`&lt;/span&gt;; &lt;span class="k"&gt;do &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$p&amp;quot;&lt;/span&gt; | gpg -q --sign --local-user &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; --passphrase-fd 0 --output /dev/null --yes /tmp/test.in &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: $p&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;break&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;; &lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0    &lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0    &lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0    &lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0    &lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: test&lt;/span&gt;
&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;And there we have it, the working passphrase. I&amp;#8217;m sure there&amp;#8217;s a
    more efficient way to do this, and probably a more secure way, but
    I&amp;#8217;m not trying to brute-force someone&amp;#8217;s &lt;span class="caps"&gt;GPG&lt;/span&gt; key, I&amp;#8217;m trying to
    remember which one of my (many, many) passwords I used for a &lt;span class="caps"&gt;GPG&lt;/span&gt; key
    that I generated a decade&amp;nbsp;ago.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The actual command that we ran, rewritten with some linebreaks for
legibility,&amp;nbsp;is:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;for &lt;/span&gt;p in &lt;span class="sb"&gt;`&lt;/span&gt;cat /tmp/passphrases&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$p&amp;quot;&lt;/span&gt; | gpg -q --sign --local-user &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; --passphrase-fd 0 --output /dev/null --yes /tmp/test.in &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: $p&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;break&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This loops over each line in the passphrases file (each passphrase that
we want to try), and for each one, echoes the password and pipes it to
&lt;span class="caps"&gt;STDIN&lt;/span&gt; of &lt;code&gt;gpg&lt;/code&gt;, which tries to sign /tmp/test.in (sending the output
to /dev/null) using the key with &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;code&gt;17AD8D3D&lt;/code&gt; (from #5 in the
Preparation steps above) and a password provided on &lt;span class="caps"&gt;STDIN&lt;/span&gt;. If the &lt;span class="caps"&gt;GPG&lt;/span&gt;
command succeeds, we echo the passphrase and stop looping through the
passphrases&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;I hope I wouldn&amp;#8217;t have to say this for anyone who&amp;#8217;s reading my blog, but
this information (as easy as it is to be figured out), is not to be used
for unethical&amp;nbsp;purposes.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Mon, 26 Aug 2013 06:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2013-08-26:2013/08/testing-gpg-key-passphrases/</guid><category>encryption</category><category>gnupg</category><category>gpg</category><category>key</category><category>passphrase</category><category>pgp</category></item><item><title>Quick Tip: Timestamping bash history</title><link>http://blog.jasonantman.com/2013/06/quick-tip-timestamping-bash-history/</link><description>&lt;p&gt;Here&amp;#8217;s a tiny little snippet that I have in my &lt;code&gt;.bashrc&lt;/code&gt; which really
comes in handy when trying to figure out what I did on a system when.
One of the first things I do when (eek) building out or working on a
one-off machine (or setting up a new laptop/desktop, as I am right now)
is set this in bashrc for my user and root, so I can go back and
document the setup process with a little more ease and sanity. Just add
this (it&amp;#8217;s just a &lt;a href="http://linux.die.net/man/3/strftime"&gt;strftime (3)&lt;/a&gt;
format string &lt;a href="http://www.gnu.org/software/bash/manual/bashref.html#index-HISTTIMEFORMAT"&gt;according to the
docs&lt;/a&gt;,
so adjust as desired) to &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;HISTTIMEFORMAT&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;%F %T &amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and bash will store commented-out integer timestamps before each line in
&lt;code&gt;.bash_history&lt;/code&gt; like&amp;nbsp;so:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt;1370950005
&lt;span class="go"&gt;less .bashrc&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;1370950017
&lt;span class="go"&gt;history &lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;1370950279
&lt;span class="go"&gt;tail -30 .bash_history &lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;1370950293
&lt;span class="go"&gt;exit&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;the output of &lt;code&gt;history&lt;/code&gt; now uses the specified time&amp;nbsp;format:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt; 997  2013-06-11 07:26:45 less .bashrc
 998  2013-06-11 07:26:57 history 
 999  2013-06-11 07:31:19 tail -30 .bash_history 
1000  2013-06-11 07:31:33 exit
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 11 Jun 2013 07:09:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2013-06-11:2013/06/quick-tip-timestamping-bash-history/</guid><category>bash</category><category>history</category><category>shell</category><category>timestamp</category></item><item><title>Python script to check a list of URLs for return code, and final return code if redirected</title><link>http://blog.jasonantman.com/2013/06/python-script-to-check-a-list-of-urls-for-return-code-and-final-return-code-if-redirected/</link><description>&lt;p&gt;Every once in a while I need to add a bunch of redirects in Apache.
Here&amp;#8217;s a handy, dead simple Python script which takes a list of URLs on
&lt;span class="caps"&gt;STDIN&lt;/span&gt;, and for each one prints out either the response code, or, if the
response is a redirect, the response code of what is redirected to.
Pretty useful when you&amp;#8217;ve just added a bunch of redirects and want to
make sure none of them&amp;nbsp;404.&lt;/p&gt;
&lt;p&gt;The latest source of this script lives at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/check_url_list.py"&gt;https://github.com/jantman/misc-scripts/blob/master/check_url_list.py&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Script to check a list of URLs (passed on stdin) for response code, and for response code of the final path in a series of redirects.&lt;/span&gt;
&lt;span class="sd"&gt;Outputs (to stdout) a list of count of a given &lt;span class="caps"&gt;URL&lt;/span&gt;, response code, and if redirected, the final &lt;span class="caps"&gt;URL&lt;/span&gt; and its response code&lt;/span&gt;

&lt;span class="sd"&gt;Optionally, with verbose flag, report on all &lt;span class="caps"&gt;URL&lt;/span&gt; checks on &lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;

&lt;span class="sd"&gt;Copyright 2013 Jason Antman  all rights reserved&lt;/span&gt;
&lt;span class="sd"&gt;This script is distributed under the terms of the GPLv3, as per the&lt;/span&gt;
&lt;span class="sd"&gt;&lt;span class="caps"&gt;LICENSE&lt;/span&gt; file in this repository.&lt;/span&gt;

&lt;span class="sd"&gt;The canonical version of this script can be found at:&lt;/span&gt;

&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_url_nofollow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcode&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;+ checking &lt;span class="caps"&gt;URL&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;get_url_nofollow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;++ &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Mon, 10 Jun 2013 06:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2013-06-10:2013/06/python-script-to-check-a-list-of-urls-for-return-code-and-final-return-code-if-redirected/</guid><category>http</category><category>python</category><category>redirect</category><category>urllib</category></item><item><title>Modern (0.10.x+) NodeJS RPMs on CentOS/REHL 5 and 6</title><link>http://blog.jasonantman.com/2013/06/modern-0-10-x-nodejs-rpms-on-centosrehl-5-and-6/</link><description>&lt;p&gt;I posted back in January about &lt;a href="/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt; Spec Files for nodejs 0.9.5 and v8
on CentOS
6&lt;/a&gt;. In
that post I also said that I was unable to get recent NodeJS to build on
CentOS 5 because of a long chain of dependencies including node-gyp, v8,
http-parser, glibc, etc. I said I couldn&amp;#8217;t get it to build. Well, I have
good news for both distro&amp;nbsp;versions.&lt;/p&gt;
&lt;p&gt;On the CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; 6 side, thanks to a lot of work by &lt;span class="caps"&gt;T. C.
&lt;/span&gt;Hollingsworth and others, NodeJS 0.10.5 is currently in the official
&lt;a href="http://fedoraproject.org/wiki/EPEL"&gt;&lt;span class="caps"&gt;EPEL&lt;/span&gt;&lt;/a&gt; repositories. They seem to be
keeping the packages pretty current, but if you need newer, you can
always grab the SRPMs from &lt;span class="caps"&gt;EPEL&lt;/span&gt; and build the newer versions. This is
great, because it means I no longer need to maintain the spec files and
do my own builds. I don&amp;#8217;t think I really did anything to help get this
package in &lt;span class="caps"&gt;EPEL&lt;/span&gt;, other than ping a few people and comment on a few&amp;nbsp;tickets.&lt;/p&gt;
&lt;p&gt;For CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; 5, I finally have packages, but they&amp;#8217;re not exactly
pretty. The dependency solving issues still stand; they&amp;#8217;re rooted at the
dependency of node-gyp which requires the v8 C++ JavaScript library, and
is required to compile shared object addons. The best solution that I
(and a few others) could find is simply not to build node-gyp, and not
to have support for addons or package any addons; we just have the
binaries that NodeJS&amp;#8217;s Makefile creates, and everything else is
interpreted. A &lt;a href="https://twitter.com/toxigenicpoem"&gt;coworker&lt;/a&gt; found
&lt;a href="https://github.com/kazuhisya/nodejs-rpm"&gt;https://github.com/kazuhisya/nodejs-rpm&lt;/a&gt;
which contains a configure patch and specfile for a dead-simple CentOS
5/6 &lt;span class="caps"&gt;RPM&lt;/span&gt; of NodeJS 0.10.9, which essentially just uses &lt;span class="caps"&gt;EPEL&lt;/span&gt;&amp;#8217;s python26
packages to power the NodeJS build process, configures and uses the
Makefile&amp;#8217;s &lt;code&gt;make binary&lt;/code&gt; command to spit out a NodeJS binary tarball,
and then packages that. That whole process way out of line from the
&lt;a href="http://fedoraproject.org/wiki/Packaging:Guidelines"&gt;Fedora Packaging
Guidelines&lt;/a&gt;, and
also only dumps out nodejs, nodejs-binary and nodejs-debuginfo packages,
so I also can&amp;#8217;t just substitute in a different package name in my puppet
manifests (which install nodejs, nodejs-devel and npm packages). So I
&lt;a href="https://github.com/jantman/nodejs-rpm-centos5"&gt;forked that repository&lt;/a&gt;
and made some changes to the specfile: I gave the package name a prefix
(&amp;#8220;cmgd_&amp;#8221;, since that&amp;#8217;s where I work these days) and some warnings in
the description, to make it abundantly clear that these packages are
very far from what you find in &lt;span class="caps"&gt;EPEL&lt;/span&gt; and other repositories, and broke
npm and the devel files out into their own subpackages. Hopefully this
spec file will be of use to someone else who also has the unfortunate
need of supporting recent NodeJS on CentOS 5. If there&amp;#8217;s enough
interest, I&amp;#8217;ll consider building the packages and putting them in a
repository&amp;nbsp;somewhere.&lt;/p&gt;
&lt;p&gt;You can see the NodeJS 0.10.9 on CentOS 5 spec file, a patch, and the
READMEs at
&lt;a href="https://github.com/jantman/nodejs-rpm-centos5"&gt;https://github.com/jantman/nodejs-rpm-centos5&lt;/a&gt;.
Patches and/or pull requests are greatly appreciated, especially from
anyone who wants to make the spec file more Fedora guidelines&amp;nbsp;compliant.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Thu, 06 Jun 2013 20:47:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2013-06-06:2013/06/modern-0-10-x-nodejs-rpms-on-centosrehl-5-and-6/</guid><category>build</category><category>centos</category><category>EPEL</category><category>node</category><category>nodejs</category><category>package</category><category>packaging</category><category>redhat</category><category>RHEL</category><category>rpm</category><category>specfile</category></item><item><title>Script to easily rebuild a SRPM</title><link>http://blog.jasonantman.com/2013/05/script-to-easily-rebuild-a-srpm/</link><description>&lt;p&gt;Between &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 5 and 6 the default &lt;span class="caps"&gt;RPM&lt;/span&gt; compression format was
changed to xz. As such, trying to build a recent Fedora or Cent6 &lt;span class="caps"&gt;SRPM&lt;/span&gt; on
Cent5 will error out with a message like
&lt;code&gt;error: unpacking of archive failed on file foo;51a4c2a5: cpio: MD5 sum mismatch&lt;/code&gt;
because tar on CentOS 5 doesn&amp;#8217;t support&amp;nbsp;xz.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a quick and dirty little script to use &lt;code&gt;rpm2cpio&lt;/code&gt; to rebuild a
&lt;span class="caps"&gt;SRPM&lt;/span&gt; using the host&amp;#8217;s native &lt;span class="caps"&gt;RPM&lt;/span&gt; compression. The latest version will
live at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/rebuild_srpm.sh"&gt;https://github.com/jantman/misc-scripts/blob/master/rebuild_srpm.sh&lt;/a&gt;&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;
&lt;span class="c"&gt;# Script to rebuild a &lt;span class="caps"&gt;SRPM&lt;/span&gt; 1:1, useful when you want to build a &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 6&lt;/span&gt;
&lt;span class="c"&gt;# &lt;span class="caps"&gt;SRPM&lt;/span&gt; on a &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 5 system that doesn&amp;#39;t support newer compression (cpio: &lt;span class="caps"&gt;MD5&lt;/span&gt; sum mismatch)&lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;
&lt;span class="c"&gt;# by Jason Antman &lt;/span&gt;
&lt;span class="c"&gt;# The latest version of this script will always live at:&lt;/span&gt;
&lt;span class="c"&gt;# &lt;/span&gt;
&lt;span class="c"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-h&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--help&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: rebuild_srpm.sh  &amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;$2&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; ! -e &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: &lt;span class="caps"&gt;SRPM&lt;/span&gt; file not found: $1&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; ! which rpmbuild &amp;amp;&amp;gt; /dev/null
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rpmbuild could not be found. please install. (sudo yum install rpm-build)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; ! which rpm2cpio &amp;amp;&amp;gt; /dev/null
&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rpm2cpio could not be found. please install. (sudo yum install rpm)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit &lt;/span&gt;1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;dirname &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;basename &lt;span class="s2"&gt;&amp;quot;$1&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;mktemp -d&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;STARTPWD&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Rebuilding $&lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;

&lt;span class="c"&gt;# copy srpm into tempdir&lt;/span&gt;
cp &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;

&lt;span class="nb"&gt;pushd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt; &amp;amp;&amp;gt;/dev/null

&lt;span class="c"&gt;# setup local build dir structure&lt;/span&gt;
mkdir -p rpm rpm/&lt;span class="caps"&gt;BUILD&lt;/span&gt; rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt; rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt; rpm/&lt;span class="caps"&gt;SPECS&lt;/span&gt; rpm/&lt;span class="caps"&gt;SRPMS&lt;/span&gt; rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/athlon rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/i&lt;span class="se"&gt;\[&lt;/span&gt;3456&lt;span class="se"&gt;\]&lt;/span&gt;86 rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/i386 rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/noarch rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/x86_64

&lt;span class="c"&gt;# setup rpmmacros file&lt;/span&gt;
cat /dev/null &amp;gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/.rpmmacros
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%_topdir        $&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;/rpm&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.rpmmacros

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Extracting &lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;pushd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt;/ &amp;amp;&amp;gt;/dev/null
rpm2cpio &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt; | cpio -idmv &amp;amp;&amp;gt;/dev/null
&lt;span class="nb"&gt;popd&lt;/span&gt; &amp;amp;&amp;gt;/dev/null

&lt;span class="c"&gt;# build the &lt;span class="caps"&gt;SRPM&lt;/span&gt; from the spec and sources&lt;/span&gt;
&lt;span class="c"&gt;# we&amp;#39;re just building a &lt;span class="caps"&gt;SRPM&lt;/span&gt; so we can ignore dependencies&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Rebuilding &lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;NEW_SRPM&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;rpmbuild -bs --nodeps --macros&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/.rpmmacros &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt;/*.spec | grep &lt;span class="s2"&gt;&amp;quot;^Wrote: &amp;quot;&lt;/span&gt; | awk &lt;span class="s1"&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Copying to $&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&amp;quot;&lt;/span&gt;
cp &lt;span class="nv"&gt;$NEW_SRPM&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;/

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Wrote file to $&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;/`basename $NEW_SRPM`&amp;quot;&lt;/span&gt;

&lt;span class="c"&gt;# cleanup&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;STARTPWD&lt;/span&gt;&lt;/span&gt;
rm -Rf &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 28 May 2013 10:26:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2013-05-28:2013/05/script-to-easily-rebuild-a-srpm/</guid><category>lzma</category><category>packaging</category><category>rpm</category><category>rpm2cpio</category><category>rpmbuild</category><category>srpm</category><category>xz</category></item><item><title>Git Cheat Sheet</title><link>http://blog.jasonantman.com/2013/05/git-cheat-sheet/</link><description>&lt;p&gt;I use &lt;a href="http://git-scm.com/"&gt;git&lt;/a&gt; quite a bit these days, both with an
internal server at work and with a bunch of my projects and random code
that now live on &lt;a href="https://github.com/jantman/"&gt;my github account&lt;/a&gt;. The
transition from &lt;span class="caps"&gt;SVN&lt;/span&gt; hasn&amp;#8217;t always been easy. Here&amp;#8217;s a quick cheat sheet
of some of the things that I usually&amp;nbsp;forget.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Show diff of the last&amp;nbsp;commit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git diff HEAD^..HEAD
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Roll back to version xyz of a specific file &lt;em&gt;(where xyz is a &lt;span class="caps"&gt;SHA1&lt;/span&gt;
    commit ref)&lt;/em&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout xyz path/to/file
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Undo any &lt;em&gt;unstaged&lt;/em&gt; changes to your&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout -f
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Undo any staged and working directory&amp;nbsp;changes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git reset --hard
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update submodules after cloning a&amp;nbsp;repository:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git submodule update --init
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebase on current master to pull in new&amp;nbsp;changes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rebase on current master, but for files that changed, take our
    version &lt;em&gt;(for some reason, a plain rebase seems to sometimes show
    conflicts on files that haven&amp;#8217;t changed in ages on master)&lt;/em&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase -s recursive -Xtheirs master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete a local&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git branch -d BranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete a remote branch from&amp;nbsp;origin:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin --delete BranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Roll back your branch to the same state as the branch in&amp;nbsp;origin:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git reset --hard origin/BranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Revert a specific&amp;nbsp;commit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git revert COMMIT_HASH
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Track an upstream branch (i.e. in a project you&amp;nbsp;forked):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote add --track master upstream https://github.com/user/project.git
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pull in upstream&amp;nbsp;changes:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout master &amp;amp;&amp;amp; git fetch upstream &amp;amp;&amp;amp; git merge upstream/master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Merge &amp;#8220;stuff&amp;#8221; from someone else&amp;#8217;s fork into&amp;nbsp;yours:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote add other-guys-repo URL_TO_REPO
git fetch other-guys-repo
git checkout my_new_branch
git merge other-guys-repo/master
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prune local branches that have been deleted in the remote&amp;nbsp;(origin):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote prune origin
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 14 May 2013 05:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2013-05-14:2013/05/git-cheat-sheet/</guid><category>git</category></item><item><title>Search for a small-scale but automated RPM build system</title><link>http://blog.jasonantman.com/2013/05/search-for-a-small-scale-but-automated-rpm-build-system/</link><description>&lt;p&gt;&lt;strong&gt;This post is part of a series of older draft posts from a few months
ago that I&amp;#8217;m just getting around to publishing. Unfortunately, I have
yet to find a build system that meets my requirements (see the last&amp;nbsp;paragraph).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At work, we have a handful - currently a really small number - of &lt;span class="caps"&gt;RPM&lt;/span&gt;
packages that we need to build and deploy internally for our CentOS
server infrastructure. A number of them are just pulled down from
specific third-party repositories and rebuilt to have the vendor set as
us, and some are internally patched or developed software. We run
websites, and on the product side, we&amp;#8217;re a
Python/&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; shop (in fact, probably
one of the largest Django apps out there). We don&amp;#8217;t deploy our Django
apps via &lt;span class="caps"&gt;RPM&lt;/span&gt;, so building and distributing RPMs is definitely not one of
our core competencies. In fact, we really only want to do it when we&amp;#8217;re
testing/deploying a new distro, or when an upstream package is&amp;nbsp;updated.&lt;/p&gt;
&lt;p&gt;Last week I pulled a ticket to deploy &lt;a href="http://nodejs.org/"&gt;node.js&lt;/a&gt; to
one of our build hosts, and we&amp;#8217;ve got a few things in the pipeline that
also rely on it. I found the
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module on Github that&amp;#8217;s supposed to install it on &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS, but it
pulls packages from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;,
and the newest version of nodejs there is 0.6.18, which is quite old. I
can&amp;#8217;t find any actively maintained sources of newer nodejs packages for
&lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS (yeah, I know, that&amp;#8217;s one down side to the
distributions&amp;#8230;). However, I did find that nodejs 0.9.5 is being &lt;a href="http://koji.fedoraproject.org/koji/packageinfo?packageID=15154"&gt;built
for Fedora 18/19 in the Fedora build
system&lt;/a&gt;,
is already in the Fedora 18 Testing and Fedora Rawhide repos, but is
failing its &lt;span class="caps"&gt;EL6&lt;/span&gt; builds in their system. The decision I&amp;#8217;ve come to is to
use the puppetlabs-nodejs module to install it, but try and rebuild the
Fedora 18 RPMs under CentOS 5 and&amp;nbsp;6.&lt;/p&gt;
&lt;p&gt;So that&amp;#8217;s the background. Now, my current task: to search for an &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system for my current job. My core requirements, in no specific
order,&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be relatively easy and quick to use for people who have a specfile
    or &lt;span class="caps"&gt;SRPM&lt;/span&gt; and want to be able to &amp;#8220;ensure =&gt; present&amp;#8221; the finished &lt;span class="caps"&gt;RPM&lt;/span&gt;
    on a system. i.e., require as little per-package configuration as&amp;nbsp;possible.&lt;/li&gt;
&lt;li&gt;Be able to handle rebuilding &amp;#8220;all&amp;#8221; of our RPMs when we roll out a
    new distro version. Doesn&amp;#8217;t necessarily need to be automatic, but
    should be relatively&amp;nbsp;simple.&lt;/li&gt;
&lt;li&gt;Ideally, not need to be running constantly - i.e. something that
    will cope well with build hosts being VMs that are shut down when
    they&amp;#8217;re not&amp;nbsp;needed.&lt;/li&gt;
&lt;li&gt;Handle automatically putting successfully built packages into a
    repository, ideally with some sort of (manual) promotion process
    from staging to&amp;nbsp;stable.&lt;/li&gt;
&lt;li&gt;Have minimal external (infrastructure) dependencies that we can&amp;#8217;t
    satisfy with existing&amp;nbsp;systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the first step was to research existing &lt;span class="caps"&gt;RPM&lt;/span&gt; build systems and how
others do this. Here&amp;#8217;s a list of what I could find online, though most
of these are from distributions and software vendors/projects, not
end-user companies that are only building for internal&amp;nbsp;use.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://fedorahosted.org/koji/wiki"&gt;Koji&lt;/a&gt; is the build system used
    by &lt;a href="http://fedoraproject.org/wiki/Koji"&gt;Fedora&lt;/a&gt; and RedHat. It&amp;#8217;s
    about as full-featured as any can be, and I&amp;#8217;m familiar with it from
    my time at &lt;a href="http://koji.rutgers.edu/koji/"&gt;Rutgers University&lt;/a&gt;, as
    it&amp;#8217;s used to maintain their CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; packages. It&amp;#8217;s based largely
    on Mock. However, &lt;a href="http://fedoraproject.org/wiki/Koji/ServerHowTo"&gt;setting up the build
    server&lt;/a&gt; is no
    trivial task; there are few installations outside of Fedora/RedHat,
    and it relies on either Kerberos or an &lt;span class="caps"&gt;SSL&lt;/span&gt; &lt;span class="caps"&gt;CA&lt;/span&gt; infrastructure to
    authenticate machines and clients. So, it&amp;#8217;s designed for too large a
    scale and too much infrastructure for&amp;nbsp;me.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux has a &lt;a href="https://www.pld-linux.org/developingpld/builderscript"&gt;builder
    script&lt;/a&gt; that
    seems to automate &lt;code&gt;rpmbuild&lt;/code&gt; as well as fetching sources and
    resolving/building dependencies. I haven&amp;#8217;t looked at the script yet,
    but apparently it&amp;#8217;s in &lt;span class="caps"&gt;PLD&lt;/span&gt;&amp;#8217;s &amp;#8220;rpm-build-tools&amp;#8221;&amp;nbsp;package.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux also has a &lt;span class="caps"&gt;CVS&lt;/span&gt; repository for something called
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new"&gt;pld-builder.new&lt;/a&gt;.
    The
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/README?rev=1.5"&gt;&lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt;
    and
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/ARCHITECTURE?rev=1.6"&gt;&lt;span class="caps"&gt;ARCHITECTURE&lt;/span&gt;&lt;/a&gt;
    files make it sound like a relatively simple mainly-Python system
    that builds &lt;span class="caps"&gt;SRPMS&lt;/span&gt; and binary packages when requested, and most
    importantly, seems like a simple system that uses little more than
    shared filesystem access for communication and&amp;nbsp;coordination.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;ALT&lt;/span&gt; Linux has &lt;a href="http://en.altlinux.org/Sisyphus"&gt;Sisyphus&lt;/a&gt;, which
    combines repository management and web interface tools, package
    building and testing tools, and&amp;nbsp;more.&lt;/li&gt;
&lt;li&gt;The Dries &lt;span class="caps"&gt;RPM&lt;/span&gt; repository uses (or at least used&amp;#8230; my reference is
    quite old) &lt;a href="http://dries.ulyssis.org/rpm/pydar2/index.html"&gt;pydar2&lt;/a&gt;,
    &amp;#8220;a distributed client/server program which allows you to build
    multiple spec files on multiple distribution/architecture
    combinations automatically.&amp;#8221; That sounds like it could be what I
    need, but the last update says that it isn&amp;#8217;t finished yet, and that
    was in &lt;strong&gt;2005&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Mandriva Linux has pretty extensive information on their build
    system &lt;a href="http://wiki.mandriva.com/en/Category:Build_System"&gt;on their
    wiki&lt;/a&gt; and a
    &lt;a href="http://wiki.mandriva.com/en/Development/Packaging/BuildSystem/Theory"&gt;build system theory
    page&lt;/a&gt;,
    but it seems to be largely a hodgepodge of shell scripts and
    cronjobs, and is likely not a candidate for use by anyone other than
    its&amp;nbsp;designers.&lt;/li&gt;
&lt;li&gt;Argeo provides the &lt;a href="https://www.argeo.org/wiki/SLC"&gt;&lt;span class="caps"&gt;SLC&lt;/span&gt; framework&lt;/a&gt;
    which has a &amp;#8220;&lt;span class="caps"&gt;RPM&lt;/span&gt; Factory&amp;#8221; component, but I can&amp;#8217;t seem to find much
    more than a wiki page, and can&amp;#8217;t tell if it&amp;#8217;s a build automation
    system or just handles mocking packages and putting them in a repo
    on a single&amp;nbsp;host.&lt;/li&gt;
&lt;li&gt;Dag Wieers&amp;#8217; repositories use (or used) a set of python scripts
    called &lt;a href="http://dag.wieers.com/home-made/dar/"&gt;&lt;span class="caps"&gt;DAR&lt;/span&gt;, &amp;#8220;Dynamic Apt Repository
    builder&amp;#8221;&lt;/a&gt;. They&amp;#8217;re on
    &lt;a href="https://github.com/dagwieers/dar"&gt;github&lt;/a&gt; but are listed as &amp;#8220;old&amp;#8221;
    and haven&amp;#8217;t been updated in at least 2 years. The features sound
    quite interesting, and though it&amp;#8217;s based on the Apt repo format, it
    might provide some good ideas for implementing a similar&amp;nbsp;system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Update four months later:&lt;/strong&gt; I&amp;#8217;ve yet to find a build system that meets
my requirements above. For the moment I&amp;#8217;m only managing \~20 packages,
so my &amp;#8220;build system&amp;#8221; is a single shell script that reads in some
environment variables and runs through using
&lt;a href="http://fedoraproject.org/wiki/Projects/Mock"&gt;mock&lt;/a&gt; to build them in the
correct order (including pushing the finished RPMs back into the local
repository that mock reads from) and then pushing the finished packages
to our internal repository. Maybe when I have some spare time, I&amp;#8217;ll
consider a project to either make a slightly better (but simple) &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system based on Python, or get our
&lt;a href="http://jenkins-ci.org/"&gt;Jenkins&lt;/a&gt; install to handle this for&amp;nbsp;me.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Mon, 13 May 2013 05:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2013-05-13:2013/05/search-for-a-small-scale-but-automated-rpm-build-system/</guid><category>build</category><category>linux</category><category>nodejs</category><category>package</category><category>packaging</category><category>repository</category><category>rpm</category><category>rpmbuild</category><category>software</category><category>sysadmin</category><category>yum</category></item><item><title>Environment Variable Substitution in Apache httpd Configs</title><link>http://blog.jasonantman.com/2013/05/environment-variable-substitution-in-apache-httpd-configs/</link><description>&lt;p&gt;I&amp;#8217;ve been configuring Apache httpd for over a decade, from a single
personal web server to web farms running thousands of vhosts. In most of
the &amp;#8220;real&amp;#8221; environments I&amp;#8217;ve worked in, we&amp;#8217;ve had some variation of
production, stage/test/&lt;span class="caps"&gt;QA&lt;/span&gt; and development hosts; and usually some method
of managing configurations between them, whether it&amp;#8217;s source control or
generating them from template. And in all of these environments, there
has invariably been drift between the configurations in the various
environments, whether it&amp;#8217;s because of poor tools to maintain a unified
configuration or many of those emergency redirect requests that make it
into production but are never backported. This is made all the worse
because everywhere I&amp;#8217;ve worked, the real difference between what
production and other environments &lt;em&gt;should&lt;/em&gt; be is really just a string
replacement in Apache configurations - &lt;code&gt;/prod/&lt;/code&gt; to &lt;code&gt;/test/&lt;/code&gt; or
&lt;code&gt;www.example.com&lt;/code&gt; to &lt;code&gt;www.dev.example.com&lt;/code&gt; or something along those&amp;nbsp;lines.&lt;/p&gt;
&lt;p&gt;Well a few days ago I was having a discussion with some co-workers that
dovetailed into this topic, and when I started some research, I found
(&lt;em&gt;finally after using httpd for years&lt;/em&gt;) that the &lt;a href="http://httpd.apache.org/docs/2.2/configuring.html#syntax"&gt;Apache httpd 2.2
configuration file syntax
documentation&lt;/a&gt;
states that httpd supports environment variable interpolation anywhere
in the config files (and &lt;a href="http://httpd.apache.org/docs/2.4/configuring.html#syntax"&gt;httpd
2.4&lt;/a&gt; supports
it with Defines as&amp;nbsp;well).&lt;/p&gt;
&lt;p&gt;Yup, that&amp;#8217;s right. All those different Apache configs I&amp;#8217;ve worked with
for years that define separate vhosts, document roots, rewrite targets,
ServerAliases, etc. for &lt;code&gt;www.example.com&lt;/code&gt; and &lt;code&gt;www.qa.example.com&lt;/code&gt; and
&lt;code&gt;www.dev.example.com&lt;/code&gt; really only had to be
&lt;code&gt;www.${ENV_URL_PART}example.com&lt;/code&gt;, and set &lt;code&gt;ENV_URL_PART&lt;/code&gt; in the init
script or sysconfig file. (Of course this all assumes that you have your
different environments served by different httpd instances, which you
do, of&amp;nbsp;course&amp;#8230;)&lt;/p&gt;
&lt;p&gt;For me, this is a very big deal. It means that finally, instead of
maintaining separate sets of configs for different environments which
are (theoretically, except for those emergencies) kept identical by
hand, or updating templates and then re-generating each environment&amp;#8217;s
configs, we can finally follow the same
commit/merge/promotion-between-environments workflow that we use for
other production code and Puppet configuration. It also means that those
pesky little rewrites and other minor tweaks will make it all the way
back to development&amp;nbsp;environments.&lt;/p&gt;
&lt;p&gt;So, here&amp;#8217;s a little example of how this would work in reality. Let&amp;#8217;s
assume that we have 3 main environments, &lt;code&gt;prod&lt;/code&gt;, &lt;code&gt;qa&lt;/code&gt; and &lt;code&gt;dev&lt;/code&gt; (though
this should work for N environments) and that domains are prefixed with
&amp;#8220;qa.&amp;#8221; or &amp;#8220;dev.&amp;#8221; for the respective internal environments. We set
environment variables before httpd is started, on a per-host basis,
depending on what environment that host is in. On RedHat based systems,
we&amp;#8217;d add the variables to &lt;code&gt;/etc/sysconfig/httpd&lt;/code&gt; for&amp;nbsp;production:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;HTTPD_ENV_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;prod&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;HTTPD_ENV_URL_PART&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;or for&amp;nbsp;&lt;span class="caps"&gt;QA&lt;/span&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;HTTPD_ENV_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;qa&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;HTTPD_ENV_URL_PART&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;qa.&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Those variables will now be available to httpd within the configurations
(and also to any applications or scripts that have access to the web
server&amp;#8217;s environment&amp;nbsp;variables).&lt;/p&gt;
&lt;p&gt;Now let&amp;#8217;s look at an example vhost configuration file that uses the
environment&amp;nbsp;variables:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nb"&gt;ServerName&lt;/span&gt; example.com
&lt;span class="nb"&gt;ServerAlias&lt;/span&gt; www.example.com
&lt;span class="c"&gt;# Aliases including proper environment name&lt;/span&gt;
&lt;span class="nb"&gt;ServerAlias&lt;/span&gt; www.${HTTPD_ENV_NAME}.example.com ${HTTPD_ENV_NAME}.example.com

&lt;span class="nb"&gt;ErrorLog&lt;/span&gt; &lt;span class="sx"&gt;/var/log/httpd/example.com-error_log&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; &lt;span class="sx"&gt;/var/log/httpd/example.com-access_log&lt;/span&gt; combined

&lt;span class="nb"&gt;DocumentRoot&lt;/span&gt; &lt;span class="sx"&gt;/sites/example.com/&lt;/span&gt;${HTTPD_ENV_NAME}/

&lt;span class="c"&gt;# Environment-specific configuration, if we absolutely need it:&lt;/span&gt;
&lt;span class="nb"&gt;Include&lt;/span&gt; &lt;span class="sx"&gt;/etc/httpd/sites/&lt;/span&gt;${HTTPD_ENV_NAME}/env.conf


&lt;span class="nb"&gt;RewriteEngine&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt;
&lt;span class="nb"&gt;RewriteRule&lt;/span&gt; &lt;span class="sx"&gt;/foobar/.&lt;/span&gt;* http://www.${HTTPD_ENV_URL_PART}example.com/baz/ [R=302,L]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Every instance of &lt;code&gt;${HTTPD_ENV_NAME}&lt;/code&gt; will be replaced with the value
set in the sysconfig file, and likewise with every instance of
&lt;code&gt;${HTTPD_ENV_URL_PART}&lt;/code&gt;. This way, we can have one set of configurations
and use our normal source control branch/promotion process to both test
and promote changes through the environments along with application
code, and ensure that any straight-to-production emergency changes
(everyone has customer-ordered rewrites like that, right?) make it back
to development and&amp;nbsp;qa.&lt;/p&gt;
&lt;p&gt;One caveat is that, if the environment variable is not defined, the
&lt;code&gt;${VAR_NAME}&lt;/code&gt; will be left as a literal string in the configuration
file. There doesn&amp;#8217;t seem to be any way to protect against this in httpd
2.2, other than making sure the variables are set before the server
starts (and maybe setting logical default values, like an empty string,
in your init script which should be overridden by the sysconfig&amp;nbsp;file).&lt;/p&gt;
&lt;p&gt;If you&amp;#8217;re running httpd 2.4+, you can turn on
&lt;a href="http://httpd.apache.org/docs/2.4/mod/mod_info.html"&gt;mod_info&lt;/a&gt; and
browse to &lt;code&gt;http://servername/server-info?config&lt;/code&gt; to dump the current
configuration, which will show the variable&amp;nbsp;substitution.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Sat, 11 May 2013 12:01:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2013-05-11:2013/05/environment-variable-substitution-in-apache-httpd-configs/</guid><category>apache</category><category>environment</category><category>httpd</category><category>variable</category></item><item><title>RPM Spec Files for nodejs 0.9.5 and v8 on CentOS 6</title><link>http://blog.jasonantman.com/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/</link><description>&lt;p&gt;The latest version of nodejs that I could find as an &lt;span class="caps"&gt;RPM&lt;/span&gt; for CentOS was
0.6.16, from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;.
That&amp;#8217;s the one that puppetlabs currently uses in their
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module. There is, however, a nodejs 0.9.5 &lt;span class="caps"&gt;RPM&lt;/span&gt; in the Fedora Rawhide (19)
repository. Below are some patches to that specfile, and the specfile
for its v8 dependency, to get them to build on CentOS 6. You can also
find the full specfiles on my &lt;a href="https://github.com/jantman/specfiles"&gt;github specfile
repository&lt;/a&gt;. I had originally
wanted to get them built on CentOS 5 as well, but after following the
dependency tree from nodejs to http-parser to gyp, and then finding
issues in the gyp source that are incompatible with CentOS 5&amp;#8217;s python
2.4, I gave up on that&amp;nbsp;target.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nodejs.spec&lt;/strong&gt;, diff from Fedora Rawhide nodejs-0.9.5-9.fc18.src.rpm,
buildID=377755 (&lt;a href="https://raw.github.com/jantman/specfiles/master/nodejs.spec"&gt;full
specfile&lt;/a&gt;)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gh"&gt;diff --git a/nodejs.spec b/nodejs.spec&lt;/span&gt;
&lt;span class="gh"&gt;index 050ed86..86c0f4b 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/nodejs.spec&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/nodejs.spec&lt;/span&gt;
&lt;span class="gu"&gt;@@ -1,6 +1,6 @@&lt;/span&gt;
 Name: nodejs
 Version: 0.9.5
&lt;span class="gd"&gt;-Release: 9%{?dist}&lt;/span&gt;
&lt;span class="gi"&gt;+Release: 10%{?dist}&lt;/span&gt;
 Summary: JavaScript runtime
 License: &lt;span class="caps"&gt;MIT&lt;/span&gt; and &lt;span class="caps"&gt;ASL&lt;/span&gt; 2.0 and &lt;span class="caps"&gt;ISC&lt;/span&gt; and &lt;span class="caps"&gt;BSD&lt;/span&gt;
 Group: Development/Languages
&lt;span class="gu"&gt;@@ -25,7 +25,7 @@ Source6: nodejs-fixdep&lt;/span&gt;
 BuildRequires: v8-devel &amp;gt;= %{v8_ge}
 BuildRequires: http-parser-devel &amp;gt;= 2.0
 BuildRequires: libuv-devel
&lt;span class="gd"&gt;-BuildRequires: c-ares-devel&lt;/span&gt;
&lt;span class="gi"&gt;+BuildRequires: c-ares-devel &amp;gt;= 1.9.0&lt;/span&gt;
 BuildRequires: zlib-devel
 # Node.js requires some features from openssl 1.0.1 for &lt;span class="caps"&gt;SPDY&lt;/span&gt; support
 BuildRequires: openssl-devel &amp;gt;= 1:1.0.1
&lt;span class="gu"&gt;@@ -165,9 +165,13 @@ cp -p common.gypi %{buildroot}%{_datadir}/node&lt;/span&gt;

 %files docs
 %{_defaultdocdir}/%{name}-docs-%{version}
&lt;span class="gd"&gt;-%doc &lt;span class="caps"&gt;LICENSE&lt;/span&gt;&lt;/span&gt;

 %changelog
&lt;span class="gi"&gt;+* Thu Jan 31 2013 Jason Antman  - 0.9.5-10&lt;/span&gt;
&lt;span class="gi"&gt;+- specify build requirement of c-ares-devel &amp;gt;= 1.9.0&lt;/span&gt;
&lt;span class="gi"&gt;+- specify build requirement of libuv-devel 0.9.4&lt;/span&gt;
&lt;span class="gi"&gt;+- remove duplicate %doc &lt;span class="caps"&gt;LICENSE&lt;/span&gt; that was causing cpio &amp;#39;Bad magic&amp;#39; error on CentOS6&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
 * Sat Jan 12 2013 &lt;span class="caps"&gt;T.C.&lt;/span&gt; Hollingsworth  - 0.9.5-9
 - fix brown paper bag bug in requires generation script
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;v8.spec&lt;/strong&gt;, diff from Fedora Rawhide 3.13.7.5-2 (&lt;a href="https://raw.github.com/jantman/specfiles/master/v8.spec"&gt;full
specfile&lt;/a&gt;)&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gd"&gt;--- v8.spec.orig       2013-01-26 16:03:18.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ v8.spec     2013-01-31 09:04:51.068029459 -0500&lt;/span&gt;
&lt;span class="gu"&gt;@@ -21,9 +21,11 @@&lt;/span&gt;

 # %%global svnver 20110721svn8716

&lt;span class="gi"&gt;+%{!?python_sitelib: %define python_sitelib %(%{__python} -c &amp;quot;import distutils.sysconfig as d; print d.get_python_lib()&amp;quot;)}&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
 Name:          v8
 Version:       %{somajor}.%{sominor}.%{sobuild}.%{sotiny}
&lt;span class="gd"&gt;-Release:       2%{?dist}&lt;/span&gt;
&lt;span class="gi"&gt;+Release:       5%{?dist}&lt;/span&gt;
 Epoch:         1
 Summary:       JavaScript Engine
 Group:         System Environment/Libraries
&lt;span class="gu"&gt;@@ -32,7 +34,7 @@&lt;/span&gt;
 Source0:       http://commondatastorage.googleapis.com/chromium-browser-official/v8-%{version}.tar.bz2
 BuildRoot:     %{_tmppath}/%{name}-%{version}-%{release}-root-%(%{__id_u} -n)
 ExclusiveArch: %{ix86} x86_64 %{arm}
&lt;span class="gd"&gt;-BuildRequires: scons, readline-devel, libicu-devel&lt;/span&gt;
&lt;span class="gi"&gt;+BuildRequires: scons, readline-devel, libicu-devel, ncurses-devel&lt;/span&gt;

 %description
 V8 is Google&amp;#39;s open source JavaScript engine. V8 is written in C++ and is used 
&lt;span class="gu"&gt;@@ -51,8 +53,13 @@&lt;/span&gt;
 %setup -q -n %{name}-%{version}

 # -fno-strict-aliasing is needed with gcc 4.4 to get past some ugly code
&lt;span class="gd"&gt;-PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -Wno-error=strict-overflow -Wno-error=unused-local-typedefs -Wno-unused-but-set-variable\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
&lt;span class="gi"&gt;+%if 0%{?el5}&lt;/span&gt;
&lt;span class="gi"&gt;+PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -lncurses\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
&lt;span class="gi"&gt;+sed -i &amp;quot;s|&amp;#39;-O3&amp;#39;,|$PARSED_OPT_FLAGS,|g&amp;quot; SConstruct&lt;/span&gt;
&lt;span class="gi"&gt;+%else&lt;/span&gt;
&lt;span class="gi"&gt;+PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -Wno-error=strict-overflow -Wno-unused-but-set-variable\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
 sed -i &amp;quot;s|&amp;#39;-O3&amp;#39;,|$PARSED_OPT_FLAGS,|g&amp;quot; SConstruct
&lt;span class="gi"&gt;+%endif&lt;/span&gt;

 # clear spurious executable bits
 find . \( -name \*.cc -o -name \*.h -o -name \*.py \) -a -executable   
&lt;span class="gu"&gt;@@ -198,6 +205,17 @@&lt;/span&gt;
 %{python_sitelib}/j*.py*

 %changelog
&lt;span class="gi"&gt;+* Thu Jan 31 2013 Jason Antman  - 1:3.13.7.5-5&lt;/span&gt;
&lt;span class="gi"&gt;+- remove -Werror=unused-local-typedefs on cent6&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+* Wed Jan 30 2013 Jason Antman  - 1:3.13.7.5-4&lt;/span&gt;
&lt;span class="gi"&gt;+- define python_sitelib if it isn&amp;#39;t already (CentOS 5)&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+* Wed Jan 30 2013 Jason Antman  - 1:3.13.7.5-3&lt;/span&gt;
&lt;span class="gi"&gt;+- pull 3.13.7.5-2 &lt;span class="caps"&gt;SRPM&lt;/span&gt; from Fedora 19 Koji most recent build&lt;/span&gt;
&lt;span class="gi"&gt;+- add ncurses-devel BuildRequires&lt;/span&gt;
&lt;span class="gi"&gt;+- modify PARSED_OPT_FLAGS to work with g++ 4.1.2 on CentOS 5&lt;/span&gt;
&lt;span class="gi"&gt;+ &lt;/span&gt;
 * Sat Jan 26 2013 &lt;span class="caps"&gt;T.C.&lt;/span&gt; Hollingsworth  - 1:3.13.7.5-2
 - rebuild for icu-50
 - ignore new &lt;span class="caps"&gt;GCC&lt;/span&gt; 4.8 warning
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Thu, 31 Jan 2013 14:13:00 -0500</pubDate><guid>tag:blog.jasonantman.com,2013-01-31:2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/</guid><category>build</category><category>centos</category><category>node</category><category>nodejs</category><category>package</category><category>packaging</category><category>redhat</category><category>RHEL</category><category>rpm</category><category>specfile</category></item><item><title>Fedora Linux and OSX Dual Boot on Mid-2010 (6,2) 15” MacBook Pro Laptop</title><link>http://blog.jasonantman.com/2013/01/fedora-linux-and-osx-dual-boot-on-mid-2010-62-15-macbook-pro-laptop/</link><description>&lt;p&gt;As part of the transition from a contractor to a full-time employee of
&lt;a href="http://www.cmgdigital.com"&gt;Cox Media Group Digital &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Strategy&lt;/a&gt; (check
out our &lt;a href="https://github.com/cmgdigital"&gt;github&lt;/a&gt;), I&amp;#8217;ve been issued a
&lt;a href="http://support.apple.com/kb/SP582"&gt;Mid-2010 (6,2)&lt;/a&gt; 15&amp;#8221; &lt;a href="http://en.wikipedia.org/wiki/Macbook_pro#Technical_specifications_2"&gt;MacBook
Pro&lt;/a&gt;
laptop, to replace my current &lt;a href="http://support.apple.com/kb/SP11"&gt;Early-2008
(3,1)&lt;/a&gt; MacPro desktop. The desktop is
currently running &lt;a href="http://fedoraproject.org/"&gt;Fedora&lt;/a&gt; 17, dual-boot with
with Mac &lt;span class="caps"&gt;OS&lt;/span&gt; X (left in place for firmware updates and emergencies) using
the &lt;a href="http://www.rodsbooks.com/refind/index.html"&gt;rEFInd boot manager&lt;/a&gt; to
choose between the two OSes. It took me two days to get this working
right on my desktop, but it had been my plan to duplicate this setup on
my laptop. I found a lot of conflicting information online, but I
decided to give it a&amp;nbsp;try.&lt;/p&gt;
&lt;p&gt;Well, I have Fedora 18 and &lt;span class="caps"&gt;OS&lt;/span&gt; X 10.8 dual-booting on the laptop, but not
as planned. After a day and a half of research, troubleshooting and
re-installs, here&amp;#8217;s what I found to actually work, in the hope that
nobody else will go through the ordeal I went through. Following that
are some notes about the new Fedora 18 installer (Anaconda 18),
especially important for anyone who&amp;#8217;s used Linux for a while. To those
who are new to Linux, don&amp;#8217;t be dissuaded by the above. Most of the
frustration I experienced is because I&amp;#8217;ve been using Linux for a
relatively long time (about 10 years), had my own ideas about exactly
how I wanted things setup (which are decidedly &lt;em&gt;not&lt;/em&gt; supported by
Fedora), and had some assumptions about the installation process based
on earlier&amp;nbsp;versions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to get it&amp;nbsp;working:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Forget about rEFInd. This had been the original advice from &lt;a href="http://mjg59.dreamwidth.org/"&gt;Matthew
Garrett&lt;/a&gt;,
&lt;a href="https://twitter.com/mjg59"&gt;@mjg59&lt;/a&gt;, kernel coder, contributor to the
Anaconda project, and all-around authority on booting Linux on &lt;span class="caps"&gt;EFI&lt;/span&gt;/&lt;span class="caps"&gt;UEFI&lt;/span&gt;
hardware. My advice, and the method that worked for&amp;nbsp;me:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Shrink your Mac partitions and leave as much free space as you want
    for Fedora. using the Disk Utility tool in &lt;span class="caps"&gt;OS&lt;/span&gt; X (I also created an
    &lt;span class="caps"&gt;8GB&lt;/span&gt; &lt;span class="caps"&gt;VFAT&lt;/span&gt; partition that both OSes can read/write&amp;nbsp;to).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://fedoraproject.org/en/get-fedora"&gt;Download Fedora 18&lt;/a&gt; 64-bit
    &lt;span class="caps"&gt;DVD&lt;/span&gt; image, I chose the &lt;span class="caps"&gt;KDE&lt;/span&gt; version. Verify the sha256 sum if you
    want (they don&amp;#8217;t have a readily visible link to the checksum file.
    Copy the download link, paste it into your address bar and remove
    the filename. You should get a directory index that includes a
    &lt;code&gt;-CHECKSUM&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;Per the Installation Guide&amp;#8217;s &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/Making_USB_Media-UNIX_Linux.html"&gt;Making Fedora &lt;span class="caps"&gt;USB&lt;/span&gt; Media
    page&lt;/a&gt;,
    use &lt;code&gt;liveusb-creator&lt;/code&gt; to setup the installation image on the &lt;span class="caps"&gt;USB&lt;/span&gt;
    flash drive (I needed to start it with the &lt;code&gt;--reset-mbr&lt;/code&gt; option).
    You can also use other tools (dd if you&amp;#8217;re not on a Fedora-based
    distro), or a &lt;span class="caps"&gt;DVD&lt;/span&gt;, but this is the method I&amp;nbsp;chose.&lt;/li&gt;
&lt;li&gt;Due to a &lt;a href="https://fedorahosted.org/liveusb-creator/ticket/810"&gt;bug in
    liveusb-creator&lt;/a&gt;,
    you may need to manually edit &lt;code&gt;/EFI/boot/grub.cfg&lt;/code&gt; on the created
    &lt;span class="caps"&gt;USB&lt;/span&gt; stick if grub gives you a file not found error. If that happens,
    please see my bug report above for the action to take (in short, you
    need to mount the &lt;span class="caps"&gt;USB&lt;/span&gt; stick, &lt;code&gt;chmod u+w /EFI/boot/grub.cfg&lt;/code&gt; then
    edit that file and replace every occurrence of &amp;#8220;isolinux&amp;#8221; with
    &amp;#8220;syslinux&amp;#8221; and every occurrence of
    &amp;#8220;root=live:&lt;span class="caps"&gt;LABEL&lt;/span&gt;=Fedora-18-x86_64-Live-&lt;span class="caps"&gt;KDE&lt;/span&gt;.iso&amp;#8221; with&amp;nbsp;&amp;#8220;root=live:&lt;span class="caps"&gt;LABEL&lt;/span&gt;=&lt;span class="caps"&gt;LIVE&lt;/span&gt;&amp;#8221;).&lt;/li&gt;
&lt;li&gt;Boot the &lt;span class="caps"&gt;USB&lt;/span&gt; drive (use the alt key when you turn on the laptop to
    select the &lt;span class="caps"&gt;USB&lt;/span&gt; drive) and just install Fedora normally, letting it
    do its thing. Select a boot disk and let it put &lt;span class="caps"&gt;GRUB2&lt;/span&gt; on the &lt;span class="caps"&gt;EFI&lt;/span&gt;&amp;nbsp;partition.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When you boot, it will boot to &lt;span class="caps"&gt;GRUB&lt;/span&gt;. There will be some options for Mac
&lt;span class="caps"&gt;OS&lt;/span&gt; there, but they don&amp;#8217;t work (more on that below). If you want to boot
Mac, hold down the alt/option key when you power on the laptop, which
will bring you to the boot disk selector and you can pick the Mac disk.
I know it&amp;#8217;s not pretty or ideal, but it&amp;#8217;s the best option right&amp;nbsp;now.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Making it&amp;nbsp;Better:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;GRUB2&lt;/span&gt; tries to automatically detect other OSes and configure them in the
boot loader (this is done through &lt;code&gt;/etc/grub.d/30_os-prober&lt;/code&gt;, commonly
just referred to as &lt;code&gt;os-prober&lt;/code&gt;). It tries to boot Mac directly through
the xnu_kernel64 module, which not only isn&amp;#8217;t installed on the boot
partition by default, but just doesn&amp;#8217;t work with at least Mountain Lion
(10.8). So getting &lt;span class="caps"&gt;GRUB&lt;/span&gt; to boot Mac means either having the bugs in the
xnu module fixed, or figuring out how to setup a chainloader to boot
from &lt;span class="caps"&gt;GRUB&lt;/span&gt; to Mac. The latter is probably the method I&amp;#8217;ll investigate,
but for now, since I rarely use Mac, I&amp;#8217;m happy having to use the alt key
at boot to get there. To remove the annoying, broken Mac &lt;span class="caps"&gt;OS&lt;/span&gt; options from
the grub screen, run the following commands as root (they assume you
have your &lt;span class="caps"&gt;EFI&lt;/span&gt; partition mounted at &lt;code&gt;/boot/efi&lt;/code&gt; which I believe Fedora
should do by&amp;nbsp;default:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;cp /boot/efi/EFI/fedora/grub.cfg /boot/efi/EFI/fedora/grub.cfg.bak
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;GRUB_DISABLE_OS_PROBER=&amp;quot;true&amp;quot;&amp;#39;&lt;/span&gt; &amp;gt;&amp;gt; /etc/default/grub
grub2-mkconfig &amp;gt; /boot/efi/&lt;span class="caps"&gt;EFI&lt;/span&gt;/fedora/grub.cfg
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Thoughts on the Fedora 18 Anaconda&amp;nbsp;Installer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I found a couple of issues with the new Anaconda 18 installer that were
either unweildy or confusing for someone who&amp;#8217;s been installing Linux for
a long time. Overall, the new installer is very nice. It has a clean,
even elegant &lt;span class="caps"&gt;UI&lt;/span&gt;, a relatively nice flow from start to completion, and is
certainly beginner-friendly. It has fewer options than any Linux
installer I&amp;#8217;ve ever used before - not even options for package
selection, firewall or SELinux configuration, etc. - but I guess this is
in line with the goal of making Fedora a desktop &lt;span class="caps"&gt;OS&lt;/span&gt; for the masses. I
would have appreciated an &amp;#8220;advanced mode&amp;#8221; installer that was more like
Fedora 17 (or even much older versions), but I guess I&amp;#8217;m an edge case,
at least in the Fedora community. However, I did find two things
especially difficult, both related to the fact that my laptop has two
main drives (a &lt;span class="caps"&gt;500GB&lt;/span&gt; hard drive and a &lt;span class="caps"&gt;120GB&lt;/span&gt;&amp;nbsp;&lt;span class="caps"&gt;SSD&lt;/span&gt;):&lt;/p&gt;
&lt;p&gt;First, the installer prompted me to select a &amp;#8220;boot disk&amp;#8221;. I guess I
should have read the installation guide, but I assumed that nomenclature
translated to either &amp;#8220;which disk should the automatic partitiioning put
yout &lt;code&gt;/boot&lt;/code&gt; partition on&amp;#8221; or &amp;#8220;which disk should I set the bootable flag
on in the partition table&amp;#8221;. In fact, it means &amp;#8220;which disk should I put
&lt;span class="caps"&gt;GRUB&lt;/span&gt; on the &lt;span class="caps"&gt;EFI&lt;/span&gt; partition of&amp;#8221;. I installed, rebooted, and was shocked -
and somewhat distressed - to boot directly to &lt;span class="caps"&gt;GRUB2&lt;/span&gt; instead of the
rEFInd installation I had setup. The installer didn&amp;#8217;t have any of the
previously-customary &amp;#8220;warning: this will overwrite your &lt;span class="caps"&gt;MBR&lt;/span&gt;/&lt;span class="caps"&gt;EFI&lt;/span&gt; boot
partition&amp;#8221; notices, so I felt safe letting it continue. It turned out
that this was the way I ended up going, and it also turns out that
there&amp;#8217;s a bug in Anaconda that makes it fail installation if you tell it
not to write a bootloader to disk (though it&amp;#8217;s patched by one line of
Python code). But I was deeply distressed that - contrary to the
experience of every, admittedly more complicated, Linux installer I&amp;#8217;d
used before - the Fedora 18 installer overwrote my &lt;span class="caps"&gt;EFI&lt;/span&gt; bootloader
(analogous to overwriting the &lt;span class="caps"&gt;MBR&lt;/span&gt; on a &lt;span class="caps"&gt;BIOS&lt;/span&gt; boot machine) without ever
warning me or asking for a&amp;nbsp;confirmation.&lt;/p&gt;
&lt;p&gt;Secondly, the partitioning tool is clearly designed for only one
destination disk. The overview screen lists configured partitions by
label and mount point, but not by physical device, so figuring out which
partitions are on which physical disks takes a click on each and every
partition to view that information in the detail panel. When you create
a new partition, it&amp;#8217;s automatically put in a &lt;span class="caps"&gt;LVM&lt;/span&gt; volume group spanning
all disks. Changing the target of the automatically created volume group
requires a few clicks, as does changing the physical disks backing any
new volume groups. To assign a newly created partition to a specific
disk, you have to click on an unlabeled &amp;#8220;tool&amp;#8221; icon under the list of
partitions, far away from the information on the partition in question.
It&amp;#8217;s a nice interface for someone who clicks the &amp;#8220;partition
automatically&amp;#8221; button, or who just knows they want to add &amp;#8220;an extra
partition&amp;#8221;, but for anyone who has a specific layout in mind (like
having &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;/boot&lt;/code&gt; and &lt;code&gt;/var&lt;/code&gt;, specifically sized, on the &lt;span class="caps"&gt;SSD&lt;/span&gt; and
&lt;code&gt;/home&lt;/code&gt; on the rotating disk) it takes about 4-5 more clicks and dialogs
to add a partition than the last Fedora installer did. Mainly, it&amp;#8217;s
lacking any sort of Advanced Mode for partitioning that allows the user
to quickly and accurately layout a more complex partitioning&amp;nbsp;scheme.&lt;/p&gt;
&lt;p&gt;Below are some screenshots from the Fedora 17 and Fedora 18 Installation
Guides, which contrast both the overview of all partitions and the
individual partition&amp;nbsp;settings:&lt;/p&gt;
&lt;p&gt;Fedora 18 Overview, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/s1-diskpartitioning-x86.html"&gt;9.13. Creating a Custom Partition
Layout&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://www.dedoimedo.com/images/computers_years/2013_1/fedora-18-installer-configure-partitions.jpg" /&gt;  &lt;/p&gt;
&lt;p&gt;Fedora 17 Overview, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/s1-diskpartitioning-x86.html"&gt;9.14. Creating a Custom Layout or Modifying
the Default
Layout&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/images/diskpartitioning/ddmain.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Fedora 18 Partition Creation/Editing, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/Create_LVM-x86.html"&gt;9.13.3. Create &lt;span class="caps"&gt;LVM&lt;/span&gt; Logical
Volume&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://docs.fedoraproject.org/en-US/Fedora/18/html/Installation_Guide/images/diskpartitioning/lvm-pv.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Fedora 17 Partition Creation/Editing, from &lt;a href="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/Adding_Partitions-x86.html"&gt;9.14.2. Adding
Partitions&lt;/a&gt;:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="http://docs.fedoraproject.org/en-US/Fedora/17/html/Installation_Guide/images/diskpartitioning/part-add.png" /&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Mon, 21 Jan 2013 12:13:00 -0500</pubDate><guid>tag:blog.jasonantman.com,2013-01-21:2013/01/fedora-linux-and-osx-dual-boot-on-mid-2010-62-15-macbook-pro-laptop/</guid><category>bootloader</category><category>efi</category><category>fedora</category><category>gpt</category><category>grub</category><category>installation</category><category>laptop</category><category>mac</category><category>macbook</category><category>os x</category></item><item><title>Fedora Init Script Specification Summary</title><link>http://blog.jasonantman.com/2013/01/fedora-init-script-specification-summary/</link><description>&lt;p&gt;I&amp;#8217;ve been deploying some new software lately (specifically
&lt;a href="https://github.com/marisaseal/selenesse"&gt;selenesse&lt;/a&gt;, which combines
&lt;a href="http://seleniumhq.org/"&gt;Selenium&lt;/a&gt; and &lt;a href="http://fitnesse.org/"&gt;fitnesse&lt;/a&gt;,
&lt;a href="http://en.wikipedia.org/wiki/Xvfb"&gt;xvfb&lt;/a&gt;). None of these seem to come
with init scripts to run as daemons, and the quality of the few
Fedora/RedHat/CentOS init scripts I was able to find was quite poor. The
Fedora project has a &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript"&gt;Specification for SysV-style Init Scripts in their
Packaging wiki&lt;/a&gt;,
which specifies what a Fedora/RedHat/CentOS init script should look
like, in excruciating detail. What follows is an overview of the more
important points, which I&amp;#8217;m using to develop or modify the scripts I&amp;#8217;m
currently working&amp;nbsp;on.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scripts must be put in &lt;code&gt;/etc/rc.d/init.d&lt;/code&gt;, not in the &lt;code&gt;/etc/init.d&lt;/code&gt;
    symlink. They should have 0755&amp;nbsp;permissions.&lt;/li&gt;
&lt;li&gt;Scripts must have a Fedora-style &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Chkconfig_Header"&gt;chkconfig
    header&lt;/a&gt;
    (&amp;#8220;chkconfig:&amp;#8221;, &amp;#8220;description:&amp;#8221; lines), and may have an &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#LSB_Header"&gt;&lt;span class="caps"&gt;LSB&lt;/span&gt;-style
    header&lt;/a&gt;
    (&lt;span class="caps"&gt;BEGIN&lt;/span&gt; &lt;span class="caps"&gt;INIT&lt;/span&gt; &lt;span class="caps"&gt;INFO&lt;/span&gt;/&lt;span class="caps"&gt;END&lt;/span&gt; &lt;span class="caps"&gt;INIT&lt;/span&gt; &lt;span class="caps"&gt;INFO&lt;/span&gt;). See &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Initscript_template"&gt;Initscript
    template&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Scripts &lt;strong&gt;must&lt;/strong&gt; make use of a lockfile in &lt;code&gt;/var/lock/subsys/&lt;/code&gt;, and
    the name of the lockfile must be the same as the name of the init
    script. (There is a technical reason for this relating to how sysv
    init terminates daemons at shutdown). The lockfile should be touched
    when the daemon successfully starts, and removed when it
    successfully&amp;nbsp;stops.&lt;/li&gt;
&lt;li&gt;Init scripts should not depend on any environment variables set
    outside the script. They should operate gracefully with an
    empty/uninitialized environment (or only &lt;span class="caps"&gt;LANG&lt;/span&gt; and &lt;span class="caps"&gt;TERM&lt;/span&gt; set and a &lt;span class="caps"&gt;CWD&lt;/span&gt;
    of &lt;code&gt;/&lt;/code&gt;, as enforced by &lt;code&gt;service(8)&lt;/code&gt;, or with a full environment if
    they are called directly by a&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Required_Actions"&gt;Required&amp;nbsp;actions&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;all of the following actions are required, and have specific&amp;nbsp;definitions:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;start&lt;/strong&gt;: starts the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;stop&lt;/strong&gt;: stops the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;restart&lt;/strong&gt;: stop and restart the service if the service is
    already running, otherwise just start the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;condrestart (and try-restart)&lt;/strong&gt;: restart the service if the
    service is already running, if not, do&amp;nbsp;nothing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;reload&lt;/strong&gt;: reload the configuration of the service without
    actually stopping and restarting the service (if the service
    does not support this, do&amp;nbsp;nothing)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;force-reload&lt;/strong&gt;: reload the configuration of the service and
    restart it so that it takes&amp;nbsp;effect&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;status&lt;/strong&gt;: print the current status of the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;usage&lt;/strong&gt;: by default, if the initscript is run without any
    action, it should list a &amp;#8220;usage message&amp;#8221; that has all actions
    (intended for&amp;nbsp;use)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are specified exit codes for &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Exit_Codes_for_the_Status_Action"&gt;status
    actions&lt;/a&gt;
    and &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Exit_Codes_for_non-Status_Actions"&gt;non-status
    actions&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;They must &amp;#8220;behave sensibly&amp;#8221;. I&amp;#8217;ve found this to be one of the
    biggest problems with homegrown init scripts. If &lt;code&gt;servicename start&lt;/code&gt;
    is called while the service is already running, it should simply
    exit 0. Likewise if the service is already stopped. Init scripts
    &lt;strong&gt;must not kill unrelated processes&lt;/strong&gt;. I don&amp;#8217;t know how many times
    I&amp;#8217;ve seen scripts that kill every java or python process on a&amp;nbsp;machine.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I intend to use this as a quick checklist when developing or evaluating
init scripts for RedHat/Fedora based systems. In my experience, the
biggest problems with most init scripts revolve around poor handling of
&lt;span class="caps"&gt;PID&lt;/span&gt; files and lockfiles,&amp;nbsp;mainly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Killing processes other than the one that the script started (i.e.
    killing all java or python processes), usually because the &lt;span class="caps"&gt;PID&lt;/span&gt; isn&amp;#8217;t
    tracked at&amp;nbsp;start&lt;/li&gt;
&lt;li&gt;Starting a second instance of the subsystem because lockfiles aren&amp;#8217;t
    used, or the status function is&amp;nbsp;broken.&lt;/li&gt;
&lt;li&gt;improper exit&amp;nbsp;codes&lt;/li&gt;
&lt;li&gt;either explicitly relying on environment variables (and therefore
    breaking when called through &lt;code&gt;service(8)&lt;/code&gt;), or conversely, not
    cleaning/resetting environment variables that are used by dependent
    code or&amp;nbsp;processes.&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Thu, 03 Jan 2013 11:30:00 -0500</pubDate><guid>tag:blog.jasonantman.com,2013-01-03:2013/01/fedora-init-script-specification-summary/</guid><category>centos</category><category>fedora</category><category>init</category><category>redhat</category><category>startup</category></item><item><title>Random Links for Wednesday, October 24th</title><link>http://blog.jasonantman.com/2012/10/random-links-for-wednesday-october-24th/</link><description>&lt;p&gt;Some random interesting links from Slashdot for&amp;nbsp;today:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://news.slashdot.org/story/12/10/23/2038220/the-greatest-battle-of-the-personal-computing-revolution-lies-ahead"&gt;The Greatest Battle of the Personal Computing Revolution Lies Ahead
    -
    Slashdot&lt;/a&gt;.
    A bit of a rant, but makes some good points that are close to my
    heart, and unfortunately far from the thoughts of many&amp;nbsp;non-techies.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tos-dr.info/"&gt;Terms of Service; Didn&amp;#8217;t Read&lt;/a&gt; - an
    interesting&amp;nbsp;project&lt;/li&gt;
&lt;li&gt;&lt;a href="http://yro.slashdot.org/story/12/10/21/208206/how-patent-trolls-harm-the-economy"&gt;How Patent Trolls Harm the Economy -
    Slashdot&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;another issue close to my&amp;nbsp;heart&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.datacenterknowledge.com/archives/2012/10/17/how-google-cools-its-armada-of-servers/"&gt;How Google Cools Its Armada of Servers » Data Center&amp;nbsp;Knowledge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.google.com/about/datacenters/gallery/#/"&gt;Data centers – Google Data
    centers&lt;/a&gt; - A
    photo tour of Google data centers, by Google, along with a &lt;a href="https://plus.google.com/+google/posts/Gk8ScjPX23n"&gt;Google+
    post&lt;/a&gt; about the
    architecture photographer who did this&amp;nbsp;work.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tech.slashdot.org/story/12/10/22/0518231/darpa-funds-a-300-software-defined-radio-for-hackers"&gt;&lt;span class="caps"&gt;DARPA&lt;/span&gt; Funds a $300 Software-Defined Radio For Hackers -
    Slashdot&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;way&amp;nbsp;cool.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://map.honeynet.org/"&gt;Honeynet Map&lt;/a&gt; - &amp;#8220;realtime&amp;#8221; map of
    cybersecurity incidents, from the Honeynet&amp;nbsp;Project.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://science.slashdot.org/story/12/10/17/1741225/malware-is-rampant-on-medical-devices-in-hospitals"&gt;Malware Is &amp;#8216;Rampant&amp;#8217; On Medical Devices In Hospitals -
    Slashdot&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;a bit scary, but unfortunately not that hard to guess. I&amp;#8217;ve seen
(probably unpatched) Windows 2000 workstations on hospital&amp;nbsp;networks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;To top off the scary posts: &lt;a href="http://news.slashdot.org/story/12/10/17/0325236/researcher-reverse-engineers-pacemaker-transmitter-to-deliver-deadly-shocks"&gt;Researcher Reverse-Engineers Pacemaker
    Transmitter To Deliver Deadly Shocks -&amp;nbsp;Slashdot&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Wed, 24 Oct 2012 12:01:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-10-24:2012/10/random-links-for-wednesday-october-24th/</guid><category>appliancization</category><category>cooling</category><category>datacenter</category><category>google</category><category>healthcare</category><category>legal</category><category>links</category><category>malware</category><category>pacemaker</category><category>patents</category><category>radio</category><category>SDR</category><category>security</category></item><item><title>Readable Nagios Log Timestamps</title><link>http://blog.jasonantman.com/2012/10/readable-nagios-log-timestamps/</link><description>&lt;p&gt;If you&amp;#8217;re like me and most humans, the Nagios logfile timestamp (a unix
timestamp) isn&amp;#8217;t terribly useful when trying to grep through the logs
and correlate&amp;nbsp;events:  &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; head -2 nagios.log
&lt;span class="go"&gt;[1350360000] &lt;span class="caps"&gt;LOG&lt;/span&gt; &lt;span class="caps"&gt;ROTATION&lt;/span&gt;: &lt;span class="caps"&gt;DAILY&lt;/span&gt;&lt;/span&gt;
&lt;span class="go"&gt;[1350360000] &lt;span class="caps"&gt;LOG&lt;/span&gt; &lt;span class="caps"&gt;VERSION&lt;/span&gt;: 2.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here&amp;#8217;s a nifty Perl one-liner that you can pipe your logs&amp;nbsp;through:  &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="n"&gt;perl&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;pe&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;s/(\\d+)/localtime($1)/e&amp;#39;&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to get nicer output&amp;nbsp;like:  &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# head -2 nagios.log&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Tue&lt;/span&gt; &lt;span class="n"&gt;Oct&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;LOG&lt;/span&gt;&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;ROTATION&lt;/span&gt;:&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;DAILY&lt;/span&gt;&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Tue&lt;/span&gt; &lt;span class="n"&gt;Oct&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;LOG&lt;/span&gt;&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;VERSION&lt;/span&gt;:&lt;/span&gt; &lt;span class="mf"&gt;2.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Wed, 17 Oct 2012 05:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-10-17:2012/10/readable-nagios-log-timestamps/</guid><category>icinga</category><category>Nagios</category><category>perl</category><category>timestamp</category></item><item><title>Custom Tombstone and Road Sign Pictures</title><link>http://blog.jasonantman.com/2012/10/custom-tombstone-and-road-sign-pictures/</link><description>&lt;p&gt;On the lighter side, I found a few web sites by &lt;a href="http://www.pixbytom.com/"&gt;Tom
Blackwell&lt;/a&gt; that do some fun stuff with text
overlays on images. seems like a nice little tool for those
end-of-project powerpoints, or to send out the monthly &amp;#8220;most rolled-back
commits&amp;#8221;&amp;nbsp;medal&amp;#8230;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.tombstonebuilder.com/index.php"&gt;Custom Tombstone&amp;nbsp;Maker&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Image of tombstone, with 'Your Text Goes Here' carved into it" src="/GFX/my_tombstone.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.customroadsign.com/"&gt;CustomRoadSign.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Highway sign with 'Your Text Goes Here' written on it" src="/GFX/menusign.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.custommotelsign.com/"&gt;CustomMotelSign.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Motel-style sign with 'Your Text Goes Here' written on it" src="/GFX/motelsign.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.getamedal.com/"&gt;GetAMedal.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Gold medal with 'Your Text Goes Here' written on it" src="/GFX/medal.jpg" /&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 16 Oct 2012 07:02:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-10-16:2012/10/custom-tombstone-and-road-sign-pictures/</guid><category>graphics</category><category>humor</category><category>road sign</category><category>sign</category><category>tombstone</category></item><item><title>All-Mechanical Computer Instructional Video</title><link>http://blog.jasonantman.com/2012/10/all-mechanical-computer-instructional-video/</link><description>&lt;p&gt;I saw a link to &lt;a href="http://www.youtube.com/watch?v=s1i-dnAH9Y4"&gt;this YouTube
video&lt;/a&gt; shared on &lt;a href="http://everythingsysadmin.com/2012/10/mechanical-computer-instructio.html"&gt;Tom
Limoncelli&amp;#8217;s
blog&lt;/a&gt;.
It&amp;#8217;s a 1953 &lt;span class="caps"&gt;US&lt;/span&gt; Navy instructional video about an all-mechanical fire
control computer. Yes, I really mean a &lt;em&gt;computer&lt;/em&gt; that can solve
continuously changing 25-variable fire control problems using only
mechanical means (gears, cams, etc.). Think about it for a minute - it&amp;#8217;s
truly mind-boggling. And really gives one an amazing appreciation for
the power of a simple pocket calculator, and the amazing engineering
that went into solving these problems before electronic computers. I&amp;#8217;m
usually not much of a math geek, but I watched the whole 40 minute video
and was in awe of both the simple ability to use three arms and a pin to
multiply numbers, and the amazingly precise engineering and machining it
would take to translate various rotation inputs into landing a shell on
a moving ship miles away. It&amp;#8217;s a really good watch, and will probably
leave you astonished by both how far technology has come (and what we
take for granted every day), and by the fact that feats of engineering
like this one worked quite&amp;nbsp;well.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Fri, 12 Oct 2012 20:54:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-10-12:2012/10/all-mechanical-computer-instructional-video/</guid><category>mechanical computer</category></item><item><title>Pretty-Print a JSON response at the command line</title><link>http://blog.jasonantman.com/2012/10/pretty-print-a-json-response-at-the-command-line/</link><description>&lt;p&gt;I&amp;#8217;ve been doing some work with &lt;a href="http://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;
lately, and have been doing some testing against its &lt;span class="caps"&gt;HTTP&lt;/span&gt;-based &lt;span class="caps"&gt;API&lt;/span&gt;,
which returns results in &lt;span class="caps"&gt;JSON&lt;/span&gt;. If you&amp;#8217;re looking to pretty-print a &lt;span class="caps"&gt;JSON&lt;/span&gt;
response for easier viewing, here&amp;#8217;s a nice way to do it at the command
line using Python and
&lt;a href="http://docs.python.org/library/json.html"&gt;json.tool&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl http://username:pass@hostname:55672/api/overview | python -m json.tool&lt;/code&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 09 Oct 2012 14:44:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-10-09:2012/10/pretty-print-a-json-response-at-the-command-line/</guid><category>curl</category><category>json</category><category>python</category><category>rabbitmq</category></item><item><title>Nagstamon on Fedora 17</title><link>http://blog.jasonantman.com/2012/10/nagstamon-on-fedora-17/</link><description>&lt;p&gt;Since I started my last job, I&amp;#8217;ve been using
&lt;a href="http://nagstamon.ifw-dresden.de/"&gt;Nagstamon&lt;/a&gt; on my workstation; it&amp;#8217;s a
really handy little system tray application that monitors a
Nagios/Icinga instance and shows status updates/summary in a handy
fashion, including flashing and (optionally) a sound alert when
something changes. Unfortunately, there doesn&amp;#8217;t seem to be a Fedora 17
package for it, though there is an entry on the &lt;a href="http://fedoraproject.org/wiki/Package_maintainers_wishlist#N-O"&gt;Fedora package
maintainers
wishlist&lt;/a&gt;.
The closest I was able to find is a
&lt;a href="http://pkgs.org/centos-6-rhel-6/repoforge-i386/nagstamon-0.9.7.1-2.el6.rf.noarch.rpm.html"&gt;repoforge/RPMforge&lt;/a&gt;
package of Nagstamon 0.9.7.1, along with a &lt;a href="http://apt.sw.be/source/nagstamon-0.9.7.1-2.rf.src.rpm"&gt;source
&lt;span class="caps"&gt;RPM&lt;/span&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here are the steps to build that package on&amp;nbsp;F17:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Download and install
    &lt;a href="http://apt.sw.be/source/rpm-macros-rpmforge-0-6.rf.src.rpm"&gt;rpm-macros-rpmforge&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;As root, edit &lt;code&gt;/etc/rpm/macros.rpmforge&lt;/code&gt; and comment out the &lt;code&gt;%dist&lt;/code&gt;
    macro, so we&amp;#8217;ll still have the default &amp;#8220;fc17&amp;#8221; dist&amp;nbsp;tag.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wget http://apt.sw.be/source/nagstamon-0.9.7.1-2.rf.src.rpm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;rpmbuild &amp;#8212;rebuild&amp;nbsp;nagstamon-0.9.7.1-2.rf.src.rpm&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hopefully this will help someone else as well. At the moment, Nagstamon
is actually up to version 0.9.9, so hopefully I&amp;#8217;ll build a newer package
sometime&amp;nbsp;soon.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Fri, 05 Oct 2012 07:37:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-10-05:2012/10/nagstamon-on-fedora-17/</guid><category>fedora</category><category>nagios. icinga</category><category>nagstamon</category><category>package</category><category>rpm</category></item><item><title>New Job</title><link>http://blog.jasonantman.com/2012/09/new-job/</link><description>&lt;p&gt;Today is my last day in my almost-year-long stint as a System
Administrator at &lt;a href="http://www.techtarget.com/"&gt;TechTarget&lt;/a&gt;. Monday, I
start a new contract-to-perm position as a Linux Engineer with &lt;a href="http://cmgdigital.com/"&gt;Cox
Media Group Digital &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Strategy&lt;/a&gt;. I can&amp;#8217;t say a
whole lot about the new job, other than it will hopefully be a great
change for me, and they make heavy use of
&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt;. If you want to get a bit of an
idea of what they&amp;#8217;re about, here&amp;#8217;s a &lt;a href="https://github.com/coxmediagroup/jobs/blob/master/ethos.rst"&gt;document on their departmental
ethos&lt;/a&gt;.
Hopefully I&amp;#8217;ll be able to post more useful information here, and post
more often, in the future. I&amp;#8217;m really psyched about the new&amp;nbsp;gig.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Fri, 28 Sep 2012 12:36:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-09-28:2012/09/new-job/</guid><category>cmg</category><category>coxmedia</category><category>job</category><category>techtarget</category></item><item><title>Some questions from a tech interview with a big Internet company</title><link>http://blog.jasonantman.com/2012/09/some-questions-from-a-tech-interview-with-a-big-internet-company/</link><description>&lt;p&gt;A while back, I did a technical phone screen with a big online &amp;#8220;social&amp;#8221;
company (I won&amp;#8217;t say who, but they&amp;#8217;re a household name, growing fast,
and doing cool things; that doesn&amp;#8217;t leave &lt;em&gt;too&lt;/em&gt; many options). I rarely
remember to write down interview questions, but I was cleaning out my
desk this morning and came by a ripped-out sheet of notebook paper with
a handful of the interview questions written on it. Most of them weren&amp;#8217;t
terribly difficult, or terribly unusual for competent technical
interviewers, but since I happen to actually have the list written down,
I though I&amp;#8217;d share it. I don&amp;#8217;t remember why the programming questions
are all Python; likely, I was asked to choose between Python (which I&amp;#8217;ve
used, though not lately), Ruby (which I can barely muddle my way through
reading on a good day), and something else I don&amp;#8217;t know. Here are some
of&amp;nbsp;them&amp;#8230;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is an inode? What does it&amp;nbsp;store?&lt;/li&gt;
&lt;li&gt;What is a hard&amp;nbsp;link?&lt;/li&gt;
&lt;li&gt;What is the difference between a hard link and a soft&amp;nbsp;link?&lt;/li&gt;
&lt;li&gt;What is a list in&amp;nbsp;Python?&lt;/li&gt;
&lt;li&gt;Name some data structures that you&amp;#8217;d use in Python. Describe them,
    and tell me why you would use&amp;nbsp;them.&lt;/li&gt;
&lt;li&gt;How would you list all the man pages containing the keyword&amp;nbsp;&amp;#8220;date&amp;#8221;?&lt;/li&gt;
&lt;li&gt;If the &lt;code&gt;chmod&lt;/code&gt; binary had its permissions set to &lt;code&gt;000&lt;/code&gt;, how would
    you fix&amp;nbsp;it?&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Wed, 12 Sep 2012 05:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-09-12:2012/09/some-questions-from-a-tech-interview-with-a-big-internet-company/</guid><category>hiring</category><category>interview</category><category>questions</category><category>sysadmin</category></item><item><title>Dumping all Macros from an RPM Spec File</title><link>http://blog.jasonantman.com/2012/09/dumping-all-macros-from-an-rpm-spec-file/</link><description>&lt;p&gt;I&amp;#8217;ve been doing a lot of &lt;span class="caps"&gt;RPM&lt;/span&gt; packaging lately, and on different (and
very old) distros and versions. Sometimes I lose track of all of the
macros used in specfiles (&lt;code&gt;_bindir _sbindir dist _localstatedir&lt;/code&gt;, etc).
There&amp;#8217;s no terribly easy way to dump a list of all of the available
macros. There is, however, a bit of a kludge. Insert the following code
in your specfile before the &lt;code&gt;%prep&lt;/code&gt; or &lt;code&gt;%setup&lt;/code&gt; lines:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;%dump
exit 1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;%dump&lt;/code&gt; macro will dump all defined macros to &lt;span class="caps"&gt;STDERR&lt;/span&gt;. The &lt;code&gt;exit 1&lt;/code&gt;
will prevent rpmbuild from going on and trying to build the package. If
you want to view the output nicely, you can pipe it through a pager like
less: &lt;code&gt;rpmbuild -ba filename.spec 2&amp;gt;&amp;amp;1 | less&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Just make sure to remove those two lines when you want to actually build
the&amp;nbsp;package.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Mon, 10 Sep 2012 10:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-09-10:2012/09/dumping-all-macros-from-an-rpm-spec-file/</guid><category>packaging</category><category>rpm</category><category>rpmbuild</category></item><item><title>Getting oVirt up and running</title><link>http://blog.jasonantman.com/2012/09/getting-ovirt-up-and-running/</link><description>&lt;p&gt;The bulk of this post was written way back in April 2012. If you&amp;#8217;re just
coming here, and looking to setup oVirt, you should probably &lt;a href="#postscript"&gt;skip down
to the postscript&lt;/a&gt; for an update, and ignore most of the
content here (as it&amp;#8217;s applicable to an older oVirt&amp;nbsp;version).&lt;/p&gt;
&lt;p&gt;I recently started setting up &lt;a href="http://www.ovirt.org"&gt;oVirt&lt;/a&gt;, the
community version of Red Hat Enterprise Virtualization, at work for some
testing (mainly a &amp;#8220;sandbox&amp;#8221; &lt;span class="caps"&gt;VM&lt;/span&gt; environment, and because
&lt;a href="http://theforeman.org/"&gt;Foreman&lt;/a&gt;
&lt;a href="http://blog.theforeman.org/2012/03/vnc-support-built-in-foreman.html"&gt;supports&lt;/a&gt;
it). To start with, I had two nodes, each with two dual-core Xeon
processors (&lt;span class="caps"&gt;VT&lt;/span&gt;-x capable) with &lt;span class="caps"&gt;20GB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;, one with &lt;span class="caps"&gt;600GB&lt;/span&gt; internal storage
and one with &lt;span class="caps"&gt;140GB&lt;/span&gt; internal. While oVirt&amp;#8217;s documentation isn&amp;#8217;t exactly
wonderful, I found a blgo post by Jason Brooks, &lt;a href="http://blog.jebpages.com/archives/how-to-get-up-and-running-with-ovirt/"&gt;How to Get Up and
Running with
oVirt&lt;/a&gt;,
which gives a great walkthrough of getting the oVirt Engine setup on a
machine, and also setting up that same machine as a &lt;span class="caps"&gt;VM&lt;/span&gt; host. As oVirt is
still fairly young, this is all done on Fedora. I performed my
installation via Cobbler, though I&amp;#8217;m afraid to admit it was an entirely
manual, interactive&amp;nbsp;install.&lt;/p&gt;
&lt;p&gt;I did run into a few bumps during Jason&amp;#8217;s tutorial. In step 15, adding
the data &lt;span class="caps"&gt;NFS&lt;/span&gt; export as a Storage Domain, I was unable to add the &lt;span class="caps"&gt;NFS&lt;/span&gt;
export. I found the &lt;a href="http://www.ovirt.org/wiki/Troubleshooting_NFS_Storage_Issues"&gt;Troubleshooting &lt;span class="caps"&gt;NFS&lt;/span&gt; Storage Issues page on the
oVirt
wiki&lt;/a&gt;,
ensured that SELinux was disabled and that the export had the correct
permissions, confirmed that &lt;code&gt;/etc/nfsmount.conf&lt;/code&gt; specified &lt;code&gt;Nfsvers=3&lt;/code&gt;,
rebooted, and then ran the &lt;code&gt;nfs-check.py&lt;/code&gt; script. At this point, I was
able to add the other storage domains in steps 15 and&amp;nbsp;16.&lt;/p&gt;
&lt;p&gt;My second issue was that even on Fedora 16, I simply can&amp;#8217;t get the spice
client (through the &lt;code&gt;spice-xpi&lt;/code&gt; browser plugin) to work. As far as I can
tell from the logs, it looks like &lt;code&gt;spicec&lt;/code&gt; is being sent a value of
&amp;#8220;None&amp;#8221; for the secured port parameter, instead of the correct port
number. I assume this is a bug in oVirt, but I&amp;#8217;ll revisit this problem
when I have time. In the mean time, I changed my test &lt;span class="caps"&gt;VM&lt;/span&gt; to use &lt;span class="caps"&gt;VNC&lt;/span&gt;,
which is launched by installing the &lt;code&gt;ovirt-engine-cli&lt;/code&gt; package (see
below) on your client computer, connecting to the oVirt &lt;span class="caps"&gt;API&lt;/span&gt; with&amp;nbsp;ovirt-shell:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;ovirt-shell --connect --url=https://ovirt-engine.example.com:8443/api --user=admin@internal --password adminpassword&lt;/code&gt;&lt;br /&gt;
and then running &lt;code&gt;console vm_name&lt;/code&gt;. This launches the &lt;code&gt;vncviewer&lt;/code&gt;
binary, which is in the &amp;#8220;tigervnc&amp;#8221; package on&amp;nbsp;Fedora.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing&amp;nbsp;ovirt-engine-cli&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To run &lt;code&gt;ovirt-shell&lt;/code&gt; on your workstation (Fedora 16, of course&amp;#8230;)
you&amp;#8217;ll need the ovirt-engine-cli and ovirt-engine-sdk packages. I
manually downloaded them from
&lt;a href="http://www.ovirt.org/releases/nightly/fedora/16/"&gt;http://www.ovirt.org/releases/nightly/fedora/16/&lt;/a&gt;,
versions 2.1.3 and 1.6.2, respecitively. The &lt;span class="caps"&gt;SDK&lt;/span&gt; and &lt;span class="caps"&gt;CLI&lt;/span&gt; are python
based, so there are a few Python dependencies, all of which were
automatically solved by yum. I know there are &lt;span class="caps"&gt;SDK&lt;/span&gt; and &lt;span class="caps"&gt;CLI&lt;/span&gt; packages out
there for other distros, but haven&amp;#8217;t tried them&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing Linux&amp;nbsp;Guests&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Installing a CentOS 6.2 x86_64 guest was relatively straightforward,
and my usual kickstart infrastructure worked fine. The only catch was
the VirtIO storage interface, which shows up as &lt;code&gt;/dev/vdx&lt;/code&gt; instead of
&lt;code&gt;/dev/sdx&lt;/code&gt;; I just added another kickstart metadata option in Cobbler
that allows me to use &lt;code&gt;sdx&lt;/code&gt; by specifying &amp;#8220;virtual=yes&amp;#8221; (for our VMWare
hosts), or &lt;code&gt;vdx&lt;/code&gt; by specifying&amp;nbsp;&amp;#8220;virtual=ovirt&amp;#8221;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setting up&amp;nbsp;Authentication&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As installed, oVirt only has one user, &amp;#8220;admin@internal&amp;#8221;; it requires an
external directory service for user authentication. Currently, it
supports &lt;span class="caps"&gt;IPA&lt;/span&gt;, Red Hat&amp;#8217;s Enterprise Identity Management tool (combines
&lt;span class="caps"&gt;RHEL&lt;/span&gt;, oVirt Directory Server, Kerberos and &lt;span class="caps"&gt;NTP&lt;/span&gt;; perhaps
&lt;a href="http://freeipa.org"&gt;FreeIPA&lt;/a&gt; would work as well?) and Microsoft Active
Directory. As much as I&amp;#8217;d like to give &lt;span class="caps"&gt;IPA&lt;/span&gt; or FreeIPA a try, my company
already has an &lt;span class="caps"&gt;AD&lt;/span&gt; infrastructure, so I opted to go that route.
Documentation is given in the &lt;a href="http://www.ovirt.org/wiki/File:OVirt-3.0-Installation_Guide-en-US.pdf"&gt;oVirt 3.0 Installation
Guide&lt;/a&gt;,
starting on page 96. Unfortunately, I was never about to get &lt;span class="caps"&gt;AD&lt;/span&gt; auth
working correctly, so I just worked with the one admin&amp;nbsp;user.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adding a&amp;nbsp;Node&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The biggest issue I had was adding the second node to oVirt. I attempted
to use the &lt;span class="caps"&gt;DVD&lt;/span&gt; Import feature of Cobbler on the &lt;a href="http://www.ovirt.org/get-ovirt/"&gt;oVirt Node Image
&lt;span class="caps"&gt;ISO&lt;/span&gt;&lt;/a&gt;, but that failed. I then found the
image&amp;#8217;s &lt;code&gt;LiveOS/livecd-iso-to-pxeboot&lt;/code&gt; script and used that to make a
kernerl and initrd, and kernel parameters, for Cobbler. &lt;span class="caps"&gt;PXE&lt;/span&gt; works&amp;nbsp;fine.&lt;/p&gt;
&lt;p&gt;&lt;a name="postscript"&gt;&lt;/a&gt;&lt;strong&gt;Postscript:&lt;/strong&gt; I ended up blowing away my
oVirt installation in favor of testing other things. At some point, the
engine install got corrupted in a way that I just couldn&amp;#8217;t fix; even
though I spent all day one Saturday working on it, it took more time
than I could allocate to a personal project. So this post is really
semi-complete at best. However, there is some good news. Jason Brooks&amp;#8217;
original post, &lt;a href="http://blog.jebpages.com/archives/how-to-get-up-and-running-with-ovirt/"&gt;How to Get Up and Running with
oVirt&lt;/a&gt;,
was written for oVirt 3.0, as was this post. Since then, there has been
a new release, &lt;a href="http://wiki.ovirt.org/wiki/OVirt_3.1_release_notes"&gt;oVirt
3.1&lt;/a&gt;, which
apparently has a better &lt;span class="caps"&gt;UI&lt;/span&gt; and a better installer. Jason Brooks has a
new post, &lt;a href="http://blog.jebpages.com/archives/up-and-running-with-ovirt-3-1-edition/"&gt;Up and Running with oVirt, 3.1
Edition&lt;/a&gt;,
which covers installation and configuration of both an all-in-one
machine and a separate node. If you&amp;#8217;re looking to try oVirt, I&amp;#8217;d
recommend you give that a shot. Unfortunately (and strangely, given that
this is supposed to be the &amp;#8220;upstream&amp;#8221; of RedHat&amp;#8217;s proprietary &lt;span class="caps"&gt;RHEV&lt;/span&gt;) it&amp;#8217;s
still all based on&amp;nbsp;Fedora.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Fri, 07 Sep 2012 05:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-09-07:2012/09/getting-ovirt-up-and-running/</guid><category>fedora</category><category>kvm</category><category>ovirt</category><category>qemu</category><category>redhat</category><category>rhev</category><category>spice</category><category>virtualization</category></item><item><title>Project - Storing and Analyzing Apache httpd Logs from Many Hosts</title><link>http://blog.jasonantman.com/2012/09/project-storing-and-analyzing-apache-httpd-logs-from-many-hosts/</link><description>&lt;p&gt;I&amp;#8217;ve recently started casual work on a side-project to collect, store,
and analyze apache logs from a bunch of servers - for the initial
implementation, I&amp;#8217;m looking to handle about 15M access_log lines per
day (that works out to 173 lines/second assuming an even distribution,
which there certainly isn&amp;#8217;t). Here is a selection of links that I&amp;#8217;ve
been using for ideas and inspiration, both for the technical side (data
collection, transport, storage and analysis) and&amp;nbsp;visualization:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://oss.oetiker.ch/rrdtool/gallery/index.en.html"&gt;RRDtool - RRDtool
    Gallery&lt;/a&gt; - I&amp;#8217;m
    starting a graphing/log analysis project, and looked here for some
    inspiration for my proof-of-concept&amp;nbsp;code&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aplawrence.com/Girish/gv-rrdtool.html"&gt;Creating pretty graphs with
    &lt;span class="caps"&gt;RRDTOOL&lt;/span&gt;&lt;/a&gt; from &lt;a href=""&gt;Girish
    Venkatachalam&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;There&amp;#8217;s some good information on RRDtool&amp;#8217;s &amp;#8220;Abberant Behavior
    Detection&amp;#8221; (Holt-Winters prediction, deviation and failure
    detection) on the
    &lt;a href="http://oss.oetiker.ch/rrdtool/doc/rrdtool.en.html"&gt;rrdtool&lt;/a&gt;,
    &lt;a href="http://oss.oetiker.ch/rrdtool/doc/rrdgraph_examples.en.html"&gt;rrdgraph_examples&lt;/a&gt;
    and &lt;a href="http://oss.oetiker.ch/rrdtool/doc/rrdcreate.en.html"&gt;rrdcreate&lt;/a&gt;
    documentation pages, but unfortunately no anchors to link directly&amp;nbsp;to.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://square.github.com/cube/"&gt;Cube&lt;/a&gt; - &amp;#8220;Cube is a system for
    collecting timestamped events and deriving metrics. By collecting
    events rather than metrics, Cube lets you compute aggregate
    statistics post hoc. It also enables richer analysis, such as
    quantiles and histograms of arbitrary event sets. Cube is built on
    MongoDB and available under the Apache License on&amp;nbsp;GitHub.&amp;#8221;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://square.github.com/cubism/"&gt;Cubism.js&lt;/a&gt; - &amp;#8220;Cubism.js is a D3
    plugin for visualizing time series. Use Cubism to construct better
    realtime dashboards, pulling data from Graphite, Cube and other
    sources. Cubism is available under the Apache License on GitHub.&amp;#8221;
    The demo on that page looks pretty&amp;nbsp;cool.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.highcharts.com/demo/"&gt;Highcharts Demo Gallery&lt;/a&gt; - &lt;span class="caps"&gt;JS&lt;/span&gt;
    chart/graph library. It requires a paid license for commercial use
    (though it&amp;#8217;s a bit unclear to me whether an internal ops dashboard
    would fall under this license provision) so I probably wouldn&amp;#8217;t go
    with this one. They have some cool charts, including a &lt;a href="http://www.highcharts.com/demo/dynamic-update/gray"&gt;dynamic line
    chart updating every
    second&lt;/a&gt;, a
    &lt;a href="http://www.highcharts.com/demo/scatter/gray"&gt;scatter plot&lt;/a&gt; and a
    nice &lt;a href="http://www.highcharts.com/demo/line-time-series/gray"&gt;zoomable time-series
    graph&lt;/a&gt;, though
    &lt;span class="caps"&gt;IMHO&lt;/span&gt; it&amp;#8217;s not as nice as the Google Chart Tools (formerly Google
    Visualization) &lt;a href="https://developers.google.com/chart/interactive/docs/gallery/annotatedtimeline"&gt;annotated
    timeline&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://forums.cacti.net/viewtopic.php?t=29963"&gt;[ &lt;span class="caps"&gt;HOWTO&lt;/span&gt; ] Graphing Holt-Winters Predictive
    Analysis&lt;/a&gt; - Cacti&amp;nbsp;forums&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dygraphs.com/"&gt;dygraphs&lt;/a&gt; - an impressive permissive-license
    &lt;span class="caps"&gt;JS&lt;/span&gt; chart library dedicated to visualizing dense time-series data.
    Developed by Google and now used by them (Google Correlate, Google
    Latitude) as well as &lt;span class="caps"&gt;NASA&lt;/span&gt;, 10gen and others. There are some very
    cool demos on that main page, and also on the &lt;a href="http://dygraphs.com/tests/"&gt;tests
    page&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.planetdevops.net/?p=12289"&gt;Graphite, JMXTrans, Ganglia, Logster, Collectd, say what ? « Planet&amp;nbsp;DevOps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://auxesis.github.com/visage/"&gt;Visage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kgorman/mongo_graph"&gt;kgorman/mongo_graph&lt;/a&gt; - a
    tool to pull data from MongoDB and put it in &lt;span class="caps"&gt;RRD&lt;/span&gt;&amp;nbsp;files&lt;/li&gt;
&lt;li&gt;&lt;a href="http://web.taranis.org/drraw/"&gt;drraw&lt;/a&gt; - a perl-based graphing
    frontend (web &lt;span class="caps"&gt;UI&lt;/span&gt;) for&amp;nbsp;RRDtool&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/etsy/logster"&gt;etsy/logster · GitHub&lt;/a&gt; - Etsy&amp;#8217;s
    Python tool to maintain a pointer on a log file, and parse at a
    regular rate feeding the data into a tool like Graphite or&amp;nbsp;Ganglia.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cebailey59/charcoal"&gt;cebailey59/charcoal&lt;/a&gt; - a
    Sinatra app that allows creation of dashboards from Graphite,
    collectd, or any other service that creates images from &lt;span class="caps"&gt;URL&lt;/span&gt;&amp;nbsp;calls.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/etsy/dashboard"&gt;etsy/dashboard&lt;/a&gt; - some examples
    of how Etsy builds monitoring&amp;nbsp;dashboards.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.devco.net/archives/2011/10/08/gdash-graphite-dashboard.php"&gt;GDash – Graphite Dashboard |
    &lt;span class="caps"&gt;R.I.&lt;/span&gt;Pienaar&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;a Sinatra dashboard app for Graphite, using Twitter bootstrap for&amp;nbsp;visualization.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/paperlesspost/graphiti"&gt;paperlesspost/graphiti&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;a Ruby and JavaScript front-end for&amp;nbsp;Graphite.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://graphite.wikidot.com/screen-shots"&gt;Graphite Screenshots&lt;/a&gt; -
    just two, but they get the idea across pretty&amp;nbsp;well.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://graylog2.org/"&gt;Graylog2&lt;/a&gt; - a centralized log management
    application with a powerful web interface. Stores logs in
    &lt;a href="http://www.elasticsearch.org/"&gt;ElasticSearch&lt;/a&gt; (which is built on
    Lucene, a Java-based index and search server) and statistics/graphs
    in MongoDB. It does analytics, alerting, monitoring/graphing and
    searching all through a web interface, and accepts log data via
    syslog, &lt;span class="caps"&gt;AMQP&lt;/span&gt; and &lt;span class="caps"&gt;GELF&lt;/span&gt; (its own log format). Java server and Ruby on
    Rails web&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://logstash.net/"&gt;Logstash&lt;/a&gt; - another centralized log project
    that stores and indexes logs, with search via a web &lt;span class="caps"&gt;UI&lt;/span&gt;. &amp;#8220;Ship any
    event to anywhere over any protocol.&amp;#8221; Takes many inputs including
    files, syslog, &lt;span class="caps"&gt;AMQP&lt;/span&gt;, Flume, &lt;span class="caps"&gt;STOMP&lt;/span&gt;, &lt;span class="caps"&gt;HTTP&lt;/span&gt; and even twitter, performs a
    number of filters including timestamp checks, parsing, dropping,
    joins, etc, and then sends logs back on an output including &lt;span class="caps"&gt;AMQP&lt;/span&gt;,
    Graylog2 &lt;span class="caps"&gt;GELF&lt;/span&gt;, &lt;span class="caps"&gt;STOMP&lt;/span&gt;, MongoDB, ElasticSearch, syslog, WebSockets and
    to Nagios. One particularly cool feature is its &amp;#8220;file&amp;#8221; input, which
    continuously tails a file and claims to be log rotation safe. Just&amp;nbsp;cool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.google.com/present/view?id=dcmwwd94_16dfdxgpw8"&gt;jordansissel&amp;#8217;s Logstash intro
    slides&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rashidkpc.github.com/Kibana/"&gt;Kibana&lt;/a&gt; - an alternative
    interface for Logstash and
    &lt;a href="http://www.elasticsearch.org/"&gt;ElasticSearch&lt;/a&gt; that allows
    searching, graphing and analysis of log data stored in&amp;nbsp;Logstash.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pivotallabs.com/talks/139-metrics-metrics-everywhere"&gt;Pivotal Labs: Talks - Metrics Metrics
    Everywhere&lt;/a&gt;
    (Coda&amp;nbsp;Hale)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aq.iriscouch.com/swinger/_design/swinger/index.html#/preso/aq-mdd/display/1"&gt;PaperlessPost - @quirkey&amp;#8217;s talk on
    metrics&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;very good high level stuff, but slides&amp;nbsp;only&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/paperlesspost/graphiti"&gt;paperlesspost/graphiti&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;graphiti, a &lt;span class="caps"&gt;JS&lt;/span&gt;/Ruby frontend for Graphite that does graphs,
dashboards, and point-in-time snapshots of graphs. Lots of&amp;nbsp;functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://redis.io/"&gt;Redis&lt;/a&gt; - a distributed key/value store that&amp;#8217;s
    really popular with the cool kids. &lt;a href="http://nosql.mypopescu.com/post/8652869828/another-redis-use-case-centralized-logging"&gt;Another Redis Use Case:
    Centralized Logging •&amp;nbsp;myNoSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cebailey59/charcoal"&gt;Charcoal&lt;/a&gt; - a
    &lt;a href="http://www.sinatrarb.com/"&gt;Sinatra&lt;/a&gt; (Ruby) dashboard app (ready for
    use on &lt;a href="http://www.heroku.com/"&gt;Heroku&lt;/a&gt; but usable anywhere).
    Graphite-oriented but will work with any tool that generates images
    from&amp;nbsp;URLs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/etsy/logster"&gt;etsy/logster&lt;/a&gt; - etsy&amp;#8217;s Logster
    tool, which keeps a tail on log files, parses them, and ships
    metrics to Graphite or&amp;nbsp;Ganglia.&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Thu, 06 Sep 2012 05:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-09-06:2012/09/project-storing-and-analyzing-apache-httpd-logs-from-many-hosts/</guid></item><item><title>Some PowerDNS Links and Interesting Features</title><link>http://blog.jasonantman.com/2012/09/some-powerdns-links-and-interesting-features/</link><description>&lt;p&gt;At $&lt;span class="caps"&gt;WORK&lt;/span&gt; we lost a disk in the &lt;span class="caps"&gt;RAID1&lt;/span&gt; of one of our external nameservers,
and it rekindled an occasional discussion of migration from &lt;a&gt;&lt;span class="caps"&gt;ISC&lt;/span&gt;
&lt;span class="caps"&gt;BIND&lt;/span&gt;&lt;/a&gt; to &lt;a href="http://powerdns.com/content/products.html"&gt;PowerDNS&lt;/a&gt;.
PowerDNS has separate authoritative and recursive servers, and doesn&amp;#8217;t
seem to natively support views or split-horizon the way &lt;span class="caps"&gt;BIND&lt;/span&gt; does, but
it has some really cool features including very mature database
backends, load balancing, Lua scripting support to modify how recursive
queries are answered, and geolocation or &lt;span class="caps"&gt;IP&lt;/span&gt;-range based query&amp;nbsp;results.&lt;/p&gt;
&lt;p&gt;While this project is still just casual research, I thought I&amp;#8217;d share
some of the useful links and information I&amp;#8217;ve&amp;nbsp;found:&lt;/p&gt;
&lt;p&gt;PowerDNS&amp;nbsp;Front-ends:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.nicmus.com/community.html"&gt;JPowerAdmin&lt;/a&gt; - One of the two
    most popular, a GPLv3 Java (JBoss &lt;span class="caps"&gt;SEAM&lt;/span&gt;) based web &lt;span class="caps"&gt;UI&lt;/span&gt; with a RESTful
    &lt;span class="caps"&gt;API&lt;/span&gt;, with support for &amp;#8220;multiple&amp;#8221; database backends. Sponsored by
    Nicmus, Inc. &lt;a href="http://www.nicmus.com/JPowerAdmin"&gt;Online demo&lt;/a&gt;
    (demo:demo). Looks nice, simple &lt;span class="caps"&gt;UI&lt;/span&gt;, but no support for&amp;nbsp;split-horizon.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.poweradmin.org"&gt;PowerAdmin&lt;/a&gt; - the other most popular,
    though it seems to be undergoing a large overhaul at the moment. Has
    full support for most of PowerDNS&amp;#8217;s features, written in &lt;span class="caps"&gt;PHP&lt;/span&gt;,
    supports &amp;#8220;large&amp;#8221; databases, fine-grained user permissions, &lt;span class="caps"&gt;RFC&lt;/span&gt;
    validation, zone templates. &lt;a href="http://demo.poweradmin.org/"&gt;Online
    demo&lt;/a&gt; (demo:demo). I don&amp;#8217;t really like
    that it manages the SOAs as full text (without any templating,
    dropdowns or default values), and that it doesn&amp;#8217;t prepopulate
    default values for &lt;span class="caps"&gt;TTL&lt;/span&gt; in the new record form, but it looks like a
    good starting place for someone (like me) who&amp;#8217;s handy with&amp;nbsp;&lt;span class="caps"&gt;PHP&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://code.google.com/p/pdns-gui/"&gt;pdns-gui - PowerDNS &lt;span class="caps"&gt;GUI&lt;/span&gt; - Google Project
    Hosting&lt;/a&gt; - &lt;span class="caps"&gt;PHP&lt;/span&gt;/MySQL &lt;span class="caps"&gt;GUI&lt;/span&gt;.
    &lt;a href="http://www.powerdns-gui.org/"&gt;Online demo&lt;/a&gt;. Handles templates
    nicely but won&amp;#8217;t scale to too many of them. Window-based &lt;span class="caps"&gt;UI&lt;/span&gt; is
    visually pleasing but will probably be a problem for big&amp;nbsp;zones.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://code.google.com/p/powerdns-webinterface/"&gt;powerdns-webinterface - PowerDNS Webinterface - Google Project
    Hosting&lt;/a&gt; - A nice
    but relatively simplistic &lt;span class="caps"&gt;UI&lt;/span&gt; written in &lt;span class="caps"&gt;PHP&lt;/span&gt;. It has some nice
    features like multi-user authentication (and logging, though I
    haven&amp;#8217;t looked into how detailed it is), automatic &lt;span class="caps"&gt;SOA&lt;/span&gt; serial
    update, automatic &lt;span class="caps"&gt;PTR&lt;/span&gt; creation, etc. Unfortunately not geared
    towards people with lots of domains and multiple records; it has
    only one template for new domains (and no way to update domains
    created from a template), no easy filtering, and still treats &lt;span class="caps"&gt;SOA&lt;/span&gt;
    like a single text&amp;nbsp;record.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sourceforge.net/projects/zoneadmin/"&gt;ZoneAdmin |
    SourceForge.net&lt;/a&gt; and
    &lt;a&gt;Project website&lt;/a&gt; - Maybe not the fastest tool to use in bulk,
    but a nice, relatively intuitive and full-featured admin tool.
    &lt;a href="http://open.megabit.net/demos/ZoneAdmin/"&gt;Online demo&lt;/a&gt;&amp;nbsp;(demo:demo).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some links on PowerDNS&amp;nbsp;split-horizon&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://old.nabble.com/Split-Horizon-Scripts-td32843045.html"&gt;Old Nabble - PowerDNS - Split Horizon&amp;nbsp;Scripts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It looks to me that split-horizon is going to be the hardest part for
us, at least to also have a web &lt;span class="caps"&gt;UI&lt;/span&gt; to manage it. It looks like with
PowerDNS, the most common way to run split horizon &lt;span class="caps"&gt;DNS&lt;/span&gt; (views) is to run
two separate sets of servers or instances, either on different boxes or
multi-homed; one for internal and one for external. While that sounds
like quite a bit of overhead beyond what &lt;span class="caps"&gt;BIND&lt;/span&gt; does, the real problem is
finding a web &lt;span class="caps"&gt;UI&lt;/span&gt; that supports it; I don&amp;#8217;t care if it&amp;#8217;s in two separate
databases, but what I want is a logical (web &lt;span class="caps"&gt;UI&lt;/span&gt;) view that has zones
made up of resource names (i.e. the leftmost column in a zone file) with
one or two RRs (type, ttl, priority, value) - one for each view. That&amp;#8217;s
the real catch - all of our machines are in private &lt;span class="caps"&gt;IP&lt;/span&gt; space behind a
firewall, so I need to be able to manage the internal and external
records on one screen. While it&amp;#8217;s not exactly scalable, and the code
stagnated quite a bit once I got it to a point that was usable for me,
this was the main goal of my &lt;a href="http://multibindadmin.jasonantman.com/"&gt;MultiBIND
Admin&lt;/a&gt;&amp;nbsp;project.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Wed, 05 Sep 2012 05:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-09-05:2012/09/some-powerdns-links-and-interesting-features/</guid><category>bind</category><category>dns</category><category>multibindadmin</category><category>powerdns</category></item><item><title>Wordpress - Automatically publish a pending post each weekday morning from a PHP script</title><link>http://blog.jasonantman.com/2012/09/wordpress-automatically-publish-a-pending-post-each-weekday-morning-from-a-php-script/</link><description>&lt;p&gt;In an earlier post, &lt;a href="/2012/08/piwik-web-analytics-and-some-unfortunate-stats-about-my-blog/"&gt;Piwik Web Analytics, and some unfortunate stats
about my
blog&lt;/a&gt;,
I mentioned that the &lt;a href="http://feedburner.google.com/"&gt;Feedburner&lt;/a&gt; stats
for this blog show a relatively high subscribe/unsubscribe rate for this
blog. I think a large part of that is my tendency to blog in spurts, and
even worse, my tendency to write drafts and not publish them. In an
effort to combat this, I&amp;#8217;ve been trying to finish blog posts and then
set them to &amp;#8220;Pending&amp;#8221; status, and go back and publish one every day
(well, every day that I have some still sitting unpublished). Of course,
that counts on me logging in to Wordpress every day, which isn&amp;#8217;t
something I do. The following script is, at least for now, the answer
for&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;This script (a standalone &lt;span class="caps"&gt;PHP&lt;/span&gt; script) uses
&lt;a href="http://core.trac.wordpress.org/browser/trunk/wp-load.php"&gt;&lt;code&gt;wp-load.php&lt;/code&gt;&lt;/a&gt;
to load the wordpress environment, and then finds the oldest post with a
given status (&amp;#8220;pending&amp;#8221; in my case) and attempts to publish it. It only
does this if there has not been another post published in the last 24
hours. The following script can be found in Git at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/wordpress_daily_post.php"&gt;https://github.com/jantman/misc-scripts/blob/master/wordpress_daily_post.php&lt;/a&gt;&lt;/p&gt;
&lt;!---
sourceinclude
---&gt;

&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="x"&gt;#!/usr/bin/php&lt;/span&gt;
&lt;span class="cp"&gt;&amp;lt;?php&lt;/span&gt;
&lt;span class="sd"&gt;/**&lt;/span&gt;
&lt;span class="sd"&gt; * wordpress_daily_post.php&lt;/span&gt;
&lt;span class="sd"&gt; * Script to publish the oldest post with a given status, if no&lt;/span&gt;
&lt;span class="sd"&gt; * other post has been published in 24 hours. Intended to be run&lt;/span&gt;
&lt;span class="sd"&gt; * via cron on weekdays.&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * Copyright 2012 Jason Antman &lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * Licensed under the Apache License, Version 2.0 &lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * use it anywhere you want, however you want, provided that this header is left intact,&lt;/span&gt;
&lt;span class="sd"&gt; * and that if redistributed, credit is given to me.&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * It is strongly requested, but not technically required, that any changes/improvements&lt;/span&gt;
&lt;span class="sd"&gt; * be emailed to the above address.&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * The latest version of this script will always be available at:&lt;/span&gt;
&lt;span class="sd"&gt; * $HeadURL: http://svn.jasonantman.com/misc-scripts/wordpress_daily_post.php $&lt;/span&gt;
&lt;span class="sd"&gt; * $LastChangedRevision: 40 $&lt;/span&gt;
&lt;span class="sd"&gt; *&lt;/span&gt;
&lt;span class="sd"&gt; * Changelog:&lt;/span&gt;
&lt;span class="sd"&gt; * 2012-09-03 Jason Antman  - 1.0&lt;/span&gt;
&lt;span class="sd"&gt; *  - first version&lt;/span&gt;
&lt;span class="sd"&gt; */&lt;/span&gt;

&lt;span class="c1"&gt;# &lt;span class="caps"&gt;BEGIN&lt;/span&gt; &lt;span class="caps"&gt;CONFIGURATION&lt;/span&gt;&lt;/span&gt;
&lt;span class="nb"&gt;define&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;WP_LOAD_LOC&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/var/www/vhosts/blog.jasonantman.com/wp-load.php&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// Configure this to the full path of your Wordpress wp-load.php&lt;/span&gt;
&lt;span class="nb"&gt;define&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;SOURCE_POST_STATUS&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pending&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// post status to publish&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;END&lt;/span&gt; &lt;span class="caps"&gt;CONFIGURATION&lt;/span&gt;&lt;/span&gt;

&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$DRY_RUN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;false&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nb"&gt;array_shift&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;isset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-d&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--dry-run&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="nv"&gt;$DRY_RUN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;DRY&lt;/span&gt; &lt;span class="caps"&gt;RUN&lt;/span&gt; &lt;span class="caps"&gt;ONLY&lt;/span&gt; - &lt;span class="caps"&gt;NOT&lt;/span&gt; &lt;span class="caps"&gt;ACTUALLY&lt;/span&gt; &lt;span class="caps"&gt;PUBLISHING&lt;/span&gt;.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;isset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-v&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--verbose&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;WP_LOAD_LOC=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;WP_LOAD_LOC&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;SOURCE_POST_STATUS=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;SOURCE_POST_STATUS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nb"&gt;array_shift&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$argv&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nv"&gt;$_SERVER&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;HTTP_HOST&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;localhost&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// needed for wp-includes/ms-settings.php:100&lt;/span&gt;
&lt;span class="k"&gt;require_once&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;WP_LOAD_LOC&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;# check that we&amp;#39;re running on a weekday&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="c1"&gt;#  if($&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;){ fwrite(&lt;span class="caps"&gt;STDERR&lt;/span&gt;, &amp;quot;today is a saturday or sunday, dieing.\n&amp;quot;); }&lt;/span&gt;
&lt;span class="c1"&gt;#  exit(1);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# find the publish date/time of the last published post&lt;/span&gt;
&lt;span class="nv"&gt;$published&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;get_posts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;numberposts&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orderby&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;order&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;DESC&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;publish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="nv"&gt;$post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$published&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="nv"&gt;$pub_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_date&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;strtotime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$pub_date&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;86400&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;last post (&lt;span class="caps"&gt;ID&lt;/span&gt; &lt;/span&gt;&lt;span class="si"&gt;$pub_id&lt;/span&gt;&lt;span class="s2"&gt;) within last day (&lt;/span&gt;&lt;span class="si"&gt;$pub_date&lt;/span&gt;&lt;span class="s2"&gt;). Nothing to do. Exiting.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Found last post (&lt;span class="caps"&gt;ID&lt;/span&gt; &lt;/span&gt;&lt;span class="si"&gt;$pub_id&lt;/span&gt;&lt;span class="s2"&gt;) with post date &lt;/span&gt;&lt;span class="si"&gt;$pub_date&lt;/span&gt;&lt;span class="s2"&gt;.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="c1"&gt;# find the earliest post of status SOURCE_POST_STATUS, if there is one.&lt;/span&gt;
&lt;span class="nv"&gt;$to_post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;get_posts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;numberposts&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orderby&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;order&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;ASC&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;SOURCE_POST_STATUS&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$to_post&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nx"&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$to_pub_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_date&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$to_pub_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$now&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;time&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="nv"&gt;$new_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y-m-d H:i:s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$now&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nv"&gt;$new_date_gmt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;gmdate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Y-m-d H:i:s&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;$now&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Post to publish: &lt;span class="caps"&gt;ID&lt;/span&gt;=&lt;/span&gt;&lt;span class="si"&gt;$to_pub_id&lt;/span&gt;&lt;span class="s2"&gt; &lt;span class="caps"&gt;DATE&lt;/span&gt;=&lt;/span&gt;&lt;span class="si"&gt;$to_pub_date&lt;/span&gt;&lt;span class="s2"&gt; NEW_DATE=&lt;/span&gt;&lt;span class="si"&gt;$new_date&lt;/span&gt;&lt;span class="s2"&gt; &lt;span class="caps"&gt;TITLE&lt;/span&gt;=&lt;/span&gt;&lt;span class="si"&gt;$to_pub_title&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# actually publish it&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt; &lt;span class="nv"&gt;$DRY_RUN&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="nv"&gt;$arr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;ID&lt;/span&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$to_pub_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;publish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$new_date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date_gmt&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;$new_date_gmt&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="nv"&gt;$ret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;wp_update_post&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$arr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// publish the post&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$ret&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: Post &lt;/span&gt;&lt;span class="si"&gt;$to_pub_id&lt;/span&gt;&lt;span class="s2"&gt; was not successfully published.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;VERBOSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt; &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Published post. New &lt;span class="caps"&gt;ID&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;$ret&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Dry run only, not publishing post.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# check that the post really was published&lt;/span&gt;
&lt;span class="nv"&gt;$published&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;get_posts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;numberposts&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;orderby&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;order&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;DESC&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;post_status&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;publish&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;span class="nv"&gt;$post&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$published&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="nv"&gt;$pub_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_date&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;&lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;post_title&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nv"&gt;$pub_guid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$post&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="na"&gt;guid&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;$pub_title&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="nv"&gt;$to_pub_title&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: title of most recent post does not match title of what we wanted to post.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="k"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Published post &lt;/span&gt;&lt;span class="si"&gt;$pub_id&lt;/span&gt;&lt;span class="s2"&gt; at &lt;/span&gt;&lt;span class="si"&gt;$pub_date&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Title: &lt;/span&gt;&lt;span class="si"&gt;$pub_title&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n\n\n&lt;/span&gt;&lt;span class="s2"&gt; &lt;span class="caps"&gt;GUID&lt;/span&gt;/Link: &lt;/span&gt;&lt;span class="si"&gt;$pub_guid&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;fwrite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;&lt;span class="caps"&gt;STDOUT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="k"&gt;__FILE__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; on &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;trim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;shell_exec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hostname --fqdn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; running as &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;get_current_user&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="cp"&gt;?&amp;gt;&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You&amp;#8217;ll need to set &lt;code&gt;WP_LOAD_LOC&lt;/code&gt; (line 29) to the full path of your
Wordpress installation&amp;#8217;s &lt;code&gt;wp-load.php&lt;/code&gt; (it should be in the top-level
directory of your Wordpress installation. I run this script from cron&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;0 6 * * 1-5 /home/jantman/bin/wordpress_daily_post.php --verbose # publish WP pending posts daily
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;so that it runs at &lt;span class="caps"&gt;6AM&lt;/span&gt; (local time) each weekday. Assuming you have cron
setup to send you mail, you&amp;#8217;ll get a daily message saying what was (or
wasn&amp;#8217;t)&amp;nbsp;done.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 04 Sep 2012 05:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-09-04:2012/09/wordpress-automatically-publish-a-pending-post-each-weekday-morning-from-a-php-script/</guid><category>cron</category><category>PHP</category><category>wordpress</category></item><item><title>Interesting Systems Links for September 3, 2012</title><link>http://blog.jasonantman.com/2012/09/interesting-systems-links-for-september-3-2012/</link><description>&lt;p&gt;Here is a small selection of sysadmin links that I recently found, and
wanted to&amp;nbsp;share:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://codeascraft.etsy.com/2012/05/22/blameless-postmortems/"&gt;Blameless PostMortems and a Just Culture - Code as
    Craft&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;some really good ideas about a culture that recognizes and seeks
to remedy human errors, rather than punishing and generating&amp;nbsp;fear.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://agilesysadmin.net/pillar-one"&gt;The first pillar: We alert on what we draw - Agile&amp;nbsp;Sysadmin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.masterzen.fr/2010/11/14/puppet-ssl-explained/"&gt;Puppet &lt;span class="caps"&gt;SSL&lt;/span&gt; explained - Masterzen&amp;#8217;s&amp;nbsp;Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.infoq.com/news/2011/05/unix-orchestration"&gt;Unix Orchestration Roundup: Tools for Programmatic Systems&amp;nbsp;Administration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Mon, 03 Sep 2012 09:42:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-09-03:2012/09/interesting-systems-links-for-september-3-2012/</guid><category>devops</category><category>links</category><category>portmortem</category><category>sysadmin</category></item><item><title>RVM and Ruby 1.9 to test logstash grok patterns on Fedora/CentOS</title><link>http://blog.jasonantman.com/2012/09/rvm-and-ruby-1-9-to-test-logstash-grok-patterns-on-fedoracentos/</link><description>&lt;p&gt;I&amp;#8217;ve been working on a personal project with
&lt;a href="http://logstash.net/"&gt;Logstash&lt;/a&gt; lately, and it relies relatively
heavily on &lt;a href="https://github.com/jordansissel/grok"&gt;grok&lt;/a&gt; filters for
matching text and extracting matched parts. Today, I&amp;#8217;ve been parsing
syslog from &lt;a href="http://puppetlabs.com/puppet/puppet-open-source/"&gt;Puppet&lt;/a&gt;
to extract various metrics and timings, which will then be passed on
from Logstash to &lt;a href="https://github.com/etsy/statsd"&gt;Etsy&amp;#8217;s statsd&lt;/a&gt; and
then to &lt;a href="http://graphite.wikidot.com/"&gt;graphite&lt;/a&gt; for display.
Unfortunately, a few of my patterns are showing the &amp;#8220;_grokparsefailure&amp;#8221;
tag and I just can&amp;#8217;t seem to find the&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;The logstash wiki provides a page on &lt;a href="https://github.com/logstash/logstash/wiki/Testing-your-Grok-patterns-(--logstash-1.1.0-and-above-)"&gt;Testing your Grok
patterns&lt;/a&gt;,
as does Sean Laurent on his blog: &lt;a href="http://blog.bealetech.com/content/testing-logstash-grok-filters"&gt;Testing Logstash grok
filters&lt;/a&gt;.
Unfortunately, I work in a CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; shop, and we&amp;#8217;re decidedly &lt;em&gt;not&lt;/em&gt; a
Ruby shop. Our Logstash install is using the monolithic/standalone Java
&lt;span class="caps"&gt;JAR&lt;/span&gt;. We run Puppet, which is currently under ruby 1.8.7, and the
&lt;a href="http://rubygems.org/gems/jls-grok"&gt;jls-grok rubygem&lt;/a&gt; requires ruby 1.9.
There&amp;#8217;s no way I&amp;#8217;d feel safe installing 1.9 on any of our machines, as
they all run (and require) Puppet. So, I found out about
&lt;a href="https://rvm.io/"&gt;&lt;span class="caps"&gt;RVM&lt;/span&gt;&lt;/a&gt;, the Ruby Version Manager, which allows you to
run and switch between multiple ruby versions, and all of it is
installed on a per-user basis. So, I created a new user on my Fedora 16
desktop called &amp;#8220;rvmtest&amp;#8221; and went about the process of setting up what&amp;#8217;s
needed to test grok patterns in the user&amp;#8217;s local environment. I imagine
this would work similarly under CentOS or &lt;span class="caps"&gt;RHEL&lt;/span&gt;, but the following is
only tested on Fedora 16. If you have any issues, you should probably
refer back to the &lt;span class="caps"&gt;RVM&lt;/span&gt;&amp;nbsp;documentation.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create the isolated user, just to be extra careful. Login as that&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As per &lt;a href="https://rvm.io/rvm/install/"&gt;Installing &lt;span class="caps"&gt;RVM&lt;/span&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;curl https://raw.github.com/wayneeseguin/rvm/master/binscripts/rvm-installer | bash -s stable
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;edit your &lt;code&gt;~/.bashrc&lt;/code&gt; and&amp;nbsp;add:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="o"&gt;[[&lt;/span&gt; -s &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;HOME&lt;/span&gt;/.rvm/scripts/rvm&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; . &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;HOME&lt;/span&gt;/.rvm/scripts/rvm&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt; -r &lt;span class="nv"&gt;$rvm_path&lt;/span&gt;/scripts/completion &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; . &lt;span class="nv"&gt;$rvm_path&lt;/span&gt;/scripts/completion
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first line sets up &lt;span class="caps"&gt;RVM&lt;/span&gt; for your sessions, and the second sources
in tab-completion for the &lt;code&gt;rvm&lt;/code&gt; command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;source .bashrc&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;If you&amp;#8217;re interested, you can see a list of all known rubies with:
    &lt;code&gt;rvm list known&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install Ruby (&lt;span class="caps"&gt;MRI&lt;/span&gt;) 1.9.2: &lt;code&gt;rvm install 1.9.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;switch&amp;#8221; to that ruby: &lt;code&gt;rvm use 1.9.2&lt;/code&gt; and confirm it by running
    &lt;code&gt;ruby -v&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Make it the default ruby for us: &lt;code&gt;rvm use 1.9.2 --default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create a &amp;#8220;gemset&amp;#8221; (set of rubygems for our environment):
    &lt;code&gt;rvm gemset create groktest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use it, and set it as default: &lt;code&gt;rvm use 1.9.2@groktest --default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;for grok testing, &lt;code&gt;gem install jls-grok&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;check that it&amp;#8217;s there: &lt;code&gt;gem list&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download Logstash&amp;#8217;s default grok patterns &lt;a href="https://raw.github.com/logstash/logstash/master/patterns/grok-patterns"&gt;from&amp;nbsp;github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;You should now be ready to test some grok&amp;nbsp;patterns.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While the two howto&amp;#8217;s linked above use &lt;code&gt;irb&lt;/code&gt; to interactively test the
patterns, I prefer something easier to move to production, more
reliable, and more repeatable. The following quick little ruby script
takes test to match against on &lt;span class="caps"&gt;STDIN&lt;/span&gt; (log files, messages, etc.) and
prints the matches to &lt;span class="caps"&gt;STDOUT&lt;/span&gt;. The script is based on
&lt;a href="https://github.com/jordansissel/ruby-grok/blob/master/examples/test.rb"&gt;test.rb&lt;/a&gt;
from &lt;a href="https://github.com/jordansissel/ruby-grok"&gt;jordansissel&amp;#8217;s
ruby-grok&lt;/a&gt;. Note one
important thing here, I couldn&amp;#8217;t get the shebang (&lt;code&gt;#!&lt;/code&gt;) to work with
anything other than the explicit path to my &lt;span class="caps"&gt;RVM&lt;/span&gt; ruby install
(&lt;code&gt;which ruby&lt;/code&gt;) so you&amp;#8217;ll need to manually update this&amp;nbsp;yourself.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#!.rvm/rubies/ruby-1.9.2-320bin/ruby&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;rubygems&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;grok-pure&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pp&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;grok&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;
&lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_patterns_from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;grok-patterns&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;your_grok_pattern_here&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;PATTERN&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;gets&lt;/span&gt;
  &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;IN&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;
    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;pp&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;captures&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;No Match.&amp;quot;&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here&amp;#8217;s an example using a pattern to capture information from custom
syslog messages triggered by updating puppet configs. Here&amp;#8217;s some sample&amp;nbsp;messages:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[rvmtest@jantmanwork ~]$ cat puppet.log&lt;/span&gt;
&lt;span class="go"&gt;Updated 2 files in puppet svn (environment prod) to revision 754&lt;/span&gt;
&lt;span class="go"&gt;Updated 3 files in puppet svn (environment prod) to revision 756&lt;/span&gt;
&lt;span class="go"&gt;Updated 1 files in puppet svn (environment prod) to revision 757&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the pattern that I&amp;nbsp;use:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Updated%{SPACE}%{NUMBER:puppet_svn_num_files}%{SPACE}files%{SPACE}in%{SPACE}puppet%{SPACE}svn%{SPACE}\(environment%{SPACE}%{WORD:puppet_svn_env}\)%{SPACE}to%{SPACE}revision%{SPACE}%{NUMBER:puppet_svn_revision}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the output of the&amp;nbsp;script:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;[rvmtest@jantmanwork ~]$ cat puppet.log | ./puppet-update-test.rb &lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;PATTERN&lt;/span&gt;: Updated%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files}%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}files%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}in%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}puppet%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}svn%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}\(environment%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env}\)%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}to%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}revision%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 2 files in puppet svn (environment prod) to revision 754&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;2&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;2&amp;quot;, &amp;quot;754&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;754&amp;quot;]}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 3 files in puppet svn (environment prod) to revision 756&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;3&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;3&amp;quot;, &amp;quot;756&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;756&amp;quot;]}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 1 files in puppet svn (environment prod) to revision 757&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;1&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;1&amp;quot;, &amp;quot;757&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;757&amp;quot;]}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hopefully this will make the process a bit simpler for someone&amp;nbsp;else&amp;#8230;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Mon, 03 Sep 2012 08:37:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-09-03:2012/09/rvm-and-ruby-1-9-to-test-logstash-grok-patterns-on-fedoracentos/</guid><category>grok</category><category>grokparsefailure</category><category>jruby</category><category>kibana</category><category>logstash</category><category>ruby</category><category>rvm</category></item><item><title>Piwik Web Analytics, and some unfortunate stats about my blog</title><link>http://blog.jasonantman.com/2012/08/piwik-web-analytics-and-some-unfortunate-stats-about-my-blog/</link><description>&lt;p&gt;Back in March when I selected a new template for this blog, I
&lt;a href="/2012/03/new-blog-theme/"&gt;posted&lt;/a&gt; that I was looking into open source
self-hosted web analytics tools to replace &lt;a href="http://www.google.com/analytics/"&gt;Google
Analytics&lt;/a&gt;. There were a few reasons
for this; most importantly, it started from a discussion with some
privacy-conscious coworkers, who said that they use
&lt;a href="http://noscript.net/"&gt;NoScript&lt;/a&gt; and specifically block Google from
tracking them (which also breaks Google Analytics). This was a serious
issue for me, as I no longer process server-side logs but relied solely
on Google Analytics for traffic information. So, I decided to try
something other than Google and ended up settling on
&lt;a href="http://piwik.org/"&gt;Piwik&lt;/a&gt; as my solution. I will say, in full
disclosure, that the amount of information Piwki gives is a bit scary; I
can watch users navigate this blog in realtime, and even the initial
dashboard page gives a list of the most recent visitors, with their &lt;span class="caps"&gt;IP&lt;/span&gt;
address, country of origin, browser, &lt;span class="caps"&gt;OS&lt;/span&gt;, and the pages they visited.
However my decision was made on two main points: first, that I wanted
something withich could use server-side &lt;span class="caps"&gt;PHP&lt;/span&gt; to log visits (albeit with a
lot less information) of people who had JavaScript or tracking disabled,
and second, that if &lt;em&gt;someone&lt;/em&gt; is going to have such amazingly detailed
information on my visitors, it should be me, so I can ensure that I&amp;#8217;m
the only person who has access to it and that it isn&amp;#8217;t used for the
wrong&amp;nbsp;purposes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Aside: The only revenue I get from this site is through &lt;a href=""&gt;Google
AdSense&lt;/a&gt;, which isn&amp;#8217;t a whole lot given the low traffic (certainly
not enough to pay for the hosting). Other than that, I keep this blog
to try and share my knowledge with others, and hope that someone else
can find the solution to their problem here instead of doing the work
that I did. So, I find analytics very helpful; I check my stats now
and then, go back and update or add to the most popular posts, and try
to write relevant posts if it seems like a lot of people are finding
their way here for something slightly different than the actual post
they landed on. Unfortunately, that last point isn&amp;#8217;t as easy since
&lt;a href="http://googleblog.blogspot.com/2011/10/making-search-more-secure.html"&gt;Google switched to &lt;span class="caps"&gt;HTTPS&lt;/span&gt; Search for logged-in users on October 18th,
2011&lt;/a&gt;
- I can no longer use Piwik see the search keywords that got Google
users to my site. Luckily, these are still available through &lt;a href="https://www.google.com/webmasters/tools/"&gt;Google
Webmaster Tools&lt;/a&gt; (via
Traffic -&gt; Search Queries on the left menu), though it adds an
additional step and removes some of my motivation to check regularly
and make sure people are getting useful content. Also, perhaps most
importantly, it doesn&amp;#8217;t let me associate search query with other stats
like time on page, so even if one search query was very popular, I
have no way of knowing whether all those people actually read the
page, or took one look at it and&amp;nbsp;left.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I really like Piwki. I don&amp;#8217;t use most of it terribly often, but it gives
me a nice overview visits graph on the WordPress dashboard (via the
&lt;a href="http://wordpress.org/extend/plugins/wp-piwik/"&gt;&lt;span class="caps"&gt;WP&lt;/span&gt;-Piwik&lt;/a&gt; plugin),
infinitely detailed information (most of which I haven&amp;#8217;t even looked at)
in the Piwki web interface, and nightly email reports of visits to the
site. It also supports multiple sites, so I have it on my ancient
&lt;a href="http://wiki.jasonantman.com"&gt;wiki&lt;/a&gt;, my
&lt;a href="http://redmine.jasonantman.com"&gt;Redmine&lt;/a&gt; instance, and even
&lt;a href="/2012/03/adding-piwik-web-analytics-integration-to-viewvc/"&gt;ViewVC&lt;/a&gt;.
I&amp;#8217;d highly recommend it; it&amp;#8217;s full-featured (beyond anything I can even
comprehend,&amp;nbsp;really)&lt;/p&gt;
&lt;p&gt;I was recently looking through the stats for this blog, and came by some
unfortunate, though not surprising, trends. Below is the graph of visits
per day, from April 1, 2012 through today (August 26,&amp;nbsp;2012):&lt;/p&gt;
&lt;p&gt;&lt;img alt="blog visits chart" src="/GFX/blog_visits.png" /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It&amp;#8217;s probably not terribly unusual for a site with as much technical
    content as mine (and mostly professional stuff, not just for
    hobbyists), my weekend traffic is usually a full 50% lower than
    weekday traffic. This can also be seen in the graph of visits by
    visitor&amp;#8217;s local time, which is decidedly biased towards the 9am-5pm
    window:&lt;br /&gt;
&lt;img alt="blog visits chart by visitor local
    time" src="/GFX/blog_visits_localtime.png" /&gt;&lt;br /&gt;
    I guess there&amp;#8217;s nothing I can really do about that, and it just
    gives me a nice maintenance window at 4am on Sunday mornings&amp;nbsp;:)&lt;/li&gt;
&lt;li&gt;Looking at the overall graph, there also appears to be quite a bit
    of oscillation of the average visits over time. It&amp;#8217;s nothing
    terribly large, but at a guess, I&amp;#8217;d attribute it to my sporadic&amp;nbsp;posting.&lt;/li&gt;
&lt;li&gt;Though it&amp;#8217;s not visible in these graphs, this site has an 80% bounce
    rate (the percent of visitors that viewed only one page and then
    left the site). I guess that&amp;#8217;s also not terribly unusual for a site
    with mostly how-to information on a wide variety of&amp;nbsp;topics.&lt;/li&gt;
&lt;li&gt;To add a little more information to some of the previous items, here
    is the chart of my &lt;a href="http://feedburner.google.com"&gt;Feedburner&lt;/a&gt;
    &lt;span class="caps"&gt;RSS&lt;/span&gt;/Atom feed, since I started using Feedburner in February. The
    number of subscribers is in green, and the reach (number of people
    who actually clicked through to a post) is in blue:&lt;br /&gt;
&lt;img alt="Feedburner stats" src="/GFX/feedburner_stats.png" /&gt;&lt;br /&gt;
    This is a clear indication of something even stronger than the
    &amp;#8220;bounce rate&amp;#8221;; the apparently high number of people who subscribe to
    and then unsubscribe from my feed (if these stats are accurate). To
    me, this is an even stronger indication that what I really need to
    do is post useful content on a more regular basis - I have a
    tendency to blog in spurts, and either start a draft and never
    finish it, or write a few posts and set them to &amp;#8220;pending&amp;#8221; status
    with the intent of publishing them over a few days&amp;#8230; and then
    forget the last&amp;nbsp;part.&lt;/li&gt;
&lt;/ol&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Sun, 26 Aug 2012 13:18:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-08-26:2012/08/piwik-web-analytics-and-some-unfortunate-stats-about-my-blog/</guid><category>blog</category><category>google analytics</category><category>piwik</category></item><item><title>Puppet facter facts for syslog daemon type and version, symantec netbackup</title><link>http://blog.jasonantman.com/2012/08/puppet-facter-facts-for-syslog-daemon-type-and-version-symantec-netbackup/</link><description>&lt;p&gt;I have a few more custom facts that I&amp;#8217;ve added to my
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;puppet-facter-facts&lt;/a&gt;
github&amp;nbsp;repository:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_bin.rb"&gt;syslog_bin&lt;/a&gt;,
    &lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_type.rb"&gt;syslog_type&lt;/a&gt;,
    and
    &lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_version.rb"&gt;syslog_version&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;tell the absolute path to the &lt;em&gt;running&lt;/em&gt; syslog binary, its short
name (basename), and its version as a string. Currently only know
about &lt;code&gt;/sbin/syslogd&lt;/code&gt; and &lt;code&gt;/sbin/rsyslogd&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/has_netbackup.rb"&gt;has_netbackup&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;tests for presence of the &lt;code&gt;/usr/openv/netbackup/bin&lt;/code&gt; directory,
created by installation of &lt;a href="http://www.symantec.com/netbackup"&gt;Symantec
Netbackup&lt;/a&gt;. Useful for making
generation of include/exclude files conditional on having NetBackup&amp;nbsp;installed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hopefully some of these will be of use to someone else as&amp;nbsp;well.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Sat, 25 Aug 2012 11:33:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-08-25:2012/08/puppet-facter-facts-for-syslog-daemon-type-and-version-symantec-netbackup/</guid><category>facter</category><category>nbu</category><category>netbackup</category><category>puppet</category><category>rsyslog</category><category>syslog</category></item><item><title>Puppet facter fact for all applied classes, returned as a CSV list</title><link>http://blog.jasonantman.com/2012/08/puppet-facter-fact-for-all-applied-classes-returned-as-a-csv-list/</link><description>&lt;p&gt;I&amp;#8217;m unfortunatey stuck, at least for the time being, using flat-file
manifests to configure my puppet nodes. Without an &lt;span class="caps"&gt;ENC&lt;/span&gt;, it&amp;#8217;s pretty
difficult to get a good ovewview of what classes are used on each node,
and what nodes use a given class. I know I could write up a simple web
tool to do this (unfortunately, given my limited Ruby knowledge, it
would have to be in &lt;span class="caps"&gt;PHP&lt;/span&gt; or Perl, not a real modification to Dashboard in
Ruby). But where to get the data&amp;nbsp;from?&lt;/p&gt;
&lt;p&gt;After some research, I found a &lt;a href="http://sjoeboo.github.com/blog/2012/07/31/updated-puppet-facts-for-puppet-classes/"&gt;puppet fact for puppet
classes&lt;/a&gt;
on &lt;a href="http://sjoeboo.github.com/"&gt;Matthew Nicholson&amp;#8217;s Coffee &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Beer blog&lt;/a&gt;.
It parses &lt;code&gt;/var/lib/puppet/classes.txt&lt;/code&gt; and returns the list of classes
found as a &lt;span class="caps"&gt;JSON&lt;/span&gt; array. Great base, but I wanted something easier, that
would be more easily parsed from its direct storage in MySQL. My
modification to his code is onlty a few characters; I dropped out the
&lt;span class="caps"&gt;JSON&lt;/span&gt; require, and return the classes as a &lt;span class="caps"&gt;CSV&lt;/span&gt; list. This lets me to easy
&lt;code&gt;LIKE '%,classname,%'&lt;/code&gt; SELECTs in MySQL, and also gives me the fact
value stored in the puppet &lt;span class="caps"&gt;DB&lt;/span&gt;, so I can build a separate tool around
that data. Thanks,&amp;nbsp;Matt.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# facter fact for puppet classes on node, pulled from /var/lib/puppet/classes.txt&lt;/span&gt;
&lt;span class="c1"&gt;# from &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;facter&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;begin&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hostname&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt;
&lt;span class="k"&gt;rescue&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loadfacts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="n"&gt;hostname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hostname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fqdn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fqdn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;classes_txt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/var/lib/puppet/classes.txt&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;classes_txt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;classes_txt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;Array&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;each&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;chomp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_s&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;push&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;hostname&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;puppet_classes_csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                &lt;span class="n"&gt;setcode&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All of my facts are now available in a GitHub repository:
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;https://github.com/jantman/puppet-facter-facts&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Wed, 22 Aug 2012 07:05:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-08-22:2012/08/puppet-facter-fact-for-all-applied-classes-returned-as-a-csv-list/</guid><category>classes</category><category>csv</category><category>fact</category><category>facter</category><category>node</category><category>puppet</category></item><item><title>Puppet facter fact for last applied configuration version</title><link>http://blog.jasonantman.com/2012/08/puppet-facter-fact-for-last-applied-configuration-version/</link><description>&lt;p&gt;For anyone else who sets the Puppet &lt;code&gt;config_version&lt;/code&gt; paramater to return
the current &lt;span class="caps"&gt;SVN&lt;/span&gt; or Git version of your configuration, here&amp;#8217;s a fact that
grabs that version (by parsing the cached &lt;span class="caps"&gt;YAML&lt;/span&gt; catalog) and sets it as a
fact called &amp;#8220;catalog_config_version&amp;#8221;. It can then be used for
sanity-checking your nodes, looking up via the Inventory Service, or you
can display it in the Dashboard using my patch: &lt;a href="http://blog.jasonantman.com/2012/08/patch-to-puppet-dashboard-1-2-10-to-show-arbitrary-facts-in-the-main-node-table/"&gt;Patch to Puppet
Dashboard 1.2.10 to show arbitrary facts in the main node
table&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# facter fact for last applied config version, skeleton from /var/lib/puppet/client_yaml/catalog/fqdn.yaml&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;puppet&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;yaml&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;facter&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;localconfig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;&lt;span class="caps"&gt;ARGV&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="no"&gt;Puppet&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:clientyamldir&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/catalog/&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt; &lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.yaml&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;unless&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exist?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;localconfig&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;puts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Can&amp;#39;t find &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt; &lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.yaml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;lc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;localconfig&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;begin&lt;/span&gt;
  &lt;span class="n"&gt;pup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Marshal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;TypeError&lt;/span&gt;
  &lt;span class="n"&gt;pup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;&lt;span class="caps"&gt;YAML&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;Exception&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
  &lt;span class="k"&gt;raise&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;pup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="ss"&gt;Puppet&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="ss"&gt;:Resource&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Catalog&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;catalog_config_version&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                &lt;span class="n"&gt;setcode&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                        &lt;span class="n"&gt;pup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;
                &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;catalog_config_version&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                &lt;span class="n"&gt;setcode&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                        &lt;span class="s2"&gt;&amp;quot;unknown&amp;quot;&lt;/span&gt;
                &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All of my facts are now available in a GitHub repository:
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;https://github.com/jantman/puppet-facter-facts&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 21 Aug 2012 08:55:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-08-21:2012/08/puppet-facter-fact-for-last-applied-configuration-version/</guid><category>config_version</category><category>fact</category><category>facter</category><category>puppet</category></item><item><title>Setting emacs zone-mode based on path</title><link>http://blog.jasonantman.com/2012/08/setting-emacs-zone-mode-based-on-path/</link><description>&lt;p&gt;At work, we do a fair amount of &lt;span class="caps"&gt;DNS&lt;/span&gt; updates. Our zone files are stored
in subversion, and are named according to the domain (with no .zone
extension). It&amp;#8217;s a real pain when updating a few (or a few dozen) zones
in Emacs, since I have to remember to &amp;#8220;M-x zone-mode&amp;#8221; so the serial gets
automatically updated. Here&amp;#8217;s a lisp snippet to put in your &lt;code&gt;.emacs&lt;/code&gt;
file that will set zone-mode for all files in any path matching the
regex &lt;code&gt;svn/named/zones-internal&lt;/code&gt;. I deliberately made it a relative path
(or, really, any path containing that) so it would work for all of my
team&amp;#8217;s workstations, no matter where we have the svn repo checked&amp;nbsp;out:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;add-to-list&lt;/span&gt; &lt;span class="ss"&gt;&amp;#39;auto-mode-alist&lt;/span&gt; &lt;span class="o"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;svn/named/zones-internal/&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="nv"&gt;zone-mode&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Many thanks to &lt;code&gt;taylanub&lt;/code&gt; on #emacs on irc.freenode.net for helping
with&amp;nbsp;this.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Wed, 15 Aug 2012 08:00:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-08-15:2012/08/setting-emacs-zone-mode-based-on-path/</guid><category>bind</category><category>emacs</category><category>lisp</category><category>named</category><category>zone-mode</category></item><item><title>Patch to Puppet Dashboard 1.2.10 to show arbitrary facts in the main node table</title><link>http://blog.jasonantman.com/2012/08/patch-to-puppet-dashboard-1-2-10-to-show-arbitrary-facts-in-the-main-node-table/</link><description>&lt;p&gt;We use &lt;a href="http://puppetlabs.com/puppet/related-projects/dashboard/"&gt;Puppet
Dashboard&lt;/a&gt; at
work to view the status of our puppet nodes. While it&amp;#8217;s very handy,
there&amp;#8217;s one feature I really wanted: the ability to show the value of
arbitrary puppet facts in the main node table on the home page.
Specifically, the facts we use for environment (we have eng/dev, qa,
prod, and test puppet environments), zone (physical location) and last
applied configuration version. I&amp;#8217;m not terribly experience with Ruby,
but I managed to muddle my way through a working patch to do this, along
with options in the settings file to enable it and configure the facts.
You&amp;#8217;ll need to restart dashboard (or your web server) to change the
facts, of course. The commit is currently &lt;a href="https://github.com/jantman/puppet-dashboard/commit/5364e2b0188d18ae62c355279e58c7ce6d7db654"&gt;available on
github&lt;/a&gt;,
but it doesn&amp;#8217;t strictly follow the &lt;a href="https://github.com/puppetlabs/puppet-dashboard/blob/master/CONTRIBUTING.md"&gt;puppet-dashboard contributing
checklist&lt;/a&gt;
so I may have to redo&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a&amp;nbsp;screenshot:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/dashboard_after_patch.png"&gt;&lt;img alt="Dashboard screenshot after
patch" src="/GFX/dashboard_after_patch_sm.png" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And here&amp;#8217;s that the configuration section added to settings.yml looks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# Enables display of arbitrary node facts in &amp;quot;home&amp;quot; page node table, between node name and latest report time&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;enable_home_facts&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;true&lt;/span&gt;

&lt;span class="c1"&gt;# If enable_home_facts is true, the fact names and column headings to display. Simply repeat the following two line pairs&lt;/span&gt;
&lt;span class="c1"&gt;# as needed:&lt;/span&gt;
&lt;span class="c1"&gt;#- name: &amp;#39;factname&amp;#39;&lt;/span&gt;
&lt;span class="c1"&gt;#  heading: &amp;#39;heading text&amp;#39;&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;home_facts&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; 
&lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;environment&amp;#39;&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;heading&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Env&amp;#39;&lt;/span&gt;
&lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;zone&amp;#39;&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;heading&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Zone&amp;#39;&lt;/span&gt;
&lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;catalog_config_version&amp;#39;&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;heading&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Cfg&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;Ver&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If I feel really adventurous, I&amp;#8217;d like to implement my other big wish,
some sort of pop-up list of links, based on arbitrary facts (mainly
hostname and fqdn) for each node - something where I can mouse over the
node name/table cell, and see links (static URLs with node
name/fqdn/other facts plugged in) to things like Nagios/Icinga, our
backup system,&amp;nbsp;etc.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Sat, 11 Aug 2012 10:34:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-08-11:2012/08/patch-to-puppet-dashboard-1-2-10-to-show-arbitrary-facts-in-the-main-node-table/</guid><category>dashboard</category><category>facts</category><category>puppet</category><category>ruby</category><category>sysadmin</category></item><item><title>Workflow for contributing to GitHub projects</title><link>http://blog.jasonantman.com/2012/08/workflow-for-contributing-to-github-projects/</link><description>&lt;p&gt;Lately I&amp;#8217;ve been contributing to some open source projects hosted on
&lt;a href="http://github.com"&gt;github&lt;/a&gt;. I&amp;#8217;m pretty new to git, and the process is a
bit confusing for beginners. So, here&amp;#8217;s a sample workflow, based on the
&lt;a href="http://theforeman.org"&gt;The Foreman&lt;/a&gt;&amp;#8216;s &lt;a href="https://github.com/theforeman/foreman"&gt;foreman github
repository&lt;/a&gt;. Note that I&amp;#8217;m
developing against the &amp;#8220;develop&amp;#8221; branch of that repository, not the
master, so that throws in a little difference that isn&amp;#8217;t documented in
most introductions. To throw in another wrench, I maintan a branch with
the code that I&amp;#8217;m currently actually using (i.e. the application code
that I have checked out on the production server), called &amp;#8220;jantman&amp;#8221;.
This is more or less composed of the upstream &amp;#8220;develop&amp;#8221; branch, with all
of my finished (but not yet merged in the upstream) topic branches. I&amp;#8217;m
pretty sure all this is correct, but honestly, I&amp;#8217;m still new enough at
git that I can&amp;#8217;t make any promises. Unfortunatelty, I haven&amp;#8217;t had the
time to &lt;em&gt;really&lt;/em&gt; learn git, and I also can&amp;#8217;t find a simple enough
tutorial that covers all&amp;nbsp;this&amp;#8230;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fork the original repository through the GitHub&amp;nbsp;interface.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On your machine, clone your&amp;nbsp;fork:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git clone git@github.com:username/reponame.git &amp;amp;&amp;amp; cd reponame
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure you&amp;#8217;ve&amp;nbsp;setup&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git config --global branch.autosetupmerge true
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add your upstream&amp;nbsp;repo:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git remote add upstream git://github.com/upstream_user/upstream_repo.git
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fetch it and initialize any&amp;nbsp;submodules:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git fetch upstream &amp;amp;&amp;amp; git submodule update --init
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the current branch (&lt;code&gt;git branch&lt;/code&gt;, let&amp;#8217;s assume it&amp;#8217;s called
    &amp;#8220;develop&amp;#8221;) and rebase to its&amp;nbsp;upstream:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase upstream/develop develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create my &amp;#8220;jantman&amp;#8221; branch, which will be the upstream &amp;#8220;develop&amp;#8221;,
    plus my finished work merged into&amp;nbsp;it:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout -b jantman origin/develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a topic branch to do some&amp;nbsp;work:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout -b NewBranchName jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Periodically, push the topic branch to&amp;nbsp;github:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin NewBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you commit to this branch from another computer (or someone else
    commits to it), periodically update your local tracking&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git pull origin NewBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Periodically, you want to pull in the upstream&amp;nbsp;changes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;switch to the develop&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;grab the latest version of the upstream git&amp;nbsp;repo:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git fetch upstream
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;rebase develop to mirror the upstream develop&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase upstream/develop develop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;switch to our personal&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git checkout jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;rebase our personal branch onto develop (pull all the new
    commits from develop into our personal&amp;nbsp;branch):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase develop jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we want those new upstream changes to continue down to our
    topic&amp;nbsp;branches:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git rebase develop topicBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When we&amp;#8217;re done with a topic branch, we want to merge it into our
    &amp;#8220;personal&amp;#8221;&amp;nbsp;branch:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    git checkout jantman; git merge --squash node-table-facts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and then&amp;nbsp;commit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;    git commit
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;--squash&lt;/code&gt; will squash all the history of that branch down to
one commit. This is generally easier for integration into upstream,
and assuming the topic branch was created for a single feature or
bug, should be&amp;nbsp;logical.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we&amp;#8217;re sure we don&amp;#8217;t need it anymore, delete the topic branch from
    our local&amp;nbsp;machine:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git branch -d topicBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and from&amp;nbsp;github:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin --delete topicBranchName
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, make sure we push our &amp;#8220;personal&amp;#8221; branch back to&amp;nbsp;origin:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;git push origin jantman
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assuming all went well, you&amp;#8217;ll see the new commit on github, and
    have a nice pull request&amp;nbsp;button.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;References:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.doctrine-project.org/contribute.html"&gt;Contribute -&amp;nbsp;Doctrine-Project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://qsapp.com/wiki/Github"&gt;Github - Quicksilver&amp;nbsp;Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/carmaa/inception/wiki/Contributor-Workflow-with-Github"&gt;Contributor Workflow with Github · carmaa/inception&amp;nbsp;Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://help.github.com/fork-a-repo/"&gt;Help.GitHub - Fork A&amp;nbsp;Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Sat, 11 Aug 2012 09:35:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-08-11:2012/08/workflow-for-contributing-to-github-projects/</guid><category>foreman</category><category>git</category><category>github</category><category>workflow</category></item><item><title>Easily comparing a bunch of files in one directory</title><link>http://blog.jasonantman.com/2012/08/easily-comparing-a-bunch-of-files-in-one-directory/</link><description>&lt;p&gt;So I pulled a specific configuration file (rsyslog.conf) off of a &lt;span class="caps"&gt;LOT&lt;/span&gt; of
hosts. I&amp;#8217;m going to be managing it with &lt;a href=""&gt;Puppet&lt;/a&gt;, but before I do, I
need to know what&amp;#8217;s out there already lest it get overwritten. I used
&lt;a href="http://code.google.com/p/parallel-ssh/"&gt;pssh&lt;/a&gt; with &lt;code&gt;cat&lt;/code&gt; and an output
directory to grab the file from all 30 servers in question. Now, I&amp;#8217;ve
got a directory with 30 files in it, and I need to figure out how many
different files (by contents) there are, and which ones&amp;nbsp;differ.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;find . -type f -exec md5sum &lt;span class="s1"&gt;&amp;#39;{}&amp;#39;&lt;/span&gt; &lt;span class="se"&gt;\;&lt;/span&gt; | sort | uniq -d -w 36
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will check the contents of each file by &lt;span class="caps"&gt;MD5&lt;/span&gt; checksum, and print out
the (lexographically) first file in each group, along with its &lt;span class="caps"&gt;MD5&lt;/span&gt; sum.
You can also strip off the uniq command, and see the list sorted by&amp;nbsp;md5.&lt;/p&gt;
&lt;p&gt;A &lt;span class="caps"&gt;GUI&lt;/span&gt; alternative would be to use
&lt;a href="http://www.pixelbeat.org/fslint/"&gt;fslint&lt;/a&gt;, which is a graphical tool
that can (among other things) display a list of the duplicate files
within a path or set of&amp;nbsp;paths.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Fri, 10 Aug 2012 09:50:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-08-10:2012/08/easily-comparing-a-bunch-of-files-in-one-directory/</guid><category>compare</category><category>diff</category></item><item><title>Dear Mom and Dad - or, a book about what I actually do</title><link>http://blog.jasonantman.com/2012/08/dear-mom-and-dad-or-a-book-about-what-i-actually-do/</link><description>&lt;p&gt;I&amp;#8217;ve followed &lt;a href="http://everythingsysadmin.com/"&gt;Tom Limoncelli&amp;#8217;s blog&lt;/a&gt;
for quite a while; his books &lt;a href="http://everythingsysadmin.com/aboutbook.html"&gt;The Practice of System and Network
Administration&lt;/a&gt; and &lt;a href="http://www.tomontime.com/"&gt;Time
Management for System Administrators&lt;/a&gt; were
infinitely helpful in the early days of my professional life, and are
among the few (literally, 4 or 5) books that live on my desk. His
insight and information into the soft skills of &lt;span class="caps"&gt;SA&lt;/span&gt; work - time
management, hiring, working in teams, etc. - is not only excellent, but
also all too rare in a largely technical&amp;nbsp;field.&lt;/p&gt;
&lt;p&gt;Anyway, Tom posted the below article to his blog about a book that
recently came out, &lt;a href="http://www.amazon.com/dp/0195374126/tomontime-20"&gt;&amp;#8220;Taming Information Technology: Lessons from Studies
of System Administrators&amp;#8221; by Eser Kandogan, Paul Maglio, Eben Haber and
John Bailey&lt;/a&gt;. I
haven&amp;#8217;t read the book yet, and at $56, it&amp;#8217;s going to be a while before
my book budget recovers enough to justify it. But going on what I&amp;#8217;ve
read from Tom and others, I want it. Not only do I want to read it, but
I want to pass it around to my parents and in-laws and everyone else who
has asked what I do for a living, and I found myself at a loss for a
less-than-6-hour-long explanation. So, here&amp;#8217;s what Tom wrote on&amp;nbsp;it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Dear Mom And&amp;nbsp;Dad,&lt;/p&gt;
&lt;p&gt;Many times I&amp;#8217;ve tried to explain to you what I do for a living.
&amp;#8220;Computer system administrator&amp;#8221; or &amp;#8220;sysadmin&amp;#8221; is a career that is
difficult to explain and I&amp;#8217;m sure my attempts have left you even more
confused. I have good news. Oxford University Press has just published
a book by 4 scientists who video taped sysadmins doing their job,
analysed what they do, and explains it to the non-computer person.
They do it by telling compelling stories of sysadmins at work plus
they give interesting analysis with great&amp;nbsp;insight.&lt;/p&gt;
&lt;p&gt;Why did they do this? Because businesses depend on technology more and
more and that means they depend on sysadmins more and more. Yet most
CEOs don&amp;#8217;t understand what we do. The scientists made some interesting
discoveries: that our jobs are high-stress, high-risk, and highly
collaborative. We invent our own tools, often on the spot, to solve
complex problems. We are men and women of every age group. It is a
career unlike any other. These are things that most people don&amp;#8217;t know
about our profession. The book is very engaging: Some of the chapters
read like the opening scene of &amp;#8220;Indiana Jones&amp;#8221;; others like &amp;#8220;Gorillas
in the Mist.&amp;#8221; Kandogan, Maglio, Haber and Bailey have put together a
very serious, scientific book with care and&amp;nbsp;compassion.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m not one of the sysadmins they studied but every story they tell
reminds me of real experiences I have&amp;nbsp;had.&lt;/p&gt;
&lt;p&gt;I hope you enjoy reading this book. I know I&amp;nbsp;did.&lt;/p&gt;
&lt;p&gt;Pre-order it here:
&lt;a href="http://www.amazon.com/dp/0195374126/tomontime-20"&gt;http://www.amazon.com/dp/0195374126/tomontime-20&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Sincerely your son,&lt;br /&gt;&amp;nbsp;Tom&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;P.S.&lt;/span&gt; In all seriousness, I read a preview copy of this book and highly
recommend it to others. You may have seen the authors speak at Usenix
&lt;span class="caps"&gt;LISA&lt;/span&gt; or &lt;span class="caps"&gt;LOPSA&lt;/span&gt; &lt;span class="caps"&gt;PICC&lt;/span&gt; conferences where they showed clips of the video
tapes they made. The book conveys the same stories, plus many more,
with interesting analysis. If you think that the profession of system
administration would benefit from non-sysadmins better understanding
what we do, I highly recommend you pre-order this book and share it.
You can pre-order it here: &lt;a href="http://www.amazon.com/dp/0195374126/tomontime-20"&gt;&amp;#8220;Taming Information Technology: Lessons
from Studies of System Administrators&amp;#8221; by Eser Kandogan, Paul Maglio,
Eben Haber and John&amp;nbsp;Bailey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More about the book here:
&lt;a href="http://everythingsysadmin.com/2012/07/kandogan.html"&gt;http://everythingsysadmin.com/2012/07/kandogan.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you have any interest, I encourage you to go out and buy the book. If
you know someone who&amp;#8217;s an &lt;span class="caps"&gt;SA&lt;/span&gt;, you should buy them the book. If you can
justify any sort of book budget at work, you should buy the book. And
while you&amp;#8217;re at it, if you haven&amp;#8217;t read Tom&amp;#8217;s other books, you should
buy those too. You might be in the unfortunate position - like I am - of
probably never being able to implement most of his suggestions at work,
but at least you&amp;#8217;ll be aware of&amp;nbsp;them&amp;#8230;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Sun, 05 Aug 2012 08:52:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-08-05:2012/08/dear-mom-and-dad-or-a-book-about-what-i-actually-do/</guid><category>books</category><category>limoncelli</category><category>sysadmin</category></item><item><title>Logging OpenSSH SFTP Transactions</title><link>http://blog.jasonantman.com/2012/07/logging-openssh-sftp-transactions/</link><description>&lt;p&gt;I just came across a really handy post on &lt;a href="https://plus.google.com/117561367404774597588/posts"&gt;David
Busby&lt;/a&gt;&amp;#8216;s blog:
&lt;a href="http://blog.oneiroi.co.uk/linux/enable-logging-in-the-sftp-subsystem/"&gt;Enable logging in the &lt;span class="caps"&gt;SFTP&lt;/span&gt; subsystem -
Oneiroi&lt;/a&gt;.
From OpenSSH 4.4 on, you can pass arguments to Subsystem calls, and the
sftp subsystem supports logging to an aribtrary syslog facility and
priority. Simply adding a line&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Subsystem       sftp    /usr/libexec/openssh/sftp-server -f LOCAL5 -l INFO
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and the appropriate lines to your syslog config will give you a handy
transfer log&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;Jul 16 09:22:25 hostname sftp-server[2058]: session opened for local user jantman from [A.B.C.D]
Jul 16 09:22:26 hostname sftp-server[2058]: open &amp;quot;/home/jantman/temp/sftp_test&amp;quot; flags WRITE,CREATE,TRUNCATE mode 0666
Jul 16 09:22:45 hostname sftp-server[2058]: close &amp;quot;/home/jantman/temp/sftp_test&amp;quot; bytes read 0 written 1464813
Jul 16 09:23:08 hostname sftp-server[2058]: session closed for local user jantman from [A.B.C.D]
Jul 16 09:27:50 hostname sftp-server[2309]: session opened for local user jantman from [A.B.C.D]
Jul 16 09:27:50 hostname sftp-server[2309]: open &amp;quot;/home/jantman/temp/sftp_test&amp;quot; flags READ mode 0666
Jul 16 09:27:54 hostname sftp-server[2309]: close &amp;quot;/home/jantman/temp/sftp_test&amp;quot; bytes read 1464813 written 0
Jul 16 09:27:54 hostname sftp-server[2309]: session closed for local user jantman from [A.B.C.D]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you have syslog write these logs to their own file, remember to setup
log rotation for&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;Unfortunately, I&amp;#8217;m not aware of any way to log &lt;span class="caps"&gt;SCP&lt;/span&gt; file&amp;nbsp;transfers.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Mon, 16 Jul 2012 08:47:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-07-16:2012/07/logging-openssh-sftp-transactions/</guid><category>logging</category><category>openssh</category><category>sftp</category><category>ssh</category></item><item><title>Nagios Check Plugin for Rsnapshot Backups</title><link>http://blog.jasonantman.com/2012/07/nagios-check-plugin-for-rsnapshot-backups/</link><description>&lt;p&gt;In a previous post, I described how I do &lt;a href="/2012/01/secure-rsnapshot-backups-over-the-wan-via-ssh/"&gt;Secure rsnapshot backups over
the &lt;span class="caps"&gt;WAN&lt;/span&gt; via
&lt;span class="caps"&gt;SSH&lt;/span&gt;&lt;/a&gt;. While my
layout of rsnapshot configuration files, data, and log files is a bit
esoteric, I monitor all this with a Nagios check plugin that runs on my
backup host. It Assumes that the output of
&lt;a href="http://rsnapshot.org/"&gt;rsnapshot&lt;/a&gt; is written to a text log file, one
file per host, at a path that matches
&lt;code&gt;/path_to_log_directory/log_HOSTNAME_YYYYMMDD-HHMMSS.log&lt;/code&gt; where
&lt;code&gt;HOSTNAME&lt;/code&gt; is the name of the host, and &lt;code&gt;YYYYMMDD-HHMMSS&lt;/code&gt; is a datestamp
(actually, the script just finds the newest file matching
&lt;code&gt;log_HOSTNAME_*.log&lt;/code&gt; in that directory). In order to obtain correct
timing of the runs, which rsnapshot doesn&amp;#8217;t offer, it assumes that you
trigger rsnapshot through a wrapper script, which runs it once per host
(inside a loop?) with per-host log files and some logging information
added,&amp;nbsp;like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;for &lt;/span&gt;h in 
&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="k"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/mnt/backup/rsnapshot/logs/log_${h}_`date +%Y%m%d-%H%M%S`.txt&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;# Starting backup at `date` (`date +%s`)&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&amp;quot;&lt;/span&gt;
    /usr/bin/rsnapshot -c /etc/rsnapshot-&lt;span class="nv"&gt;$h&lt;/span&gt;.conf daily &amp;amp;&amp;gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;# Finished backup at `date` (`date +%s`)&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;$&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;check_rsnapshot.pl&lt;/code&gt; plugin uses &lt;code&gt;utils.pm&lt;/code&gt; from Nagios, as well as
&lt;a href="http://search.cpan.org/~jv/Getopt-Long-2.38/lib/Getopt/Long.pm"&gt;Getopt::Long&lt;/a&gt;,
&lt;a href="http://search.cpan.org/~makoto/File-Stat-0.01/Stat.pm"&gt;File::stat&lt;/a&gt;,
&lt;a href="http://search.cpan.org/~flora/perl-5.14.2/lib/File/Basename.pm"&gt;File::Basename&lt;/a&gt;,
&lt;a href="http://search.cpan.org/~smueller/PathTools-3.33/lib/File/Spec.pm"&gt;File::Spec&lt;/a&gt;
and
&lt;a href="http://search.cpan.org/~ferreira/Number-Bytes-Human-0.07/Human.pm"&gt;Number::Bytes::Human&lt;/a&gt;.
This was one of my first Perl plugins, but seems to be rather
acceptable. It makes the following checks based on the rsnapshot&amp;nbsp;log:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Backup run in the last X seconds (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;li&gt;Maximum time from start to finish (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;li&gt;Minimum size of backup (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;li&gt;Minimum number of files in backup (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In addition to &lt;code&gt;check_file_age&lt;/code&gt; checks on a number of files that are
included in backups and I know are modified before each backup run, this
seems to handle monitoring quite well for me. I certainly preferred
running &lt;a href="http://www.bacula.org/"&gt;Bacula&lt;/a&gt; and using my MySQL-based
&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/check_bacula_job.php"&gt;check_bacula_job.php&lt;/a&gt;,
but as I&amp;#8217;m now backing up 4 machines to my desktop, I no longer have a
need for Bacula (or&amp;nbsp;tapes).&lt;/p&gt;
&lt;p&gt;The script itself can be found at
&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/check_rsnapshot.pl"&gt;github&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Sat, 07 Jul 2012 06:34:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-07-07:2012/07/nagios-check-plugin-for-rsnapshot-backups/</guid><category>backups</category><category>monitoring</category><category>Nagios</category><category>rsnapshot</category><category>rsync</category></item><item><title>What I Look For When Interviwing SysAdmin Candidates</title><link>http://blog.jasonantman.com/2012/07/what-i-look-for-when-interviwing-sysadmin-candidates/</link><description>&lt;p&gt;I recently came by a question on ServerFault, &lt;a href="http://serverfault.com/questions/210218/listing-side-projects-in-a-jr-sysadmin-resume/405054#405054"&gt;Listing side projects in
a jr. sysadmin
resume&lt;/a&gt;
asking whether people (hiring managers) think it&amp;#8217;s appropriate to put
&amp;#8220;side projects&amp;#8221; (running your own web and mail servers, freelance web
work, etc.) on your resume. Since I&amp;#8217;ve been interviewing candidates for
a few SysAdmin positions lately, I thought I&amp;#8217;d take the time to write
down a few of my ideas on this. Two disclaimers first, though. (1) I tend
to be pretty geeky, progressive, and very open source/DevOps focused at
heart. Not everyone I work with will agree with what I say here. As a
candidate, remember that you&amp;#8217;ll probably interview with all types, and
what I say here won&amp;#8217;t be the best advice with Enterprise types. I&amp;#8217;m very
open source centric, and have always held &lt;span class="caps"&gt;SA&lt;/span&gt; jobs where the majority of
the software I run is open source and not vendor supported. (2) If you
happen to actually interview with me, don&amp;#8217;t make the mistake of reading
this and tailoring your resume/responses to fit if that&amp;#8217;s not accurate.
I&amp;#8217;m not a manager, I&amp;#8217;m a line&amp;nbsp;&lt;span class="caps"&gt;SA&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;First, my response to the ServerFault&amp;nbsp;question:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Not a hiring manager, but an &lt;span class="caps"&gt;SA&lt;/span&gt; doing technical interviews and hiring
recommendations, and also have only been with my current employer for
7 months (so I&amp;#8217;ve been on both sides of the table recently). My
current employer is a pretty big company and pays well, so we&amp;#8217;re quite&amp;nbsp;selective.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;SA&lt;/span&gt; candidates with 5-10 years experience and a laundry list of
certifications, software and hardware names, protocols, etc. are a
dime a dozen. I&amp;#8217;m looking for people who really love what they do. I
have an instant bias against resumes that don&amp;#8217;t have either a personal
website/&lt;span class="caps"&gt;URL&lt;/span&gt;, or some personal projects/experience other than 9-5 job
on them. There are lots of people who meet the technical
qualifications. I want someone truly passionate, and that means
learning and experimenting outside of&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;Personally, on my resume, I have a few personal projects listed
(mainly programming projects and volunteer &lt;span class="caps"&gt;IT&lt;/span&gt; work I did for
non-profits), and I also have a link to my personal resume site that
has links to my &lt;span class="caps"&gt;SVN&lt;/span&gt; repo, and a bunch of other&amp;nbsp;projects.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Some things I look&amp;nbsp;for:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not in all cases, but I like to see a website or blog listed on a
    resume. It&amp;#8217;s a big plus. I have
    &lt;a href="http://resume.jasonantman.com"&gt;resume.jasonantman.com&lt;/a&gt; with copies
    of my resume in various formats, as well as a bunch of links I&amp;#8217;d
    like employers to&amp;nbsp;see.&lt;/li&gt;
&lt;li&gt;If you&amp;#8217;re a working &lt;span class="caps"&gt;SA&lt;/span&gt;, I should be able to find you on Google.
    Either by name or email address, I expect to google the contact
    information I find on your resume and find at least some mailing
    list/forum posts, bug reports, or software&amp;nbsp;projects.&lt;/li&gt;
&lt;li&gt;I can&amp;#8217;t stress this enough, &lt;strong&gt;do not overstate your experience&lt;/strong&gt;.
    I&amp;#8217;ve been an &lt;span class="caps"&gt;SA&lt;/span&gt; for 5 years, a hobbyist for much longer, and I&amp;#8217;ve
    never used the word &amp;#8220;expert&amp;#8221;. I list software, protocols, languages
    on my resume as beginner/basic, intermediate, and &amp;#8220;strongest&amp;#8221;. If
    you list something as &amp;#8220;advanced&amp;#8221; or &amp;#8220;expert&amp;#8221;, be prepared to answer
    expert-level questions. If you can&amp;#8217;t explain a 3-way handshake,
    don&amp;#8217;t list &lt;span class="caps"&gt;TCP&lt;/span&gt;/&lt;span class="caps"&gt;IP&lt;/span&gt; on your resume. If you list &amp;#8220;strong knowledge of
    Linux internals&amp;#8221;, you should be able to at least explain &lt;code&gt;open()&lt;/code&gt;
    and &lt;code&gt;close()&lt;/code&gt;. If you list advanced &lt;span class="caps"&gt;RADIUS&lt;/span&gt; experience, I &lt;em&gt;will&lt;/em&gt; ask
    you to explain &lt;span class="caps"&gt;CSID&lt;/span&gt;, &lt;span class="caps"&gt;WPA&lt;/span&gt; key exchange, and what attributes are valid
    in an Access-Reject. In short, don&amp;#8217;t say you&amp;#8217;re a genius in
    something unless you are; you never know when your interviewer may
    have spent the last 6 months immersed in&amp;nbsp;it.&lt;/li&gt;
&lt;li&gt;All SAs should have some programming skills. If you&amp;#8217;re a recent
    graduate (let&amp;#8217;s say any time in the last 5-8 years) I&amp;#8217;d expect at
    the very least a vague memory of C++, &lt;span class="caps"&gt;VB&lt;/span&gt; or Java. If you&amp;#8217;re a
    working &lt;span class="caps"&gt;SA&lt;/span&gt;, I expect to see either strong Bash skills, or at least a
    functional knowledge of Perl. Python, &lt;span class="caps"&gt;PHP&lt;/span&gt; or Ruby; preferably both.
    If you&amp;#8217;re a &amp;#8220;senior&amp;#8221; Linux &lt;span class="caps"&gt;SA&lt;/span&gt;, you should know enough C to be able
    to make sense of &lt;code&gt;strace&lt;/code&gt; output.&lt;/li&gt;
&lt;li&gt;As stated above, non-full-time-job projects are a big plus. When I
    took my first &lt;span class="caps"&gt;SA&lt;/span&gt; job, the majority of my experience had been doing
    volunteer work for a non-profit ambulance corps (which I was also a
    volunteer &lt;span class="caps"&gt;EMT&lt;/span&gt; on). If I said that I did 40 hours a week for them, it
    would be an understatement. I wrote a few 10,000+ line &lt;span class="caps"&gt;PHP&lt;/span&gt;
    applications for them, and designed the infrastructure to run them
    24x7x365. Small shop? Sure. But I learned a &lt;span class="caps"&gt;LOT&lt;/span&gt;, especially about
    how to make things resilient enough that I didn&amp;#8217;t get paged&amp;nbsp;often.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;#8217;m sure I&amp;#8217;ll update this over time as I distill more of my&amp;nbsp;ideas.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Thu, 05 Jul 2012 11:07:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-07-05:2012/07/what-i-look-for-when-interviwing-sysadmin-candidates/</guid></item><item><title>Tools for watching apache httpd and memcached</title><link>http://blog.jasonantman.com/2012/06/tools-for-watching-apache-httpd-and-memcached/</link><description>&lt;p&gt;Recently I was working on a code release on a site running &lt;span class="caps"&gt;PHP&lt;/span&gt; on
&lt;a href="http://httpd.apache.org/"&gt;Apache httpd&lt;/a&gt;, and using
&lt;a href="http://memcached.org/"&gt;memcached&lt;/a&gt;. Without getting into specifics, we
had a number of issues that were both Apache and memcached problems, and
little visibility into them as it was running on an older server without
much monitoring in place. I started looking around for simple tools that
could provide a bit more insight, without many dependencies (as the
machine is a relatively minimalist install). Here are some of the
options I&amp;nbsp;found:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://code.google.com/p/memcache-top/"&gt;memcache-top&lt;/a&gt; - A top-like
    script that pulls stats from memcached instances and can show both
    per-instance, total and average usage %, hit rate, number of
    connections, time to run the stats query, evictions, gets, sets, and
    read and write amounts. Best of all, it&amp;#8217;s a very small perl script
    that requires only &lt;span class="caps"&gt;IO&lt;/span&gt;::Socket and Time::HiRes. Here&amp;#8217;s a small
    example of the&amp;nbsp;output:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;memcache-top v0.6       (default port: 11211, color: on, refresh: 3 seconds)

INSTANCE                USAGE   HIT %   CONN    TIME    EVICT   GETS    SETS    READ    WRITE
127.0.0.1:11211         86.6%   99.4%   115     0.6ms   0.0     4114    1669    1.3M    24.2M
127.0.0.1:11212         85.5%   59.9%   2       0.4ms   0.0     0       0       90      8055

AVERAGE:                86.0%   79.6%   58      0.5ms   0.0     2057    834     682.4K  12.1M

TOTAL:          0.9GB/  1.0GB           117     1.0ms   0.0     4114    1669    1.3M    24.2M
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/dormando/damemtop"&gt;damemtop&lt;/a&gt; is also a nice
    top-like memcached tool. On the positive side, you can specify any
    column from &amp;#8220;stats&amp;#8221;, &amp;#8220;stats items&amp;#8221; or &amp;#8220;stats slabs&amp;#8221; in the
    configuration file, and can choose between average or one-second
    snapshots for each column. On the down side, it requires the &lt;span class="caps"&gt;YAML&lt;/span&gt;
    and AnyEvent Perl modules, so it has some uncommon&amp;nbsp;dependencies.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;damemtop: Tue Jun 26 14:02:24 2012 [sort: hostname asc] [delay: 3s]
hostname           all_version  all_fill_rate  hit_rate  evictions  curr_items  curr_connections   cmd_get  cmd_set  bytes_written  bytes_read  get_hits  get_misses  
TOTAL:             
NA                 NA           NA             NA        NA         NA          NA                 87       32       491,735        30,894      86        1           
AVERAGE:           
NA                 NA           86.00%         99.00%    NA         NA          NA                 43       16       122,933        7,723       43        1           
10.200.1.78:11211  1.2.6        86.63%         98.04%    0          0           -1.00204024880524  51       19       386,492        21,613      50        1           
10.200.1.78:11212  1.2.6        85.46%         NA        0          0           0                  0        0        11,373         31          0         0           
10.200.1.79:11211  1.2.6        87.31%         100.00%   0          0           -1.00204024880524  36       13       82,479         9,219       36        0           
10.200.1.79:11212  1.2.6        85.08%         NA        0          0           0                  0        0        11,389         31          0         0           
loop took: 0.305617094039917
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;#8217;m still looking around for something for apache that uses mod_status
and isn&amp;#8217;t too verbose; ideally I&amp;#8217;d like to be able to watch memcached,
apache response codes/times, and apache mod_status all in the same
terminal&amp;nbsp;window.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 26 Jun 2012 13:46:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-06-26:2012/06/tools-for-watching-apache-httpd-and-memcached/</guid><category>apache</category><category>memcached</category><category>perl</category><category>top</category><category>troubleshooting</category></item><item><title>Emacs Mode Variable for HTML</title><link>http://blog.jasonantman.com/2012/06/emacs-mode-variable-for-html/</link><description>&lt;p&gt;Unfortunately, I often find myself editing files that are mixed &lt;span class="caps"&gt;PHP&lt;/span&gt; and
&lt;span class="caps"&gt;HTML&lt;/span&gt;, and ending with a &amp;#8220;.php&amp;#8221; extension. For most smaller
projects/tasks, I use &lt;a href="http://www.gnu.org/software/emacs/"&gt;emacs&lt;/a&gt; at the
command line (nox) and my .emacs settings for
&lt;a href="http://php-mode.sourceforge.net/"&gt;php-mode&lt;/a&gt; will latch onto the &amp;#8220;.php&amp;#8221;
extension and open it with &lt;span class="caps"&gt;PHP&lt;/span&gt; mode. Unfortunately, &lt;span class="caps"&gt;PHP&lt;/span&gt; mode really
doesn&amp;#8217;t like embedded &lt;span class="caps"&gt;HTML&lt;/span&gt; (let alone mostly &lt;span class="caps"&gt;HTML&lt;/span&gt; with some inline &lt;span class="caps"&gt;PHP&lt;/span&gt;),
and the indentation gets very messy, among other&amp;nbsp;problems.&lt;/p&gt;
&lt;p&gt;The simple solution is to add the following (&lt;span class="caps"&gt;XHTML&lt;/span&gt; 1.0
Transitional-compliant) comment to the first line of the file, which
tells emacs to load&amp;nbsp;html-mode:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;&amp;lt;!-- -*- mode: html; -*- --&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can also get emacs to do this for you, as per the &lt;a href="http://www.gnu.org/software/emacs/manual/html_node/emacs/Specifying-File-Variables.html"&gt;Specifying File
Variables&lt;/a&gt;
documentation page. Once in html-mode, simply &lt;code&gt;M-x
add-file-local-variable-prop-line&lt;/code&gt;, enter &amp;#8220;mode&amp;#8221; for the variable
name and use the default of the current&amp;nbsp;mode.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 26 Jun 2012 08:43:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-06-26:2012/06/emacs-mode-variable-for-html/</guid><category>emacs</category><category>html. php</category></item><item><title>Script to Chart Intervals Between Problem and Recovery from Nagios/Icinga Log Files</title><link>http://blog.jasonantman.com/2012/05/script-to-chart-intervals-between-problem-and-recovery-from-nagiosicinga-log-files/</link><description>&lt;p&gt;At work, we use &lt;a href="http://www.icinga.org"&gt;Icinga&lt;/a&gt; (a fork of
&lt;a href="http://nagios.org/"&gt;Nagios&lt;/a&gt;) for monitoring. We have a few services
which are restarted or otherwise poked by event handlers, but the
recovery takes a while - so we often get paged for problems which
recover in a few minutes. I wrote a small perl script that greps through
the archived log files for a given regex (service and/or host name) and
then calculates the time from problem to recovery and graphs those&amp;nbsp;times.&lt;/p&gt;
&lt;p&gt;The script is called &lt;code&gt;nagios_log_problem_interval.pl&lt;/code&gt; and can be
downloaded from &lt;a href="https://github.com/jantman/nagios-scripts/blob/master/nagios_log_problem_interval.pl"&gt;my
github&lt;/a&gt;.
Below is some sample output, the number of minutes from problem to
recovery are along the Y axis and the count is along the X&amp;nbsp;axis:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt; nagios_log_problem_interval.pl --archivedir&lt;span class="o"&gt;=&lt;/span&gt;/var/icinga/archive --match&lt;span class="o"&gt;=&lt;/span&gt;myhost --backtrack&lt;span class="o"&gt;=&lt;/span&gt;10 myhost;&lt;span class="caps"&gt;HTTP&lt;/span&gt;
&lt;span class="go"&gt;Count&lt;/span&gt;
&lt;span class="go"&gt;1:########(8)&lt;/span&gt;
&lt;span class="go"&gt;2:##(2)&lt;/span&gt;
&lt;span class="go"&gt;3:#(1)&lt;/span&gt;
&lt;span class="go"&gt;4:##(2)&lt;/span&gt;
&lt;span class="go"&gt;5:#######(7)&lt;/span&gt;
&lt;span class="go"&gt;6:(0)&lt;/span&gt;
&lt;span class="go"&gt;7:(0)&lt;/span&gt;
&lt;span class="go"&gt;8:#(1)&lt;/span&gt;
&lt;span class="go"&gt;9:(0)&lt;/span&gt;
&lt;span class="go"&gt;10:(0)&lt;/span&gt;
&lt;span class="go"&gt;11:#(1)&lt;/span&gt;
&lt;span class="go"&gt;12:(0)&lt;/span&gt;
&lt;span class="go"&gt;13:#(1)&lt;/span&gt;
&lt;span class="go"&gt;14:(0)&lt;/span&gt;
&lt;span class="go"&gt;15:(0)&lt;/span&gt;
&lt;span class="go"&gt;16-29:(0)&lt;/span&gt;
&lt;span class="go"&gt;30-59:(0)&lt;/span&gt;
&lt;span class="go"&gt;60+:(0)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Thu, 31 May 2012 13:54:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-05-31:2012/05/script-to-chart-intervals-between-problem-and-recovery-from-nagiosicinga-log-files/</guid><category>chart</category><category>icinga</category><category>monitoring</category><category>Nagios</category><category>perl</category></item><item><title>Apache httpd - logging for sites with and without load balancing</title><link>http://blog.jasonantman.com/2012/05/apache-httpd-logging-for-sites-with-and-without-load-balancing/</link><description>&lt;p&gt;There are a few unfortunate places where I have an Apache httpd server
serving multiple vhosts, some behind a F5 BigIp load balancer and some
with direct traffic. For sites behind the &lt;span class="caps"&gt;LB&lt;/span&gt;, the remote &lt;span class="caps"&gt;IP&lt;/span&gt;/host will
always show up as the &lt;span class="caps"&gt;LB&lt;/span&gt;&amp;#8217;s &lt;span class="caps"&gt;IP&lt;/span&gt;/host, not that of the actual client. Using
the default configuration with LogFormat directives in &lt;code&gt;httpd.conf&lt;/code&gt;,
this means that either we need to define log formats per-vhost or lose
the client &lt;span class="caps"&gt;IP&lt;/span&gt; in one of our scenarios (&lt;span class="caps"&gt;LB&lt;/span&gt; or no&amp;nbsp;&lt;span class="caps"&gt;LB&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;I came by a simple solution to this on &lt;a href="http://www.maretmanu.org/homepage/inform/apache-forwarded.php"&gt;Emmanuel
Chantréau&lt;/a&gt;&amp;#8216;s
blog, and here is my condensed version of it. It sets an environment
variable (&amp;#8220;bigip-request&amp;#8221;) if the BIOrigClientAddr request header is set
(this header holds the client&amp;#8217;s &lt;span class="caps"&gt;IP&lt;/span&gt;; it&amp;#8217;s the BigIp proprietary version
of the X-Forwarded-For header. You could easily substitute that more
standard header in the following snippet) and then sets the &amp;#8220;combined&amp;#8221;
LogFormat based on that variable - a version using BIOrigClientAddr if
it is set, and a version using the normal &amp;#8220;%h&amp;#8221; remote host&amp;nbsp;otherwise.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;httpd.conf:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# set the &amp;quot;bigip-request&amp;quot; env variable to &amp;quot;1&amp;quot; if there is a BIOrigClientAddr header in the request                                                                                                   &lt;/span&gt;
&lt;span class="nb"&gt;SetEnvIf&lt;/span&gt; BIOrigClientAddr . bigip-request
&lt;span class="c"&gt;# we&amp;#39;ll use this following LogFormat (BIOrigClientAddr in place of remote host) as &amp;quot;combined&amp;quot; &lt;span class="caps"&gt;IF&lt;/span&gt; the bigip-request env variable is set                                                                     &lt;/span&gt;
&lt;span class="nb"&gt;LogFormat&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%{BIOrigClientAddr}i %l %u %t %v \&amp;quot;%r\&amp;quot; %&amp;gt;s %b \&amp;quot;%{Referer}i\&amp;quot; \&amp;quot;%{User-Agent}i\&amp;quot;&amp;quot;&lt;/span&gt; combined_lb
&lt;span class="c"&gt;# else we&amp;#39;ll use this one (remote host &lt;span class="caps"&gt;IP&lt;/span&gt; address) as &amp;quot;combined&amp;quot; &lt;span class="caps"&gt;IF&lt;/span&gt; the bigip-request env variable is &lt;span class="caps"&gt;NOT&lt;/span&gt; set                                                                                   &lt;/span&gt;
&lt;span class="nb"&gt;LogFormat&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%h %l %u %t %v \&amp;quot;%r\&amp;quot; %&amp;gt;s %b \&amp;quot;%{Referer}i\&amp;quot; \&amp;quot;%{User-Agent}i\&amp;quot;&amp;quot;&lt;/span&gt; combined
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then in our vhost&amp;nbsp;configuration:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# use this log format if we&amp;#39;re behind an &lt;span class="caps"&gt;LB&lt;/span&gt;&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; logs/&amp;lt;%= domain %&amp;gt;_access_log combined env=!bigip-request
&lt;span class="c"&gt;# or this format if we&amp;#39;re not&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; logs/&amp;lt;%= domain %&amp;gt;_access_log combined_lb env=bigip-request
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Wed, 30 May 2012 09:46:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-05-30:2012/05/apache-httpd-logging-for-sites-with-and-without-load-balancing/</guid><category>apache</category><category>bigip</category><category>f5</category><category>httpd</category><category>load balancer</category><category>logging</category></item><item><title>Creating RPMs from Perl CPAN Modules</title><link>http://blog.jasonantman.com/2012/05/creating-rpms-from-perl-cpan-modules/</link><description>&lt;p&gt;I try my absolute best to always install software on my Linux boxes as
&lt;a href="http://en.wikipedia.org/wiki/RPM_Package_Manager"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt;&lt;/a&gt;s, installed
through &lt;a href="http://yum.baseurl.org/"&gt;Yum&lt;/a&gt; (yes, I use
&lt;a href="http://www.centos.org"&gt;CentOS&lt;/a&gt; on servers and
&lt;a href="http://fedoraproject.org/"&gt;Fedora&lt;/a&gt; on my desktops/laptops). Not only is
this more-or-less required to sanely manage configuration through
Puppet, but it also lets me recreate a machine, or install dependencies
for something, in one simple command line. Unfortunately, I run quite a
bit of Perl code, and there are a lot of &lt;a href="http://www.cpan.org/"&gt;&lt;span class="caps"&gt;CPAN&lt;/span&gt;&lt;/a&gt;
Perl modules that aren&amp;#8217;t in any of the usual CentOS/Fedora&amp;nbsp;repositories.&lt;/p&gt;
&lt;p&gt;Enter cpan2rpm: a Perl script that, in its simplest invocation,
downloads a specified &lt;span class="caps"&gt;CPAN&lt;/span&gt; module and automatically builds RPMs and
SRPMs for it. The &lt;a href="http://perl.arix.com/cpan2rpm/"&gt;original version&lt;/a&gt; by
&lt;a href="http://www.arix.com/ec/"&gt;Erick Calder&lt;/a&gt; hasn&amp;#8217;t been touched since 2005,
but there&amp;#8217;s &lt;a href="http://www.mediaburst.co.uk/blog/creating-perl-module-rpms/"&gt;a newer version from
Mediaburst&lt;/a&gt;,
&lt;a href="http://www2.mbstatic.co.uk/wp-content/uploads/2009/09/cpan2rpmmb"&gt;cpan2rpmmb&lt;/a&gt;,
that seems to incorporate some nice improvements and worked quite well
for&amp;nbsp;me.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 15 May 2012 15:01:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-05-15:2012/05/creating-rpms-from-perl-cpan-modules/</guid><category>cpan</category><category>cpan2rpm</category><category>perl</category><category>rpm</category><category>yum</category></item><item><title>Perl script to convert F5 BigIp VIP address to list of internal pool member addresses</title><link>http://blog.jasonantman.com/2012/04/perl-script-to-convert-f5-bigip-vip-address-to-list-of-internal-pool-member-addresses/</link><description>&lt;p&gt;I often find myself logging in to the web &lt;span class="caps"&gt;UI&lt;/span&gt; of &lt;a href="http://www.f5.com/products/big-ip/"&gt;F5
BigIp&lt;/a&gt; load balancers and tracing
down a &lt;span class="caps"&gt;VIP&lt;/span&gt; address to the servers that actually back it. This is an
arduous, repetitive task of tracing from the &lt;span class="caps"&gt;VIP&lt;/span&gt; list to the &lt;span class="caps"&gt;VIP&lt;/span&gt; details
page to find the default pool, then matching up that in the pool list
and checking the pool members page. Luckily, the F5 boxes have a &lt;a href="https://devcentral.f5.com/"&gt;web
service &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt; that can be used for tasks like
this. They have &lt;span class="caps"&gt;GPL&lt;/span&gt; sample code in Perl that uses only
&lt;a href="http://search.cpan.org/~mkutter/SOAP-Lite-0.714/lib/SOAP/Lite.pm"&gt;&lt;span class="caps"&gt;SOAP&lt;/span&gt;::Lite&lt;/a&gt;
(as well as Getopt::Long and Pod::Usage) to interact with an F5 BigIp. I
wrote a simple script to trace a &lt;span class="caps"&gt;VIP&lt;/span&gt; to the appropriate internal pool
member addresses, assuming you have a simple configuration of &lt;span class="caps"&gt;VIP&lt;/span&gt; -&gt;
Single default pool -&amp;gt; pool&amp;nbsp;members.&lt;/p&gt;
&lt;p&gt;Usage is quite&amp;nbsp;simple:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt; ./VipToInternalHosts.pl --host&lt;span class="o"&gt;=&lt;/span&gt;prod-lb1.example.com --user&lt;span class="o"&gt;=&lt;/span&gt;myname --pass&lt;span class="o"&gt;=&lt;/span&gt;mypassword --vip&lt;span class="o"&gt;=&lt;/span&gt;128.6.30.130:80
&lt;span class="go"&gt;&lt;span class="caps"&gt;VIP&lt;/span&gt; 128.6.30.130:80 (f5_vip_name) -&amp;gt; Pool &amp;#39;pool_name&amp;#39;&lt;/span&gt;
&lt;span class="go"&gt;Members of Pool &amp;#39;pool_name&amp;#39;:&lt;/span&gt;
&lt;span class="go"&gt;    10.145.15.10:80&lt;/span&gt;
&lt;span class="go"&gt;    10.145.15.11:80&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The code can be found at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/VipToInternalHosts.pl"&gt;https://github.com/jantman/misc-scripts/blob/master/VipToInternalHosts.pl&lt;/a&gt;. I hope it&amp;#8217;s of use to someone else as&amp;nbsp;well.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">admin</dc:creator><pubDate>Tue, 24 Apr 2012 22:04:00 -0400</pubDate><guid>tag:blog.jasonantman.com,2012-04-24:2012/04/perl-script-to-convert-f5-bigip-vip-address-to-list-of-internal-pool-member-addresses/</guid><category>bigip</category><category>f5</category><category>load balancer</category><category>perl</category></item></channel></rss>