<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jason Antman's Blog - DIY / Home Automation / Security</title><link href="https://blog.jasonantman.com/" rel="alternate"></link><link href="https://blog.jasonantman.com/feeds/categories/diy-home-automation-security.atom.xml" rel="self"></link><id>https://blog.jasonantman.com/</id><updated>2018-12-31T21:25:00-05:00</updated><entry><title>Twilio Programmable Wireless PPP Proxy Docker Image</title><link href="https://blog.jasonantman.com/2018/12/twilio-programmable-wireless-ppp-proxy-docker-image/" rel="alternate"></link><published>2018-12-31T21:25:00-05:00</published><updated>2018-12-31T21:25:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-12-31:/2018/12/twilio-programmable-wireless-ppp-proxy-docker-image/</id><summary type="html">&lt;p&gt;Docker container with &lt;span class="caps"&gt;HTTP&lt;/span&gt;(S) proxy to Twilio Programmable Wirless &lt;span class="caps"&gt;PPP&lt;/span&gt; cellular&amp;nbsp;connection.&lt;/p&gt;</summary><content type="html">&lt;div class="alert alert-warning" role="alert"&gt;&lt;strong&gt;Notice/Disclaimer:&lt;/strong&gt; The information I provide on home automation/security and surveillance is based on what I&amp;#8217;ve set up for myself based on a balance of cost, ease of use, and security, and should be considered for hobby purposes only. My current system and code has grown organically over time and is not how I&amp;#8217;d approach this if I started over from scratch. My code and system has a few obvious vulnerabilities and probably some non-obvious ones as well; I humbly but sincerely ask that you do not attempt to exploit these. I highly recommend that anyone implementing a similar system - especially if you also publish the details of it - have undocumented backup systems/devices. Finally, the systems that I describe are intended to provide some protection against or notification of crimes of opportunity, not targeted attacks. Please keep in mind that none of this is intended to protect against someone who targets &lt;em&gt;me&lt;/em&gt; specifically (and takes the time to research me) as opposed to my home at random.&lt;/div&gt;

&lt;p&gt;While my &lt;a href="/2018/12/aws-reinvent-2018-my-experience-and-recommendations-for-next-time/"&gt;trip to the &lt;span class="caps"&gt;AWS&lt;/span&gt; re:Invent conference last month&lt;/a&gt; resulted in a giant pile of swag from the expo, by far the most interesting of it was from the communications company &lt;a href="https://www.twilio.com"&gt;Twilio&lt;/a&gt; that gave me a &lt;span class="caps"&gt;SIM&lt;/span&gt; card for their &lt;a href="https://www.twilio.com/wireless"&gt;Programmable Wireless&lt;/a&gt; service (as well as something else that will be the topic of at least one future post). Programmable Wireless is really cool: for $3 per &lt;span class="caps"&gt;SIM&lt;/span&gt; and $3 per month (in &lt;strong&gt;single unit&lt;/strong&gt; quantity) I get a 2G/3G/4G &lt;span class="caps"&gt;SIM&lt;/span&gt; card with &lt;span class="caps"&gt;20MB&lt;/span&gt; of monthly data. That&amp;#8217;s not much data in the world of smartphones, but it&amp;#8217;s more than enough for many IoT or embedded use cases. More importantly, the &lt;span class="caps"&gt;SIM&lt;/span&gt; is also tied to your Twilio account that provides customizable rate plans (data rates, quotas, and roaming configuration) and detailed bi-hourly breakdowns of upload and download transfer, as well as &lt;a href="https://www.twilio.com/docs/usage/api"&gt;ReST APIs&lt;/a&gt; to manage everything and retrieve usage information and &lt;a href="https://www.twilio.com/docs/wireless"&gt;wonderful documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, at re:Invent one of the Twilio folks was telling me about their new Programmable Wireless service and the low costs even for a single &lt;span class="caps"&gt;SIM&lt;/span&gt;, and it occurred to me that this would be the perfect solution for an out-of-band notification solution for my &lt;a href="/2018/08/home-automation-and-security-system-overview/"&gt;home automation and security system&lt;/a&gt; (&lt;a href="/tags/security/index.html"&gt;blog posts in the &amp;#8220;security&amp;#8221; category&lt;/a&gt;). I&amp;#8217;ve done quite a bit this year with automation and security for my house, as well as video surveillance. I&amp;#8217;ve handled a lot of reasonable failure scenarios including power outage but, while my &lt;span class="caps"&gt;AT&lt;/span&gt;&amp;amp;T fiber connection has been remarkably reliable so far, loss of connectivity was the one major issue I didn&amp;#8217;t have a working solution for. My needs in the case of a loss of connectivity are somewhat different from the normal day-to-day; it&amp;#8217;s a rare enough condition that I&amp;#8217;m not really concerned with getting massive collections of surveillance camera still images like usual, but just a simple alert when connectivity is lost or restored, or if the alarm is triggered when my primary Internet connection is offline. Within those constraints it seemed like Programmable Wireless would be perfect for my needs, especially at the $3 &lt;span class="caps"&gt;USD&lt;/span&gt;/month price tag for a one-off personal&amp;nbsp;project.&lt;/p&gt;
&lt;p&gt;A few weeks ago, before going out of state for a week, I purchased the Huawei E397u-53 unlocked &lt;span class="caps"&gt;USB&lt;/span&gt; 4G &lt;span class="caps"&gt;LTE&lt;/span&gt; modem on &lt;a href="https://www.twilio.com/docs/wireless/tutorials/compatible-hardware"&gt;Twilio&amp;#8217;s compatible hardware list&lt;/a&gt; from &lt;a href="https://www.amazon.com/gp/product/B01M0JY15V/"&gt;Amazon&lt;/a&gt; and started work on the project. At first I spun my wheels for quite a while trying to figure out a way to handle the insane routing that I wanted in Linux: route everything out the default gateway (my &lt;span class="caps"&gt;LAN&lt;/span&gt;, going to my router and out the &lt;span class="caps"&gt;AT&lt;/span&gt;&amp;amp;T Fiber uplink) when it&amp;#8217;s working, but when the &lt;span class="caps"&gt;AT&lt;/span&gt;&amp;amp;T link is down, route only certain &amp;#8220;special&amp;#8221; traffic through the &lt;span class="caps"&gt;USB&lt;/span&gt; modem. After a bunch of thinking in circles and researching - and digging into all sorts of ugly stuff like policy-based routing - I resorted to posting a question on Twitter. Luckily a brilliant engineer who I used to work with &lt;a href="https://twitter.com/j_metzmeier/status/1076234692167454721"&gt;pointed me in the right direction&lt;/a&gt; with Docker. After thinking through his suggestion for a comparatively short amount of time, I hit on the solution that I&amp;#8217;m currently&amp;nbsp;using.&lt;/p&gt;
&lt;p&gt;My solution was to run a lightweight &lt;span class="caps"&gt;HTTP&lt;/span&gt;(S) proxy server (&lt;a href="https://tinyproxy.github.io/"&gt;tinyproxy&lt;/a&gt;) inside a Docker container, with the container running in privileged mode and the &lt;span class="caps"&gt;PPP&lt;/span&gt; connection managed inside the container. Since it&amp;#8217;s running in privileged mode, the Docker container has full access to the host devices including the &lt;span class="caps"&gt;USB&lt;/span&gt; modem. When the container starts it launches &lt;a href="https://en.wikipedia.org/wiki/Point-to-Point_Protocol_daemon"&gt;pppd&lt;/a&gt; which establishes the &lt;span class="caps"&gt;PPP&lt;/span&gt; link over the cellular modem, sets a new default route over the link, and then starts tinyproxy (adding some other routes to the &lt;span class="caps"&gt;LAN&lt;/span&gt; as needed). The container exposes port 8888 for tinyproxy, which allows &lt;span class="caps"&gt;HTTP&lt;/span&gt;(S) traffic to be routed over the cellular link just by using the container as a proxy. I handle the failover component at the application level, by attempting to send data over the default route a certain number of times and then falling back to the proxy if all attempts failed (&lt;a href="https://github.com/jantman/home-automation-configs/commit/2cf9eb933969f7527786393703e91f0a32538deb"&gt;example commit&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;My solution to this is still very rough around the edges and shows all the unfortunate signs of being thrown together in a single rushed evening, but the &lt;a href="https://hub.docker.com/r/jantman/twilio-ppp-proxy"&gt;jantman/twilio-ppp-proxy Docker image&lt;/a&gt; and corresponding &lt;a href="https://github.com/jantman/docker-twilio-ppp-proxy"&gt;GitHub repo&lt;/a&gt; are available for anyone who would like to use them; I hope to polish them up a bit in the near future. While my needs are somewhat specific, I hope this will be of assistance to anyone else who wants the ability to easily proxy certain traffic over a Twilio Programmable Wireless link while preserving their existing&amp;nbsp;routing.&lt;/p&gt;
&lt;p&gt;Most importantly, many many thanks to the folks at the Twilio booth at re:Invent (I really, really wish I remembered the name of the person I spoke to) for discussing their services with me and giving me the &lt;span class="caps"&gt;SIM&lt;/span&gt; card that got this project&amp;nbsp;started!&lt;/p&gt;</content><category term="twilio"></category><category term="wireless"></category><category term="cellular"></category><category term="4G"></category><category term="DIY"></category><category term="security"></category><category term="reliability"></category><category term="alarm"></category></entry><entry><title>Inexpensive $26USD 1080p WiFi Camera</title><link href="https://blog.jasonantman.com/2018/11/inexpensive-26USD-1080p-wifi-camera/" rel="alternate"></link><published>2018-11-04T18:04:00-05:00</published><updated>2018-11-04T18:04:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-11-04:/2018/11/inexpensive-26USD-1080p-wifi-camera/</id><summary type="html">&lt;p&gt;Review of a tiny inexpensive $&lt;span class="caps"&gt;26USD&lt;/span&gt; 1080p WiFi surveillance&amp;nbsp;camera.&lt;/p&gt;</summary><content type="html">&lt;p&gt;While I&amp;#8217;ve been very happy with the &lt;a href="/2018/05/amcrest-ip-camera-first-impressions/"&gt;Amcrest security cameras that I bought&lt;/a&gt;, I&amp;#8217;m going out of town for a few days and would like to be able to keep an eye on my cats (and the pet sitter) while I&amp;#8217;m away. Since this is going to be essentially temporary and indoors, I didn&amp;#8217;t want to spend the $60-80 per camera that I did for the Amcrests. After looking around on Amazon a bit, I decided to try the &lt;a href="https://www.amazon.com/UnionCam-Q5-Surveillance-Detection-Monitoring/dp/B07F6GXWC9/"&gt;UnionCam Q5&lt;/a&gt;, a $&lt;span class="caps"&gt;26USD&lt;/span&gt; indoor 1080p WiFi security camera. It&amp;#8217;s a cheap-looking Chinese model with a baby-monitor-esque design, but it claims &lt;span class="caps"&gt;ONVIF&lt;/span&gt; compatibility and to work with some popular security DVRs like Blue Iris, so I figured it would be worth&amp;nbsp;trying.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/UnionCamQ5.jpg"&gt;&lt;img alt="UnionCam Q5 product photo" src="/GFX/UnionCamQ5_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;While the picture isn&amp;#8217;t amazing (see some examples at the end of this post), I was pleasantly surprised that - despite documentation to the contrary - I was able to set it up without ever installing the vendor&amp;#8217;s questionable proprietary phone apps, and that it works quite well with ZoneMinder. The night mode leaves something to be desired, but this should do quite well for my intended purpose and is priced perfectly for something that will be in a closet all but a few days a&amp;nbsp;year.&lt;/p&gt;
&lt;p&gt;The setup instructions say to download their iOS or Android app, connect your phone to a &lt;span class="caps"&gt;SSID&lt;/span&gt; broadcast by the camera, and then use the app to set it up. On a hunch I just connected my laptop to the &lt;span class="caps"&gt;SSID&lt;/span&gt;, checked my default route (192.168.10.1), and pointed my browser to http://192.168.10.1. Sure enough I got a login screen and used the default username from the documentation (admin) and the password from the sticker on the back of the camera (123) and was prompted to change the password. After that, I was dumped right into a really bare-bones &lt;span class="caps"&gt;UI&lt;/span&gt; with a &amp;#8220;Network Configuration&amp;#8221; page asking for a &lt;span class="caps"&gt;SSID&lt;/span&gt; and password. I entered the info for my isolated IoT network and clicked save. Some sort of error dialog popped up, but within a few seconds the camera was connected to my network, no app&amp;nbsp;needed.&lt;/p&gt;
&lt;p&gt;Setup in ZoneMinder was more or less the same as any other &lt;span class="caps"&gt;RTSP&lt;/span&gt; source, like my Amcrest cameras. I set a source type of ffmpeg and a source &lt;span class="caps"&gt;URL&lt;/span&gt; of &lt;code&gt;rtsp://admin:PASSWORD@IP:554/&lt;/code&gt; (where &lt;span class="caps"&gt;PASSWORD&lt;/span&gt; is the password I set through the web &lt;span class="caps"&gt;UI&lt;/span&gt; and &lt;span class="caps"&gt;IP&lt;/span&gt; is the &lt;span class="caps"&gt;IP&lt;/span&gt; address of the camera). ZoneMinder started capturing within a few seconds, and appears to be capturing full 1920x1080 at approximately&amp;nbsp;15fps.&lt;/p&gt;
&lt;p&gt;One thing that really bothered me was that the camera was showing a timestamp in the top left of the frame, stuck at a Unix timestamp of zero (January 1, 1970); I figured this is something that the app would normally fix, as the web &lt;span class="caps"&gt;UI&lt;/span&gt; doesn&amp;#8217;t provide a way to set anything useful other than the password and wireless connection details. The vendor claims &lt;span class="caps"&gt;ONVIF&lt;/span&gt; compatibility but some of the Amazon reviews dispute this, so I decided to look into it a bit. I fired up a Windows &lt;span class="caps"&gt;VM&lt;/span&gt; with &lt;a href="https://sourceforge.net/projects/onvifdm/"&gt;&lt;span class="caps"&gt;ONVIF&lt;/span&gt; Device Manager&lt;/a&gt; and the camera was immediately&amp;nbsp;detected.&lt;/p&gt;
&lt;p&gt;The &lt;span class="caps"&gt;ONVIF&lt;/span&gt; support itself, however, appears to be a bit spotty. I attempted to change the frame rate from 20fps down to 10fps, but it just reverted back. Telling the camera to sync with &lt;span class="caps"&gt;NTP&lt;/span&gt; using servers from &lt;span class="caps"&gt;DHCP&lt;/span&gt; does nothing, and trying to manually set the &lt;span class="caps"&gt;NTP&lt;/span&gt; server just reverts back to &lt;span class="caps"&gt;DHCP&lt;/span&gt;. I was able to get the time somewhat correct by synchronizing with the local computer, but the timezone on the camera won&amp;#8217;t change from &lt;span class="caps"&gt;UTC&lt;/span&gt;. Overall, &lt;span class="caps"&gt;ONVIF&lt;/span&gt; seemed to be a strange mix of clearly unsupported settings (i.e. &lt;span class="caps"&gt;ONVIF&lt;/span&gt; Device Manager reports them as unsupported), settings that would error on change, and settings that would appear to update successfully but then revert back to their previous&amp;nbsp;values.&lt;/p&gt;
&lt;p&gt;Overall, I&amp;#8217;d say that I got what I paid for and I&amp;#8217;m quite happy with the camera. I wasn&amp;#8217;t expecting much, and just the fact that I could set it up without using the app, and it works successfully (and without any disconnect issues) as an &lt;span class="caps"&gt;RTSP&lt;/span&gt; source has me quite&amp;nbsp;happy.&lt;/p&gt;
&lt;p&gt;For reference, here are some stills from the camera in my storage room where I have the cats&amp;#8217; litter boxes, first during the day and then at night with a light on and without any lights&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/UnionCamQ5_1.jpg"&gt;&lt;img alt="still from camera during day" src="/GFX/UnionCamQ5_1_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/UnionCamQ5_2.jpg"&gt;&lt;img alt="still from camera at night with a light on" src="/GFX/UnionCamQ5_2_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/UnionCamQ5_3.jpg"&gt;&lt;img alt="still from camera at night with no lights on" src="/GFX/UnionCamQ5_3_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="camera"></category><category term="security"></category><category term="surveillance"></category><category term="video"></category><category term="linux"></category><category term="IP camera"></category></entry><entry><title>Home Automation and Security System Overview</title><link href="https://blog.jasonantman.com/2018/08/home-automation-and-security-system-overview/" rel="alternate"></link><published>2018-08-18T19:19:00-04:00</published><updated>2018-08-18T19:19:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-08-18:/2018/08/home-automation-and-security-system-overview/</id><summary type="html">&lt;p&gt;An overview of the current working state of my &lt;span class="caps"&gt;DIY&lt;/span&gt; home automation and security&amp;nbsp;system.&lt;/p&gt;</summary><content type="html">&lt;!--- remove this next line to disable Table of Contents --&gt;

&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#security-cameras"&gt;Security Cameras&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#neural-network-object-detection"&gt;Neural Network Object&amp;nbsp;Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tie-in-with-alarm-system"&gt;Tie-In with Alarm&amp;nbsp;System&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#alarm-system"&gt;Alarm System&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#zooz-multi-sensors"&gt;Zooz&amp;nbsp;Multi-Sensors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#control-panel"&gt;Control&amp;nbsp;Panel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#home-automation"&gt;Home&amp;nbsp;Automation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="alert alert-warning" role="alert"&gt;&lt;strong&gt;Notice/Disclaimer:&lt;/strong&gt; The information I provide on home automation/security and surveillance is based on what I&amp;#8217;ve set up for myself based on a balance of cost, ease of use, and security, and should be considered for hobby purposes only. My current system and code has grown organically over time and is not how I&amp;#8217;d approach this if I started over from scratch. My code and system has a few obvious vulnerabilities and probably some non-obvious ones as well; I humbly but sincerely ask that you do not attempt to exploit these. I highly recommend that anyone implementing a similar system - especially if you also publish the details of it - have undocumented backup systems/devices. Finally, the systems that I describe are intended to provide some protection against or notification of crimes of opportunity, not targeted attacks. Please keep in mind that none of this is intended to protect against someone who targets &lt;em&gt;me&lt;/em&gt; specifically (and takes the time to research me) as opposed to my home at random.&lt;/div&gt;

&lt;p&gt;I&amp;#8217;ve done a lot of work on my &lt;span class="caps"&gt;DIY&lt;/span&gt; HomeAssistant-based home automation and security system since my &lt;a href="/2018/07/ip-camera-home-security-and-automation-update/"&gt;last post on it&lt;/a&gt; just over a month ago. While it was a lot of work and frustrating at times, I&amp;#8217;m happy to say that I think I&amp;#8217;ve finally gotten everything to a usable and working state, and I don&amp;#8217;t currently have anything left on my to-do list for this project. I have four working security cameras that run both motion detection and object detection and notify me if a person is detected, a functional alarm system for unauthorized entry, and a few home automation&amp;nbsp;conveniences.&lt;/p&gt;
&lt;p&gt;Virtually all of the code and configuration backing this is available in my &lt;a href="https://github.com/jantman/home-automation-configs"&gt;home-automation-configs GitHub repo&lt;/a&gt; but I want to use this post to go over each of the major components as well as some of the difficulties I&amp;nbsp;encountered.&lt;/p&gt;
&lt;h1 id="security-cameras"&gt;&lt;a class="toclink" href="#security-cameras"&gt;Security&amp;nbsp;Cameras&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;About a month ago I purchased the two more security cameras I&amp;#8217;d been thinking about, a pair of WiFi  &lt;a href="https://amcrest.com/amcrest-prohd-outdoor-1080p-wifi-wireless-ip-security-bullet-camera-ip67-weatherproof-1080p-1920tvl-ip2m-852w-white.html"&gt;Amcrest &lt;span class="caps"&gt;IP2M&lt;/span&gt;-852W&lt;/a&gt; 1080P with a super-wide 128º field of view. After switching out the &lt;span class="caps"&gt;IPM&lt;/span&gt;-723W (960P / 92º FoV) on my front porch for one of them and mounting the other on the far side of the house, I now have a total of four cameras (three outside, one inside) and coverage of both entrances to my house and all meaningful approaches to the&amp;nbsp;property.&lt;/p&gt;
&lt;p&gt;One thing I didn&amp;#8217;t take into account, unfortunately, was the signal strength from my aged (in-service 24x7 for ) 2.4GHz Ubiquiti Networks access point at the far corners of the house. After a sweaty, hot summer afternoon up on a ladder mounting a camera at the back corner of the house and attempting in vain to aim it using the stream over WiFi, I realized that the construction of my (rental) house causes severe signal shadows at the back corners. I spent a fruitless few hours trying to set up a Netgear &lt;span class="caps"&gt;WN3000RP&lt;/span&gt; &amp;#8220;WiFi Range Extender&amp;#8221; that I picked up at Best Buy (the setup process was horribly frustrating and error-prone even for someone who worked as a wireless network engineer) only to realize that it was actually a layer 3 router and nothing connected to the extended network could be accessed from my&amp;nbsp;&lt;span class="caps"&gt;LAN&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;After spending another afternoon considering some options - moving my &lt;span class="caps"&gt;AP&lt;/span&gt; or adding another, neither very feasible in a rented house that I don&amp;#8217;t want to run permanent cabling in - I ended up using existing holes and wiring paths to hook up both cameras with wired Ethernet. In retrospect, I should have done either a proper wireless site survey or at least some spot tests with my phone or laptop beforehand. It would&amp;#8217;ve been much faster if I&amp;#8217;d known about the poor signal beforehand, and I also would&amp;#8217;ve purchased PoE cameras instead of using the WiFi models which ended up requiring both Ethernet and power cables. On that note, my one complaint so far about the Amcrest cameras is that they are &lt;em&gt;either&lt;/em&gt; wired Ethernet with PoE &lt;em&gt;or&lt;/em&gt; WiFi with separate Ethernet and 12V &lt;span class="caps"&gt;DC&lt;/span&gt; power cables. I&amp;#8217;m not quite sure why they were designed this way as opposed to all supporting PoE, but I assume there&amp;#8217;s a manufacturing or cost&amp;nbsp;reason.&lt;/p&gt;
&lt;p&gt;One thing that I have noticed in the past month of having both wireless and wired cameras is the difference in frame rate. While my one outdoor camera that&amp;#8217;s actually using the 2.4GHz WiFi works acceptably well, ZoneMinder is all too happy to show me that it runs at between five and nine &lt;span class="caps"&gt;FPS&lt;/span&gt;, whereas the indoor WiFi and outdoor wired cameras run at the full configured &lt;span class="caps"&gt;10FPS&lt;/span&gt; rate. If I had to do the camera installation over again, I would&amp;#8217;ve spent much more time assessing the 2.4GHz coverage around my house from my existing &lt;span class="caps"&gt;AP&lt;/span&gt; and likely considered PoE cameras for all of the outdoor&amp;nbsp;locations.&lt;/p&gt;
&lt;h2 id="neural-network-object-detection"&gt;&lt;a class="toclink" href="#neural-network-object-detection"&gt;Neural Network Object&amp;nbsp;Detection&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my last post, I &lt;a href="/2018/07/ip-camera-home-security-and-automation-update/#neural-network-object-detection"&gt;mentioned&lt;/a&gt; how I started passing still images from motion events through &lt;a href="https://pjreddie.com/darknet/yolo/"&gt;Joseph Redmon&amp;#8217;s Darknet yolo3&lt;/a&gt; neural network object detection library. With some caveats this has worked out extremely well. While I&amp;#8217;ve decided that my cameras are mainly for remote monitoring and possible evidentiary value, and not really for use as an alarm, I&amp;#8217;m still pushing notifications from them to my phone when my alarm is armed; I&amp;#8217;m just not relying on them as a primary means of detecting a&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;One down side to my current setup is the &amp;#8220;tiny&amp;#8221; version of the yolov3 model that I&amp;#8217;m forced to use because of my poor choice of graphics card. I got the feeling that the performance of the tiny model was significantly worse than the full version and, sure enough, comparison tests on the same images proved that. It seems reasonably good at detecting people, but has a relatively high number of false positives. To compensate for this, I&amp;#8217;ve built functionality to ignore certain objects in certain locations in to my image processing scripts; I can now easily log but ignore when yolo detects a stump in my front yard as a cow, or my porch railing as a&amp;nbsp;bench.&lt;/p&gt;
&lt;p&gt;My current code for handling ZoneMinder events, available &lt;a href="https://github.com/jantman/home-automation-configs/tree/master/zoneminder"&gt;on github&lt;/a&gt; implements what seems to me to be a reasonable workflow for my needs. When events are detected by ZoneMinder a selection of frames - first, last, and a variable number of high-motion (high-score) frames - are passed through yolov3-tiny object detection. Using the tiny model and 1920x1080 frames, this takes about 1/4 second per frame on my &lt;span class="caps"&gt;GPU&lt;/span&gt;. Once a list of detections is obtained (category, confidence level, and bounding boxes for each detected object) it parses the Notes field on the ZoneMinder event to determine what zones motion was detected in, then retrieves the coordinates of each zone on the monitor form ZoneMinder and calculates which zones contain each detected object. All of that information is used to evaluate - via a configuration file - which objects should be ignored. All of this information - the ZoneMinder Event details, object detections and their containing zones, etc. - is passed to HomeAssistant as an event, where it&amp;#8217;s picked up by an AppDaemon&amp;nbsp;app.&lt;/p&gt;
&lt;h2 id="tie-in-with-alarm-system"&gt;&lt;a class="toclink" href="#tie-in-with-alarm-system"&gt;Tie-In with Alarm&amp;nbsp;System&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Once the ZoneMinder events/alarms are sent to HomeAssistant as events they&amp;#8217;re picked up by an AppDaemon app, &lt;a href="https://github.com/jantman/home-automation-configs/blob/master/appdaemon/apps/zmevent_alarm_handler.py"&gt;zmevent_alarm_handler.py&lt;/a&gt;. This handles the logic behind whether or not to send me a notification for a given ZoneMinder alarm. The logic I&amp;#8217;m currently using is as&amp;nbsp;follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If my alarm system is disarmed, no&amp;nbsp;notification.&lt;/li&gt;
&lt;li&gt;If no objects were detected by &lt;span class="caps"&gt;YOLO3&lt;/span&gt;, no&amp;nbsp;notification.&lt;/li&gt;
&lt;li&gt;If the only motion was in the &amp;#8220;Street&amp;#8221; zones, no notification. I have distinct zones for the road in front of my property, and record motion there but don&amp;#8217;t alert on&amp;nbsp;it.&lt;/li&gt;
&lt;li&gt;Formulate a short string describing the objects detected and what zones they&amp;#8217;re in, for use in&amp;nbsp;notifications.&lt;/li&gt;
&lt;li&gt;If an &lt;code&gt;input_boolean&lt;/code&gt; in HomeAssistant called &amp;#8220;silence_cameras&amp;#8221; is &lt;em&gt;not&lt;/em&gt; on, send a Pushover notification to my phone containing the description of the alert and the highest-motion frame containing the detected&amp;nbsp;object(s).&lt;/li&gt;
&lt;li&gt;Send an email containing all analyzed/detected frames as well as the full details of the&amp;nbsp;event.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So far this is working quite well for me. I get &lt;em&gt;very&lt;/em&gt; few false positives with the above logic combined with object detection, only get notified if my alarm system is armed, and as far as I can tell get notified 100% of the time a person is on my&amp;nbsp;property.&lt;/p&gt;
&lt;h1 id="alarm-system"&gt;&lt;a class="toclink" href="#alarm-system"&gt;Alarm&amp;nbsp;System&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;My traditional alarm system hasn&amp;#8217;t changed much since my last post. I have door/window sensors on both entry doors to the house as well as the gate to my fenced yard and the door on the crawlspace under the house. I&amp;#8217;ve added motion detectors in most rooms, but because of problems with the sensors I chose (more on that below) I only have one in use as a trigger for the alarm, a more reliable model than the other four I purchased. With the addition of a physical control panel near the front door (more on that below as well) it&amp;#8217;s working quite well for me. I&amp;#8217;ve had zero false positives so far, and a 100% detection rate based on HomeAssistant&amp;#8217;s logs of the sensors (and my own occasional forgetting to disarm the system before I open a door). There&amp;#8217;s still something to be desired in terms of reliability of notifications as it relies on my cable Internet connection, but I &lt;em&gt;do&lt;/em&gt; get notified within five minutes by offsite monitoring if my Internet connection goes down. If I really wanted more than that, I&amp;#8217;d look into some sort of cellular backup&amp;nbsp;connection.&lt;/p&gt;
&lt;p&gt;The overall functionality of the system is incredibly basic: when armed (&lt;code&gt;input_select&lt;/code&gt; in HomeAssistant) and one of the sensors is tripped, it pushes a loud high-priority notification to my phone via Pushover. I opted not to use HomeAssistant&amp;#8217;s state machine-based &lt;a href="https://www.home-assistant.io/components/alarm_control_panel.manual/"&gt;manual alarm control panel&lt;/a&gt; component and rather implement my own logic in AppDaemon. I have an &lt;code&gt;input_select&lt;/code&gt; with three options: Disarmed, Home and Away. The alarm does nothing in &amp;#8220;Disarmed&amp;#8221; state. The &amp;#8220;Home&amp;#8221; state uses only external (door/window) sensors for trigger and the &amp;#8220;Away&amp;#8221; state also includes interior motion sensors. This trinary state is also used to control whether ZoneMinder events notify me, as described previously. My logic doesn&amp;#8217;t include any &amp;#8220;triggered&amp;#8221; state or delay; I get one notification for every sensor trigger. It also doesn&amp;#8217;t include any arming delay, but since I built and installed a real physical control panel near the door, it includes a configurable delay (currently 10 seconds) to give me time to disarm before triggering the alarm if it&amp;#8217;s currently in the Away&amp;nbsp;state.&lt;/p&gt;
&lt;p&gt;One added bit of fancy-ness that I put into the alarm is integration with ZoneMinder and my cameras. All of the doors (as well as the fence gate) have external coverage by outdoor cameras, and the front and back doors also share internal coverage from a &lt;span class="caps"&gt;PTZ&lt;/span&gt; camera mounted in view of both of them. When the alarm is armed and a door sensor trips, the AppDaemon app that handles the alarm captures images from whatever cameras have a view of the door that opened (including panning the indoor camera if needed). Those images are included in the Pushover notification that I receive, making it much more informative than just knowing that a particular door&amp;nbsp;opened.&lt;/p&gt;
&lt;h2 id="zooz-multi-sensors"&gt;&lt;a class="toclink" href="#zooz-multi-sensors"&gt;Zooz&amp;nbsp;Multi-Sensors&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my last post I &lt;a href="/2018/07/ip-camera-home-security-and-automation-update/#doorwindow-and-motion-sensors"&gt;mentioned&lt;/a&gt; that I&amp;#8217;d purchased some Z-Wave security sensors, including a $40 &lt;a href="https://www.amazon.com/gp/product/B01MQXXG0I/"&gt;EcoLink &lt;span class="caps"&gt;PIRZWAVE2&lt;/span&gt;.5-&lt;span class="caps"&gt;ECO&lt;/span&gt;&lt;/a&gt; Z-Wave Plus &lt;span class="caps"&gt;PIR&lt;/span&gt; motion sensor &amp;#8220;with &lt;span class="caps"&gt;PET&lt;/span&gt; immunity&amp;#8221; (I&amp;#8217;m pretty sure they mean domestic animals, not Positron Emission Tomography). I originally just set it to lowest sensitivity (via a physical jumper) and balanced it on top of the blinds in my living room to see how it worked. I was pleasantly surprised to find that it seemed to work perfectly - it triggered every time I moved in the room, and never when no person was in the room. After a week or so I decided that it was working well enough to order some more for full coverage of my house. I put the EcoLink &lt;span class="caps"&gt;PIR&lt;/span&gt; sensor in the back room that I use for storage and the cats&amp;#8217; food and litter boxes, and in the month-plus since then it&amp;#8217;s had a 100% accuracy&amp;nbsp;rate.&lt;/p&gt;
&lt;p&gt;When I began shopping for four more sensors, though, I was tempted to see if I could find something a bit less expensive. As I&amp;#8217;d just gotten my Z-Wave thermostat working, I was really intrigued by the $36 &lt;a href="https://www.amazon.com/gp/product/B01AKSO80O/"&gt;&lt;span class="caps"&gt;ZOOZ&lt;/span&gt; &lt;span class="caps"&gt;ZSE40&lt;/span&gt; 4-in-1 sensor, version 2.0&lt;/a&gt; which combines a &lt;span class="caps"&gt;PIR&lt;/span&gt; motion sensor with sensors for light, temperature, and humidity. I figured these would let me save a tiny bit of money while also getting the bonus of temperature sensors in every room, and the &lt;span class="caps"&gt;PIR&lt;/span&gt; motion sensors have seven levels of sensitivity - settable over Z-Wave - which I figured would be more than enough to get them to ignore my&amp;nbsp;cats.&lt;/p&gt;
&lt;p&gt;The Zooz sensors only had a 3.5 star rating on Amazon and lots of negative reviews, but it seemed that most of the reviews were for the older (non-2.0) version. Unfortunately I didn&amp;#8217;t heed my concerns and bought four of them, and I&amp;#8217;ve regretted that ever since. Setting them up initially was nowhere near as simple as the EcoLink products, since they&amp;#8217;d usually end up going to sleep before they completed pairing with my Z-Wave controller. The same was true of their seven-level sensitivity; each change required me to run around the house with a laptop and paperclip, setting the sensitivity I wanted and then waking the device up with the paperclip. This often required multiple cycles per sensor until the setting change took. Lastly, and most importantly, the machine I have running &lt;span class="caps"&gt;HASS&lt;/span&gt; and my Z-Wave network went offline for about six hours a few weeks ago. All of my other battery-operated sensors came back online within 30 minutes of getting &lt;span class="caps"&gt;HASS&lt;/span&gt; up and running again, but these took up to four hours to come back even after manually waking them&amp;nbsp;up.&lt;/p&gt;
&lt;p&gt;After all of that, even on the lowest of the seven sensitivity levels, my cats still set them off. The motion sensing is adequate for controlling lights, but causes false alarms quite often for security purposes. I&amp;#8217;ve only had them for about a month and a half, but one of the four is now completely dead - it won&amp;#8217;t even blink when I replace the battery. The temperature sensors are adequate, but not terribly accurate and suffer from serious lag problems. The light sensors function but report in &lt;em&gt;percentage&lt;/em&gt; instead of any actual measurement of light and the scale seems poorly calibrated for indoor use unless the sensor is pointed directly at the dominant light source. The sensor in my kitchen (which is pointed almost directly at the ceiling fixture) reads near 80% with the light on, about 60% with the light off during the day, and about 20% with the light off at night. However, the sensor in my bedroom reads about 2% when dark at night and only increases to about 10% with the light on during the&amp;nbsp;day.&lt;/p&gt;
&lt;p&gt;In all, I was tempted by the prospect of being able to get motion, temperature, and light level sensors all in one package and for a really low price. I ended up getting what I paid for - a $10 motion sensor, $10 temperature sensor, and $10 light level sensor. If I had to do it over again (or, when I eventually do) I&amp;#8217;d get more of the EcoLink motion sensors and add some dedicated temperature/light sensors where I need&amp;nbsp;them.&lt;/p&gt;
&lt;h2 id="control-panel"&gt;&lt;a class="toclink" href="#control-panel"&gt;Control&amp;nbsp;Panel&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After using my alarm system for a few weeks, it was clear to me that relying on proximity detection of my phone (updated by &lt;span class="caps"&gt;GPS&lt;/span&gt; using the &lt;a href="https://gpslogger.app/"&gt;GPSLogger app&lt;/a&gt;) or the &lt;span class="caps"&gt;HASS&lt;/span&gt; web interface to arm and disarm wasn&amp;#8217;t going to work. The presence detection often didn&amp;#8217;t update fast enough if I was driving to or from my house and disarming via the &lt;span class="caps"&gt;HASS&lt;/span&gt; &lt;span class="caps"&gt;UI&lt;/span&gt; just took way too long - especially since my phone connecting to WiFi when I get home causes problems with this. After giving it some thought, I decided to build a physical alarm control panel. I did some quick proofs-of-concept using the &lt;span class="caps"&gt;HASS&lt;/span&gt; WebSocket &lt;span class="caps"&gt;API&lt;/span&gt;, static &lt;span class="caps"&gt;HTML&lt;/span&gt; and Javascript served by &lt;span class="caps"&gt;HASS&lt;/span&gt; itself, and an AppDaemon app to handle the logic. It&amp;#8217;s not pretty, but it gives me a working interface that handled my main&amp;nbsp;requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Control of the lights in the&amp;nbsp;room&lt;/li&gt;
&lt;li&gt;Arming in either Home or Away modes, with a configurable delay for arming in Away (and ensuring all external door sensors are closed before&amp;nbsp;arming)&lt;/li&gt;
&lt;li&gt;One-touch diarming from Home&amp;nbsp;state&lt;/li&gt;
&lt;li&gt;Code-entry disarming from Away state, with a configurable delay between sensor activation and alarm&amp;nbsp;trigger&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After getting the software side of that working locally on my desktop computer, I decided that I&amp;#8217;d use a Raspberry Pi 3B+ that I already had for the control panel. I ordered a simple 320x480 3.5-inch &lt;span class="caps"&gt;TFT&lt;/span&gt; touchscreen &lt;a href="https://www.amazon.com/gp/product/B01FXC5ECS/"&gt;from Amazon&lt;/a&gt;, along with a &lt;a href="https://www.amazon.com/gp/product/B07B5YG4LC/"&gt;decent case&lt;/a&gt; for the Pi and screen, for about $46 total. Assembly and getting the software up and running was pretty easy (my notes are &lt;a href="https://github.com/jantman/home-automation-configs/blob/master/doorpanels.md"&gt;on GitHub here&lt;/a&gt;) and I had it up and running in an hour or so. This has really helped make the alarm more usable, since I have the touchscreen near my front door and can just tap a button to arm on my way out the door, and have fifteen seconds to enter a code when I get&amp;nbsp;home.&lt;/p&gt;
&lt;p&gt;Here are a few photos of the finished unit currently hanging out on top of the entertainment center in my living room, just a few feet inside the front&amp;nbsp;door:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/doorpanel_installed1_1920x1080.jpg"&gt;&lt;img alt="photo of finished touchscreen control panel in place" src="/GFX/doorpanel_installed1_480x320.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/doorpanel_installed2_1920x1080.jpg"&gt;&lt;img alt="photo of finished touchscreen control panel in place" src="/GFX/doorpanel_installed2_480x320.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/doorpanel_installed3_1920x1080.jpg"&gt;&lt;img alt="photo of finished touchscreen control panel in place" src="/GFX/doorpanel_installed3_480x320.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/doorpanel_installed4_1920x1080.jpg"&gt;&lt;img alt="photo of finished touchscreen control panel in place" src="/GFX/doorpanel_installed4_480x320.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And some screenshots of the really simple &lt;span class="caps"&gt;UI&lt;/span&gt; that I set up for&amp;nbsp;it:&lt;/p&gt;
&lt;p&gt;Disarmed:&lt;/p&gt;
&lt;p&gt;&lt;img alt="screenshot of touchscreen in disarmed mode" src="/GFX/doorpanel_disarmed_480x320.png"&gt;&lt;/p&gt;
&lt;p&gt;Arming Away (exit&amp;nbsp;delay):&lt;/p&gt;
&lt;p&gt;&lt;img alt="screenshot of touchscreen in arming away mode" src="/GFX/doorpanel_arming-away_480x320.png"&gt;&lt;/p&gt;
&lt;p&gt;Armed&amp;nbsp;Away:&lt;/p&gt;
&lt;p&gt;&lt;img alt="screenshot of touchscreen in armed away mode" src="/GFX/doorpanel_armed-away_480x320.png"&gt;&lt;/p&gt;
&lt;p&gt;Armed&amp;nbsp;home:&lt;/p&gt;
&lt;p&gt;&lt;img alt="screenshot of touchscreen in armed home mode" src="/GFX/doorpanel_armed-home_480x320.png"&gt;&lt;/p&gt;
&lt;p&gt;All of the code for this is available in my GitHub&amp;nbsp;repo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/home-automation-configs/blob/master/doorpanels.md"&gt;notes on the hardware and&amp;nbsp;software&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/home-automation-configs/tree/master/homeassistant/www/doorpanels"&gt;&lt;span class="caps"&gt;HTML&lt;/span&gt;, &lt;span class="caps"&gt;CSS&lt;/span&gt; and &lt;span class="caps"&gt;JS&lt;/span&gt; for the&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/home-automation-configs/blob/master/appdaemon/apps/doorpanels.py"&gt;appdaemon&amp;nbsp;app&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/home-automation-configs/tree/master/testing"&gt;some scripts I use for running it&amp;nbsp;locally&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="home-automation"&gt;&lt;a class="toclink" href="#home-automation"&gt;Home&amp;nbsp;Automation&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;I haven&amp;#8217;t delved too deep into the home automation side of things yet, and am going to try not to go overboard with it. The Z-Wave thermostat &lt;a href="/2018/07/ip-camera-home-security-and-automation-update/#thermostat"&gt;that I mentioned previously&lt;/a&gt; is working well, but unfortunately the undersized and poorly-installed &lt;span class="caps"&gt;HVAC&lt;/span&gt; system in my poorly-insulated house renders it largely moot; in the summer heat the air conditioning can&amp;#8217;t keep up anyway so there&amp;#8217;s little need for me to change the thermostat. I do have motion-activated lights in my kitchen which has proved quite convenient and satisfying, and I&amp;#8217;ve also set up some automations around my front porch light to automatically turn it on when the front door opens and it&amp;#8217;s dark outside and to turn it on just before I arrive home when I&amp;#8217;m away from the house at night. I&amp;#8217;ve also set up an automation in &lt;span class="caps"&gt;HASS&lt;/span&gt; to detect when I first turn on my bedroom light in the morning, and automatically disarm the alarm and turn on the kitchen and living room lights. I&amp;#8217;m going to try and make this the end of my home automation experiment, but I&amp;#8217;m sure I&amp;#8217;ll give in and add a few more pieces over&amp;nbsp;time.&lt;/p&gt;</content><category term="amcrest"></category><category term="camera"></category><category term="security"></category><category term="surveillance"></category><category term="video"></category><category term="linux"></category><category term="IP camera"></category><category term="evaluation"></category><category term="alarm"></category><category term="IR"></category><category term="homeassistant"></category><category term="hass"></category><category term="automation"></category><category term="z-wave"></category><category term="darknet"></category><category term="yolo"></category><category term="machine learning"></category><category term="neural network"></category><category term="object detection"></category></entry><entry><title>Shamelessly Over-Engineered Coax Lightning Protector</title><link href="https://blog.jasonantman.com/2018/07/shamelessly-over-engineered-coax-lightning-protector/" rel="alternate"></link><published>2018-07-05T16:43:00-04:00</published><updated>2018-07-05T16:43:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-07-05:/2018/07/shamelessly-over-engineered-coax-lightning-protector/</id><summary type="html">&lt;p&gt;My shamelessly over-engineered coax lightning protector using fiber media&amp;nbsp;converters.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I wrote a few weeks ago about my &lt;a href="/2018/06/new-home-router---partaker-i5"&gt;new router purchase&lt;/a&gt; thanks to a close lightning strike that came in over the coax for my cable &lt;span class="caps"&gt;TV&lt;/span&gt; and Internet (we have aerial lines in my neighborhood) and fried a good portion of my network (my router, switch, and the on-board Ethernet port on my desktop). A few days later I learned that at least four of my neighbors had damage from the same storm, all to devices connected to incoming coax or their home networks, and in some cases much more catastrophic than&amp;nbsp;mine.&lt;/p&gt;
&lt;p&gt;Given what this &lt;em&gt;could&lt;/em&gt; have cost me both monetarily and in time - if it had decimated my desktop and/or the rest of my wired devices - I decided that I had to find a decent solution. I bought an inexpensive &lt;span class="caps"&gt;UPS&lt;/span&gt; to provide backup power and hopefully-better &lt;span class="caps"&gt;AC&lt;/span&gt; surge protection (it&amp;#8217;s not a double-conversion so I&amp;#8217;m doubtful it would do much for a lightning-induced surge) but still needed to figure out a solution for coax, the actual source of the damaging surge last month. Unfortunately it seems that there aren&amp;#8217;t many options for suppressing high-current surges on coax that work without permanent installation and with broadband Internet. There certainly are some, but many seem to either have little proof for their effectiveness against lightning-induced surges or are single-use devices that fail destructively and &lt;em&gt;should&lt;/em&gt; stop the&amp;nbsp;surge.&lt;/p&gt;
&lt;p&gt;After trying for a while to come up with a decent, reliable solution I realized that I may be approaching the problem from the wrong direction. My cable modem is rented from Comcast, and I really don&amp;#8217;t care if it gets damaged from lightning - that&amp;#8217;s Comcast&amp;#8217;s problem. What I care about is my network. And while there may not be accepted and readily-accessible methods of protecting coax, air-gapping an Ethernet network is both feasible and relatively common. Enter, the shamelessly over-engineered coax lightning&amp;nbsp;protector:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/mediaconverter1_med.jpg"&gt;&lt;img alt="side view of my desk with the fiber media converters installed" src="/GFX/mediaconverter1_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/mediaconverter2_med.jpg"&gt;&lt;img alt="close-up of one end of the fiber circuit" src="/GFX/mediaconverter2_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/mediaconverter3_med.jpg"&gt;&lt;img alt="close-up of the other end of the fiber circuit" src="/GFX/mediaconverter3_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For $84 - a small fraction of the damage that could have been done - I bought a pair of &lt;a href="https://www.amazon.com/gp/product/B06XZ6CV6W/"&gt;10Gtek 10/100/1000Base-Tx to 1000Base-&lt;span class="caps"&gt;LX&lt;/span&gt;&lt;/a&gt; copper to fiber media converters and a &lt;a href="https://www.amazon.com/gp/product/B009938B50/"&gt;2M &lt;span class="caps"&gt;SC&lt;/span&gt;-&lt;span class="caps"&gt;SC&lt;/span&gt; singlemode patch cable&lt;/a&gt;. I hooked one of them to my router via a standard Cat6 &lt;span class="caps"&gt;UTP&lt;/span&gt; patch cable and the other to the cable modem with a similar cable. Between them is only non-conductive optical fiber, effectively providing a relatively complete air gap between the cable modem connected to the coax (which is strung pole-to-pole in the air, effectively like a lightning rod) at one end and my network at the other. The cable modem and its media converter are plugged directly into the wall on a separate circuit from my computer&amp;#8230; so for a surge to make it to my network (assuming everything is wired as it appears to be), it would need to jump from the coax to the mains and then travel to the breaker panel on the other side of the house, back through a separate circuit to my desk, and through my&amp;nbsp;&lt;span class="caps"&gt;UPS&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;It may be horribly over-engineered, but for less than $100, I have some peace of mind that the damage from last month won&amp;#8217;t be&amp;nbsp;repeated.&lt;/p&gt;</content><category term="network"></category><category term="lightning"></category><category term="surge"></category><category term="fiber"></category><category term="coax"></category></entry><entry><title>IP Camera, Home Security and Automation Update</title><link href="https://blog.jasonantman.com/2018/07/ip-camera-home-security-and-automation-update/" rel="alternate"></link><published>2018-07-02T06:10:00-04:00</published><updated>2018-07-02T06:10:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-07-02:/2018/07/ip-camera-home-security-and-automation-update/</id><summary type="html">&lt;p&gt;An update on my &lt;span class="caps"&gt;IP&lt;/span&gt; camera and home security project, now branching out into home automation and machine learning as&amp;nbsp;well.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#amcrest-cameras"&gt;Amcrest Cameras&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#ir-illuminator"&gt;&lt;span class="caps"&gt;IR&lt;/span&gt;&amp;nbsp;Illuminator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#surveillance-software-zoneminder"&gt;Surveillance Software - ZoneMinder&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#notifications"&gt;Notifications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#image-processing-ir-switch-detection"&gt;Image Processing - &lt;span class="caps"&gt;IR&lt;/span&gt; Switch&amp;nbsp;Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#monitoring"&gt;Monitoring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#neural-network-object-detection"&gt;Neural Network Object&amp;nbsp;Detection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#homeassistant-and-z-wave"&gt;HomeAssistant and Z-Wave&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#doorwindow-and-motion-sensors"&gt;Door/Window and Motion&amp;nbsp;Sensors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#thermostat"&gt;Thermostat&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#whats-next"&gt;What&amp;#8217;s&amp;nbsp;Next&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="alert alert-warning" role="alert"&gt;&lt;strong&gt;Notice/Disclaimer:&lt;/strong&gt; The information I provide on home automation/security and surveillance is based on what I&amp;#8217;ve set up for myself based on a balance of cost, ease of use, and security, and should be considered for hobby purposes only. My current system and code has grown organically over time and is not how I&amp;#8217;d approach this if I started over from scratch. My code and system has a few obvious vulnerabilities and probably some non-obvious ones as well; I humbly but sincerely ask that you do not attempt to exploit these. I highly recommend that anyone implementing a similar system - especially if you also publish the details of it - have undocumented backup systems/devices. Finally, the systems that I describe are intended to provide some protection against or notification of crimes of opportunity, not targeted attacks. Please keep in mind that none of this is intended to protect against someone who targets &lt;em&gt;me&lt;/em&gt; specifically (and takes the time to research me) as opposed to my home at random.&lt;/div&gt;

&lt;p&gt;Last month I posted about my &lt;a href="/2018/05/linux-surveillance-camera-software-evaluation/"&gt;Linux Surveillance Camera Software Evaluation&lt;/a&gt; and my plans for turning some Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt; cameras into a home security system. I&amp;#8217;ve made a lot of progress and some big changes since then and decided that I had better post an update before the effort of doing so becomes overwhelming. There are a lot of changes and new information, and some really cool plans for the future (this has become my new obsession, albeit a prohibitively expensive one), so I&amp;#8217;ll break this up into a number of&amp;nbsp;sections.&lt;/p&gt;
&lt;h2 id="amcrest-cameras"&gt;&lt;a class="toclink" href="#amcrest-cameras"&gt;Amcrest&amp;nbsp;Cameras&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m extremely happy with the two Amcrest cameras I purchased, and am planning to add two more at some point in the near future to cover the rest of the exterior of my house. The one I currently have outside is an Amcrest &lt;a href="https://amcrest.com/amcrest-1-3mp-bullt-wifi-video-security-ip-camera-pt-ipm-723w.html"&gt;&lt;span class="caps"&gt;IPM&lt;/span&gt;-723W&lt;/a&gt; WiFi camera with a 1.&lt;span class="caps"&gt;3MP&lt;/span&gt; 1280x960 resolution and a 92º field of view. It&amp;#8217;s a decent camera and the resolution is perfectly adequate but I wouldn&amp;#8217;t mind a bit more, and more importantly, both sides of my house would benefit a lot from a winder field of view. I believe I&amp;#8217;ve settled on two Amcrest &lt;a href="https://amcrest.com/amcrest-prohd-outdoor-1080p-wifi-wireless-ip-security-bullet-camera-ip67-weatherproof-1080p-1920tvl-ip2m-852w-white.html"&gt;&lt;span class="caps"&gt;IP2M&lt;/span&gt;-852W&lt;/a&gt;, which are similar outdoor WiFi cameras but with 1920x1080 resolution and a super-wide 128º field of&amp;nbsp;view.&lt;/p&gt;
&lt;p&gt;I received some questions via email after writing this post about the Amcrest cameras with Linux as well as the security of them. I think I&amp;#8217;m quite happy with both, but both with some caveats. First of all, regarding security, I&amp;#8217;m skeptical of the security of any proprietary software (especially from a small vendor or one not in the software business) and generally expect all IoT devices to have abysmal security. When I originally purchased the devices, I blocked all Internet-bound traffic from them at my router before even plugging them in. For the time being at least, I&amp;#8217;m going to assume that to be enough for my needs. I certainly wouldn&amp;#8217;t expose these directly to the Internet or allow them to access both the Internet and my home network, as is the case for any consumer-oriented&amp;nbsp;devices.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve also received some questions about the Linux support for Amcrest cameras. My experience so far has been consistent with my &lt;a href="/2018/05/amcrest-ip-camera-first-impressions/"&gt;Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt; Camera First Impressions - Jason Antman&amp;#8217;s Blog&lt;/a&gt;. The cameras certainly work fine under Linux in general; they can be fully controlled and configured via any browser and you can view the low-resolution &lt;span class="caps"&gt;MJPEG&lt;/span&gt; stream in any browser. Viewing the full-resolution &lt;span class="caps"&gt;RTSP&lt;/span&gt; stream requires either the Amcrest Web View Chrome app or a viewer that supports &lt;span class="caps"&gt;RTSP&lt;/span&gt; streams (&lt;span class="caps"&gt;VLC&lt;/span&gt; or any common surveillance camera software). Aside from watching the stream in &lt;span class="caps"&gt;VLC&lt;/span&gt; or Amcrest Web View while I was outside aiming the camera, I&amp;#8217;ve been using either the low-res &lt;span class="caps"&gt;MJPEG&lt;/span&gt; stream in a browser or, more recently ZoneMinder and HomeAssistant, to view it. Unless you want a closed-source native desktop app, I can&amp;#8217;t find any meaningful difference between how the cameras work on Linux vs Mac or presumably&amp;nbsp;Windows.&lt;/p&gt;
&lt;h3 id="ir-illuminator"&gt;&lt;a class="toclink" href="#ir-illuminator"&gt;&lt;span class="caps"&gt;IR&lt;/span&gt;&amp;nbsp;Illuminator&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;My first step in attempting to reduce false-positive motion detection caused by flying bugs at night was purchasing an external &lt;span class="caps"&gt;IR&lt;/span&gt; illuminator. I opted for a 12V &lt;span class="caps"&gt;DC&lt;/span&gt; model on amazon that uses the same power supply as the camera (I purchased a splitter for them), the
&lt;a href="https://www.amazon.com/gp/product/B01G6EDOO2/"&gt;Univivi 850nm 12 &lt;span class="caps"&gt;LED&lt;/span&gt; Wide Angle &lt;span class="caps"&gt;IR&lt;/span&gt; Illuminator&lt;/a&gt;. It&amp;#8217;s a large-ish unit that looks much like a &lt;span class="caps"&gt;LED&lt;/span&gt; floodlight, except that when on it emits only a barely-visible red glow from the LEDs. This has helped immensely; I have it placed about a foot and a half away from the camera and it has dramatically cut down on (but not eliminated) the number of times that the motion detection is triggered at night by moths and other light-seeking insects. That being said, with some of the advances I&amp;#8217;ve made in other areas (read on) I probably won&amp;#8217;t be replicating this for my other cameras, at least not initially. I &lt;em&gt;will&lt;/em&gt; also remark that the light output from this unit isn&amp;#8217;t wide enough to cover the camera&amp;#8217;s whole field of view, and it does suffer from some definite hot&amp;nbsp;spots.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a view of the camera and &lt;span class="caps"&gt;IR&lt;/span&gt; illuminator during the&amp;nbsp;day:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/ir_illuminator_day.jpg"&gt;&lt;img alt="camera and IR illuminator as installed, during the day" src="/GFX/ir_illuminator_day_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And here&amp;#8217;s a view of it at night. Note that this was taken in almost total darkness and to the human eye the illuminator only emits a barely-visible red glow; unfortunately this photo does more to illustrate how sensitive my phone camera is to &lt;span class="caps"&gt;IR&lt;/span&gt; than what it actually looks&amp;nbsp;like.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/ir_illuminator_night.jpg"&gt;&lt;img alt="camera and IR illuminator at night" src="/GFX/ir_illuminator_night_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="surveillance-software-zoneminder"&gt;&lt;a class="toclink" href="#surveillance-software-zoneminder"&gt;Surveillance Software -&amp;nbsp;ZoneMinder&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When I last posted I&amp;#8217;d done an &lt;a href="/2018/05/linux-surveillance-camera-software-evaluation/"&gt;evaluation&lt;/a&gt; of a number of options for Linux-based video surveillance, discounted ZoneMinder mainly because of its age, resource requirements, and difficulty getting it running in Docker. I ended up settling on the &lt;a href="https://motion-project.github.io/"&gt;Motion Project&lt;/a&gt; (&lt;code&gt;motion&lt;/code&gt;) because of its simplicity and low resource requirements. Unfortunately, that path ended up being a dead&amp;nbsp;end.&lt;/p&gt;
&lt;p&gt;I spent quite a bit of time tuning motion and developing a horribly simple proof-of-concept web interface for it (the defunct project lives at &lt;a href="https://github.com/jantman/motion-pipeline"&gt;https://github.com/jantman/motion-pipeline&lt;/a&gt; if anyone is interested) and playing with masks and various values to get reliable motion detection at 1920x1080 10fps on a RaspberryPi 3B+. While I eventually got that working including notifications with images, it failed completely when I installed the camera in its final environment - the exterior of my house. No matter how hard I tried, I couldn&amp;#8217;t get the motion detection to capture legitimate events but ignore the large amounts of shadow motion when wind caught the trees around my house. I hadn&amp;#8217;t considered this relatively obvious issue when I did my initial tests at my former (and relatively tree-free) apartment complex. It&amp;#8217;s also worth noting that when running motion detection at 1920x1080 10fps, the RaspberryPi 3B+ was essentially at its limits; if I wanted to add another camera of equal resolution and frame rate I&amp;#8217;d need a Pi per&amp;nbsp;camera.&lt;/p&gt;
&lt;p&gt;After that non-starter I remembered that the motion detection algorithm in &lt;code&gt;motion&lt;/code&gt; only takes luminance into account (effectively a black-and-white image) but ZoneMinder uses full color in its motion detection. So, I decided to take another look at ZoneMinder. After some initial hiccups I decided to just install the &lt;code&gt;zoneminder&lt;/code&gt; package on the RaspberryPi 3B+ running Debian 9. After a bit of setup, I had it running and processing 1920x1080 10fps on the Pi. This taxed the system quite a bit and the web &lt;span class="caps"&gt;UI&lt;/span&gt; was almost unusably sluggish, but it was enough for me to get &lt;span class="caps"&gt;ZM&lt;/span&gt; up and running and to prove that its motion detection algorithm handles clouds and shadows &lt;em&gt;much&lt;/em&gt; better than &lt;code&gt;motion&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It was apparent that if I wanted to make use of &lt;span class="caps"&gt;ZM&lt;/span&gt; with multiple cameras and also have it be useful and reliable, I needed significantly better hardware than the RaspberryPi. After some searching on Amazon, I found a &lt;a href="https://www.amazon.com/gp/product/B01KWP82CK/"&gt;refurbished &lt;span class="caps"&gt;HP&lt;/span&gt; Elite 8200 small-form-factor desktop&lt;/a&gt; on Amazon for $300. It was quite a bit more money than I&amp;#8217;d wanted to put into this system, but with an Intel Core i7-2600 with four cores (plus hyper-threading) at 3.4GHz, &lt;span class="caps"&gt;16GB&lt;/span&gt; memory and a &lt;span class="caps"&gt;2TB&lt;/span&gt; spinning disk, I figured it would be more than adequate for four or more cameras (in fact the specs are shockingly close to my desktop computer, which was quite beefy when I built it three or four years&amp;nbsp;ago).&lt;/p&gt;
&lt;p&gt;That machine arrived two weeks ago and I installed Debian 9 on it along with the official ZoneMinder package, and it&amp;#8217;s performing amazingly well. With one camera at 1920x1080 10fps in monitor mode and another at 1280x960 10fps in motion detection (Modect) mode, the system barely breaks a sweat with half of its memory free and half or three-quarters of the &lt;span class="caps"&gt;CPU&lt;/span&gt; cores idle. &lt;span class="caps"&gt;ZM&lt;/span&gt; is performing exceedingly well, with the web &lt;span class="caps"&gt;UI&lt;/span&gt; fast and streaming working very well. I&amp;#8217;m still having some false positives from shadows when it gets very windy, but I have a plan for addressing that as well. Overall I&amp;#8217;m really glad I switched to ZoneMinder with decent hardware, and plan on further improving and expanding this set-up in the&amp;nbsp;future.&lt;/p&gt;
&lt;h3 id="notifications"&gt;&lt;a class="toclink" href="#notifications"&gt;Notifications&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;One thing that ZoneMinder completely lacks is the built-in ability to notify immediately on new events/alarms. The closest that it has are &amp;#8220;filters&amp;#8221;, which run at a configurable interval (usually 60 seconds) and can be set to send email or execute an external command for new alarms. Unfortunately there are some issues around how they&amp;#8217;re configured that result in either notification storms or severe delays when multiple short events happen in rapid succession. After using this method for a few days and researching other possibilities, I found the &lt;a href="https://github.com/pliablepixels/zmeventserver"&gt;zmeventserver&lt;/a&gt; project, a daemon written in Perl that polls the ZoneMinder shared memory map for new events at a short interval and pushes them to clients via a websocket server. After some initial experimentation, I unashamedly hacked up the Perl source, ripped out the websocket server, and modified it to execute a shell command with the event &lt;span class="caps"&gt;ID&lt;/span&gt; as an argument (backgrounded with &lt;code&gt;&amp;amp;&lt;/code&gt; so as not to tie up the Perl&amp;nbsp;code).&lt;/p&gt;
&lt;p&gt;For my event handler script I wrote something in Python that grabs the details of the event directly from ZoneMinder&amp;#8217;s database, along with the first and best (most motion) frames, and sends them to me via email and Pushover. I&amp;#8217;ve added a bit more to the script but it&amp;#8217;s still quite a hack-ish proof-of-concept and too rough to share, but there&amp;#8217;s really nothing terribly complicated about it: it gets called with ZoneMinder&amp;#8217;s EventId, looks up that event and a bunch of related stuff in the database, and then generates an email and Pushover notification. I&amp;#8217;m not sure if I&amp;#8217;m going to keep using this or try to push most of the logic into HomeAssistant (see below); if I do stick with this script, I&amp;#8217;ll make an effort to clean it up and publish the&amp;nbsp;code.&lt;/p&gt;
&lt;h3 id="image-processing-ir-switch-detection"&gt;&lt;a class="toclink" href="#image-processing-ir-switch-detection"&gt;Image Processing - &lt;span class="caps"&gt;IR&lt;/span&gt; Switch&amp;nbsp;Detection&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once I got ZoneMinder relatively well tuned for motion detection in my environment and notifications up and running, my first bit of intelligence in the alerting process was disregarding events when the camera switched from visible light to infra-red mode. This &lt;span class="caps"&gt;IR&lt;/span&gt; switch occurs twice a day - visible to &lt;span class="caps"&gt;IR&lt;/span&gt; around dusk and &lt;span class="caps"&gt;IR&lt;/span&gt; to visible around dawn - and was a bit of an annoyance to me. When the switch-over happens, virtually all pixels in the image go white for a frame or two and the image switches between color and black and white. My gut reaction was to ignore events with a massive percentage of changed pixels around dawn or dusk, but that seemed too uncertain. With a bit of thought, I realized that detecting a change from color to black-and-white (or vice-versa) should be rather&amp;nbsp;straightforward.&lt;/p&gt;
&lt;p&gt;As the script was already written in Python, I installed &lt;a href="https://pillow.readthedocs.io/"&gt;pillow&lt;/a&gt;, a modern fork of the Python Imaging Library, and came up with the following snippet to tell whether a specific Frame from ZoneMinder is color or black-and-white (note this is a partial snippet with a lot of unrelated code&amp;nbsp;removed):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;&lt;span class="caps"&gt;PIL&lt;/span&gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="c1"&gt;# lots of internals redacted here...&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frame_fmt&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FrameId&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;is_color&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Finding if image is color or not for &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;bands&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;histos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;histogram&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;bands&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;histos&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;histos&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Loading image for &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; from: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_image&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This loads the &lt;span class="caps"&gt;JPEG&lt;/span&gt; image (frame) from ZoneMinder as a &lt;span class="caps"&gt;PIL&lt;/span&gt; &lt;code&gt;Image&lt;/code&gt;, splits the image
into its color-component bands (red, green, and blue), and then checks if the histograms
of the three color bands are identical. If so, the image is&amp;nbsp;black-and-white.&lt;/p&gt;
&lt;p&gt;My notification script simply looks at each event, checks if the first frame is color
and the last is black and white or vice-versa, and if so suppresses the notification
and renames the Event in ZoneMinder for later&amp;nbsp;cleanup.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;There is one issue with this method,&lt;/strong&gt; when ZoneMinder loses signal from a camera it
generates a completely blue frame until signal is regained. I&amp;#8217;ve only had this happen
once, but at some point I plan on modifying the above to ignore the blue &amp;#8220;loss of signal&amp;#8221;&amp;nbsp;frames.&lt;/p&gt;
&lt;h3 id="monitoring"&gt;&lt;a class="toclink" href="#monitoring"&gt;Monitoring&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;At this point I decided that I was sufficiently close to having a minimally-usable system that
I should turn my attention to monitoring it, and making sure I&amp;#8217;m alerted if it stops working.
Since I&amp;#8217;ve moved all of my personal services to &lt;span class="caps"&gt;AWS&lt;/span&gt;, I didn&amp;#8217;t have an existing monitoring
infrastructure for anything running in my home. Not wanting anything too heavy-weight or
complicated, and having an existing Lambda function to handle re-notification of CloudWatch
alarms, I hacked a &amp;#8220;monitoring system&amp;#8221; together using that Lambda function and &lt;span class="caps"&gt;API&lt;/span&gt; Gateway
in a few&amp;nbsp;hours.&lt;/p&gt;
&lt;p&gt;The functionality is relatively simple: every five minutes a Python script runs on my ZoneMinder
system that does a bunch of checks and &lt;span class="caps"&gt;POSTS&lt;/span&gt; them to &lt;span class="caps"&gt;API&lt;/span&gt; Gateway as a &lt;span class="caps"&gt;JSON&lt;/span&gt; array of results. The
POSTed data for each check includes the timestamp, a check name, a boolean &lt;code&gt;is_ok&lt;/code&gt; field, and
an optional string with additional information. &lt;span class="caps"&gt;API&lt;/span&gt; Gateway writes this information to DynamoDB,
and triggers a Lambda function if any of the &lt;code&gt;is_ok&lt;/code&gt; fields changed from true to false. The
Lambda is also run every 30 minutes, and notifies me via email or text message if any of the
check &lt;code&gt;is_ok&lt;/code&gt; fields is False &lt;em&gt;or&lt;/em&gt; if any of the timestamp values are more than 10 minutes old.
For now, this should suffice as a really simple monitoring system. I also have a quick and simple
single-page web view of the current Dynamo&amp;nbsp;contents.&lt;/p&gt;
&lt;p&gt;The checks that I&amp;#8217;m currently running&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;System load average&lt;sup&gt;1&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Disk free space as reported by&amp;nbsp;ZoneMinder&lt;/li&gt;
&lt;li&gt;ZoneMinder daemon status as reported by&amp;nbsp;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;ZoneMinder Run State (one of my custom values, not&amp;nbsp;&amp;#8220;stopped&amp;#8221;)&lt;/li&gt;
&lt;li&gt;ZoneMinder &lt;span class="caps"&gt;SHM&lt;/span&gt;&amp;nbsp;free&lt;/li&gt;
&lt;li&gt;ZoneMinder status as reported by &lt;code&gt;zmpkg.pl&lt;/code&gt; (&amp;#8220;running&amp;#8221;)&lt;/li&gt;
&lt;li&gt;ZoneMinder &lt;span class="caps"&gt;UI&lt;/span&gt; - page loads and has a link to my primary&amp;nbsp;camera&lt;/li&gt;
&lt;li&gt;zmdc process&amp;nbsp;running&lt;/li&gt;
&lt;li&gt;zmwatch process&amp;nbsp;running&lt;/li&gt;
&lt;li&gt;My custom event server process running (based on zmeventnotification.pl; see&amp;nbsp;above)&lt;/li&gt;
&lt;li&gt;For each&amp;nbsp;camera:&lt;/li&gt;
&lt;li&gt;Direct image check against the Amcrest&amp;nbsp;camera&lt;/li&gt;
&lt;li&gt;Camera&amp;nbsp;enabled&lt;/li&gt;
&lt;li&gt;Image check via&amp;nbsp;ZoneMinder&lt;/li&gt;
&lt;li&gt;zmu frame&amp;nbsp;rate&lt;/li&gt;
&lt;li&gt;zmu last frame&amp;nbsp;time&lt;/li&gt;
&lt;li&gt;zmc process&amp;nbsp;running&lt;/li&gt;
&lt;li&gt;zma process running if Monitor is set to a motion-detecting&amp;nbsp;state&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the &amp;#8220;Image check&amp;#8221; tests, I do the&amp;nbsp;following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Retrieve the binary image from the camera or&amp;nbsp;&lt;span class="caps"&gt;ZM&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Use the python &lt;code&gt;imghdr.what()&lt;/code&gt; function to ensure it&amp;#8217;s a &lt;span class="caps"&gt;JPEG&lt;/span&gt;&amp;nbsp;image&lt;/li&gt;
&lt;li&gt;Ensure that the size of the image matches what &lt;span class="caps"&gt;ZM&lt;/span&gt; thinks the monitor size&amp;nbsp;is&lt;/li&gt;
&lt;li&gt;Use the &lt;span class="caps"&gt;PIL&lt;/span&gt; &lt;code&gt;getextrema()&lt;/code&gt; function to ensure that there&amp;#8217;s more than one color in the image (i.e. fail if it&amp;#8217;s an all-blue &amp;#8220;signal lost&amp;#8221; or an all-black&amp;nbsp;image).&lt;/li&gt;
&lt;li&gt;Ensure that the histogram of the image has more than 20 distinct buckets / pixel&amp;nbsp;values.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; I&amp;#8217;ve usually found Load Average to be an often misunderstood metric, and one that people rely on much too often (generally without knowing enough about it). ZoneMinder exposes it prominently in the &lt;span class="caps"&gt;UI&lt;/span&gt; as one of the three health metrics, and while I&amp;#8217;m not sure I agree with this, it &lt;em&gt;is&lt;/em&gt; a good metric for the specific workload of this particular system of mine. If you&amp;#8217;d like to learn more about Load Average as a performance metric on modern Linux systems, system performance expert and current Senior Performance Architect at Netflix Brendan Gregg has an excellent blog post, &lt;a href="http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html"&gt;Linux Load Averages: Solving the Mystery&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="neural-network-object-detection"&gt;&lt;a class="toclink" href="#neural-network-object-detection"&gt;Neural Network Object&amp;nbsp;Detection&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When I was researching how other ZoneMinder users are attempting to reduce false positives, I came by a &lt;a href="https://forums.zoneminder.com/viewtopic.php?f=36&amp;amp;t=26222"&gt;post on the ZoneMinder Forums&lt;/a&gt; from someone who is using &lt;a href="https://pjreddie.com/darknet/yolo/"&gt;Joseph Redmon&amp;#8217;s Darknet yolo3&lt;/a&gt; neutral network object detection implementation for detecting and localizing meaningful changes in ZoneMinder&amp;#8217;s captured frames. This idea immediately appealed to me; if I could reliably tell whether a frame contains a person, for my purposes as a security system, that would completely solve the environmental false positive problem. I was also very interested in Darknet yolo3 as it is simple to build and distributes pre-trained models - my initial testing was as simple as cloning a repo, downloading a few files, running &lt;code&gt;make&lt;/code&gt;, and then running the included command-line script on a &lt;span class="caps"&gt;JPEG&lt;/span&gt; image. I was pretty amazed at how accurately it recognized the person, car, and dogs in the image I selected. There is also a Python wrapper around yolo3, &lt;a href="https://github.com/madhawav/YOLO3-4-Py"&gt;yolo34py&lt;/a&gt;, which I found quite easy to&amp;nbsp;use.&lt;/p&gt;
&lt;p&gt;Using yolo34py I was able to relatively quickly add object detection to my Python-based ZoneMinder event notification script. Over three or four days of testing, I found yolo3 using the pre-trained model to be &lt;em&gt;extremely&lt;/em&gt; accurate across all of the events my camera captured. The one down side was that, running on my Intel i7-2600 at 3.4GHz, it was taking a full &lt;em&gt;ten to fifteen seconds per frame&lt;/em&gt; to run the object detection. That&amp;#8217;s fine for testing, but if I were to rely on this as an alarm system, I&amp;#8217;d want something considerably&amp;nbsp;faster.&lt;/p&gt;
&lt;p&gt;A cursory glance at the Darknet documentation told me what I already knew - though I have no prior experience with the subject - that running neural network image processing with any reasonable speed requires a &lt;span class="caps"&gt;GPU&lt;/span&gt;. I decided that I could allocate around $100 to speeding up the detection given the Darknet documentation&amp;#8217;s claim of a 10x or better speedup on a &lt;span class="caps"&gt;GPU&lt;/span&gt;. I found that about the best $100 &lt;span class="caps"&gt;GPU&lt;/span&gt; I could get on Amazon was a &lt;span class="caps"&gt;1GB&lt;/span&gt; Nvidia Quadro K600, so I purchased &lt;a href="https://www.amazon.com/gp/product/B00BLTE8HK/"&gt;this&lt;/a&gt; &lt;span class="caps"&gt;PNY&lt;/span&gt;&amp;nbsp;card.&lt;/p&gt;
&lt;p&gt;When I got the card and requisite software installed and recompiled Darknet with &lt;span class="caps"&gt;CUDA&lt;/span&gt; support and attempted to run detection on an image, I was rather dismayed to be greeted with an error&amp;nbsp;message:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;0 &lt;span class="caps"&gt;CUDA&lt;/span&gt; Error: out of&amp;nbsp;memory&lt;/p&gt;
&lt;p&gt;darknet: ./src/cuda.c:36: check_error: Assertion &lt;code&gt;0&lt;/code&gt; failed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Unfortunately, after just googling that error for Darknet, I found quite a few GitHub issues and mailing list threads explaining that Darknet Yolo3&amp;#8217;s default (and most accurate) model requires about 3.&lt;span class="caps"&gt;6GB&lt;/span&gt; of &lt;span class="caps"&gt;GPU&lt;/span&gt; memory, far too much for my &lt;span class="caps"&gt;1GB&lt;/span&gt; card (at the moment, &lt;span class="caps"&gt;4GB&lt;/span&gt; GPUs start at&amp;nbsp;$&lt;span class="caps"&gt;500USD&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Luckily for the fate of my project, Darknet also has a pre-trained &amp;#8220;tiny&amp;#8221; model designed to work for low-memory GPUs - like the apparently-puny one I just bought. The project states that its accuracy is only about 2-3% lower, though the results I&amp;#8217;ve seen are noticeably inferior especially when two objects are in close proximity or overlap. For the time being, I&amp;#8217;m still getting notified by my Python script for every motion detection event, along with the &lt;span class="caps"&gt;YOLO&lt;/span&gt; object detection results. I&amp;#8217;m saving every event that has questionable results for later comparison against the full (albeit slow, running on &lt;span class="caps"&gt;CPU&lt;/span&gt;) model and possibly other object detection&amp;nbsp;tools.&lt;/p&gt;
&lt;h2 id="homeassistant-and-z-wave"&gt;&lt;a class="toclink" href="#homeassistant-and-z-wave"&gt;HomeAssistant and&amp;nbsp;Z-Wave&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Just before I began experimenting with Darknet object detection, I decided that the number of false positive motion detection events I was receiving merited investigation into a more classic alarm system approach. I also received a coupon for the &lt;a href="https://simplisafe.com/"&gt;SimpliSafe&lt;/a&gt; home security system in my address change packet from the &lt;span class="caps"&gt;USPS&lt;/span&gt;. After a fair amount of investigation I decided that there weren&amp;#8217;t any off-the-shelf wireless home alarm systems that seemed attractive to me (I don&amp;#8217;t really need central monitoring, but I do need to be able to access the system and status programmatically) but this did get me doing some research, and I found there is a wide array of alarm system components using the &lt;a href="http://www.z-wave.com/"&gt;Z-Wave&lt;/a&gt; radio technology that seemed suitable for a &lt;span class="caps"&gt;DIY&lt;/span&gt;&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;One of my colleagues speaks quite highly of &lt;a href="https://www.home-assistant.io/"&gt;HomeAssistant&lt;/a&gt;, an open source (though Apache licensed) home automation suite written in Python3. Browsing through the project&amp;#8217;s website and documentation, I became reasonably confident that it could handle my needs for an alarm system (it has a fair amount of built-in logic for this use case, and other people actively use it for this) and that it also integrates natively with Z-Wave. Even better, it also has a native integration with ZoneMinder to tie the two systems&amp;nbsp;together.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m really, &lt;em&gt;really&lt;/em&gt; liking HomeAssistant so far, but I&amp;#8217;ll leave the details of that for a future&amp;nbsp;post.&lt;/p&gt;
&lt;h3 id="doorwindow-and-motion-sensors"&gt;&lt;a class="toclink" href="#doorwindow-and-motion-sensors"&gt;Door/Window and Motion&amp;nbsp;Sensors&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After a bit of research, I determined that I wanted Z-Wave Plus components for their better (than none) security and advanced features and purchased some initial Z-Wave components to test from Amazon: a &lt;span class="caps"&gt;USB&lt;/span&gt; &lt;a href="https://www.amazon.com/gp/product/B00X0AWA6E/"&gt;Aeotec Gen5 Z-Stick&lt;/a&gt; Z-Wave controller for $45, an &lt;a href="https://www.amazon.com/gp/product/B01N5HB4U5/"&gt;Ecolink Z-Wave Plus magnetic Door/Window sensor&lt;/a&gt; for $30, and an &lt;a href="https://www.amazon.com/gp/product/B01MQXXG0I/"&gt;Ecolink Z-Wave Plus &lt;span class="caps"&gt;PIR&lt;/span&gt; Motion Sensor&lt;/a&gt; for $40. I figured that was a reasonable enough price to test the system and determine how well it works, and either move forward or return the&amp;nbsp;items.&lt;/p&gt;
&lt;p&gt;So far I&amp;#8217;ve had the Z-Wave components running via HomeAssistant for seven days, with the door sensor on my front door and the motion sensor placed atop the adjacent window. I&amp;#8217;ve configured HomeAssistant to do nothing more than notify me via Pushover when the door opens or motion is sensed. So far in a week, I&amp;#8217;ve received zero false-positive alarms and zero false-negative alarms, so I&amp;#8217;m quite happy. The motion or door opening signals make it from the sensors to HomeAssistant, out to Pushover, and to my phone within one to three seconds, which seems quite reasonable to me. The &amp;#8220;pet immunity&amp;#8221; on the motion sensor &lt;em&gt;is&lt;/em&gt; still triggered by my two dogs walking around, but that&amp;#8217;s rather expected since they&amp;#8217;re fifty-five and seventy pounds, respectively, and not a problem since they&amp;#8217;re crated whenever I&amp;#8217;m not home. I&amp;#8217;m quite happy with the performance of both of these sensors so&amp;nbsp;far.&lt;/p&gt;
&lt;h3 id="thermostat"&gt;&lt;a class="toclink" href="#thermostat"&gt;Thermostat&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Last weekend, after unpacking and enabling my two &lt;a href="https://github.com/jantman/pi2graphite"&gt;RaspberryPi-to-Graphite temperature sensors&lt;/a&gt;, I finally determined that I&amp;#8217;m not going crazy but the thermostat in my house was. It was wildly inaccurate, and letting the house overheat during the day and then over-cooling at night. I knew I had to replace it and, having seen that HomeAssistant supports climate control systems, immediately remembered my dream of having a computer-controlled thermostat that I briefly &lt;a href="https://github.com/jantman/RPyMostat"&gt;explored&lt;/a&gt; since I first built a &lt;a href="https://github.com/jantman/tuxostat"&gt;crude solution&lt;/a&gt; back &lt;a href="http://blog.jasonantman.com/2008/06/new-project/"&gt;in 2008&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After a short search on Amazon, I found the &lt;a href="https://www.amazon.com/gp/product/B0095P7B80/"&gt;Iris &lt;span class="caps"&gt;CT&lt;/span&gt;-101 Z-Wave thermostat&lt;/a&gt;. It&amp;#8217;s a touchscreen 7-day programmable thermostat with Z-Wave, essentially the same unit as the &lt;a href="http://www.radiothermostat.com/products/"&gt;Radio Thermostat &lt;span class="caps"&gt;CT&lt;/span&gt;-101&lt;/a&gt; but intended to work with the Lowes Iris home automation system. A number of the positive reviews mentioned it working with HomeAssistant or other F/&lt;span class="caps"&gt;OSS&lt;/span&gt; home automation systems, and the $40 price was well below most networked thermostats and about the same as a normal &amp;#8220;dumb&amp;#8221; 7-day thermostat at local&amp;nbsp;stores.&lt;/p&gt;
&lt;p&gt;So far I&amp;#8217;m quite happy with it. I had some initial concerns - even though the device is constantly powered and even a Z-Wave repeater, I had to configure HomeAssistant to explicitly poll it on a regular interval for up-to-date information - but now that I&amp;#8217;ve figured it out, the thermostat seems to be working quite well. I can view the current and target temperatures, the operational/power status of my &lt;span class="caps"&gt;HVAC&lt;/span&gt; system&amp;#8217;s fan and compressor, and set the target temperature and on/off controls. The unit &lt;em&gt;does&lt;/em&gt; show up as two separate controls - heating and cooling - but that seems to be the standard for Z-Wave climate controls and logically matches up with the physical thermostat&amp;#8217;s &amp;#8220;heat/off/cool&amp;#8221; controls. I haven&amp;#8217;t done any automation with it yet, but at a minimum this should make it easy for me to control heating and cooling based on different temperature sensors throughout the house at different times of&amp;nbsp;day.&lt;/p&gt;
&lt;h2 id="whats-next"&gt;&lt;a class="toclink" href="#whats-next"&gt;What&amp;#8217;s&amp;nbsp;Next&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This past weekend I purchased two more outdoor Amcrest WiFi cameras - this time the &lt;a href="https://amcrest.com/amcrest-prohd-outdoor-1080p-wifi-wireless-ip-security-bullet-camera-ip67-weatherproof-1080p-1920tvl-ip2m-852w-white.html"&gt;&lt;span class="caps"&gt;IP2M&lt;/span&gt;-852W&lt;/a&gt; 1080P models with an impressive 128º field of view - to complete my camera coverage, as well as a few more of the same &lt;a href="https://www.amazon.com/gp/product/B01N5HB4U5/"&gt;Z-Wave door/window sensors&lt;/a&gt;, a pair of Z-Wave lightbulbs to try, and some well-reviewed &lt;a href="https://www.amazon.com/gp/product/B01AKSO80O/"&gt;&lt;span class="caps"&gt;ZOOZ&lt;/span&gt; Z-Wave 4-in-1 sensors&lt;/a&gt; that combine motion sensors with light level, temperature, and humidity. Over the next week or two I&amp;#8217;ll be installing all of that to finally finish the system, and also spending quite a bit of time customizing HomeAssistant to be the heart of it all. I&amp;#8217;ll share my experiences in follow-up posts, but some of the things I have planned&amp;nbsp;include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Experimenting with some other machine-learning-based object detection&amp;nbsp;implementations&lt;/li&gt;
&lt;li&gt;Localizing detected objects to a ZoneMinder zone in the image, and using that to determine whether to alarm or&amp;nbsp;not&lt;/li&gt;
&lt;li&gt;Modifying the ZoneMinder HomeAssistant integration to know about run&amp;nbsp;states&lt;/li&gt;
&lt;li&gt;Using HomeAssistant&amp;#8217;s alarm control panel component to implement real alarm system logic, with notifications to my&amp;nbsp;phone&lt;/li&gt;
&lt;li&gt;Having my Amcrest ProHD pan/tilt camera, which has clear line of sight to both front and back doors, pan to a door and capture a snapshot when the door sensor&amp;nbsp;activates.&lt;/li&gt;
&lt;/ul&gt;</content><category term="amcrest"></category><category term="camera"></category><category term="security"></category><category term="surveillance"></category><category term="video"></category><category term="linux"></category><category term="IP camera"></category><category term="evaluation"></category><category term="alarm"></category><category term="IR"></category><category term="homeassistant"></category><category term="hass"></category><category term="automation"></category><category term="z-wave"></category><category term="darknet"></category><category term="yolo"></category><category term="machine learning"></category><category term="neural network"></category><category term="object detection"></category></entry><entry><title>Linux Surveillance Camera Software Evaluation</title><link href="https://blog.jasonantman.com/2018/05/linux-surveillance-camera-software-evaluation/" rel="alternate"></link><published>2018-05-12T07:18:00-04:00</published><updated>2018-05-12T07:18:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-05-12:/2018/05/linux-surveillance-camera-software-evaluation/</id><summary type="html">&lt;p&gt;My evaluation of some options for streaming and motion-activated recording of &lt;span class="caps"&gt;IP&lt;/span&gt;&amp;nbsp;cameras.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#initial-requirements"&gt;Initial&amp;nbsp;Requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#contenders"&gt;Contenders&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#zoneminder"&gt;ZoneMinder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#kerberosio"&gt;Kerberos.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#shinobi"&gt;Shinobi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#motion"&gt;Motion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#final-choice"&gt;Final&amp;nbsp;Choice&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="alert alert-warning" role="alert"&gt;&lt;strong&gt;Notice/Disclaimer:&lt;/strong&gt; The information I provide on home automation/security and surveillance is based on what I&amp;#8217;ve set up for myself based on a balance of cost, ease of use, and security, and should be considered for hobby purposes only. My current system and code has grown organically over time and is not how I&amp;#8217;d approach this if I started over from scratch. My code and system has a few obvious vulnerabilities and probably some non-obvious ones as well; I humbly but sincerely ask that you do not attempt to exploit these. I highly recommend that anyone implementing a similar system - especially if you also publish the details of it - have undocumented backup systems/devices. Finally, the systems that I describe are intended to provide some protection against or notification of crimes of opportunity, not targeted attacks. Please keep in mind that none of this is intended to protect against someone who targets &lt;em&gt;me&lt;/em&gt; specifically (and takes the time to research me) as opposed to my home at random.&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; The next post in this series is up, &lt;a href="/2018/07/ip-camera-home-security-and-automation-update"&gt;&lt;span class="caps"&gt;IP&lt;/span&gt; Camera, Home Security and Automation Update&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In my last post, &lt;a href="/2018/05/amcrest-ip-camera-first-impressions/"&gt;Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt; Camera First Impressions&lt;/a&gt;, I went over what I&amp;#8217;d found about the pair of &lt;span class="caps"&gt;IP&lt;/span&gt; cameras that I bought to keep an eye on my dogs and my new house. My next step was to figure out how I&amp;#8217;d handle motion-activated recording, and that&amp;#8217;s what I&amp;#8217;ll discuss this time. I&amp;#8217;ve spent all of my spare time in the past week - probably twenty to thirty hours - researching and experimenting and the results have actually been quite&amp;nbsp;surprising.&lt;/p&gt;
&lt;h2 id="initial-requirements"&gt;&lt;a class="toclink" href="#initial-requirements"&gt;Initial&amp;nbsp;Requirements&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The initial requirements that I identified&amp;nbsp;were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open source (preferably &lt;span class="caps"&gt;GPL&lt;/span&gt;) and runs on&amp;nbsp;Linux&lt;/li&gt;
&lt;li&gt;Must be able to run with low-end hardware - either a Raspberry Pi or another small and inexpensive system (I don&amp;#8217;t want this to depend on my desktop, and I don&amp;#8217;t want to invest a lot in&amp;nbsp;it)&lt;/li&gt;
&lt;li&gt;Support multiple cameras - at least two, ideally four or&amp;nbsp;six&lt;/li&gt;
&lt;li&gt;Works behind a &lt;span class="caps"&gt;HTTP&lt;/span&gt; reverse proxy, such as nginx with certificate&amp;nbsp;auth&lt;/li&gt;
&lt;li&gt;Can stream live via the &lt;span class="caps"&gt;UI&lt;/span&gt;, ideally full resolution with low&amp;nbsp;latency&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PTZ&lt;/span&gt; (pan/tilt/zoom) control from the&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;List, search and playback videos from the&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Decent mobile support, either via built-in web &lt;span class="caps"&gt;UI&lt;/span&gt; or native&amp;nbsp;app&lt;/li&gt;
&lt;li&gt;Motion detection to trigger recording and notifications/scripts; configurable post-motion recording time; prerecord&amp;nbsp;buffer&lt;/li&gt;
&lt;li&gt;On-demand manual recording (ideally via both &lt;span class="caps"&gt;UI&lt;/span&gt; and&amp;nbsp;script/&lt;span class="caps"&gt;API&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;Ability to disable motion activation/recording via script or&amp;nbsp;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Detect loss of video/tamper and trigger&amp;nbsp;notification&lt;/li&gt;
&lt;li&gt;Detect loss of camera (on network) and trigger&amp;nbsp;notification&lt;/li&gt;
&lt;li&gt;Relatively straightforward monitoring (i.e. I should get a text message if the system goes down or stops working&amp;nbsp;correctly)&lt;/li&gt;
&lt;li&gt;Bonuses:&lt;/li&gt;
&lt;li&gt;Runs in Docker, even if not officially&amp;nbsp;supported&lt;/li&gt;
&lt;li&gt;Written in a language I have some experience in (which essentially means Python, Ruby, or maybe (maaaaybe)&amp;nbsp;NodeJS)&lt;/li&gt;
&lt;li&gt;Only uses&amp;nbsp;&lt;span class="caps"&gt;HTTP&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Nice multi-camera&amp;nbsp;view&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="contenders"&gt;&lt;a class="toclink" href="#contenders"&gt;Contenders&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Right away I knew two of the projects I wanted to look at: &lt;a href="https://zoneminder.com/"&gt;ZoneMinder&lt;/a&gt;, which I&amp;#8217;ve heard many people mention and seems to be the de-facto standard in open-source video surveillance, and &lt;a href="https://motion-project.github.io/"&gt;Motion&lt;/a&gt; which I&amp;#8217;ve used before and only knew as a limited and somewhat archaic daemon. After some investigation and reading of feature lists, I came up with two other, much newer, contenders in &lt;a href="https://shinobi.video/"&gt;Shinobi&lt;/a&gt; and &lt;a href="https://www.kerberos.io/"&gt;Kerberos.io&lt;/a&gt;. I saw a few other possibilities online, but they didn&amp;#8217;t fit the above&amp;nbsp;criteria.&lt;/p&gt;
&lt;p&gt;I did all of my initial tests in Docker since I was testing each of these on my main computer and didn&amp;#8217;t want to clutter up the system, and I also &lt;em&gt;really&lt;/em&gt; like using Docker for testing and deployment of software. That may be unfair for some of them, but it&amp;#8217;s both how I intend on deploying the final choice and my preferred deployment strategy lately in general. I can&amp;#8217;t say that I dove deep into all, or even any, of these options but I gave each of them at least four hours (and quite more than that for some of them) of experimentation. I expect to be able to get something at least minimally working within that amount of&amp;nbsp;time.&lt;/p&gt;
&lt;h3 id="zoneminder"&gt;&lt;a class="toclink" href="#zoneminder"&gt;ZoneMinder&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://zoneminder.com/"&gt;ZoneMinder&lt;/a&gt; seems to be what everyone talks about when the topic of Linux-based open source surveillance software comes up. It&amp;#8217;s an incredibly mature and long-lived project - first released in 2002 - and for a long time seems to have been the only option. It&amp;#8217;s probably most famous for allowing the user to select various &amp;#8220;zones&amp;#8221; (regions of the image) with different motion detection sensitivity levels, including completely ignoring certain areas. When I started actually looking into it, though, my expectations decreased significantly. During my testing the first problem I found was that, while Docker is now a &lt;a href="https://zoneminder.readthedocs.io/en/latest/installationguide/packpack.html"&gt;recommended installation method&lt;/a&gt;, all of the &lt;a href="https://github.com/ZoneMinder/zmdockerfiles"&gt;official Dockerfiles&lt;/a&gt; and most of the others that I could find run it in a single super-container with &lt;em&gt;every&lt;/em&gt; process, including MySQL and all of the web tier (which ends up being 20-something processes). This is extremely un-Docker-like, and horribly inefficient for me since my test system (my desktop) already runs MariaDB for a number of other applications. The official Dockerfiles are also based on a full and bloated &lt;code&gt;centos:7&lt;/code&gt; image (73 &lt;span class="caps"&gt;MB&lt;/span&gt; just for the base image). Lastly, and most shocking to me, while Docker is an officially-supported installation method the project doesn&amp;#8217;t actually distribute Docker images. While ZoneMinder has packages for Ubuntu, &lt;span class="caps"&gt;RHEL&lt;/span&gt;, Debian and Gentoo, their Docker-based installation instructions build the image locally which almost completely obviates the entire purpose and idea of Docker as a build-once, run-anywhere packaging&amp;nbsp;format.&lt;/p&gt;
&lt;p&gt;After some investigation, I was able to find &lt;a href="https://github.com/pschmitt/docker-zoneminder"&gt;Philipp Schmitt&amp;#8217;s docker-zoneminder repo&lt;/a&gt; which provides an Alpine 3.4-based ZoneMinder image. Unfortunately it includes MySQL and doesn&amp;#8217;t build anymore (the last commit was two years ago), but I &lt;a href="https://github.com/jantman/docker-zoneminder"&gt;forked the repo&lt;/a&gt; and was able to get it to build and run on the latest Alpine Linux 3.7 with the distro&amp;#8217;s official zoneminder package. That took me a mere three days, which included giving up on Philipp&amp;#8217;s use of lighttpd and switching to Apache httpd 2.4 configured according to ZoneMinder&amp;#8217;s upstream instructions. Let&amp;#8217;s just say that the process was anything but easy. I eventually got ZoneMinder working, but didn&amp;#8217;t even get as far as setting up motion detection. I attempted to tell my &lt;span class="caps"&gt;ONVIF&lt;/span&gt;-compliant Amcrest ProHD camera to pan right using ZoneMinder&amp;#8217;s builtin &lt;span class="caps"&gt;ONVIF&lt;/span&gt; control support, and my entire machine locked up for about an hour (note this is an Arch Linux desktop with a 4-core/8-thread (&lt;span class="caps"&gt;HT&lt;/span&gt;) Intel i7-3770 at 3.4GHz and &lt;span class="caps"&gt;16GB&lt;/span&gt; of &lt;span class="caps"&gt;DDR3&lt;/span&gt; memory). Even before that just watching the live streams of my two cameras (1920x1080 and 1280x960) at 15fps, with motion detection and recording and all other features disabled, would result in them regularly dropping to 1-2 fps for a minute or&amp;nbsp;two.&lt;/p&gt;
&lt;p&gt;After the lockup caused by &lt;span class="caps"&gt;ONVIF&lt;/span&gt; support, I went about setting up resource constraints on memory and &lt;span class="caps"&gt;CPU&lt;/span&gt; usage for the container. That was the final straw; no matter what I set the constraints to, even values far in excess of the maximum of what the container was actually using, ZoneMinder seemed to behave horribly. I tried setting the memory limits to 12G (75% of my system&amp;#8217;s memory, when the container was only using ~&lt;span class="caps"&gt;512MB&lt;/span&gt;) and the &lt;span class="caps"&gt;CPU&lt;/span&gt; limits to a period of 100000 and a limit of 700000 (allowing it to consume 7 of my 8 threads/virtual cores) and it still performed as though ZoneMinder was crippled. Given that my target platform is a Raspberry Pi (3 B+ with 1.4GHz 64-bit quad-core &lt;span class="caps"&gt;ARM&lt;/span&gt; Coretx-A53 and &lt;span class="caps"&gt;1GB&lt;/span&gt; &lt;span class="caps"&gt;LPDDR2&lt;/span&gt; memory), I figured it was time to stop my ZoneMinder experiments. I know people and have heard many positive stories about ZoneMinder, and work with a few people who use it and find it to be great, but I think it&amp;#8217;s just capable of doing too much - and has too high resource requirements - for my&amp;nbsp;needs.&lt;/p&gt;
&lt;p&gt;In the interest of transparency, here are some of the &lt;a href="https://github.com/jantman/docker-zoneminder/blob/master/README.md#current-status"&gt;notes&lt;/a&gt; I wrote down during my attempt at an Alpine-based Docker&amp;nbsp;container:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As a preface, I need to mention that ZoneMinder was first released in 2002. It is a mature, even aged, piece of software. The level of effort that has gone into it is astonishing, and the mere fact that it&amp;#8217;s still an active and well-respected project after 16 years is pretty damn amazing, even more so for an open source project. That being said, two of my main criteria for selecting home security/surveillance software are how stable I think it will be (will it run for weeks/months without me even looking at it, and be working when I need it to) and how easily I can customize it&amp;nbsp;(code).&lt;/li&gt;
&lt;li&gt;ZoneMinder is a &lt;em&gt;giant&lt;/em&gt; codebase made up of Perl, &lt;span class="caps"&gt;PHP&lt;/span&gt;, C++, JavaScript, and probably some others. There are just &lt;em&gt;so&lt;/em&gt; many moving pieces (see the &lt;a href="http://zoneminder.readthedocs.io/en/stable/userguide/components.html"&gt;Components documentation&lt;/a&gt;) that I can&amp;#8217;t really imagine this running reliably without intervention for terribly&amp;nbsp;long.&lt;/li&gt;
&lt;li&gt;As a corollary, when I did finally get this running, the logs (written to the &lt;span class="caps"&gt;DB&lt;/span&gt; and shown in the &lt;span class="caps"&gt;UI&lt;/span&gt;) kept reporting Errors (in red nonetheless) for processes that died and were then respawned by the watchdog without any noticeable effects in the &lt;span class="caps"&gt;UI&lt;/span&gt;/streams. I don&amp;#8217;t want to take on a system that doesn&amp;#8217;t even know the difference between an error and a warning, or that reports errors (with whistles and bells and sirens) to the user that it can self-recover from. I intend on leaving this alone as a security system, and need to be able to reliably tell (and programmatically alert on) whether it&amp;#8217;s &amp;#8220;working&amp;#8221; or &amp;#8220;not working&amp;#8221;. A process dying and being successfully restarted a second later isn&amp;#8217;t what I&amp;#8217;d call an&amp;nbsp;&amp;#8220;error&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Apparently Docker is now &lt;a href="https://github.com/ZoneMinder/ZoneMinder/wiki/Docker"&gt;a recommended install mathod&lt;/a&gt;, but the &lt;a href="https://github.com/ZoneMinder/zmdockerfiles"&gt;official Dockerfiles&lt;/a&gt; (and almost all of the others I&amp;#8217;ve found) are decidedly un-Docker-like, running &lt;em&gt;everything&lt;/em&gt; including both the web and &lt;span class="caps"&gt;DB&lt;/span&gt; tiers in one container. Given how many components make up ZoneMinder, it seems like it would much more naturally be made up of a handful of containers - maybe half a dozen plus a container per&amp;nbsp;camera.&lt;/li&gt;
&lt;li&gt;Even on my main desktop computer - a relatively beefy machine for its day, with a four-core/eight-thread Intel i7-3770 @ 3.4GHz and &lt;span class="caps"&gt;16GB&lt;/span&gt; &lt;span class="caps"&gt;DDR3&lt;/span&gt; - ZoneMinder seemed to be struggling with two &lt;span class="caps"&gt;IP&lt;/span&gt; cameras and I saw occasional framerate drops down to one to two fps. It just seems to be trying to do too&amp;nbsp;much.&lt;/li&gt;
&lt;li&gt;I still think there&amp;#8217;s a ghost in the machine re: docker resource constraints. Once I set &lt;span class="caps"&gt;CPU&lt;/span&gt; or memory limits on the container, even if I set them way (i.e. ten times) above what Docker reports ZoneMinder to be using, &lt;span class="caps"&gt;ZM&lt;/span&gt; behaves differently and starts to have crippling performance&amp;nbsp;issues.&lt;/li&gt;
&lt;li&gt;Bottom line: I do a lot of work with Docker, and automating deployment and monitoring of software has been a big part of my job for the last decade. I need something that&amp;#8217;s simpler, feels more reliable, and is easier to deploy and monitor. Something that logs to &lt;span class="caps"&gt;STDOUT&lt;/span&gt;/&lt;span class="caps"&gt;STDERR&lt;/span&gt;, looks at least something like a 12-factor app, and feels like it can actually run (if not be designed) natively in&amp;nbsp;Docker.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So after three or four incredibly frustrating afternoons and evenings, I put ZoneMinder aside and continued down my evaluation&amp;nbsp;list.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Postscript:&lt;/strong&gt; One of my colleagues, &lt;a href="https://github.com/jbruce12000"&gt;Jason Bruce&lt;/a&gt;, told me that he uses the &lt;a href="https://hub.docker.com/r/aptalca/zoneminder-1.29/"&gt;aptalca/zoneminder-1.29&lt;/a&gt; Docker image to great success. If you&amp;#8217;re considering ZoneMinder, it&amp;#8217;s probably worth trying that image, and it&amp;#8217;s only&amp;nbsp;&lt;span class="caps"&gt;310MB&lt;/span&gt;.&lt;/p&gt;
&lt;h3 id="kerberosio"&gt;&lt;a class="toclink" href="#kerberosio"&gt;Kerberos.io&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The next candidate on my list was &lt;a href="https://www.kerberos.io/"&gt;Kerberos.io&lt;/a&gt;, one of the newcomers that I&amp;#8217;d never heard of before. It&amp;#8217;s billed as a &amp;#8220;free [and open-source] video surveillance solution, which works with any camera and on every Linux based machine. You can deploy a fully configured video surveillance system within a few minutes on the environment you prefer: Raspberry Pi, Orange Pi, Docker, etc.&amp;#8221; So that caught my attention as it seemed to check a lot of the non-functional boxes - Docker, modern, etc. - right in the introductory &amp;#8220;advertising&amp;#8221;. The website also looks clean and modern, and the screenshots and demo look nice. The one negative instantly apparent is that it only supports one camera unless you use the paid and hosted Kerberos.cloud product, but I figured that I could either run the cloud software myself or else hack something together (their &lt;a href="https://doc.kerberos.io/2.0/installation/Multi-camera/Docker"&gt;docs on Multi-Camera Docker&lt;/a&gt; are essentially just how to run multiple instances, one per&amp;nbsp;camera).&lt;/p&gt;
&lt;p&gt;On the positive side, Kerberos.io &lt;em&gt;was&lt;/em&gt; incredibly easy to get running. The &lt;a href="https://doc.kerberos.io/2.0/installation/Docker"&gt;docs&lt;/a&gt; just point to their &lt;a href="https://hub.docker.com/u/kerberos/"&gt;public images on the Docker Hub&lt;/a&gt; and a &lt;a href="https://github.com/kerberos-io/docker"&gt;github repo&lt;/a&gt; with a &lt;code&gt;docker-compose.yml&lt;/code&gt; that runs the appropriate containers (one for the &amp;#8220;machinery&amp;#8221; capture backend and one for the &amp;#8220;web&amp;#8221; frontend), and even has an &lt;span class="caps"&gt;ARM&lt;/span&gt;-specific Dockerfile for Raspberry Pi users. Setup was a complete breeze as the web &lt;span class="caps"&gt;UI&lt;/span&gt; starts out with an installation wizard that walks you through configuring the app. After setting up a user I was able to log in and click the &amp;#8220;Configuration&amp;#8221; button on the top menu bar and configure my camera. It was quite straightforward - just select &amp;#8220;&lt;span class="caps"&gt;IP&lt;/span&gt; Camera&amp;#8221; and specify the &lt;span class="caps"&gt;RSTP&lt;/span&gt; &lt;span class="caps"&gt;URL&lt;/span&gt;, dimensions, delay (zero) and live stream framerate, click save, and view the camera. I had a &lt;span class="caps"&gt;UI&lt;/span&gt; showing the stream from my 1080P camera and the ability to record within about two minutes. The &lt;span class="caps"&gt;UI&lt;/span&gt; initially loads to a dashboard with the live camera view and some graphs of motion detection metrics by hour of day, day of week, and today vs average, as well as a listing of dates (presumably motion detection history/recordings) on the left sidebar. There&amp;#8217;s also a handy &amp;#8220;System&amp;#8221; video that shows uptime, some system information, the currently-running Kerberos.io versions, statistics on captured images, and some system performance information (disk space that was incorrect in Docker, network &lt;span class="caps"&gt;IO&lt;/span&gt;, and &lt;span class="caps"&gt;CPU&lt;/span&gt;&amp;nbsp;usage).&lt;/p&gt;
&lt;p&gt;Unfortunately, the system almost instantly showed a &amp;#8220;Hey, your disk is almost full. Please remove some images..&amp;#8221; header at the top of the pages. Yes, with the containers running, my &lt;code&gt;/var&lt;/code&gt; partition was 97% full (lots of churn lately, and lots of cruft from the ZoneMinder&amp;nbsp;tests).&lt;/p&gt;
&lt;p&gt;At this point I went back to &amp;#8220;Configuration&amp;#8221; and clicked the &amp;#8220;Motion&amp;#8221; button to set up motion detection. I was presented with a gray box that I assume was supposed to show the live image from the camera, and some points on a polygon to select a motion detection region. I did the best I could with the missing image and moved on to some sliders for &amp;#8220;sensitivity&amp;#8221; (default fifteen on a scale of zero to thirty) and &amp;#8220;number of detections before valid&amp;#8221; (default two on a scale of zero to ten) and then configured the recording settings: both images and video, no timestamp overlays, fifteen frames per second (the same as the cameras), record five seconds after motion detection, and nothing set for the options to trigger webhooks, scripts, &lt;span class="caps"&gt;GPIO&lt;/span&gt; or &lt;span class="caps"&gt;MQTT&lt;/span&gt; on detection. I should note that the &amp;#8220;seconds to record&amp;#8221; field is a slider for &amp;#8220;The number of seconds that will be recorded after motion was detected&amp;#8221;, which defaults to five and can go from zero to&amp;nbsp;thirty.&lt;/p&gt;
&lt;p&gt;I confirmed those settings and browsed back to the Dashboard, where I could see the live video view and&amp;#8230; a whole lot of nothing&amp;nbsp;else:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/kerberos1.png"&gt;&lt;img alt="screenshot of Kerberos.io dashboard with live webcam feed but all graphs saying &amp;quot;No data available&amp;quot;" src="/GFX/kerberos1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Refreshing the page didn&amp;#8217;t seem to help get any of the other data to show up, even when there was obviously motion. There&amp;#8217;s a Heatmap feature in the Configuration page, but I haven&amp;#8217;t been able to get it to display anything other than &amp;#8220;No data available&amp;#8221;. Thinking that something was wrong, I went back through the motion detection configuration and found that the region I&amp;#8217;d selected was reset back to the strange-shaped default. I fixed it, pressed the &amp;#8220;Confirm and Select&amp;#8221; button without going through to the second and third screens of the Motion configuration dialog, and then opened the Motion configuration dialog again. This time, the region was effectively empty (a flat line in the top left corner, with multiple points on it) but I could actually see the camera stream albeit frozen at the latest frame. I adjusted the region polygon again, Saved, and then reloaded the Motion configuration dialog&amp;#8230; and got back to a correct-looking region but no picture. I assumed that was right and proceeded back through the three screens of the dialog and found the rest of my settings back to default. Through trial and error, I found that the configuration dialog for the Motion detection has three screens, which are paged through by using either left/right arrows on the sides of the dialog or one of three small circles (inactive two grayed out) at the bottom of the settings. Apparently, while the &amp;#8220;Confirm and Select&amp;#8221; button dismisses the dialog, it only saves the settings on the &lt;em&gt;current&lt;/em&gt; one of three pages. So eventually, I realized that I had to edit the first page, save, bring the dialog back up, move to the second page, save, then bring the dialog back up, move to the third page, and save. I then needed to press the &amp;#8220;Update&amp;#8221; button on the main Configuration page to commit my&amp;nbsp;changes.&lt;/p&gt;
&lt;p&gt;After all that, things seemed to be working. Navingating back to the Dashboard showed some actual data on the graphs including a large number of detections for the current&amp;nbsp;hour:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/kerberos2.png"&gt;&lt;img alt="screenshot of Kerberos.io dashboard with data in graphs and hourly graph showing 18 motion detections this hour" src="/GFX/kerberos2_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;However, when I clicked on the date in the left sidebar, something seemed to be very&amp;nbsp;amiss:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/kerberos3.png"&gt;&lt;img alt="screenshot of Kerberos.io dashboard for current date, saying &amp;quot;Oeps, no detections found at 11 o'clock&amp;quot;" src="/GFX/kerberos3_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The main Dashboard had reported 18 detections, and the slider bar on the view for today&amp;#8217;s date (above) clearly showed some heatmap colors for the current hour, but it was also telling me that it couldn&amp;#8217;t find any detections (videos/images). On a hunch I looked at the Docker logs for the container, and found the &amp;#8220;machinery&amp;#8221; (capture and storage) container&amp;#8217;s logs full of this, repeated over and&amp;nbsp;over:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;machinery_1  | Cleaning disk
machinery_1  | Cleaning disk
machinery_1  | rm: missing operand
machinery_1  | Try &amp;#39;rm --help&amp;#39; for more information.
machinery_1  | Cleaning disk
machinery_1  | rm: missing operand
machinery_1  | Try &amp;#39;rm --help&amp;#39; for more information.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As best I can tell, it was detecting that the disk backing the Docker volume was 97% full (it&amp;#8217;s a 100G volume) and cleaning up the disk&amp;#8230; which apparently meant deleting all of the recordings, including the ones that had just been made and I hadn&amp;#8217;t reviewed&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;That was the end of my experimentation with Kerberos.io. Not only was it apparently executing a shell command (&lt;code&gt;rm&lt;/code&gt;) with invalid/missing arguments, but it was also deleting all of the recordings it had because the disk was 97% full. First and foremost, the camera I&amp;#8217;m using is streaming 1920x1080 H.264 at 15 frames per second; &lt;span class="caps"&gt;3GB&lt;/span&gt; of disk space remaining shouldn&amp;#8217;t be a reason to delete all of the five-second video clips unless the cleanup logic is purely based on percentages. I didn&amp;#8217;t dig into the source code, but I&amp;#8217;m pretty sure if my 100-Petabyte disk was 97% full, it would still start deleting single-digit-megabyte images to free up space. Secondly, and more importantly, I intend on using this as part of a security system which to me means engineering for the worst-case scenario. Under normal circumstances, I should be able to respond to a low disk warning and manually free up some space. My Internet connection is generally very stable, so the &amp;#8220;worst case&amp;#8221; I want to engineer for is someone burglarizing my house and being smart enough to cut the cable line. If that happens, causing storage to fill up, the most important video is actually the &lt;em&gt;oldest&lt;/em&gt;! It&amp;#8217;s the video that was recorded closest to when I lost access to the system. In which case, I&amp;#8217;d want the failure mode to be either filling up the storage or ceasing to record, but definitely not to arbitrarily delete old-but-unreviewed&amp;nbsp;recordings.&lt;/p&gt;
&lt;h3 id="shinobi"&gt;&lt;a class="toclink" href="#shinobi"&gt;Shinobi&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Aside from my old standby of Motion, the last candidate on my list was &lt;a href="https://shinobi.video/"&gt;Shinobi&lt;/a&gt;. Shinobi&amp;#8217;s tag line is &amp;#8220;The open source &lt;span class="caps"&gt;CCTV&lt;/span&gt; solution&amp;#8221; and prides itself on being modern and using modern technologies. The first section of their pretty and modern homepage, https://shinobi.video/, includes a link to the docs and GitHub and&amp;nbsp;states:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Shinobi is Open Source, written in Node.js, and real easy to use. It is the future of &lt;span class="caps"&gt;CCTV&lt;/span&gt; and &lt;span class="caps"&gt;NVR&lt;/span&gt; for developers and end-users alike. It is catered to by professionals and most importantly by the one who created&amp;nbsp;it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After seeing what&amp;#8217;s happening under the hood of ZoneMinder, this certainly got my attention, as did the general modern open-source community feel of the site. Granted, I initially missed the section comparing Shinobi &lt;span class="caps"&gt;CE&lt;/span&gt; (Community Edition; GPLv3) and Shinobi Pro (Professional but free for non-commercial use; Creative Commons) and that Community Edition is &amp;#8220;updated only for major changes or bug fixes.&amp;#8221; But the &lt;a href="https://github.com/ShinobiCCTV/Shinobi/blob/2bc74064da5484545d86fce9cf95db74ace0db48/README.md#key-aspects"&gt;current features list&lt;/a&gt; includes most of what I wanted (even audio recording too, from my&amp;nbsp;ProHD)&lt;/p&gt;
&lt;p&gt;First I headed over to the &lt;a href="https://github.com/moeiscool/docker-shinobi"&gt;Dockerfiles from Shinobi&amp;#8217;s author&lt;/a&gt;. I had some issues with the Alpine-based vatiant and decided to give the Debian ones a try. One &lt;code&gt;docker-compose up&lt;/code&gt; and some patience later, I had two containers running: camera and cron. I immediately hit the web port and got a login box, which confused me with invalid logins for a while until I went back and re-read the &lt;a href="https://shinobi.video/docs/start"&gt;installation docs&lt;/a&gt; and realized that Shinobi supports multiple users, and I had to login via &lt;code&gt;/super&lt;/code&gt; (superuser) to set up a user account for myself. I did that and logged in as a regular user, and was greeted with a clean, modern, responsive&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Not being one to read documentation for end-user software, I muddled around in the &lt;span class="caps"&gt;UI&lt;/span&gt; a bit until I managed to add my two cameras. It wasn&amp;#8217;t terribly difficult: click the &amp;#8220;+&amp;#8221; icon in the top left of the &lt;span class="caps"&gt;UI&lt;/span&gt; (tooltip says, &amp;#8220;Add Monitor&amp;#8221;) and fill out the form. One early problem I had adding the first camera is that the &lt;span class="caps"&gt;URL&lt;/span&gt; parsing discards query strings. I added my Amcrest ProHD with its primary stream &lt;span class="caps"&gt;URL&lt;/span&gt;, which has a path of &lt;code&gt;/cam/realmonitor?channel=1&amp;amp;subtype=0&lt;/code&gt;. The stream didn&amp;#8217;t work and when I went back into the settings to edit it, the query string had been discarded. I just changed the &amp;#8220;Automatic&amp;#8221; (parsing of &lt;span class="caps"&gt;URL&lt;/span&gt;) to &amp;#8220;No&amp;#8221; and manually entered the protocol, host, port, authentication and path details myself, and it worked fine. Shinobi has a very nice interface for adding cameras, and one of the things I liked the most was the ability to choose the streaming details for the live stream; it supports Poseidon, &lt;span class="caps"&gt;JPEG&lt;/span&gt;, &lt;span class="caps"&gt;MJPEG&lt;/span&gt;, &lt;span class="caps"&gt;FLV&lt;/span&gt;, &lt;span class="caps"&gt;HLS&lt;/span&gt; (with audio) or a custom base64-over-websockets. The &lt;span class="caps"&gt;HLS&lt;/span&gt; stream also allows selection of video and audio codecs including copying the source codec (which is what I did). There&amp;#8217;s also an option for a &lt;span class="caps"&gt;CGI&lt;/span&gt;-style &lt;span class="caps"&gt;JPEG&lt;/span&gt; snapshot&amp;nbsp;&lt;span class="caps"&gt;API&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi1.png"&gt;&lt;img alt="screenshot of Shinobi dialog to add a monitor" src="/GFX/shinobi1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class="caps"&gt;UI&lt;/span&gt; is smooth and modern, with a fully responsive design that apparently works on mobile too (though I didn&amp;#8217;t test it). It even includes nice dropdown menus and mouseover menus for streams that  include snapshot, start/stop recording, pop-out, recording list, calendar of events, monitor/stream settings, and fullscreen. It also includes something called the &amp;#8220;Power Viewer&amp;#8221; that I&amp;#8217;ll discuss&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi2.png"&gt;&lt;img alt="screenshot of Shinobi with mouseover controls for streams" src="/GFX/shinobi2_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Within a few minutes, I had both cameras up and running with their full resolution H.264 &lt;span class="caps"&gt;RTSP&lt;/span&gt; streams (1920x1080 and 1280x960, respectively) at 15fps. The camera streams are shown by clicking on the camera in the left sidebar, and the stream windows can be resized by dragging the lower right corner (though it doesn&amp;#8217;t keep the aspect ratio) and rearranged via&amp;nbsp;drag-and-drop.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi3.png"&gt;&lt;img alt="screenshot of Shinobi with both streams" src="/GFX/shinobi3_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I was happy to see that, in this configuration with video streaming but not being analyzed, the Docker containers were only using a combined total of about 5% of my &lt;span class="caps"&gt;CPU&lt;/span&gt; and &lt;span class="caps"&gt;100MB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;. I tried some experiments with snapshots (they force-download) and manually-requested recordings and was quite happy with both. I did have some occasional issues with live streams freezing if I refreshed the page, but they resumed fine if I logged back in. The calendar interface seemed handy - it shows a monthly calendar with the time, camera name, and size of each recording for each day - and the videos list for each camera lists the start and end time, filename, and size of each video for each camera, along with buttons to preview (on the same dialog), watch (fullscreen-ish in the viewer), download, and&amp;nbsp;delete.&lt;/p&gt;
&lt;p&gt;This all seemed wonderful, so I figured it was time to enable motion detection. Well&amp;#8230; little did I know that would be a six-hour struggle. The &lt;a href="https://shinobi.video/docs/motion"&gt;documentation on Motion detection&lt;/a&gt; is separate, and states that motion detection isn&amp;#8217;t built-in because not everybody wants it and it has dependencies, which is also started at other places on their site. The &lt;a href="https://shinobi.video/docs/motion#content-use-builtin"&gt;first section on the Motion detection docs page&lt;/a&gt; says that it&amp;#8217;s now built-in and people should just use that, but is rather easy to miss (the section heading is at the same level as &amp;#8220;Install on Ubuntu/Debian&amp;#8221;, &amp;#8220;Install on CentOS/Fedora&amp;#8221;, etc.) and doesn&amp;#8217;t explicitly say whether there are external dependencies or not. Without going into the details, I went through a six-hour marathon of trying different Docker images, installing dependencies, running NodeJS scripts, starting other processes, adding containers, etc. in an attempt to get motion detection&amp;nbsp;working.&lt;/p&gt;
&lt;p&gt;Through the course of this I found that Shinobi&amp;#8217;s documentation is quite lacking, and also that it seems to be sporadically updated. The &lt;a href="https://shinobi.video/docs/settings"&gt;settings documentation&lt;/a&gt; contains a lot that doesn&amp;#8217;t seem to line up with what I&amp;#8217;m seeing in the &lt;span class="caps"&gt;UI&lt;/span&gt;, and I&amp;#8217;m not sure if it&amp;#8217;s because the docs are out of date or because they&amp;#8217;re ahead of the code, or a Pro vs Community Edition issue, or what. There are other places in the docs that seem horribly outdated, and many sections that seem to give conflicting&amp;nbsp;information.&lt;/p&gt;
&lt;p&gt;At one point I also stopped and tried to configure pan/tilt control, but couldn&amp;#8217;t find a setting for that either, so I went back to motion&amp;nbsp;detection.&lt;/p&gt;
&lt;p&gt;Most of my frustration was based on the Motion Detection documentation page and its statements that once Motion Detection is set up you should see &amp;#8220;Detector: Motion Connected&amp;#8221; in the Monitor Settings, and have configuration options for motion detection. No matter what I tried - Debian or Alpine, different images, adding packages and &lt;span class="caps"&gt;OS&lt;/span&gt;-level dependencies, restarting the services, trying the older, no-longer-recommended plugin-based method - I couldn&amp;#8217;t find or see the Motion Detection settings like the docs said I should. I just kept trying different things to get those settings to show up. When I was just about to give up and was searching through Shinobi&amp;#8217;s &lt;a href="https://forum.shinobi.video/"&gt;forums&lt;/a&gt; for some confirmation of whether anyone could get this working, I stumbled upon a &lt;a href="https://forum.shinobi.video/post/160"&gt;forum post&lt;/a&gt; that mentioned something about &amp;#8220;Advanced&amp;nbsp;settings&amp;#8221;.&lt;/p&gt;
&lt;p&gt;I started the containers back up and sure enough, in the far lower right corner of the Monitor Settings dialog, colored almost the same as the background, was a button that says &amp;#8220;Simple&amp;#8221; and has an arrow. I clicked it, selected &amp;#8220;Advanced&amp;#8221;, and suddenly the left sidebar of the dialog grew&amp;#8230; to include Global Detector Settings and Control, among other&amp;nbsp;options.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi4.png"&gt;&lt;img alt="screenshot of Shinobi Monitor Settings in Advanced mode" src="/GFX/shinobi4_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As far as I can tell, motion detection was probably working the whole time and my six-ish hours of struggling were all for naught. The only problem I had was not changing the Monitor Settings dialog from Simple mode - which hides all motion detection and control settings - to Advanced. I&amp;#8217;ve gone back over the documentation multiple times, and there&amp;#8217;s not a single occurrence of the word &amp;#8220;Advanced&amp;#8221; on the Motion Detection page or the Settings page, and certainly nothing telling users that they need to explicitly switch to Advanced Mode to see these&amp;nbsp;settings.&lt;/p&gt;
&lt;p&gt;At that point, I was already quite frustrated with Shinobi and felt that if this was at all indicative of the quality of documentation and user experience, I should definitely avoid it. But I at least wanted to know what its motion detection could&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://shinobi.video/docs/settings#content-detector"&gt;settings documentation for Motion Detection&lt;/a&gt; was mostly straightforward, with the exception of a few&amp;nbsp;settings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Recording Timeout&lt;/strong&gt; - &amp;#8220;The length of time &amp;#8220;Trigger Record&amp;#8221; will run for. This is read in minutes.&amp;#8221; Apparently when Shinobi detects motion it records &lt;em&gt;minutes&lt;/em&gt; of video, with a minimum of one and a default of ten. This was very strange to me, especially since many motion events that I&amp;#8217;ve seen only span a few&amp;nbsp;seconds.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timeout Reset on Next Motion&lt;/strong&gt; - &amp;#8220;If there is an overlap in trigger record should it reset. &lt;strong&gt;No:&lt;/strong&gt; Finish the current 10 minute order.. &lt;strong&gt;Yes:&lt;/strong&gt; Reset the timer&amp;#8221;. I didn&amp;#8217;t have to worry about this since it wasn&amp;#8217;t visible in my&amp;nbsp;version.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Save Events to &lt;span class="caps"&gt;SQL&lt;/span&gt;&lt;/strong&gt; - &amp;#8220;Save Motion Events in &lt;span class="caps"&gt;SQL&lt;/span&gt;. This will allow display of motion over video during the time motion events occured [sic] in the Power&amp;nbsp;Viewer.&amp;#8221;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Indifference&lt;/strong&gt; - &amp;#8220;How much Shinobi doesn&amp;#8217;t care about motion before doing something. The opposite of sensitivity; a lower number means it will trigger sooner. The value ranges up to 15(+) decimal places. 10 is default, 0.005 is pretty sensitive to motion changes. Note: If using Region Editor, leave this blank, and set indifference in the Region Editor (below).&amp;#8221; So&amp;#8230; firstly, the semantics of this are awful. Secondly, in my version, the global default (if not using Regions) isn&amp;#8217;t 10 it&amp;#8217;s 0.5, and the per-region default is&amp;nbsp;0.0005.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There were also a number of settings visible in the &lt;span class="caps"&gt;UI&lt;/span&gt; for the version I was running (&lt;a href="https://github.com/ShinobiCCTV/Shinobi/commit/4bf071abb5706f9240f32617bf3bb4b8aa52f3ca"&gt;https://github.com/ShinobiCCTV/Shinobi.git &amp;#8220;dev&amp;#8221; branch 4bf071abb5706f9240f32617bf3bb4b8aa52f3ca&lt;/a&gt;) that weren&amp;#8217;t in the&amp;nbsp;documentation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Allow Next Trigger&lt;/strong&gt; - &amp;#8220;in Milliseconds&amp;#8221;, default&amp;nbsp;2000.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Send Events to &lt;span class="caps"&gt;SQL&lt;/span&gt;&lt;/strong&gt; - &amp;#8220;Save Motion Events in &lt;span class="caps"&gt;SQL&lt;/span&gt;. This will allow display of motion over video during the time motion events occured [sic] in the Power Viewer.&amp;#8221; As I found out later, the Power Viewer does barely anything without&amp;nbsp;this.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After configuring the detection settings, the documentation told me that I had to add regions (zones) or else the detection would use the full frame. I did that via an editor modal from the Monitor Settings which allows adding multiple region polygons to the video via a simple but somewhat jerky and annoying (drag too close to the edges and points won&amp;#8217;t stick there) polygon editor. It was supposed to show the live video stream under the polygon, but that only worked once or twice for me, usually being a brown box where the video should&amp;nbsp;be.&lt;/p&gt;
&lt;p&gt;I was happy to see that running almost-full-frame, 15fps motion detection on both video feeds was only using about &lt;span class="caps"&gt;400MB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt; and the equivalent of one core (on my host &lt;span class="caps"&gt;OS&lt;/span&gt; it showed all 8 cores running around 20%, which is pretty good since I was also running graphite, grafana, nginx, apache, MySQL, Chrome, Atom,&amp;nbsp;etc.).&lt;/p&gt;
&lt;p&gt;One thing I immediately noticed after enabling motion detection, though, is that there&amp;#8217;s no &lt;span class="caps"&gt;UI&lt;/span&gt; indication of motion events. To see motion events for a camera, you need to use the Calendar, Video List, or Power Viewer modals. The other thing I noticed immediately is that using the default &amp;#8220;indifference&amp;#8221; value, my outdoor camera was recording constantly. I tried adjusting this value on both cameras but it certainly wasn&amp;#8217;t scientific; the default indifference for a zone was &amp;#8220;0.0005&amp;#8221; so I tried increasing it (decreasing sensitivity) by powers of 10. The best I could get that way was a point where almost everything was recorded, and then another point where it never&amp;nbsp;triggered.&lt;/p&gt;
&lt;p&gt;After that experience, I turned to the &amp;#8220;Power Viewer&amp;#8221; which seemed like it might be able to solve this. The layout actually seems quite well done and useful, despite the fact that the Live View of the camera was only sporadically working for&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/shinobi5.png"&gt;&lt;img alt="screenshot of Shinobi Power Viewer" src="/GFX/shinobi5_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The main elements&amp;nbsp;are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Live View&lt;/strong&gt; - This only worked sporadically for me, and I was unable to get a screenshot of it. When it worked, it showed the live stream from the&amp;nbsp;camera.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timeline&lt;/strong&gt; - A relatively handy view of all recordings and motion events for the specified date range. It seems to default to two days, though I only had the system running and recording for an hour or so. The blue dots along the timeline represent recordings; clicking one of them brings up the recording and starts playing it. The red bars represent the count of motion detection events in each&amp;nbsp;recording.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recording&lt;/strong&gt; - Plays the selected recording along with displaying the&amp;nbsp;filename.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Playback Timer&lt;/strong&gt; - It&amp;#8217;s a simple playback timer for the currently-playing video. It&amp;#8217;s clickable and draggable to advance through the&amp;nbsp;video.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Motion Meter&lt;/strong&gt; - The tooltip for this says &amp;#8220;Motion Meter&amp;#8221;, and the only clear documentation I could find on this says, &amp;#8220;When motion occurs a red bar will appear under your stream to indicate how much motion has happened.&amp;#8221; Some other documentation &lt;em&gt;implies&lt;/em&gt; that this should be the detected indifference value, presumably on a scale of zero to 100, but nothing explains that specifically. This also appeared to lag quite a bit behind the video and doesn&amp;#8217;t have a numeric output even on&amp;nbsp;hover.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Motion Confidence&lt;/strong&gt; - This is a graph over time (for the currently-playing recording) of &amp;#8220;Motion Confidence&amp;#8221;. I was unable to find any reference to this in the documentation and haven&amp;#8217;t yet received a response to my &lt;a href="https://forum.shinobi.video/topic/216/relationship-between-indifference-and-motion-confidence"&gt;forum post&lt;/a&gt; asking about it. The numeric definitely seems different from the &amp;#8220;Motion Meter&amp;#8221; to me, but I don&amp;#8217;t know what it&amp;nbsp;means.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point it seemed like Shinobi was the frontrunner in everything except motion detection, which it seemed to fail horribly at. There&amp;#8217;s a Noise Filter setting that I tried, but I couldn&amp;#8217;t find any clear documentation on how to tune Shinobi for motion thresholds and it certainly seemed to lack many of the advanced tuning features of &lt;code&gt;motion&lt;/code&gt; such as imprinting the number of changed pixels in the frame, debug images/videos with motion highlighted, adaptive thresholds or blob detection. I decided that I might as well explore &lt;code&gt;motion&lt;/code&gt; since I understand it and it&amp;#8217;s well documented, and come back to Shinobi later if I want&amp;nbsp;to.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Postscript:&lt;/strong&gt; Some of my other notes on&amp;nbsp;Shinobi:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One feature I do like about Shinobi is the &amp;#8220;Delete Motionless&amp;#8221; toggle that apparently records all the time and then deletes recording segments that didn&amp;#8217;t have motion detected. This seems like a &lt;em&gt;very&lt;/em&gt; good idea and, if done right, could help with capturing the low-motion events leading up to an event that crosses the&amp;nbsp;threshold.&lt;/li&gt;
&lt;li&gt;There were some annoying timezone bugs, where the &lt;span class="caps"&gt;UI&lt;/span&gt; showed the time in my local timezone (including the clock in the upper right corner) but the filenames and Power Viewer were using&amp;nbsp;&lt;span class="caps"&gt;UTC&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="motion"&gt;&lt;a class="toclink" href="#motion"&gt;Motion&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I&amp;#8217;ve used the &lt;a href="https://motion-project.github.io/"&gt;Motion Project&lt;/a&gt; a few times over the years and had a pretty good impression of it - at one point I had it running motion detection with a 1080P webcam on an original Raspberry Pi Model B (700MHz &lt;span class="caps"&gt;ARM&lt;/span&gt; with &lt;span class="caps"&gt;512MB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;). It&amp;#8217;s an established project (the git history goes back to 2005, but the initial commit is &amp;#8220;initial import&amp;#8221;), written in C and highly performant, and follows the Unix philosophy of doing one thing and doing it well. The project has been recently taken over by new developers and has a new home in the &lt;a href="https://github.com/Motion-Project"&gt;Motion-Project GitHub org&lt;/a&gt; but the previous maintainer&amp;#8217;s amazingly detailed and helpful wiki is still available at &lt;a href="http://www.lavrsen.dk/foswiki/bin/view/Motion/WebHome"&gt;http://www.lavrsen.dk/foswiki/bin/view/Motion/WebHome&lt;/a&gt;. Also note that I&amp;#8217;m not sure about the other projects listed here, but Motion uses luminance / intensity only to detect motion, i.e. no color&amp;nbsp;information.&lt;/p&gt;
&lt;p&gt;The main things that I remember about Motion from using it in the past (aside from feeling somewhat archaic though amazingly stable and fast)&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tuning of thresholds as a number of changed&amp;nbsp;pixels.&lt;/li&gt;
&lt;li&gt;For tuning, the ability to output &amp;#8220;debug&amp;#8221; images showing only the pixels that triggered motion&amp;nbsp;detection.&lt;/li&gt;
&lt;li&gt;Output as videos and/or &lt;span class="caps"&gt;JPEG&lt;/span&gt; snapshots, but it handles everything internally as still&amp;nbsp;frames.&lt;/li&gt;
&lt;li&gt;Ability to mask off certain parts of the frame using a manually-generated mask&amp;nbsp;image.&lt;/li&gt;
&lt;li&gt;Ability to watermark every frame with the number of changes pixels, for&amp;nbsp;debugging/tuning.&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Lightswitch mode&amp;#8221; that automatically ignores massive changes in&amp;nbsp;brightness.&lt;/li&gt;
&lt;li&gt;Motion detection based on the largest contiguous region of changed pixels, so it&amp;#8217;s less effected by&amp;nbsp;wind/leaves/rain/etc.&lt;/li&gt;
&lt;li&gt;Support for multiple&amp;nbsp;cameras.&lt;/li&gt;
&lt;li&gt;Snapshots either on a regular interval automatically, or triggered by a&amp;nbsp;signal.&lt;/li&gt;
&lt;li&gt;Ability to execute arbitrary programs/scripts when events occur (&lt;em&gt;many&lt;/em&gt; events; motion detect start and end, pictures and movies being written, event start and end,&amp;nbsp;etc.)&lt;/li&gt;
&lt;li&gt;Built-in ability to write extremely detailed information to&amp;nbsp;MySQL/PostgreSQL/SQLite3&lt;/li&gt;
&lt;li&gt;Highly configurable picture/video paths/filenames and overlay of text on&amp;nbsp;images.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Apparently since I last looked at the project, a number of major new features have been introduced&amp;nbsp;including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Live streaming of incoming cam video via &lt;span class="caps"&gt;HTTP&lt;/span&gt;&amp;nbsp;&lt;span class="caps"&gt;MJPEG&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Motion tracking in the frame, and experimental control of tracking motion via pan/tilt camera&amp;nbsp;controls.&lt;/li&gt;
&lt;li&gt;Control via a simple web interface, even including the ability to change/tune many settings live from the web&amp;nbsp;interface.&lt;/li&gt;
&lt;li&gt;Automatic/adaptive noise and threshold&amp;nbsp;control.&lt;/li&gt;
&lt;li&gt;Official support for both the RaspberryPi and &lt;span class="caps"&gt;MUSL&lt;/span&gt; LibC (i.e. Alpine&amp;nbsp;Linux)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The project also has wonderfully detailed documentation, as well as active &lt;span class="caps"&gt;IRC&lt;/span&gt; and mailing&amp;nbsp;lists.&lt;/p&gt;
&lt;p&gt;While Motion only has a very basic web interface for control, there are a number of more full-featured web UIs for it including the quite popular &lt;a href="https://github.com/ccrisan/motioneye"&gt;MotionEye&lt;/a&gt; that uses Python and&amp;nbsp;Tornado.&lt;/p&gt;
&lt;h2 id="final-choice"&gt;&lt;a class="toclink" href="#final-choice"&gt;Final&amp;nbsp;Choice&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After my frustrations with ZoneMinder, Kerberos.io, and Shinobi, I believe I&amp;#8217;m going to be going the minimalist route and using Motion with some sort of web &lt;span class="caps"&gt;UI&lt;/span&gt; for motion detection, recording, and review, and the cameras&amp;#8217; built-in &lt;span class="caps"&gt;RSTP&lt;/span&gt; stream for high-resolution live viewing. Given how long this post ended up being, I&amp;#8217;ll save the Motion setup and testing for my next&amp;nbsp;installment.&lt;/p&gt;</content><category term="amcrest"></category><category term="camera"></category><category term="security"></category><category term="surveillance"></category><category term="video"></category><category term="linux"></category><category term="IP camera"></category><category term="evaluation"></category></entry><entry><title>Amcrest IP Camera First Impressions</title><link href="https://blog.jasonantman.com/2018/05/amcrest-ip-camera-first-impressions/" rel="alternate"></link><published>2018-05-06T20:13:00-04:00</published><updated>2018-05-06T20:13:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-05-06:/2018/05/amcrest-ip-camera-first-impressions/</id><summary type="html">&lt;p&gt;My first impressions on interfacing with Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt;&amp;nbsp;cameras&lt;/p&gt;</summary><content type="html">&lt;!--- remove this next line to disable Table of Contents --&gt;

&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#devices-and-purchase"&gt;Devices and&amp;nbsp;Purchase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#initial-setup"&gt;Initial&amp;nbsp;Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#chrome-app"&gt;Chrome&amp;nbsp;App&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#api-and-digest-auth"&gt;&lt;span class="caps"&gt;API&lt;/span&gt; and Digest Auth&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#python-digest-auth-removing-proxy"&gt;Python Digest-Auth-Removing&amp;nbsp;Proxy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#json-configuration-backups"&gt;&lt;span class="caps"&gt;JSON&lt;/span&gt; Configuration&amp;nbsp;Backups&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#api"&gt;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#alarms-events-initial-research"&gt;Alarms / Events - Initial Research&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#snmp"&gt;&lt;span class="caps"&gt;SNMP&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#smtp"&gt;&lt;span class="caps"&gt;SMTP&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#system-logs"&gt;System&amp;nbsp;logs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#gpl-compliance"&gt;&lt;span class="caps"&gt;GPL&lt;/span&gt;&amp;nbsp;Compliance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#auto-maintain"&gt;Auto&amp;nbsp;Maintain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#status-and-next-steps"&gt;Status and Next&amp;nbsp;Steps&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="alert alert-warning" role="alert"&gt;&lt;strong&gt;Notice/Disclaimer:&lt;/strong&gt; The information I provide on home automation/security and surveillance is based on what I&amp;#8217;ve set up for myself based on a balance of cost, ease of use, and security, and should be considered for hobby purposes only. My current system and code has grown organically over time and is not how I&amp;#8217;d approach this if I started over from scratch. My code and system has a few obvious vulnerabilities and probably some non-obvious ones as well; I humbly but sincerely ask that you do not attempt to exploit these. I highly recommend that anyone implementing a similar system - especially if you also publish the details of it - have undocumented backup systems/devices. Finally, the systems that I describe are intended to provide some protection against or notification of crimes of opportunity, not targeted attacks. Please keep in mind that none of this is intended to protect against someone who targets &lt;em&gt;me&lt;/em&gt; specifically (and takes the time to research me) as opposed to my home at random.&lt;/div&gt;

&lt;p&gt;I&amp;#8217;m going to be moving to a new area at the end of the month and will be leaving my dogs home alone during the days I work in the office - and my home unattended - on a regular basis for the first time. While the neighborhood I&amp;#8217;m moving to seems safe, I wanted some peace of mind about both the security of my new home and the well-being of my dogs when I&amp;#8217;m out. While I&amp;#8217;ve set up a &lt;a href="https://blog.jasonantman.com/2016/01/raspberry-pi-security-system/"&gt;&lt;span class="caps"&gt;DIY&lt;/span&gt; RaspberryPi-based security system&lt;/a&gt; in a past apartment, that won&amp;#8217;t help knowing that my dogs are doing &lt;span class="caps"&gt;OK&lt;/span&gt; (and the house I&amp;#8217;m moving to isn&amp;#8217;t wired for a security system). While I may look into setting up a security system in the future (likely based on &lt;a href="https://en.wikipedia.org/wiki/Z-Wave"&gt;Z-Wave&lt;/a&gt; wireless components), I decided that some &lt;span class="caps"&gt;IP&lt;/span&gt;-based surveillance cameras are the best way to achieve my short-term need. I recently bought some of them, and want to share my&amp;nbsp;experience.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; The next post in this series is up, &lt;a href="/2018/05/linux-surveillance-camera-software-evaluation"&gt;Linux Surveillance Camera Software Evaluation&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="devices-and-purchase"&gt;&lt;a class="toclink" href="#devices-and-purchase"&gt;Devices and&amp;nbsp;Purchase&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;I started my search with the hardware compatibility lists of &lt;a href="http://www.lavrsen.dk/foswiki/bin/view/Motion/WorkingDevices"&gt;Motion&lt;/a&gt; and &lt;a href="https://wiki.zoneminder.com/Hardware_Compatibility_List"&gt;ZoneMinder&lt;/a&gt;, the most well-known (albeit rather aged) open source video motion detection projects. I figured that most likely I&amp;#8217;d be using one of these to detect and alert on motion; I&amp;#8217;ve used Motion before quite successfully but it is a daemon only whereas ZoneMinder offers a full web interface. The outcome of my research was that most decent modern &lt;span class="caps"&gt;IP&lt;/span&gt;-based surveillance cameras support the &lt;a href="https://en.wikipedia.org/wiki/ONVIF"&gt;&lt;span class="caps"&gt;ONVIF&lt;/span&gt;&lt;/a&gt; interoperability standard, and almost any camera that supports &lt;span class="caps"&gt;ONVIF&lt;/span&gt; and third-party clients (i.e. unencrypted video streams) should&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;I decided that I&amp;#8217;d get three initial cameras for some tests: an indoor camera with remote pan and tilt to keep an eye on the dogs and two outdoor fixed cameras, one wireless and one wired with Power over Ethernet (PoE) support. I currently have a very good 5GHz wireless access point (a &lt;a href="https://www.ubnt.com/airmax/nanostationm/"&gt;Uniquiti NanoStation M&lt;/a&gt;) and a serviceable but nine-year-old 2.4 GHz 802.11b/g Ubiquiti PicoStation 2. Unfortunately, I&amp;#8217;ve been unable to find &lt;em&gt;any&lt;/em&gt; reasonably-priced 5GHz &lt;span class="caps"&gt;IP&lt;/span&gt;&amp;nbsp;cameras.&lt;/p&gt;
&lt;p&gt;My initial desire was to get only 1080p cameras, but I decided to try a 960p wireless model given my aged access point. After a few hours of browsing on Amazon I settled on buying the following three cameras, all of which claimed &lt;span class="caps"&gt;ONVIF&lt;/span&gt; support and support for third-party video management&amp;nbsp;systems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/B01G1U4MVA/"&gt;&lt;span class="caps"&gt;SV3C&lt;/span&gt; V-B01-&lt;span class="caps"&gt;1080PL&lt;/span&gt;&lt;/a&gt; 1080P wired outdoor camera with PoE&amp;nbsp;support&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/B01I00987C/"&gt;Amcrest &lt;span class="caps"&gt;IPM&lt;/span&gt;-723W&lt;/a&gt; 2.4GHz wireless 960P outdoor camera (shipped with latest firmware, &lt;code&gt;2.400.AC02.15.R,build:2017-07-31&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/B0145OQTPG/"&gt;Amcrest &amp;#8220;ProHD&amp;#8221; &lt;span class="caps"&gt;IP2M&lt;/span&gt;-841B&lt;/a&gt; 2.4GHz (or wired) 1080p indoor pan/tilt camera (shipped with latest firmware, &lt;code&gt;2.520.AC00.18.R,build:2017-06-29&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of them support wired Ethernet in addition to WiFi. They&amp;#8217;re all highly reviewed on Amazon with a number of positive reviews mentioning Linux. My choice of the Amcrest cameras was based largely on a number of very positive reviews from other people using Linux and/or leveraging their APIs and on the availability of a detailed &lt;a href="https://support.amcrest.com/hc/en-us/articles/232310528-Amcrest-HTTP-API-SDK"&gt;&lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; document&lt;/a&gt; on Amcrest&amp;#8217;s site. The Amcrest &lt;span class="caps"&gt;API&lt;/span&gt; document specifically mentioned &lt;span class="caps"&gt;HTTP&lt;/span&gt; Basic authentication, which I considered a plus since I could easily add the required headers in an Nginx reverse proxy and use my own authentication methods for remote&amp;nbsp;access.&lt;/p&gt;
&lt;p&gt;After unboxing the Amcrest cameras and experimenting with them a bit, I decided to return the &lt;span class="caps"&gt;SV3C&lt;/span&gt; camera unopened. It was clear to me that if I wanted to use Amcrest&amp;#8217;s &lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;, it would make sense to stick with the cameras from one manufacturer. Since &lt;span class="caps"&gt;SV3C&lt;/span&gt; didn&amp;#8217;t even have any &lt;span class="caps"&gt;API&lt;/span&gt; documentation that I could find, Amcrest won. The rest of this post will discuss my initial exploration of the Amcrest&amp;nbsp;cameras.&lt;/p&gt;
&lt;h1 id="initial-setup"&gt;&lt;a class="toclink" href="#initial-setup"&gt;Initial&amp;nbsp;Setup&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;While Amcrest seemed to be well-reviewed, I&amp;#8217;m always very hesitant to put new devices on my network, especially if they&amp;#8217;re running opaque proprietary firmware. And even more so if they have &amp;#8220;cloud&amp;#8221; features (as Amcrest does) that imply remote access which I&amp;#8217;d need to trust the manufacturer to properly secure and allow me to disable. &lt;a href="https://blog.jessfraz.com/post/home-lab-is-the-dopest-lab/"&gt;Jess Frazelle&amp;#8217;s Home Lab blog post&lt;/a&gt;, along with some great reviews from my colleague &lt;a href="https://github.com/jniesen"&gt;jniesen&lt;/a&gt;, spurred me to plan replacing my almost-decade-old Ubiquiti access points with some new ones that support BSSIDs and 802.1q VLANs, but until I do I&amp;#8217;m still stuck with a single &lt;span class="caps"&gt;SSID&lt;/span&gt; and flat&amp;nbsp;network.&lt;/p&gt;
&lt;p&gt;So, my initial unboxing process for each camera was as&amp;nbsp;follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Plug in to my MacBook with a crossover cable and Wireshark running; power on the camera and record the wired Ethernet &lt;span class="caps"&gt;MAC&lt;/span&gt; address for the camera. Then power off the&amp;nbsp;camera.&lt;/li&gt;
&lt;li&gt;On my &lt;a href="http://www.vyos.io/"&gt;VyOS&lt;/a&gt; router, assign the camera&amp;#8217;s wired &lt;span class="caps"&gt;MAC&lt;/span&gt; a static &lt;span class="caps"&gt;IP&lt;/span&gt; and local&amp;nbsp;&lt;span class="caps"&gt;DNS&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Alter my firewall rules to reject all traffic from the camera to the &lt;span class="caps"&gt;WAN&lt;/span&gt;, so it can&amp;#8217;t phone home or send anything directly to the external&amp;nbsp;world.&lt;/li&gt;
&lt;li&gt;Plug the camera in to my switch and power it on. Wait a few minutes and then access the builtin &lt;span class="caps"&gt;HTTP&lt;/span&gt; web interface at the &lt;span class="caps"&gt;IP&lt;/span&gt; I&amp;nbsp;assigned.&lt;/li&gt;
&lt;li&gt;Log in with the default username/password (admin/admin) and change the&amp;nbsp;password.&lt;/li&gt;
&lt;li&gt;Browse through the &amp;#8220;setup&amp;#8221; portion of the &lt;span class="caps"&gt;UI&lt;/span&gt; and record some of the current/default settings and&amp;nbsp;information:&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Information&amp;#8221; -&amp;gt; &amp;#8220;Version&amp;#8221; - record all&amp;nbsp;versions&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Camera&amp;#8221; -&amp;gt; &amp;#8220;Video&amp;#8221; - record streaming and snapshot settings; change Overlay to the camera&amp;#8217;s hostname and the Sub Stream to &lt;span class="caps"&gt;MJPEG&lt;/span&gt;, &lt;span class="caps"&gt;VGA&lt;/span&gt;, 5&amp;nbsp;&lt;span class="caps"&gt;FPS&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Camera&amp;#8221; -&amp;gt; &amp;#8220;Audio&amp;#8221; (on ProHD) - record stream&amp;nbsp;information&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Network&amp;#8221; -&amp;gt; &amp;#8220;&lt;span class="caps"&gt;TCP&lt;/span&gt;/&lt;span class="caps"&gt;IP&lt;/span&gt;&amp;#8221; - change hostname; record wireless &lt;span class="caps"&gt;MAC&lt;/span&gt;; disable&amp;nbsp;&lt;span class="caps"&gt;P2P&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Network&amp;#8221; -&amp;gt; &amp;#8220;Connection&amp;#8221; - record all ports; ensure &lt;span class="caps"&gt;ONVIF&lt;/span&gt; authentication is&amp;nbsp;enabled&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Network&amp;#8221; -&amp;gt; (&amp;#8220;&lt;span class="caps"&gt;DDNS&lt;/span&gt;&amp;#8221;, &amp;#8220;&lt;span class="caps"&gt;IP&lt;/span&gt; Filter&amp;#8221;, &amp;#8220;&lt;span class="caps"&gt;SMTP&lt;/span&gt;&amp;#8221;, &amp;#8220;UPnP&amp;#8221;) - ensure all are&amp;nbsp;disabled&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Network&amp;#8221; -&amp;gt; &amp;#8220;&lt;span class="caps"&gt;SNMP&lt;/span&gt;&amp;#8221; (if present) - enable&amp;nbsp;v1&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Network&amp;#8221; -&amp;gt; (&amp;#8220;Bonjour&amp;#8221;, &amp;#8220;Multicast&amp;#8221;, &amp;#8220;802.1x&amp;#8221;, &amp;#8220;QoS&amp;#8221;, &amp;#8220;HTTPs&amp;#8221;) - ensure all are&amp;nbsp;disabled&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;System&amp;#8221; -&amp;gt; &amp;#8220;General&amp;#8221; -&amp;gt; &amp;#8220;Date &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Time&amp;#8221; - enable&amp;nbsp;&lt;span class="caps"&gt;NTP&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;System&amp;#8221; -&amp;gt; &amp;#8220;Export&amp;#8221; - export a configuration file and save&amp;nbsp;it.&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Event&amp;#8221; - disable all of them for&amp;nbsp;now&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After that, I added the wireless &lt;span class="caps"&gt;MAC&lt;/span&gt; address for the camera to my access point&amp;#8217;s &lt;span class="caps"&gt;ACL&lt;/span&gt; and then set up a static &lt;span class="caps"&gt;IP&lt;/span&gt;, local &lt;span class="caps"&gt;DNS&lt;/span&gt;, and outbound traffic reject the same way I did for the wired &lt;span class="caps"&gt;MAC&lt;/span&gt;. I then configured the WiFi connection in the camera&amp;#8217;s Setup &lt;span class="caps"&gt;UI&lt;/span&gt;, ensured it connected to the network properly, and unplugged the wired&amp;nbsp;Ethernet.&lt;/p&gt;
&lt;h1 id="chrome-app"&gt;&lt;a class="toclink" href="#chrome-app"&gt;Chrome&amp;nbsp;App&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;One thing I noted in the web &lt;span class="caps"&gt;UI&lt;/span&gt; in Chrome is the high-res H.264 video stream was unavailable, displaying a &amp;#8220;Please click here to download and install the plug-in&amp;#8221; link. I was amazingly happy to find that this link brought me to the &lt;a href="https://chrome.google.com/webstore/detail/amcrest-web-view/oddndbjhpcpopbebhonolceinkbnheih?hl=en-US"&gt;Amcrest Web View&lt;/a&gt; Chrome App, which actually works with Linux. The Chrome App really just seems to wrap the existing web &lt;span class="caps"&gt;UI&lt;/span&gt; while providing the required plug-in, but it works fine in Chrome on Linux. I&amp;#8217;m vaguely concerned about the Chrome App being another data exfiltration or phone-home avenue, but for initial testing I was willing to take that risk. The App worked quite nicely, streaming near-realtime and very fluid, high-&lt;span class="caps"&gt;FPS&lt;/span&gt; images from both the 960P and 1080P cameras over WiFi, and gave me smooth, natural control of the pan and tilt for the ProHD&amp;nbsp;camera.&lt;/p&gt;
&lt;h1 id="api-and-digest-auth"&gt;&lt;a class="toclink" href="#api-and-digest-auth"&gt;&lt;span class="caps"&gt;API&lt;/span&gt; and Digest&amp;nbsp;Auth&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Next I wanted to dive right into the documented &lt;span class="caps"&gt;CGI&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;, and had even prepared a few curl commands for the basics (according to the &lt;a href="https://support.amcrest.com/hc/en-us/articles/232310528-Amcrest-HTTP-API-SDK"&gt;&lt;span class="caps"&gt;API&lt;/span&gt; document&lt;/a&gt; on Amcrest&amp;#8217;s site) before I even got the cameras. Unfortunately, they all failed with 401 Unauthorized errors. After some investigation and a trip to the &lt;a href="https://amcrest.com/forum/technical-discussion-f3/"&gt;Amcrest Technical Forums&lt;/a&gt;, I found that recent firmware versions dropped support for Basic authentication in favor of only Digest. This was confirmed by &lt;a href="https://amcrest.com/forum/technical-discussion-f3/cgi-sdk-no-longer-functioning-on-17r--t2401.html"&gt;multiple&lt;/a&gt; &lt;a href="https://amcrest.com/forum/technical-discussion-f3/basic-http-auth-not-working-after-firmware-update--t2771.html"&gt;threads&lt;/a&gt; &lt;a href="https://amcrest.com/forum/technical-discussion-f3/http-api-authentication-via-url-t3899.html"&gt;on&lt;/a&gt; &lt;a href="https://amcrest.com/forum/technical-discussion-f3/authentication-examples--t7128.html"&gt;the&lt;/a&gt; forum. This was quite problematic for my plans, since &lt;a href="https://en.wikipedia.org/wiki/Digest_access_authentication"&gt;Digest authentication&lt;/a&gt; is significantly more complicated than Basic and relies on &lt;span class="caps"&gt;MD5&lt;/span&gt; hashes generated on the client that include various fields sent in the headers of the server 401 response. In short, there doesn&amp;#8217;t seem to be any common reverse proxy (I checked Nginx, Apache, Lighttpd, and HAproxy) that supports Digest authentication to the backend/upstream. So my plans of wrapping the cameras in my own security (&lt;span class="caps"&gt;TLS&lt;/span&gt; and client certificate authentication in Nginx, with Nginx adding the appropriate Basic auth headers during the proxy process) weren&amp;#8217;t working out so well - the best I could get is a combination of the authentication I enabled in Nginx, plus Digest authentication to each&amp;nbsp;stream.&lt;/p&gt;
&lt;p&gt;I spent the better part of two afternoons and evenings looking into this and trying to develop a workaround. The &lt;a href="https://amcrest.com/forum/technical-discussion-f3/cgi-sdk-no-longer-functioning-on-17r--t2401.html"&gt;main Amcrest forum thread&lt;/a&gt; about this didn&amp;#8217;t have a whole lot of information other than many frustrated customers broken by the latest firmware upgrade (without even a corresponding &lt;span class="caps"&gt;API&lt;/span&gt; documentation update; the latest &lt;span class="caps"&gt;API&lt;/span&gt; docs still listed support for both Basic and Digest) and a few people who received unhelpful support responses. I opened my own support ticket about the problem, stating that I&amp;#8217;d purchased the cameras based on the &lt;span class="caps"&gt;API&lt;/span&gt; documentation and planned to integrate them with a system that only supports Basic authentication. I received a response the next day, stating in&amp;nbsp;part:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I am sorry for the bad information you got about our cameras. You are correct, Basic Authentication is no longer supported on our &lt;span class="caps"&gt;IP&lt;/span&gt; Cameras, &lt;span class="caps"&gt;NVR&lt;/span&gt;&amp;#8217;s and &lt;span class="caps"&gt;DVR&lt;/span&gt;&amp;#8217;s since latest firmware&amp;nbsp;updates.&lt;/p&gt;
&lt;p&gt;This was an intended decision as our developer decided to move away from Basic Authentication due to major security concern. Our devices will work only on Digest Authentication from now on. We did suggest our product management team and developers to re-enable Basic Authentication as some sort of &amp;#8220;optional&amp;#8221; feature able to be disabled by the user. However, this suggestion was&amp;nbsp;dismissed.&lt;/p&gt;
&lt;p&gt;The best situation for you at this point is to send back the cameras as, as stated, they won&amp;#8217;t work with Basic&amp;nbsp;Authentication.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It&amp;#8217;s worth pointing out at this point that the recent firmware versions for these cameras include &lt;span class="caps"&gt;HTTPS&lt;/span&gt; support, and even include support for either uploading your own &lt;span class="caps"&gt;TLS&lt;/span&gt; cert and key or generating a &lt;span class="caps"&gt;CSR&lt;/span&gt; on the camera and then uploading the signed certificate. &lt;span class="caps"&gt;TLS&lt;/span&gt; with Basic auth (i.e. &lt;span class="caps"&gt;API&lt;/span&gt; keys/tokens) is a widely accepted method in the world of public APIs, and would surely be sufficient for devices such as these cameras. In fact, Amcrest runs their own dynamic &lt;span class="caps"&gt;DNS&lt;/span&gt; service for (optional) remote access to cameras, so it should be relatively simple to leverage that and LetsEncrypt for automated certs. Instead - probably spurred on by the archaic &lt;span class="caps"&gt;ONVIF&lt;/span&gt; standard that specifies Digest authentication - they seem to be going the route of alleviating their &amp;#8220;major security concern&amp;#8221; by means of a 25-year-old authentication system based on &lt;span class="caps"&gt;MD5&lt;/span&gt; hashes, and likely quite easy to break offline given access to a successful authentication exchange and a &lt;span class="caps"&gt;GPU&lt;/span&gt;-based &lt;span class="caps"&gt;EC2&lt;/span&gt; instance (not to mention simple to&amp;nbsp;man-in-the-middle).&lt;/p&gt;
&lt;p&gt;So, being the obsessive person that I am, I started thinking about how to fix this. I went through the usual suspects for reverse proxying - Nginx, Apache, HAproxy, Lighttpd, etc. - and couldn&amp;#8217;t find any examples of existing solutions to handle Digest authentication for the upstream. While it would probably be &lt;em&gt;possible&lt;/em&gt;, most of my recent programming experience is in Python and Ruby with a handful of Groovy and &lt;span class="caps"&gt;JS&lt;/span&gt;, and none of those seemed to fit the bill. I spent a bit of time looking at simple &lt;span class="caps"&gt;HTTP&lt;/span&gt; proxy solutions in languages that I know (or at least sort-of know) and found the &lt;a href="https://github.com/nodejitsu/node-http-proxy"&gt;nodejitsu/node-http-proxy&lt;/a&gt; project. With a bit of experimentation I was able to get that working for the simple text-based &lt;span class="caps"&gt;API&lt;/span&gt; URLs but (as expected, looking at the source) it failed completely for the secondary &lt;span class="caps"&gt;MJPEG&lt;/span&gt; streams. I found and tried &lt;a href="https://github.com/legege/node-mjpeg-proxy"&gt;node-mjpeg-proxy&lt;/a&gt; next, but was unable to get it working&amp;nbsp;satisfactorily.&lt;/p&gt;
&lt;p&gt;After all of those experiments and research I decided that I should stop looking for an exsiting solution or magic bullet and go back to what I know best: Python. After only a few minutes more on Google, I stumbled on a complete gem in the form of a Flask snippet, &lt;a href="http://flask.pocoo.org/snippets/118/"&gt;Stream Proxy with Requests&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# -*- coding: utf-8 -*-&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Response&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;stream_with_context&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;

&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nd"&gt;@app.route&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;lt;path:url&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;home&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;req&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Response&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stream_with_context&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iter_content&lt;/span&gt;&lt;span class="p"&gt;()),&lt;/span&gt; &lt;span class="n"&gt;content_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;content-type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="python-digest-auth-removing-proxy"&gt;&lt;a class="toclink" href="#python-digest-auth-removing-proxy"&gt;Python Digest-Auth-Removing&amp;nbsp;Proxy&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Starting with the above snippet using &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; and &lt;a href="http://docs.python-requests.org/en/master/"&gt;requests&lt;/a&gt; - two Python packages that I&amp;#8217;m quite familiar with - I was able to quickly add the Digest authentication option to the requests call and achieve a working, auth-less &lt;span class="caps"&gt;MJPEG&lt;/span&gt; stream from the camera. With a bit of tuning, I came up with a rough proof-of-concept that provided unauthenticated access to the &lt;span class="caps"&gt;MJPEG&lt;/span&gt; stream and &lt;span class="caps"&gt;CGI&lt;/span&gt;-based &lt;span class="caps"&gt;API&lt;/span&gt; (including snapshots and &lt;span class="caps"&gt;PTZ&lt;/span&gt; control) simultaneously via multiple workers. It&amp;#8217;s not amazing; running on my desktop the &lt;span class="caps"&gt;MJPEG&lt;/span&gt; stream suffers some pretty bad latency that gets even worse when other &lt;span class="caps"&gt;CGI&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; endpoints are used simultaneously (I suspect this may be a problem on the camera&amp;nbsp;itself).&lt;/p&gt;
&lt;p&gt;Note that this does not proxy either non-&lt;span class="caps"&gt;MJPEG&lt;/span&gt; streams (i.e. the high-resolution &lt;span class="caps"&gt;RSTP&lt;/span&gt; stream) or the built-in web &lt;span class="caps"&gt;UI&lt;/span&gt; itself (which relies on client-side javascript XMLHttpRequest and cookies for&amp;nbsp;login).&lt;/p&gt;
&lt;p&gt;For the time being I&amp;#8217;m not sure if I&amp;#8217;m even going to use this proxy, but for anyone who&amp;#8217;s interested, the code is &lt;a href="https://github.com/jantman/python-amcrest-noauth-proxy"&gt;on GitHub&lt;/a&gt; along with a ready-to-run &lt;a href="https://hub.docker.com/r/jantman/python-amcrest-noauth-proxy/"&gt;Docker image&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="json-configuration-backups"&gt;&lt;a class="toclink" href="#json-configuration-backups"&gt;&lt;span class="caps"&gt;JSON&lt;/span&gt; Configuration&amp;nbsp;Backups&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;While looking into the Digest authentication changes, I used the configuration export/backup functionality (Export via the Setup web &lt;span class="caps"&gt;UI&lt;/span&gt;, or &lt;code&gt;/cgi-bin/Config.backup?action=All&lt;/code&gt; via the &lt;span class="caps"&gt;API&lt;/span&gt; for a more detailed config) to see if there was a chance that Digest/Basic was hidden somewhere in the config. It&amp;#8217;s not, but I was pleasantly surprised to see that the exported configuration file was plain and cleanly-deserializable &lt;span class="caps"&gt;JSON&lt;/span&gt; (even pretty-printed). This definitely makes it easier to back up configuration to a git repository and track changes over time, or make sweeping changes to defaults for provisioning new&amp;nbsp;cameras.&lt;/p&gt;
&lt;h1 id="api"&gt;&lt;a class="toclink" href="#api"&gt;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;For the majority of the last five-plus years of my career, I&amp;#8217;ve worked almost exclusively with software and generally with modern, well-known systems and services. Coming from a ReST-ful world, the Amcrest cameras&amp;#8217; &lt;span class="caps"&gt;API&lt;/span&gt; was a bit of a shock and trip back in time for me. While the current version (2.12) of the &lt;span class="caps"&gt;API&lt;/span&gt; documentation calls it a &amp;#8220;&lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;&amp;#8221;, the filename of the previous version that I found (1.51) is much more accurate: &lt;a href="https://s3.amazonaws.com/amcrest-files/AMCREST_CGI_SDK_API.pdf"&gt;AMCREST_CGI_SDK_API.pdf&lt;/a&gt;. While functional, the &lt;span class="caps"&gt;API&lt;/span&gt; appears to be a minimum-effort project to wrap (likely existing) system tooling on the camera in some sort of &lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt;. Some pertinent pieces of the &lt;span class="caps"&gt;API&lt;/span&gt; specification&amp;nbsp;include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Aside from &lt;span class="caps"&gt;RSTP&lt;/span&gt; streams, all paths are to &lt;span class="caps"&gt;CGI&lt;/span&gt; scripts - i.e. &lt;code&gt;/cgi-bin/mjpg/video.cgi&lt;/code&gt;, &lt;code&gt;/cgi-bin/configManager.cgi&lt;/code&gt;,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;Many of the paths use query parameters that sound like they map to command-line arguments, i.e. &lt;code&gt;/cgi-bin/configManager.cgi?action=getConfig&amp;amp;name=Snap&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;While the &lt;span class="caps"&gt;API&lt;/span&gt; specification defines &lt;span class="caps"&gt;HTTP&lt;/span&gt; status codes including 200, 400, 404, and 500, it also &lt;em&gt;clearly&lt;/em&gt; states (with examples) that &amp;#8220;fits with syntax but an error occurs while the server handles it&amp;#8221; will result in a &lt;span class="caps"&gt;HTTP&lt;/span&gt; 200 with a body containing a plain text error&amp;nbsp;message.&lt;/li&gt;
&lt;li&gt;The &lt;span class="caps"&gt;API&lt;/span&gt; appears to use the &lt;span class="caps"&gt;POST&lt;/span&gt; verb for anything that uploads a file, and &lt;span class="caps"&gt;GET&lt;/span&gt; for everything else. URLs that result in configuration changes or pan/tilt/zoom commands are still &lt;span class="caps"&gt;GET&lt;/span&gt;&amp;nbsp;requests.&lt;/li&gt;
&lt;li&gt;For query parameters (which drive the majority of the &lt;span class="caps"&gt;API&lt;/span&gt;), various &lt;span class="caps"&gt;CGI&lt;/span&gt; paths use either logically-named parameters (e.g. &amp;#8220;channel&amp;#8221;, &amp;#8220;action&amp;#8221;, etc.) or generic ones (&amp;#8220;arg1&amp;#8221;, &amp;#8220;arg2&amp;#8221;, &amp;#8220;arg3&amp;#8221;,&amp;nbsp;etc.).&lt;/li&gt;
&lt;li&gt;While the &lt;span class="caps"&gt;JSON&lt;/span&gt; configuration file format was a welcome surprise, &lt;span class="caps"&gt;API&lt;/span&gt; endpoints that return textual responses (as opposed to image/video/audio) respond with line-based key/value pairs separated by equal&amp;nbsp;signs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I imagine that much of this is dictated by needing to support Amcrest&amp;#8217;s network video recorder products, and perhaps some of it is also dictated by their manufacturer Dahua (Amcrest&amp;#8217;s products seem to be running customized and branded Dahua software, and likely hardware too). While much of this &lt;span class="caps"&gt;API&lt;/span&gt; is simpler for me to work with than the &lt;span class="caps"&gt;SOAP&lt;/span&gt;- and &lt;span class="caps"&gt;WSDL&lt;/span&gt;-based &lt;span class="caps"&gt;ONVIF&lt;/span&gt; standard, I&amp;#8217;d still be much happier if the devices exposed a modern ReST/&lt;span class="caps"&gt;JSON&lt;/span&gt;&amp;nbsp;&lt;span class="caps"&gt;API&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;There &lt;em&gt;is&lt;/em&gt; a Python package, &lt;a href="http://python-amcrest.readthedocs.io/"&gt;python-amcrest&lt;/a&gt;, that claims to provide a native Python client for this &lt;span class="caps"&gt;CGI&lt;/span&gt; &lt;span class="caps"&gt;API&lt;/span&gt; but I haven&amp;#8217;t tried it&amp;nbsp;yet.&lt;/p&gt;
&lt;h1 id="alarms-events-initial-research"&gt;&lt;a class="toclink" href="#alarms-events-initial-research"&gt;Alarms / Events - Initial&amp;nbsp;Research&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;These cameras support a number of internal &amp;#8220;alarms&amp;#8221; for events such as motion detection (likely nowhere near as good as Motion or ZoneMinder), video loss, audio detection, failed logins, disk (optional &lt;span class="caps"&gt;SD&lt;/span&gt; card) missing, error or full, network disconnect or &lt;span class="caps"&gt;IP&lt;/span&gt; conflict, or external alarms (the ProHD has four analog relay input/output connections on the back that can be used for either external trigger inputs or outputs). I&amp;#8217;m not concerned with most of them and currently don&amp;#8217;t have &lt;span class="caps"&gt;SD&lt;/span&gt; cards in the cameras, but I am interested in the &amp;#8220;Video Tamper&amp;#8221; alarm that detects loss of picture such as when the lens is obstructed. So, I began a bit of research into what options were available for receiving these alarms. Of course I wasn&amp;#8217;t lucky enough to see a webhook or &lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;GET&lt;/span&gt;/&lt;span class="caps"&gt;POST&lt;/span&gt; delivery method, let alone &lt;span class="caps"&gt;SNS&lt;/span&gt; or &lt;span class="caps"&gt;SQS&lt;/span&gt;. The options for alarm handling are recording, triggering one of the relays (on the ProHD that supports them), taking a snapshot, sending email, or polling the &lt;span class="caps"&gt;API&lt;/span&gt; for alarm events. The ProHD also supposedly supports &lt;span class="caps"&gt;SNMP&lt;/span&gt; traps, though they&amp;#8217;re not explicitly listed as an event&amp;nbsp;action.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; Upon review of the &lt;span class="caps"&gt;API&lt;/span&gt; documentation, it appears that it&amp;#8217;s also possible to &amp;#8220;subscribe&amp;#8221; to events via &lt;span class="caps"&gt;HTTP&lt;/span&gt;/&lt;span class="caps"&gt;CGI&lt;/span&gt;. This &lt;span class="caps"&gt;API&lt;/span&gt; appears to be a &lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;GET&lt;/span&gt; that responds with a &lt;code&gt;multipart/x-mixed-replace&lt;/code&gt; content-type and streams plaintext event descriptions to the client as they occur. The client must send keepalive data to the server every 1 to 60 seconds (helpfully, the doc states that the keepalive data can be the string &amp;#8220;keep&amp;nbsp;alive&amp;#8221;).&lt;/p&gt;
&lt;p&gt;Given those options, I decided that either &lt;span class="caps"&gt;SNMP&lt;/span&gt; or &amp;#8220;email&amp;#8221; (&lt;span class="caps"&gt;SMTP&lt;/span&gt;) would be the best bet for programmatically receiving the events and acting on&amp;nbsp;them.&lt;/p&gt;
&lt;h2 id="snmp"&gt;&lt;a class="toclink" href="#snmp"&gt;&lt;span class="caps"&gt;SNMP&lt;/span&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The latest firmware for the &lt;span class="caps"&gt;IPM&lt;/span&gt;-723W, &amp;#8220;15.R&amp;#8221;, doesn&amp;#8217;t appear to support &lt;span class="caps"&gt;SNMP&lt;/span&gt; at all; it&amp;#8217;s missing the &amp;#8220;Setup&amp;#8221; -&amp;gt; &amp;#8220;Network&amp;#8221; -&amp;gt; &amp;#8220;&lt;span class="caps"&gt;SNMP&lt;/span&gt;&amp;#8221; configuration that the ProHD running &amp;#8220;18.R&amp;#8221; software has. So it seems like &lt;span class="caps"&gt;SNMP&lt;/span&gt; isn&amp;#8217;t going to be a viable option for me but I wanted to explore it anyway. I enabled &lt;span class="caps"&gt;SNMP&lt;/span&gt; v1 with the default &amp;#8220;public&amp;#8221; read community and issued a quick &lt;code&gt;snmpwalk&lt;/code&gt;. There wasn&amp;#8217;t a whole lot aside from what I&amp;#8217;d expect to find on a typical Linux device (&lt;span class="caps"&gt;SNMP&lt;/span&gt;*-&lt;span class="caps"&gt;MIB&lt;/span&gt;, &lt;span class="caps"&gt;IF&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;, &lt;span class="caps"&gt;TCP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;, &lt;span class="caps"&gt;IP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;, etc.). The sum of the interesting parts&amp;nbsp;was:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.10 = &lt;span class="caps"&gt;OID&lt;/span&gt;: SNMPv2-&lt;span class="caps"&gt;SMI&lt;/span&gt;::enterprises.1004849.2.1.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.11 = &lt;span class="caps"&gt;OID&lt;/span&gt;: SNMPv2-&lt;span class="caps"&gt;SMI&lt;/span&gt;::enterprises.1004849.2.1.2
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.12 = &lt;span class="caps"&gt;OID&lt;/span&gt;: SNMPv2-&lt;span class="caps"&gt;SMI&lt;/span&gt;::enterprises.1004849.2.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.13 = &lt;span class="caps"&gt;OID&lt;/span&gt;: SNMPv2-&lt;span class="caps"&gt;SMI&lt;/span&gt;::enterprises.1004849.2.2.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.14 = &lt;span class="caps"&gt;OID&lt;/span&gt;: SNMPv2-&lt;span class="caps"&gt;SMI&lt;/span&gt;::enterprises.1004849.2.2.2
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.15 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.16 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.17 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.18 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.19 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.20 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.21 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.22 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.23 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.24 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORID.25 = &lt;span class="caps"&gt;OID&lt;/span&gt;: ccitt.1
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.10 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: Dahua &lt;span class="caps"&gt;SNMP&lt;/span&gt; Mib Module -- System oidVersionInfo
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.11 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: Dahua &lt;span class="caps"&gt;SNMP&lt;/span&gt; Mib Module -- System oidProductInfo
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.12 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: Dahua &lt;span class="caps"&gt;SNMP&lt;/span&gt; Mib Module -- System oidSysetmInfo
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.13 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: Dahua &lt;span class="caps"&gt;SNMP&lt;/span&gt; Mib Module -- network oidNetworkPort
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.14 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: Dahua &lt;span class="caps"&gt;SNMP&lt;/span&gt; Mib Module -- network oidTcpIpInfo
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.15 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: RegularStreamInfoTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.16 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: MDStreamInfoTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.17 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: AlarmStreamInfoTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.18 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: Extra1StreamInfoTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.19 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: VideoMotionInfoTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.20 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: VideoLossInfoTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.21 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: VideoBlindInfoTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.22 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: LocalAlarmInfoTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.23 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: NetworkAlarmTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.24 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: RecordMainStreamInfoTable
SNMPv2-&lt;span class="caps"&gt;MIB&lt;/span&gt;::sysORDescr.25 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: PhysicalVolumeInfoTable
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It appears that there are two sets of custom MIBs exposed, one from their manufacturer Dahua and another presumably from Amcrest and claiming to be exposed at &amp;#8220;.0.1&amp;#8221; (ccitt.1). I&amp;#8217;ve been completely unable to get anything out of the Amcrest MIBs (sysORID&amp;#8217;s 15 through 25; ccitt.1) and have presumed them to be broken; the &lt;a href="https://amcrest.com/forum/technical-discussion-f3/snmp-t1045.html"&gt;one thread on the Amcrest forums&lt;/a&gt; about this seems to concur. For the Dahua OIDs, neither Amcrest nor Dahua appear to publish the MIBs but thanks to a &lt;a href="https://github.com/librenms/librenms/issues/8126"&gt;LibreNMS issue&lt;/a&gt;, &lt;a href="https://ipcamtalk.com/threads/snmp-mib.25434/"&gt;IPcamTalk forum thread&lt;/a&gt; and &lt;a href="https://www.reddit.com/r/homedefense/comments/7n0bhj/dahua_nvr_looking_for_snmp_mib_files/"&gt;reddit post&lt;/a&gt; I was able to find them. The information I got from walking that &lt;span class="caps"&gt;OID&lt;/span&gt; tree with the appropriate &lt;span class="caps"&gt;MIB&lt;/span&gt; from those links didn&amp;#8217;t prove terribly&amp;nbsp;useful:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::softwareRevision.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: 2.520.&lt;span class="caps"&gt;AC00&lt;/span&gt;.18.R
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::hardwareRevision.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: 1.00
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::videoChannel.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 0
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::alarmInput.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 1
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::alarmOutput.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 1
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::serialNumber.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: &lt;span class="caps"&gt;AMC00056485D24AAF8&lt;/span&gt;
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::systemVersion.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: 2.520.0000.18, Build Date:2017-06-29
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::deviceType.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: &lt;span class="caps"&gt;IP2M&lt;/span&gt;-841B
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::deviceClass.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: &lt;span class="caps"&gt;IPC&lt;/span&gt;
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::deviceStatus.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 1
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::machineName.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: AMC00056_24AAF8
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::cpuUsage.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 70
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::lastestEvent.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: videoBlindEvent
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::encodeNo.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 0
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::tcpPort.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 37777
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::udpPort.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 37778
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::httpPort.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 80
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::rtspPort.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 554
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::maxConnectNum.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 10
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::httpsPort.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 443
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::getIpmode.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 0
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::macAddr.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: 9c:8e:cd:xx:xx:xx
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::ipVersion.0 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 0
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::subnetMast.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: 255.255.255.0
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::defaultGateway.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: 192.168.0.1
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::preferredDns.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: 192.168.0.1
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::alternateDns.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: 1.0.0.1
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::ipAddr.0 = &lt;span class="caps"&gt;STRING&lt;/span&gt;: 192.168.0.60
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::localAlarmIndex.1 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 1
&lt;span class="caps"&gt;DAHUA&lt;/span&gt;-&lt;span class="caps"&gt;SNMP&lt;/span&gt;-&lt;span class="caps"&gt;MIB&lt;/span&gt;::networkAlarmIndex.1 = &lt;span class="caps"&gt;INTEGER&lt;/span&gt;: 1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So&amp;#8230; nothing terribly interesting. I&amp;#8217;m planning on seeing what I can get from the &lt;span class="caps"&gt;SNMP&lt;/span&gt; traps, but since only one of my cameras supports them (and they&amp;#8217;re &lt;span class="caps"&gt;UDP&lt;/span&gt;) I&amp;#8217;m not planning on using them for actually receiving&amp;nbsp;events/alarms.&lt;/p&gt;
&lt;h2 id="smtp"&gt;&lt;a class="toclink" href="#smtp"&gt;&lt;span class="caps"&gt;SMTP&lt;/span&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With &lt;span class="caps"&gt;SNMP&lt;/span&gt; out of the running for receiving alarms, I turned to &lt;span class="caps"&gt;SMTP&lt;/span&gt;. The configuration page I was greeted with, as well as its pop-up help page, left me slightly confused and&amp;nbsp;unsettled:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/amcrest_smtp_config.png"&gt;&lt;img alt="screenshot of Amcrest camera SMTP configuration page and help pop-up" src="/GFX/amcrest_smtp_config_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When I finally muddled through the options and poor translation - checking the &amp;#8220;Login Anonymously&amp;#8221; checkbox directly above the &lt;span class="caps"&gt;SMTP&lt;/span&gt; username and password actually enables authentication, i.e. disables non-&lt;span class="caps"&gt;AUTH&lt;/span&gt;/anonymous &lt;span class="caps"&gt;SMTP&lt;/span&gt; - I found that support for anonymous &lt;span class="caps"&gt;SMTP&lt;/span&gt; (i.e. without &lt;span class="caps"&gt;AUTH&lt;/span&gt;) is completely broken. When setting unchecking the &amp;#8220;Login anonymously&amp;#8221; box (i.e. no &lt;span class="caps"&gt;AUTH&lt;/span&gt;), the &lt;span class="caps"&gt;UI&lt;/span&gt; displays the same &amp;#8220;Email test failed&amp;#8221; error message as with bad credentials, but (per Wireshark/tcpdump) it never actually sends &lt;em&gt;any&lt;/em&gt; traffic to the &lt;span class="caps"&gt;SMTP&lt;/span&gt; server at all. I found a &lt;a href="https://amcrest.com/forum/technical-discussion-f3/email-test-always-fails-brand-new-camera-t1104-s10.html"&gt;forum thread&lt;/a&gt; going back &lt;strong&gt;almost two years&lt;/strong&gt; confirming&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;I quickly hacked together a &lt;span class="caps"&gt;SMTP&lt;/span&gt; server that accepts any credentials and prints the message to &lt;span class="caps"&gt;STDOUT&lt;/span&gt; (based on &lt;a href="https://github.com/bcoe/secure-smtpd"&gt;secure-smtpd&lt;/a&gt;), pointed the camera&amp;#8217;s &lt;span class="caps"&gt;SMTP&lt;/span&gt; settings to it, and then threw a black shirt over the lens of the camera. Within a minute or so, I got the following message via my dummy &lt;span class="caps"&gt;SMTP&lt;/span&gt;&amp;nbsp;server:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Date: Sun, 06 May 2018 15:28:45 -0600
From: &amp;lt;&amp;gt;
To: &amp;lt;jason@jasonantman.com&amp;gt;
Subject: =?&lt;span class="caps"&gt;UTF&lt;/span&gt;-8?B?SVBDIE1lc3NhZ2U=?=
&lt;span class="caps"&gt;MIME&lt;/span&gt;-Version: 1.0
Content-type: multipart/mixed;boundary=&amp;quot;======DAHUA_TECH======&amp;quot;

This is a multi-part message in &lt;span class="caps"&gt;MIME&lt;/span&gt; format.

--======DAHUA_TECH======
Content-Type: text/plain;
        charset=&lt;span class="caps"&gt;UTF&lt;/span&gt;-8
Content-Transfer-Encoding: base64

QWxhcm0gRXZlbnQ6IFRhbXBlciBEZXRlY3QNCkFsYXJtIElucHV0IENoYW5uZWw6IDENCkFsYXJt
IFN0YXJ0IFRpbWUoRC9NL1kgSDpNOlMpOiAwNi8wNS8yMDE4IDE1OjI4OjQwDQpBbGFybSBEZXZp
Y2UgTmFtZTogQU1DMDAwNTZfMjRBQUY4DQpBbGFybSBOYW1lOiANCklQIEFkZHJlc3M6IDE5Mi4x
NjguMC42MA0K



--======DAHUA_TECH======
Content-Type: application/octet-stream;
        name=&amp;quot;20180506152840423ch01.jpg&amp;quot;
Content-Disposition: attachment;
        filename=&amp;quot;20180506152840423ch01.jpg&amp;quot;
Content-Transfer-Encoding: base64
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The second attachment is a full 1920x1080 snapshot of the video. I was a bit confused to see the &lt;span class="caps"&gt;UTF&lt;/span&gt;-8 base64-encoded subject, but the base64-decoded Subject is &amp;#8220;&lt;span class="caps"&gt;IPC&lt;/span&gt; Message&amp;#8221; and body text&amp;nbsp;is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Alarm Event: Tamper Detect
Alarm Input Channel: 1
Alarm Start Time(D/M/Y H:M:S): 06/05/2018 15:28:40
Alarm Device Name: AMC00056_24AAF8
Alarm Name:
&lt;span class="caps"&gt;IP&lt;/span&gt; Address: 192.168.0.60
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since the only alarm/event I really care about is loss of picture, and motion detection software should be able to handle the same task, I&amp;#8217;m going to completely ignore the alarm/event features for now and focus on the camera solely as a video&amp;nbsp;source.&lt;/p&gt;
&lt;h1 id="system-logs"&gt;&lt;a class="toclink" href="#system-logs"&gt;System&amp;nbsp;logs&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The cameras keep rudimentary &amp;#8220;system logs&amp;#8221; which include events (e.g. video tamper/video loss) as well as login/logout from the web &lt;span class="caps"&gt;UI&lt;/span&gt; as well as &lt;span class="caps"&gt;API&lt;/span&gt;, configuration saves, and &amp;#8220;Set Time&amp;#8221; events which perplex me as they show web &lt;span class="caps"&gt;UI&lt;/span&gt; client IPs as the source. These logs are available via a searchable table in the web &lt;span class="caps"&gt;UI&lt;/span&gt;, as well as &lt;span class="caps"&gt;CGI&lt;/span&gt; access to either page through logs filtered by date/time or return a &amp;#8220;log backup&amp;#8221; file of all logs between a given start and end time. Unfortunately, they don&amp;#8217;t support syslog or any other remote log&amp;nbsp;aggregation.&lt;/p&gt;
&lt;h1 id="gpl-compliance"&gt;&lt;a class="toclink" href="#gpl-compliance"&gt;&lt;span class="caps"&gt;GPL&lt;/span&gt;&amp;nbsp;Compliance&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Between the &lt;span class="caps"&gt;SNMP&lt;/span&gt; output and nmap results, as well as some other information exposed in the documentation and user interface, I&amp;#8217;m certain that these devices are running Linux and &lt;a href="https://www.ffmpeg.org/"&gt;FFmpeg&lt;/a&gt; (LGPLv2). I&amp;#8217;ve also seen some things that make it highly likely that they&amp;#8217;re also running &lt;a href="https://busybox.net/"&gt;busybox&lt;/a&gt; (GPLv2) and the other common embedded Linux utilities. However, I was unable to find any open source license information or source code offer in the packaging and printed documentation that came with either camera, or on Amcrest&amp;#8217;s website or user documentation. I&amp;#8217;ve posted a &lt;a href="https://amcrest.com/forum/technical-discussion-f3/source-code-availability--t8163.html"&gt;thread&lt;/a&gt; in Amcrest&amp;#8217;s technical discussion forums inquiring about this but don&amp;#8217;t expect much response from them. If I have time, I may try downloading one of the firmware images and doing some simple tests like running it through &lt;code&gt;strings&lt;/code&gt; to see if I can spot any well-known copyright headers. But as far as I can&amp;nbsp;tell,&lt;/p&gt;
&lt;h1 id="auto-maintain"&gt;&lt;a class="toclink" href="#auto-maintain"&gt;Auto&amp;nbsp;Maintain&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The cameras both came out-of-the-box with the &amp;#8220;Auto maintain&amp;#8221; feature enabled, which&amp;#8230; reboots the cameras automatically once a week. By default, on Thursday mornings just after 3am&amp;nbsp;local.&lt;/p&gt;
&lt;p&gt;Having spent some time in the past developing embedded Linux network devices, this does &lt;em&gt;not&lt;/em&gt; give me a terribly confident feeling about the&amp;nbsp;software.&lt;/p&gt;
&lt;h1 id="status-and-next-steps"&gt;&lt;a class="toclink" href="#status-and-next-steps"&gt;Status and Next&amp;nbsp;Steps&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;To wrap up, I currently have two Amcrest &lt;span class="caps"&gt;IP&lt;/span&gt; cameras running on my home network; one looking out the front window, and one (indoor pan/tilt) overlooking my dogs&amp;#8217; crates. Now that I have them configured for the basics, I&amp;#8217;m going to attempt to ignore Amcrest&amp;#8217;s irritating software and focus on the cameras solely as video sources. My next steps - hopefully in a follow-up post not too long from now - will&amp;nbsp;include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evaluation of Linux-based video surveillance recording/streaming/motion detection software, and choosing one to use. This will likely come down to choosing between something with an existing multi-camera web interface (ZoneMinder, or perhaps one of the newer variants) or something to handle motion detection only (Motion, or a modern variant) and cobbling together a simple web &lt;span class="caps"&gt;UI&lt;/span&gt; for streaming and event&amp;nbsp;viewing.&lt;/li&gt;
&lt;li&gt;Experimenting with using &lt;span class="caps"&gt;ONVIF&lt;/span&gt; instead of the &lt;span class="caps"&gt;CGI&lt;/span&gt;&amp;nbsp;interface.&lt;/li&gt;
&lt;li&gt;Expermenting with FFmpeg or something else to restream the video instead of trying to remove authentication in a&amp;nbsp;proxy.&lt;/li&gt;
&lt;li&gt;Possibly using &lt;a href="http://python-amcrest.readthedocs.io/"&gt;python-amcrest&lt;/a&gt; as a wrapper around the &lt;span class="caps"&gt;CGI&lt;/span&gt;&amp;nbsp;interface.&lt;/li&gt;
&lt;li&gt;Figuring out a system to notify me of important events such as motion, video loss, or connectivity loss to a&amp;nbsp;camera.&lt;/li&gt;
&lt;li&gt;The cameras support &lt;span class="caps"&gt;SD&lt;/span&gt; cards and a built-in simple &lt;span class="caps"&gt;DVR&lt;/span&gt; feature. I may get cards for them and configure them to record on network connection loss, just as a&amp;nbsp;test.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; The next post in this series is up, &lt;a href="/2018/05/linux-surveillance-camera-software-evaluation"&gt;Linux Surveillance Camera Software Evaluation&lt;/a&gt;.&lt;/p&gt;</content><category term="amcrest"></category><category term="camera"></category><category term="security"></category><category term="surveillance"></category><category term="video"></category></entry><entry><title>DIY Raspberry Pi Zero GPS Track Logger</title><link href="https://blog.jasonantman.com/2018/03/diy-raspberry-pi-zero-gps-track-logger/" rel="alternate"></link><published>2018-03-06T16:00:00-05:00</published><updated>2018-03-06T16:00:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-03-06:/2018/03/diy-raspberry-pi-zero-gps-track-logger/</id><summary type="html">&lt;p&gt;Simple &lt;span class="caps"&gt;DIY&lt;/span&gt; Raspberry Pi Zero &lt;span class="caps"&gt;USB&lt;/span&gt; &lt;span class="caps"&gt;GPS&lt;/span&gt; logger, with code and&amp;nbsp;instructions.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last weekend I was out hiking with one of my dogs when I realized that I didn&amp;#8217;t know the exact length of the route we were taking. We were at the &lt;a href="http://arabiaalliance.org/explore/plan-your-visit/visit-davidson-arabia-nature-preserve/"&gt;Davidson-Arabia Nature Preserve&lt;/a&gt;, part of the Arabia Mountain National Heritage Area, only about 20 minutes from home. It&amp;#8217;s a wonderful afternoon hike for me since it&amp;#8217;s so close to home and the trails are easy. It&amp;#8217;s also a laid back hike - the area is only about 2.1 square miles (5.4 sq. km.) bordered on all sides by well-traveled roads or suburban neighborhoods and dominated by Arabia Mountain and a lake - with many trails and high traffic, so I&amp;#8217;m less concerned about navigation than I would be in the backcountry. However, since my usual route covers portions of two trails and a cut-through between them, I don&amp;#8217;t know what the actual distance&amp;nbsp;is.&lt;/p&gt;
&lt;p&gt;At first it seemed like the logical solution to this would be tracking hikes on my phone using one of the many apps for this (or a similar) purpose. But that didn&amp;#8217;t seem like a good solution to me for a number of reasons. First, my current phone is an aging Samsung Galaxy S6 (I tend to buy the best phone available at the time, and keep it until it dies) and the battery life is far from what it used to be. I carry an external battery pack for it, but frequently polling &lt;span class="caps"&gt;GPS&lt;/span&gt; position is extremely power intensive on any phone; I&amp;#8217;d rather leave my phone for tasks that actually require it  like communication, weather, and checking some of the great digital maps that are available. More importantly, the &lt;span class="caps"&gt;GPS&lt;/span&gt; antennas in most smartphones seem to be rather position sensitive and I haven&amp;#8217;t gotten very good results recording an accurate track with my phone in my pocket or belt holster, let alone in my pack (where it often is on more challenging&amp;nbsp;terrain).&lt;/p&gt;
&lt;p&gt;I started looking at the commercial &lt;span class="caps"&gt;GPS&lt;/span&gt; loggers available online, but few of them seemed like compelling choices for the cost. Then I realized that I could probably piece one together at no cost using parts that I already had, namely a &lt;a href="https://www.raspberrypi.org/products/raspberry-pi-zero/"&gt;RaspberryPi Zero&lt;/a&gt;, &lt;span class="caps"&gt;USB&lt;/span&gt; &lt;span class="caps"&gt;GPS&lt;/span&gt;, and the &lt;a href="https://www.amazon.com/gp/product/B01JIYWUBA/"&gt;10Ah external battery pack&lt;/a&gt; I use for my phone. It turns out that the &lt;a href="https://www.amazon.com/gp/product/B000FPILZG/"&gt;Deluo 31-311-01 &lt;span class="caps"&gt;USB&lt;/span&gt; &lt;span class="caps"&gt;GPS&lt;/span&gt;&lt;/a&gt; I bought a decade ago has been lost to time, likely thrown out in one of the electronics purges I&amp;#8217;ve done over the past few years. But I was able to get a new SiRF Star &lt;span class="caps"&gt;IV&lt;/span&gt;-based &lt;a href="https://www.amazon.com/gp/product/B008200LHW/"&gt;GlobalSat &lt;span class="caps"&gt;BU&lt;/span&gt;-353-S4 &lt;span class="caps"&gt;USB&lt;/span&gt; &lt;span class="caps"&gt;GPS&lt;/span&gt;&lt;/a&gt; on Amazon. The manufacturer&amp;#8217;s specifications sound quite nice and even though the &lt;a href="http://www.catb.org/gpsd/hardware.html"&gt;gpsd hardware list&lt;/a&gt; rates it extremely poorly, once I received it in the mail I unboxed it and set it on the sill inside my window and was able to get a very accurate fix in about a&amp;nbsp;minute.&lt;/p&gt;
&lt;h2 id="the-result"&gt;&lt;a class="toclink" href="#the-result"&gt;The&amp;nbsp;Result&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="/GFX/pizero_gpslogger_1.jpg"&gt;&lt;img alt="Photograph of finished hardware next to playing card deck for size comparison" src="/GFX/pizero_gpslogger_1_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The solution I came up with uses the very stable and mature &lt;a href="http://www.catb.org/gpsd/"&gt;gpsd daemon&lt;/a&gt; to handle communication with the &lt;span class="caps"&gt;GPS&lt;/span&gt; and caching the last position information, and a small Python daemon to read from &lt;code&gt;gpsd&lt;/code&gt; and log to the RaspberryPi&amp;#8217;s &lt;span class="caps"&gt;SD&lt;/span&gt; card using gpsd&amp;#8217;s full &lt;span class="caps"&gt;JSON&lt;/span&gt; data format. The Pi itself is running the &lt;a href="https://www.raspbian.org/"&gt;Raspbian&lt;/a&gt; Linux distribution with virtually no customization, and all of the default services (plus &lt;span class="caps"&gt;SSH&lt;/span&gt;) running out of laziness. I also added two status LEDs driven by the board&amp;#8217;s &lt;span class="caps"&gt;GPIO&lt;/span&gt;, to give visual indication of the position fix state and &lt;span class="caps"&gt;SD&lt;/span&gt; card writes. Unlike many of the commercial &lt;span class="caps"&gt;GPS&lt;/span&gt; loggers available which log data every 60 seconds, my code defaults to 5-second intervals (that, along with most other parameters, are configurable via environment variables). My code (along with detailed instructions, an installation script, and a script to convert from gpsd &lt;span class="caps"&gt;JSON&lt;/span&gt; format to standard &lt;a href="https://en.wikipedia.org/wiki/GPS_Exchange_Format"&gt;&lt;span class="caps"&gt;GPX&lt;/span&gt;&lt;/a&gt;) is available at &lt;a href="https://github.com/jantman/pizero-gpslog"&gt;https://github.com/jantman/pizero-gpslog&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="hardware"&gt;&lt;a class="toclink" href="#hardware"&gt;Hardware&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="/GFX/pizero_gpslogger_2.jpg"&gt;&lt;img alt="Photograph of finished hardware inside backpack" src="/GFX/pizero_gpslogger_2_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This all fits conveniently in my hiking pack inside the mesh bag that the battery pack came in. I plan on putting the Pi and battery safely inside the main compartment (I can unzip it periodically to check that the &lt;span class="caps"&gt;GPS&lt;/span&gt; has a fix and is logging) and dangling the &lt;span class="caps"&gt;GPS&lt;/span&gt; receiver out the zipper, affixed between the zipper pulls of the smaller compartment (with a hair elastic&amp;#8230;). This seems to be relatively horizontal, but I may also experiment with taping the &lt;span class="caps"&gt;GPS&lt;/span&gt; to the carry handle on top of the pack, or packing all of it into the top outside&amp;nbsp;pocket.&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/pizero_gpslogger_3.jpg"&gt;&lt;img alt="Front angle pohotograph of GPS affixed to outside of pack" src="/GFX/pizero_gpslogger_3_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/pizero_gpslogger_4.jpg"&gt;&lt;img alt="Side angle photograph of GPS affixed to outside of pack" src="/GFX/pizero_gpslogger_4_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s worth mention that my hardware choice was largely dependent on what I already had or what I thought I could reuse for other projects. While the &lt;span class="caps"&gt;GPS&lt;/span&gt; receiver is small and lightweight - about 2&amp;#8221; (5cm) around and about 2 ounces (57g) - I could have saved a fair amount of space and some weight by purchasing a component &lt;span class="caps"&gt;GPS&lt;/span&gt; to connect to the Pi via &lt;span class="caps"&gt;GPIO&lt;/span&gt; and mount directly to the Pi itself. I decided to get a &lt;span class="caps"&gt;USB&lt;/span&gt; model as it will be more useful to me for other projects as well. Some space and weight could also be saved by using a simpler microcontroller than the Pi Zero (this application certainly doesn&amp;#8217;t need the power of a Pi, or a full Linux system) but I used what I had&amp;nbsp;handy.&lt;/p&gt;
&lt;p&gt;The full system as I have it set up weighs 11.5 ounces (326g) which is quite heavy by the standards of serious hikers. However, 7 ounces (203g) of that is the 10,000mAh external battery pack which I already had for my cell phone. This battery can run the logger for 42 hours continuously, which is definitely overkill for my purposes. I could likely cut the weight in half if I used a more appropriately-sized battery; Anker, a company whose products I really like, makes a $15 &lt;a href="https://www.amazon.com/dp/B005X1Y7I2"&gt;3350mAh &lt;span class="caps"&gt;USB&lt;/span&gt; battery pack&lt;/a&gt; that weighs in at just 3oz (85g), to say nothing of the lighter Pi-specific options&amp;nbsp;available.&lt;/p&gt;
&lt;p&gt;As-is, this hardware allows me to continuously log &lt;span class="caps"&gt;GPS&lt;/span&gt; fixes every 5 seconds for 42 hours, consuming about &lt;span class="caps"&gt;40MB&lt;/span&gt; for the data. Each data point is approximately 1400 bytes, and the &lt;span class="caps"&gt;8GB&lt;/span&gt; microSD card I use (5.6G free after &lt;span class="caps"&gt;OS&lt;/span&gt; and software) has space to log about &lt;strong&gt;240 days&lt;/strong&gt; of data at this&amp;nbsp;interval.&lt;/p&gt;
&lt;h2 id="initial-tests"&gt;&lt;a class="toclink" href="#initial-tests"&gt;Initial&amp;nbsp;Tests&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My first test, as described above, was just a test of the &amp;#8220;cold fix&amp;#8221; speed for the &lt;span class="caps"&gt;BU&lt;/span&gt;-353-S4 &lt;span class="caps"&gt;GPS&lt;/span&gt; after unboxing. Sitting on the sill inside a residential window with a view of half the sky at best, I got a fix accurate to 3-4 meters within about a&amp;nbsp;minute.&lt;/p&gt;
&lt;p&gt;My next test was placing the &lt;span class="caps"&gt;GPS&lt;/span&gt; on the dash of my car during a quick five-mile trip to the grocery store and gas station. The results were shockingly accurate: not only did the unit perform perfectly as intended, but when I converted the logs to &lt;span class="caps"&gt;GPX&lt;/span&gt; format and used &lt;a href="http://www.gpsvisualizer.com/"&gt;gpsvisualizer.com&lt;/a&gt; to overlay them on Google Maps, I could clearly see my route down to which side of the road I was driving on, the exact space I parked in, and which gas pump I&amp;nbsp;used.&lt;/p&gt;
&lt;p&gt;I also did a test of the total time that I can capture data using the 10Ah battery pack and &lt;span class="caps"&gt;8GB&lt;/span&gt; &lt;span class="caps"&gt;SD&lt;/span&gt; card. This might be a very slight amount unrealistic, since the &lt;span class="caps"&gt;GPS&lt;/span&gt; was stationary most of the time. After doing the above driving test I set the &lt;span class="caps"&gt;GPS&lt;/span&gt; up on the inside sill of my bedroom window and let it run. And run. And drove to work the next day with it on the dashboard of my car, left it in the car during my work day (on the bottom floor of a 4-story parking deck, where a &lt;span class="caps"&gt;GPS&lt;/span&gt; fix is impossible to get), drove home, put it back on the window sill, and eventually fell asleep. Sometime during the night, at the 42-hour mark, the battery finally gave out. The total space used for 42 hours of data was approximately&amp;nbsp;&lt;span class="caps"&gt;40MB&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="source-code"&gt;&lt;a class="toclink" href="#source-code"&gt;Source&amp;nbsp;Code&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For code, detailed hardware information, and instructions see: &lt;a href="https://github.com/jantman/pizero-gpslog"&gt;https://github.com/jantman/pizero-gpslog&lt;/a&gt;.&lt;/p&gt;</content><category term="embedded"></category><category term="gps"></category><category term="hiking"></category><category term="logger"></category><category term="raspberrypi"></category></entry><entry><title>Raspberry Pi Security System</title><link href="https://blog.jasonantman.com/2016/01/raspberry-pi-security-system/" rel="alternate"></link><published>2016-01-16T10:00:00-05:00</published><updated>2016-01-16T10:00:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2016-01-16:/2016/01/raspberry-pi-security-system/</id><summary type="html">&lt;p&gt;A Raspberry Pi and webcam security&amp;nbsp;system.&lt;/p&gt;</summary><content type="html">&lt;div class="alert alert-warning" role="alert"&gt;&lt;strong&gt;Notice/Disclaimer:&lt;/strong&gt; The information I provide on home automation/security and surveillance is based on what I&amp;#8217;ve set up for myself based on a balance of cost, ease of use, and security, and should be considered for hobby purposes only. My current system and code has grown organically over time and is not how I&amp;#8217;d approach this if I started over from scratch. My code and system has a few obvious vulnerabilities and probably some non-obvious ones as well; I humbly but sincerely ask that you do not attempt to exploit these. I highly recommend that anyone implementing a similar system - especially if you also publish the details of it - have undocumented backup systems/devices. Finally, the systems that I describe are intended to provide some protection against or notification of crimes of opportunity, not targeted attacks. Please keep in mind that none of this is intended to protect against someone who targets &lt;em&gt;me&lt;/em&gt; specifically (and takes the time to research me) as opposed to my home at random.&lt;/div&gt;

&lt;p&gt;It seems that crime is on the rise in the area where I live, and in my &amp;#8220;gated&amp;#8221; (when they actually close)
apartment complex. I&amp;#8217;m going out of town for a while to visit family, and was a bit wary of leaving my
apartment - and all of my posessions, and most importantly my cats, unattended for too long. I&amp;#8217;m having
some family in the area check on the cats every few days, but that doesn&amp;#8217;t do a lot for my peace of mind
in a complex that&amp;#8217;s had a few break-ins this&amp;nbsp;year.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve played around on previous trips with with &lt;a href="http://www.lavrsen.dk/foswiki/bin/view/Motion/WebHome"&gt;motion&lt;/a&gt;, a motion-activated video recording tool,
and a &lt;a href="http://www.amazon.com/Logitech-960-000585-HD-Webcam-C310/dp/B003LVZO8S/ref=sr_1_1?ie=UTF8&amp;amp;qid=1450663461&amp;amp;sr=8-1&amp;amp;keywords=logitech+c310"&gt;Logitech C310 webcam&lt;/a&gt;,
but with four cats, it&amp;#8217;s far from a tool to detect a human in my apartment. So, the weekend before my trip,
I decided to do some&amp;nbsp;tinkering.&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s an &amp;#8220;alarm system&amp;#8221; control panel next to the entry to my apartment, but it appears to be a no-name system that probably
cost $20 and doesn&amp;#8217;t actually do anything other than sound a chime when the door opens. I turned it off the day I moved in,
and hadn&amp;#8217;t given it a second thought since. However, it occurred to me that the useless panel next to the washing machine
probably had magnetic contact switches for the doors. Sure enough, after a few minutes with a multimeter, I found that both
the entry door and the sliding balcony door have normally-closed magnetic contacts wired back to the panel. After thinking
over the options for a few minutes, I remembered that I had a &lt;a href="https://www.raspberrypi.org/"&gt;Raspberry Pi&lt;/a&gt; (the original)
sitting unused under my &lt;span class="caps"&gt;TV&lt;/span&gt;, and a &lt;a href="https://www.sparkfun.com/products/11772"&gt;PiFace I/O card&lt;/a&gt; that I&amp;#8217;d never&amp;nbsp;used.&lt;/p&gt;
&lt;p&gt;After about an hour of connecting some wires and playing around with the wonderfully-simple &lt;a href="http://piface.github.io/pifacedigitalio/"&gt;pifacedigitalio&lt;/a&gt;
Python package &lt;a href="https://pypi.python.org/pypi/pifacedigitalio/3.0.5"&gt;available on PyPi&lt;/a&gt;, I was able to successfully read
inputs for when either door was open. I figured that this would provide the perfect squelch for motion recording from the
webcam, as the cats aren&amp;#8217;t able to operate the deadbolt on my front door (I had to replace all of the interior door handles
with cat-proof&amp;nbsp;models).&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/rpi_alarm_1_large.jpg"&gt;&lt;img alt="Photograph of RPi in alarm enclosure" src="/GFX/rpi_alarm_1_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/rpi_alarm_2_large.jpg"&gt;&lt;img alt="Photograph of alarm enclosure closed, showing wires to RPi" src="/GFX/rpi_alarm_2_sm.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The system that I&amp;#8217;ve come up with is rather rough around the edges&amp;#8230; to put it lightly. It&amp;#8217;s pretty obvious that it was written
in a few days, and at this point, it&amp;#8217;s not really intended to be used by anyone who doesn&amp;#8217;t have a good understanding of the
components (and Python). But I&amp;#8217;m hoping that someone else might find it interesting, or perhaps improve on it. It&amp;#8217;s not terribly
robust, but it seems to be working acceptably well for my&amp;nbsp;needs.&lt;/p&gt;
&lt;h2 id="components"&gt;&lt;a class="toclink" href="#components"&gt;Components&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The system is split into a number of components, with some of them running on the Raspberry Pi and some on my desktop&amp;nbsp;computer.&lt;/p&gt;
&lt;p&gt;The Pi is running my &lt;a href="https://github.com/jantman/piface-webhooks"&gt;piface-webhooks&lt;/a&gt; project (everything needed to set it up on
&lt;a href="https://www.raspbian.org/"&gt;Raspbian&lt;/a&gt; or &lt;a href="https://osmc.tv/"&gt;&lt;span class="caps"&gt;OSMC&lt;/span&gt;&lt;/a&gt; is available in the repo), which is made up of two Python&amp;nbsp;services:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;piface-listener&lt;/strong&gt; Is the code that actually polls the PiFace inputs. When the state of an input changes, it writes out
a file (under &lt;code&gt;/var/spool/piface-webhooks&lt;/code&gt; by default) with the input number, state, and&amp;nbsp;timestamp.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;piface-worker&lt;/strong&gt; Polls this directory for files; when one is found, it takes some action and then removes the file. The
current actions are sending an &lt;span class="caps"&gt;HTTP&lt;/span&gt; webhook, sending a message via &lt;a href="https://pushover.net/"&gt;Pushover&lt;/a&gt;, and sending an email
via Gmail. I currently use all of these, mainly for redudnancy. The webhook feature is used to &lt;span class="caps"&gt;POST&lt;/span&gt; data to &lt;code&gt;motion_piface_handler.py&lt;/code&gt;,
a Flask app running on my&amp;nbsp;desktop.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My desktop computer is the heart of the system, handling the webcam and most of the &amp;#8220;alarm&amp;#8221;&amp;nbsp;logic:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.lavrsen.dk/foswiki/bin/view/Motion/WebHome"&gt;motion&lt;/a&gt; monitors the webcam feed for motion above a certain number of
pixels. When motion is detected, it saves both &lt;span class="caps"&gt;JPEG&lt;/span&gt; images and &lt;span class="caps"&gt;AVI&lt;/span&gt; files to disk, logs the event in a MySQL database, and
executes a Python script. It also saves a snapshot from the webcam every 30&amp;nbsp;seconds.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/misc-scripts/blob/master/s3sync_inotify.py"&gt;s3sync_inotify.py&lt;/a&gt; is a quick Python script I wrote that
uses Linux inotify to monitor &lt;code&gt;motion&lt;/code&gt;&amp;#8216;s output directory for new files (only when they&amp;#8217;ve been closed, and are finished being
written) and syncs them to an S3 bucket set up for static website hosting. It also generates an &lt;code&gt;index.html&lt;/code&gt; file for the bucket,
with links to all uploaded files. At startup, any files that aren&amp;#8217;t yet synced are uploaded, so it &lt;em&gt;should&lt;/em&gt; handle crashes relatively&amp;nbsp;well.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;handle_motion.py&lt;/strong&gt; is the command executed by &lt;code&gt;motion&lt;/code&gt; when an event is detected; it POSTs data to &lt;code&gt;motion_piface_handler.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;motion_piface_handler.py&lt;/strong&gt; is the heart of the system, explained&amp;nbsp;below.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="motion_piface_handlerpy-pulling-it-all-together"&gt;&lt;a class="toclink" href="#motion_piface_handlerpy-pulling-it-all-together"&gt;motion_piface_handler.py - Pulling it all&amp;nbsp;together&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Webhooks from both the Raspberry Pi door sensor and &lt;code&gt;motion&lt;/code&gt;&amp;#8216;s command execution go to a Python &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; app
running on my desktop. This app accepts the incoming data, and also connects to the MySQL database used by Motion. When a &lt;span class="caps"&gt;POST&lt;/span&gt; from
&lt;code&gt;piface-worker&lt;/code&gt; comes in showing that a door has been opened, it adds a record to the MySQL database with information on the input
pin (which door) and state (open/closed), and&amp;nbsp;timestamp.&lt;/p&gt;
&lt;p&gt;When a &lt;span class="caps"&gt;POST&lt;/span&gt; comes in from &lt;code&gt;handle_motion.py&lt;/code&gt;, the command executed by &lt;code&gt;motion&lt;/code&gt; when a file is written, the app checks to see if
a door has been opened in the past few minutes. If not, the event is ignored (and logged, of course). However, if a door has been
opened, the real fun starts. First, the database is queried for the last time a notification was sent out. If one has been sent
in the past few minutes, the current event is ignored (and a rate-limiting message is logged). If it hasn&amp;#8217;t sent out a message
recently, the database is queried for the last door event (which door, and if it was opened or closed) as well as the last &lt;span class="caps"&gt;AVI&lt;/span&gt;
and last five JPEGs saved by &lt;code&gt;motion&lt;/code&gt;. This information is all formatted into a message and sent to my GMail account, and a
shortened version (with just the door event information, and that motion was detected) is sent to my phone via Pushover, with
the highest priority and a custom notification&amp;nbsp;sound.&lt;/p&gt;
&lt;p&gt;So far - at least as far as taking my dogs out is concerned - it appears to be working relatively well. There&amp;#8217;s a bit of
latency in the S3 uploads, especially when AVIs are written, so the files linked in the notification emails may not be
uploaded before the message goes out. That&amp;#8217;s a bit annying, but something that I think I can live&amp;nbsp;with.&lt;/p&gt;
&lt;p&gt;The use of disk queueing probably isn&amp;#8217;t the best, especially with the Pi&amp;#8217;s &lt;span class="caps"&gt;SD&lt;/span&gt; card, but I wanted something that was simple
and didn&amp;#8217;t introduce any additional service dependencies. Each of the components runs as a systemd service, configured to
always restart, so it should tolerate internal failures relatively well. The Python code has a &lt;em&gt;lot&lt;/em&gt; of bare excepts;
I&amp;#8217;m not sure this was the right way to approach it, but my initial theory was that in the event of an error, I&amp;#8217;m more
concerned about keeping the system running than getting an individual message through. The point of the system is to let
me know if my home - and more importantly, my four-legged children - are in danger. I figured that I&amp;#8217;d rather get a delayed
notification than none at&amp;nbsp;all.&lt;/p&gt;
&lt;h2 id="results"&gt;&lt;a class="toclink" href="#results"&gt;Results&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After two weeks away, the system worked quite well. It triggered correctly, and quickly, when my family came to check on the cats.
On average, it took about 3-5 seconds for me to receive the PushOver and GMail notifications for a door open event, and about 30 seconds
for an alarm (motion after door state change)&amp;nbsp;event.&lt;/p&gt;
&lt;p&gt;However, I did have a few&amp;nbsp;issues:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Late one night, I got a door open alert when I hadn&amp;#8217;t been expecting anyone. After about half an hour of panic checking the webcam feed
and watching the logs remotely, I determined that it was a false positive. All was well, there wasn&amp;#8217;t any sign of anyone in the apartment,
the cats were all wandering (or lounging) around as normal, and the door never registered as closed. A day or two later, the door registered
as closing. I&amp;#8217;m not sure if this was an issue with the door sensor triggering because of wind or vibration, or an issue with the PiFace itself
having internal issues reading an input over such a long time, or something with induced current in the long unshielded sensor wire in the wall
(and possibly compounded by my naive debounce&amp;nbsp;logic).&lt;/li&gt;
&lt;li&gt;Having &lt;code&gt;motion&lt;/code&gt; store everything in one directory, and then &lt;code&gt;s3sync_inotify.py&lt;/code&gt; sync that to S3 and create an &lt;code&gt;index.html&lt;/code&gt; file was a
bad idea. &lt;code&gt;motion&lt;/code&gt; was triggered quite often by the cats; after about a week away, I had ~&lt;span class="caps"&gt;10GB&lt;/span&gt; of photos and videos in the S3 bucket, and the
&lt;code&gt;index.html&lt;/code&gt; file was over &lt;span class="caps"&gt;7MB&lt;/span&gt;. Not only did the index page take a painfully long amount of time to load, but generation of it introduced enough
latency in the upload process that &lt;code&gt;s3sync_inotify.py&lt;/code&gt; ended up missing a large number of&amp;nbsp;files.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="next-steps"&gt;&lt;a class="toclink" href="#next-steps"&gt;Next&amp;nbsp;Steps&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m not sure if I&amp;#8217;ll do much more work on this - we don&amp;#8217;t travel often - but if I do, the next things that I want to tackle&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Queueing of outgoing messages, so that network outages won&amp;#8217;t result in completely-lost&amp;nbsp;communication.&lt;/li&gt;
&lt;li&gt;Some sort of heartbeat - ideally to an off-premesis system, such as my &lt;span class="caps"&gt;EC2&lt;/span&gt; instance - from every process involved, to
confirm that all of the components (a) are running correctly, and (b) have&amp;nbsp;connectivity.&lt;/li&gt;
&lt;li&gt;Modify the &lt;code&gt;motion&lt;/code&gt; output directory structure and &lt;code&gt;s3sync_inotify.py&lt;/code&gt; to write into per-day (or per-hour) directories
and write &lt;code&gt;index.html&lt;/code&gt; files for each of&amp;nbsp;them.&lt;/li&gt;
&lt;li&gt;See if there&amp;#8217;s a straightforward way to use systemd&amp;#8217;s &lt;a href="http://www.freedesktop.org/software/systemd/man/sd_notify.html"&gt;sd_notify&lt;/a&gt;
from Python, to build a watchdog into the processes and have systemd restart them if they&amp;nbsp;hang.&lt;/li&gt;
&lt;li&gt;Packaging this all together into one or more real repositories, so maybe it can be used by&amp;nbsp;others.&lt;/li&gt;
&lt;li&gt;Cleaning up &lt;code&gt;handle_motion.py&lt;/code&gt; and &lt;code&gt;motion_piface_handler.py&lt;/code&gt; and releasing them along with everything&amp;nbsp;else.&lt;/li&gt;
&lt;/ul&gt;</content><category term="rpi"></category><category term="pi"></category><category term="raspberrypi"></category><category term="security"></category><category term="alarm"></category><category term="motion"></category><category term="camera"></category></entry></feed>