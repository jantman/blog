<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jason Antman's Blog - Software</title><link href="https://blog.jasonantman.com/" rel="alternate"></link><link href="https://blog.jasonantman.com/feeds/categories/software.atom.xml" rel="self"></link><id>https://blog.jasonantman.com/</id><updated>2021-03-28T10:55:00-04:00</updated><entry><title>Migrating Kodi to MariaDB, with locked-down permissions and noÂ import/export</title><link href="https://blog.jasonantman.com/2021/03/migrating-kodi-to-mariadb-with-locked-down-permissions-and-no-importexport/" rel="alternate"></link><published>2021-03-28T10:55:00-04:00</published><updated>2021-03-28T10:55:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2021-03-28:/2021/03/migrating-kodi-to-mariadb-with-locked-down-permissions-and-no-importexport/</id><summary type="html">&lt;p&gt;Instructions for migrating Kodi from SQLite to MySQL/MariaDB, without giving root database permissions or needing import/export of&amp;nbsp;media.&lt;/p&gt;</summary><content type="html">&lt;p&gt;For the past two years or so, I&amp;#8217;ve been using &lt;a href="https://kodi.tv/"&gt;Kodi&lt;/a&gt; to power my television. It works great, as I don&amp;#8217;t have cable and all of my DVDs have been ripped to a hard drive. It lets me watch any of my digital movies/&lt;span class="caps"&gt;TV&lt;/span&gt; shows, as well as Netflix and Amazon Prime Video - which is all that I need. Kodi itself is running on a Raspberry Pi 4 in a tiny little case, so it works great for a media center / &lt;span class="caps"&gt;HTPC&lt;/span&gt;. I recently wanted to add another Kodi device for my bedroom &lt;span class="caps"&gt;TV&lt;/span&gt;, but unfortunately (unlike the older &lt;a href="https://www.mythtv.org/"&gt;MythTV&lt;/a&gt;, that I used years ago) Kodi isn&amp;#8217;t a client/server app, it&amp;#8217;s just a single local&amp;nbsp;program.&lt;/p&gt;
&lt;p&gt;Using multiple front-ends is sort of supported by &lt;a href="https://kodi.wiki/view/MySQL"&gt;switching from the built-in SQLite database to MySQL&lt;/a&gt;, but there&amp;#8217;s a fair amount left out (such as addons). The process for switching to a MySQL-compatible database server also had some pain points for me, namely that it requires complete root permissions on the database and it relies on exporting and then re-importing all of your media. The first point (database permissions) is untenable, since my MariaDB server contains a number of other databases, some of which have private information in them. The second point - exporting information on all of the media, then switching from SQLite to MariaDB, then re-importing everything - just seemed horribly&amp;nbsp;inefficient.&lt;/p&gt;
&lt;p&gt;So, here&amp;#8217;s the process I used for switching Kodi from SQLite to MariaDB and adding a second frontend. This assumes that you already have your media/library stored remotely and mounted via &lt;span class="caps"&gt;NFS&lt;/span&gt;, and that your two frontend devices (Raspberry Pi 4&amp;#8217;s for me) are running the exact same &lt;span class="caps"&gt;OS&lt;/span&gt;, Kodi version, and versions of everything else (for me, it&amp;#8217;s Raspberry Pi &lt;span class="caps"&gt;OS&lt;/span&gt;, everything updated to&amp;nbsp;latest).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; Point Kodi to a temporary MySQL server to create the schema. Use a Python script to &lt;span class="caps"&gt;SELECT&lt;/span&gt; every row from the SQLite DBs and &lt;span class="caps"&gt;INSERT&lt;/span&gt; them into MySQL. &lt;code&gt;mysqldump&lt;/code&gt; the result and import it into your production &lt;span class="caps"&gt;DB&lt;/span&gt; server.&amp;nbsp;Done.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Identify the exact database server version you&amp;#8217;re going to be using. For me, this is MariaDB&amp;nbsp;10.5.9.&lt;/li&gt;
&lt;li&gt;Stand up another, brand new and empty, server running that version. For ease, I&amp;#8217;m using the Docker container for &lt;code&gt;mariadb:10.5.9&lt;/code&gt; running on my laptop. Expose the port (3306) to your network. If running in Docker, make sure you mount a directory into the container. For me, this was &lt;code&gt;docker run -it --rm --name db -v /tmp:/host-tmp -p 3306:3306 -e MYSQL_ROOT_PASSWORD=foobar mariadb:10.5.9&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Do whatever you need to, to get port 3306 passed through your firewall and available to the Kodi&amp;nbsp;hosts.&lt;/li&gt;
&lt;li&gt;Stop/exit Kodi on the existing&amp;nbsp;host.&lt;/li&gt;
&lt;li&gt;Back up your entire Kodi directory (&lt;code&gt;~/.kodi&lt;/code&gt;) somewhere. Copy the SQLite database files (&lt;code&gt;.kodi/userdata/Database&lt;/code&gt;) to the computer you&amp;#8217;re working on. Also rename or move the &lt;code&gt;MyMusic72.db&lt;/code&gt; and &lt;code&gt;MyVideos116.db&lt;/code&gt; files from the &lt;code&gt;Database&lt;/code&gt; directory, so we can be sure that we&amp;#8217;re using MySQL later&amp;nbsp;on.&lt;/li&gt;
&lt;li&gt;Get a root session on your temporary database; for me, this is &lt;code&gt;docker exec -it db mysql -uroot -p&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set up permissions for kodi as described in &lt;a href="https://kodi.wiki/view/MySQL/Setting_up_MySQL"&gt;the documentation&lt;/a&gt;: &lt;code&gt;CREATE USER 'kodi' IDENTIFIED BY 'kodi'; GRANT ALL ON *.* TO 'kodi'; flush privileges;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;SHOW DATABASES;&lt;/code&gt; - this should list 3 default databases: information_schema, mysql, and&amp;nbsp;performance_schema&lt;/li&gt;
&lt;li&gt;On the Kodi host, create &lt;code&gt;~/.kodi/userdata/advancedsettings.xml&lt;/code&gt; with the &lt;a href="https://kodi.wiki/view/MySQL/Setting_up_Kodi"&gt;appropriate content for MySQL&lt;/a&gt; pointing to your test/temporary &lt;span class="caps"&gt;DB&lt;/span&gt;. Start Kodi back&amp;nbsp;up.&lt;/li&gt;
&lt;li&gt;You should get a blank, empty Kodi main screen, but on your temporary &lt;span class="caps"&gt;DB&lt;/span&gt; server you should see two new databases. For Kodi 18 (Leia) they will be called &lt;code&gt;MyMusic72&lt;/code&gt; and &lt;code&gt;MyVideos116&lt;/code&gt;. Once this is done, stop Kodi&amp;nbsp;again.&lt;/li&gt;
&lt;li&gt;Save the &lt;code&gt;sqlite-to-mysql.py&lt;/code&gt; script, below, to the same directory as your database backups. This script is written for Python 3.7 or later, and needs the &lt;a href="https://pymysql.readthedocs.io/en/latest/"&gt;PyMySQL&lt;/a&gt; (&lt;code&gt;pip install PyMySQL&lt;/code&gt;)&amp;nbsp;package.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;python3 sqlite-to-mysql.py&lt;/code&gt; to copy all data from the SQLite databases to MySQL/MariaDB on the &lt;strong&gt;temporary&lt;/strong&gt; database server. Run first with &lt;code&gt;-h&lt;/code&gt; to see the available options and their default&amp;nbsp;values.&lt;/li&gt;
&lt;li&gt;Start Kodi back up. You should see all of your library, your watched history and current positions, etc. That means&amp;#8230; it worked! Stop kodi on all&amp;nbsp;frontends.&lt;/li&gt;
&lt;li&gt;On the temporary database server, dump both databases. For me, this was &lt;code&gt;docker exec -it db /bin/bash&lt;/code&gt; then &lt;code&gt;cd /host-tmp&lt;/code&gt; then &lt;code&gt;mysqldump --insert-ignore --routines --triggers --databases MyMusic72 MyVideos116 -uroot -p &amp;gt; kodi-data.sql&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Copy the resulting &lt;span class="caps"&gt;SQL&lt;/span&gt; dump file (&lt;code&gt;kodi-data.sql&lt;/code&gt;) to your actual database server and restore&amp;nbsp;it.&lt;/li&gt;
&lt;li&gt;Update &lt;code&gt;~/.kodi/userdata/advancedsettings.xml&lt;/code&gt; to point to your production database&amp;nbsp;server.&lt;/li&gt;
&lt;li&gt;Now, copy all of &lt;code&gt;~/.kodi&lt;/code&gt; from the primary frontend that you&amp;#8217;ve been working on to all others. This will update them with not only your database configuration but also your addons, settings,&amp;nbsp;etc.&lt;/li&gt;
&lt;li&gt;Start up all Kodi frontends; they should now be functional and&amp;nbsp;synchronized.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="upgrading"&gt;&lt;a class="toclink" href="#upgrading"&gt;Upgrading&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Upgrading will be a bit less of a pain, but still not&amp;nbsp;fun:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Dump your databases from MySQL/MariaDB, stand up another temporary &lt;span class="caps"&gt;DB&lt;/span&gt; server, restore the dump. Give Kodi full&amp;nbsp;privileges.&lt;/li&gt;
&lt;li&gt;Stop all of your Kodi&amp;nbsp;frontends.&lt;/li&gt;
&lt;li&gt;Switch one of your Kodi frontends to the temporary server, upgrade Kodi, start it up, let it upgrade the&amp;nbsp;database.&lt;/li&gt;
&lt;li&gt;Dump the database, restore it on your production server. Adjust permissions for new database names as&amp;nbsp;needed.&lt;/li&gt;
&lt;li&gt;Point your running Kodi instance back to the production&amp;nbsp;server.&lt;/li&gt;
&lt;li&gt;Upgrade all remaining frontends and start them&amp;nbsp;up.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="sqlite-to-mysqlpy"&gt;&lt;a class="toclink" href="#sqlite-to-mysqlpy"&gt;sqlite-to-mysql.py&lt;/a&gt;&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Script for migrating Kodi SQLite databases to MySQL / MariaDB.&lt;/span&gt;

&lt;span class="sd"&gt;Requires Python &amp;gt;= 3.7 and PyMySQL.&lt;/span&gt;

&lt;span class="sd"&gt;For usage, see:&lt;/span&gt;
&lt;span class="sd"&gt;https://blog.jasonantman.com/2021/03/migrating-kodi-to-mariadb-with-locked-down-permissions-and-no-importexport/&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;NOTE&lt;/span&gt;: This currently ignores triggers, as all triggers that Kodi currently uses&lt;/span&gt;
&lt;span class="sd"&gt;in these DBs are &lt;span class="caps"&gt;AFTER&lt;/span&gt; delete.&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;logging&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;typing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Any&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Tuple&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pymysql&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pymysql.cursors&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sqlite3&lt;/span&gt;

&lt;span class="n"&gt;&lt;span class="caps"&gt;FORMAT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;[&lt;/span&gt;&lt;span class="si"&gt;%(asctime)s&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;%(levelname)s&lt;/span&gt;&lt;span class="s2"&gt;] &lt;/span&gt;&lt;span class="si"&gt;%(message)s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basicConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;&lt;span class="caps"&gt;WARNING&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;&lt;span class="caps"&gt;FORMAT&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Logger&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getLogger&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;KodiMigrator&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;passwd&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;dry_run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;bool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dry_run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;bool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dry_run&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="s1"&gt;&amp;#39;Connecting to MySQL at &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;:&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; as &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;user&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pymysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connections&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Connection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pymysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;passwd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;charset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;utf8mb4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;cursorclass&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pymysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictCursor&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Connected to MySQL&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;dbname&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MyMusic72&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;MyVideos116&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;handle_db&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;handle_db&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Handling database: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MySQL select &lt;span class="caps"&gt;DB&lt;/span&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_db&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;mysql_tables&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_mysql_table_names&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;SQLite3 open &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;.db&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sqlite3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Connection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sqlite3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{dbname}.db&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;sqlite_tables&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_sqlite_table_names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;row_factory&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sqlite3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Row&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mysql_tables&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;sqlite_tables&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;RuntimeError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: MySQL table names in {dbname} ({mysql_tables}) do &amp;#39;&lt;/span&gt;
                &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;not match SQLite table names ({sqlite_tables})!&amp;#39;&lt;/span&gt;
            &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;set FOREIGN_KEY_CHECKS = 0;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_fix_db&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;tname&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;mysql_tables&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_handle_table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tname&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;set FOREIGN_KEY_CHECKS = 1;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;commit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_fix_db&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dbname&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pymysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictCursor&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;dbname&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;MyVideos116&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt;
        &lt;span class="c1"&gt;# for data conversion, change tvshow.c06 from &lt;span class="caps"&gt;TEXT&lt;/span&gt; to &lt;span class="caps"&gt;MEDIUMTEXT&lt;/span&gt;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_mysql_execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;ALTER&lt;/span&gt; &lt;span class="caps"&gt;TABLE&lt;/span&gt; tvshow &lt;span class="caps"&gt;MODIFY&lt;/span&gt; &lt;span class="caps"&gt;COLUMN&lt;/span&gt; c06 &lt;span class="caps"&gt;MEDIUMTEXT&lt;/span&gt;;&amp;#39;&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_handle_table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sqlite3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Connection&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pymysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictCursor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;table_name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# first empty the MySQL table&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_mysql_execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;DELETE&lt;/span&gt; &lt;span class="caps"&gt;FROM&lt;/span&gt; {table_name};&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# now get the data from SQLite and copy it over&lt;/span&gt;
        &lt;span class="n"&gt;sql&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;SELECT&lt;/span&gt; * &lt;span class="caps"&gt;FROM&lt;/span&gt; {table_name};&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;SQLite execute: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;local_cur&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sqlite3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Cursor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;local_cur&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;local_cur&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;table_name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;tvshow&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;idShow&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;# Doctor Who - c06 too long&lt;/span&gt;
                &lt;span class="k"&gt;continue&lt;/span&gt;
            &lt;span class="n"&gt;tmp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_mysql_insert_for_row&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_mysql_execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Copied &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt; rows for table &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;table_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_mysql_insert_for_row&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tname&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sqlite3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Row&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Tuple&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Tuple&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
        &lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;sql&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;INSERT&lt;/span&gt; &lt;span class="caps"&gt;INTO&lt;/span&gt; {tname} ({&amp;quot;, &amp;quot;.join(keys)}) &lt;span class="caps"&gt;VALUES&lt;/span&gt; (&amp;#39;&lt;/span&gt; \
              &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{&amp;quot;, &amp;quot;.join([&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;quot; for x in values])});&amp;#39;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;tuple&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_mysql_execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pymysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Cursor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;tuple&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dry_run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;warning&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;span class="caps"&gt;DRY&lt;/span&gt; &lt;span class="caps"&gt;RUN&lt;/span&gt;: MySQL Execute: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MySQL Execute: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;pymysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MySQLError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Error in query: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;raise&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_sqlite_table_names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sqlite3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Connection&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
        &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sqlite3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Cursor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;SELECT&lt;/span&gt; name &lt;span class="caps"&gt;FROM&lt;/span&gt; sqlite_master &lt;span class="caps"&gt;WHERE&lt;/span&gt; type=&amp;#39;table&amp;#39;;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;SQLite execute: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetchall&lt;/span&gt;&lt;span class="p"&gt;()])&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;SQLite tables: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_mysql_table_names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
        &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;show full tables where Table_Type != &amp;#39;&lt;span class="caps"&gt;VIEW&lt;/span&gt;&amp;#39;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MySQL execute: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pymysql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cursors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Cursor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;cursor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetchall&lt;/span&gt;&lt;span class="p"&gt;()])&lt;/span&gt;
        &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MySQL tables: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    parse arguments/options&lt;/span&gt;

&lt;span class="sd"&gt;    this uses the new argparse module instead of optparse&lt;/span&gt;
&lt;span class="sd"&gt;    see: &amp;lt;https://docs.python.org/2/library/argparse.html&amp;gt;&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Migrate Kodi SQLite to MySQL&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-d&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;--dry-run&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;dry_run&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;store_true&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                   &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                   &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dry-run - print &lt;span class="caps"&gt;SQL&lt;/span&gt; that would be sent to MySQL but &amp;quot;&lt;/span&gt;
                        &lt;span class="s2"&gt;&amp;quot;don&amp;#39;t actually run it&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-v&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;--verbose&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;verbose&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;store_true&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                   &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;debug-level output.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-H&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;--host&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;host&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                   &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MySQL host (default: 127.0.0.1)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;127.0.0.1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-P&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;--port&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;port&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3306&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                   &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MySQL port (default: 3306)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-u&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;--user&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;kodi&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                   &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MySQL user (default: kodi)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-p&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;--passwd&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;passwd&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;kodi&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                   &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;MySQL password (default: kodi)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_log_info&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;set logger level to &lt;span class="caps"&gt;INFO&lt;/span&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;set_log_level_format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;&lt;span class="caps"&gt;INFO&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                         &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;%(asctime)s&lt;/span&gt;&lt;span class="s1"&gt; &lt;/span&gt;&lt;span class="si"&gt;%(levelname)s&lt;/span&gt;&lt;span class="s1"&gt;:&lt;/span&gt;&lt;span class="si"&gt;%(name)s&lt;/span&gt;&lt;span class="s1"&gt;:&lt;/span&gt;&lt;span class="si"&gt;%(message)s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_log_debug&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;set logger level to &lt;span class="caps"&gt;DEBUG&lt;/span&gt;, and debug-level output format&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;set_log_level_format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;&lt;span class="caps"&gt;DEBUG&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%(asctime)s&lt;/span&gt;&lt;span class="s2"&gt; [&lt;/span&gt;&lt;span class="si"&gt;%(levelname)s&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;%(filename)s&lt;/span&gt;&lt;span class="s2"&gt;:&lt;/span&gt;&lt;span class="si"&gt;%(lineno)s&lt;/span&gt;&lt;span class="s2"&gt; - &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%(name)s&lt;/span&gt;&lt;span class="s2"&gt;.&lt;/span&gt;&lt;span class="si"&gt;%(funcName)s&lt;/span&gt;&lt;span class="s2"&gt;() ] &lt;/span&gt;&lt;span class="si"&gt;%(message)s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;set_log_level_format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Set logger level and format.&lt;/span&gt;

&lt;span class="sd"&gt;    :param level: logging level; see the :py:mod:`logging` constants.&lt;/span&gt;
&lt;span class="sd"&gt;    :type level: int&lt;/span&gt;
&lt;span class="sd"&gt;    :param format: logging formatter format string&lt;/span&gt;
&lt;span class="sd"&gt;    :type format: str&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;formatter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Formatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fmt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;handlers&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setFormatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;formatter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setLevel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;

    &lt;span class="c1"&gt;# set logging level&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;set_log_debug&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;set_log_info&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;KodiMigrator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;passwd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dry_run&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dry_run&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="kodi"></category><category term="osmc"></category><category term="database"></category><category term="mysql"></category><category term="mariadb"></category></entry><entry><title>On The Creation, Use, and Management of DockerÂ Images</title><link href="https://blog.jasonantman.com/2020/11/on-the-creation-use-and-management-of-docker-images/" rel="alternate"></link><published>2020-11-10T15:11:00-05:00</published><updated>2020-11-10T15:11:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2020-11-10:/2020/11/on-the-creation-use-and-management-of-docker-images/</id><summary type="html">&lt;p&gt;Some hard-earned thoughts on how to build, manage, and use Docker&amp;nbsp;images.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#on-to-the-topic-docker"&gt;On toÂ the topic: Docker&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#aside-nomenclature"&gt;Aside -&amp;nbsp;Nomenclature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-docker-images-are-and-arent"&gt;What Docker Images Are and&amp;nbsp;Aren&amp;#8217;t&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-to-put-in-an-image"&gt;What to put in an&amp;nbsp;image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#logging"&gt;Logging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tagging-and-versioning"&gt;Tagging and&amp;nbsp;Versioning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#repeatable-builds"&gt;Repeatable&amp;nbsp;Builds&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#no-runtime-downloads"&gt;No Runtime&amp;nbsp;Downloads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#everything-in-source-control-git"&gt;Everything in Source Control&amp;nbsp;(Git)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#labels"&gt;Labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#add-a-healthcheck"&gt;Add a&amp;nbsp;&lt;span class="caps"&gt;HEALTHCHECK&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#testing-built-images"&gt;Testing Built&amp;nbsp;Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#updates-rollbacks-issue-reproduction-and-disaster-recovery"&gt;Updates, Rollbacks, Issue Reproduction, and Disaster&amp;nbsp;Recovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#automated-builds"&gt;Automated&amp;nbsp;Builds&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#docker-image-checklist"&gt;Docker Image Checklist&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#footnotes"&gt;Footnotes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h1 id="introduction"&gt;&lt;a class="toclink" href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;I know that it&amp;#8217;s been ages since I&amp;#8217;ve posted anything here, but frankly, I haven&amp;#8217;t had much interest to. I&amp;#8217;ve been in a strange place personally for the past few years, and especially for much of 2020. I&amp;#8217;ve let much of my public/professional profile languish over the past few years, and I also haven&amp;#8217;t given my open source projects the attention they deserve. I&amp;#8217;m hoping to fix that soon, and hopefully this post is the first step. I&amp;#8217;m also hoping to add a few posts on the non-computer-related &lt;span class="caps"&gt;DIY&lt;/span&gt; carpentry and electronics projects that I&amp;#8217;ve worked on over the past year, as well as my first steps into 3D printing. Hopefully my interest in writing will&amp;nbsp;hold.&lt;/p&gt;
&lt;p&gt;For the past five years I&amp;#8217;ve been working on a team that&amp;#8217;s called Release Engineering, but is best described as a tooling &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; automation development and consulting team (we&amp;#8217;d likely be Developer Enablement anywhere else). Our goal is to provide tooling, consulting services, processes, documentation, and timely advice to a bunch (i.e. over 100) of software development teams. While my team is heavily involved in many aspects of software and infrastructure lifecycle, most of our work is with &lt;span class="caps"&gt;AWS&lt;/span&gt; infrastructure automation and with build/test/deploy pipelines. One common thread that connects the two is the use of Docker images, both as the environment where we run much of our tooling, build, and test processes, as well as the final artifact from our build processes - the blob of ones and zeroes that actually gets deployed and&amp;nbsp;run.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s safe to say that I don&amp;#8217;t make it through a normal work day without running a bunch of Docker containers and likely building (via automated pipelines, of course) a few. It&amp;#8217;s also safe to say that, after spending five-ish years working on Docker-heavy processes at a large Enterprise, including being intimately involved with developing many of our tools, processes, and standards around Docker, and helping in the management of multiple private Docker Registries, I have some pretty strong opinions and some advice that I find myself passing on time after time. The extreme popularity and accessibility of Docker is wonderful, and has certainly been wonderful for everyone involved in the software and operations lifecycles. However, along with this has also come a large amount of misinformation and poor examples on how to use Docker, and a striking difficulty in finding good information on the hard-earned lessons from using Docker at&amp;nbsp;scale.&lt;/p&gt;
&lt;p&gt;There are some wonderful resources, including the official Docker documentation, for how to run Docker. This post is going to focus on Docker Images and their&amp;nbsp;lifecycle.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;IMPORTANT&lt;/span&gt;:&lt;/strong&gt; Please note that (1) while my language may be rather declarative, &lt;em&gt;this is just my opinion&lt;/em&gt;. It&amp;#8217;s shared by many others in the industry, and it&amp;#8217;s based on hard-learned lessons, but it&amp;#8217;s still an opinion. Also, (2), if you&amp;#8217;re not doing what I describe here, &lt;em&gt;I&amp;#8217;m not by any means saying that you&amp;#8217;re &amp;#8220;doing Docker wrong&amp;#8221;&lt;/em&gt;. These are lessons learned from a company that builds hundreds of Docker images every day, and has thousands of them running at any given time. &lt;strong&gt;In short, this is what I wish someone told us many years&amp;nbsp;ago.&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id="on-to-the-topic-docker"&gt;&lt;a class="toclink" href="#on-to-the-topic-docker"&gt;On toÂ the topic:&amp;nbsp;Docker&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id="aside-nomenclature"&gt;&lt;a class="toclink" href="#aside-nomenclature"&gt;Aside -&amp;nbsp;Nomenclature&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For those who may not be familiar with the difference, the following are taken from the &lt;a href="https://docs.docker.com/glossary/"&gt;Docker Glossary&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://docs.docker.com/glossary/#image"&gt;Docker image&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Docker images are the basis of containers. An Image is an ordered collection of root filesystem changes and the corresponding execution parameters for use within a container runtime. An image typically contains a union of layered filesystems stacked on top of each other. An image does not have state and it never&amp;nbsp;changes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://docs.docker.com/glossary/#container"&gt;Docker container&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A container is a runtime instance of a docker&amp;nbsp;image.&lt;/p&gt;
&lt;p&gt;A Docker container consists&amp;nbsp;of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Docker&amp;nbsp;image&lt;/li&gt;
&lt;li&gt;An execution&amp;nbsp;environment&lt;/li&gt;
&lt;li&gt;A standard set of&amp;nbsp;instructions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The concept is borrowed from Shipping Containers, which define a standard to ship goods globally. Docker defines a standard to ship&amp;nbsp;software.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="what-docker-images-are-and-arent"&gt;&lt;a class="toclink" href="#what-docker-images-are-and-arent"&gt;What Docker Images Are and&amp;nbsp;Aren&amp;#8217;t&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To begin with, I&amp;#8217;m going to make some blanket statements about what Docker (mainly in the context of images, and containers) is and&amp;nbsp;isn&amp;#8217;t:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker images are &lt;strong&gt;not Virtual Machines (VMs)&lt;/strong&gt;. While they do provide a means to isolate some data and process(es) and a way to start and stop them, they still share a kernel with the underlying operating system and are visible to it, and do not &lt;em&gt;virtualize&lt;/em&gt; anything. They&amp;#8217;re really just a way to group and (somewhat, and only if done very carefully) isolate things from the underlying Linux kernel (or the various compatibility layers for Mac, Windows, and other&amp;nbsp;OSes).&lt;/li&gt;
&lt;li&gt;Docker images are much more analogous to &lt;strong&gt;software packages&lt;/strong&gt;, albeit ones that also know about the environment and some networking, and can have their own storage (volumes). In so far as building and distributing software is concerned, Docker images should mostly be regarded like any other package or&amp;nbsp;artifact.&lt;/li&gt;
&lt;li&gt;Docker containers (and images) should ideally only &lt;a href="https://docs.docker.com/config/containers/multi-service_container/"&gt;run on service per image/container&lt;/a&gt;. Most of the docker ecosystem is built around this concept. While there are many images that don&amp;#8217;t follow this pattern (especially earlier images and proprietary software), you usually wouldn&amp;#8217;t put your application, web server, and database in the same package, and they shouldn&amp;#8217;t be in the same image either. &lt;a href="https://docs.docker.com/compose/"&gt;docker-compose&lt;/a&gt; was specifically designed to aid in this&amp;nbsp;pattern.&lt;/li&gt;
&lt;li&gt;Docker image &lt;strong&gt;tags are package versions.&lt;/strong&gt; No packaging system that I&amp;#8217;m aware of doesn&amp;#8217;t have a concept of a version. With Docker images, that versioning is entirely up to you - by tagging your images. You can tag a single image multiple times, and probably should. Every docker image that&amp;#8217;s built should have at least one completely unique tag, so that same exact image can be used where needed. For versioning, tags that get updated can and should be used (i.e. if you release version &lt;span class="caps"&gt;X.Y.&lt;/span&gt;Z of your image, you can have X and X.Y tags that point to the most recent relevant&amp;nbsp;image).&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;latest&lt;/code&gt; tag is horribly misleading. There is nothing magic or special about &lt;code&gt;latest&lt;/code&gt;; it is simply a convention. If you build and push a newer Docker image and don&amp;#8217;t tag it &lt;code&gt;latest&lt;/code&gt; (and push that tag), your &lt;code&gt;latest&lt;/code&gt; will still point to an older image. Using the &lt;code&gt;latest&lt;/code&gt; tag also removes repeatability when running&amp;nbsp;containers.&lt;/li&gt;
&lt;li&gt;If at all possible, Docker images should not write log files to disk. Docker has pluggable &lt;a href="https://docs.docker.com/config/containers/logging/configure/"&gt;logging drivers&lt;/a&gt;, the simplest being the default which is what&amp;#8217;s displayed by &lt;code&gt;docker logs&lt;/code&gt;. Ideally, all logs should go to &lt;span class="caps"&gt;STDOUT&lt;/span&gt; or &lt;span class="caps"&gt;STDERR&lt;/span&gt; of the container, and the Docker daemon should be configured to handle them&amp;nbsp;appropriately.&lt;/li&gt;
&lt;li&gt;Many of the best practices for working with Dockerized services match up well with the &lt;a href="https://12factor.net/"&gt;12 factor app&lt;/a&gt;&amp;nbsp;guidelines.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you&amp;#8217;re unsure about any of the prescriptive statements I&amp;#8217;ve made, I&amp;#8217;d encourage you to look at the &lt;a href="https://github.com/docker-library/official-images"&gt;docker-library Official images&lt;/a&gt;. These are the official Docker images for many popular programming languages, runtimes, and applications. Most, if not all, of them follow these guidelines. The &lt;a href="https://github.com/docker-library/official-images/blob/master/README.md"&gt;docker-library &lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt; provides some very helpful&amp;nbsp;information.&lt;/p&gt;
&lt;h2 id="what-to-put-in-an-image"&gt;&lt;a class="toclink" href="#what-to-put-in-an-image"&gt;What to put in an&amp;nbsp;image&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;A Docker image should only run one service. That may mean more than one &lt;em&gt;process&lt;/em&gt; (in the case of a forking or threaded model), but there should only be one service, and ideally no real init subsystem; just a daemon, perhaps run via a wrapper script. Not only is this in line with the Docker model (see &lt;a href="https://docs.docker.com/config/containers/multi-service_container/"&gt;here&lt;/a&gt; as an official reference), but it also provides many benefits in terms of isolation (especially if using resource limits), monitoring, modularity and management. Even in trivial cases such as a desktop or home computer, it may be desirable to upgrade or restart services separately, move them to different machines on the same network, or swap out one service for another. When multiple services are needed, they should be run as separate containers and connected via &lt;a href="https://docs.docker.com/network/"&gt;Docker networking&lt;/a&gt;. This can be made easy for inexperienced users via &lt;a href="https://docs.docker.com/compose/"&gt;docker-compose&lt;/a&gt;, but retains the flexibility desired by more experienced users with more advanced&amp;nbsp;configurations.&lt;/p&gt;
&lt;h2 id="configuration"&gt;&lt;a class="toclink" href="#configuration"&gt;Configuration&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Configuration should never be included in a Docker image. One of the main advantages of Docker is &amp;#8220;build once, run anywhere&amp;#8221;, where a single image can be used anywhere it&amp;#8217;s needed (i.e. in the test environment, on a developer&amp;#8217;s laptop, and anywhere through production). I won&amp;#8217;t go into the many possibilities in configuration management, but for a general-purpose image, it&amp;#8217;s most desirable to take all configuration via environment variables with sane defaults provided as needed. For more complex scenarios (such as a web server needing many configuration files), it&amp;#8217;s preferable to provide sane defaults built-in to the container and allow overriding them by mounting a directory of configuration files to a known path in the&amp;nbsp;container.&lt;/p&gt;
&lt;p&gt;Under no circumstances should a Docker image be built multiple times for running on different&amp;nbsp;systems/environments/locations.&lt;/p&gt;
&lt;h2 id="logging"&gt;&lt;a class="toclink" href="#logging"&gt;Logging&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Logging should not be written directly to files. This is a bit more difficult if you deviate from the one-service-per-container model, but ideally all logging should be sent to the container&amp;#8217;s &lt;span class="caps"&gt;STDOUT&lt;/span&gt; and &lt;span class="caps"&gt;STDERR&lt;/span&gt; streams. This will be captured by the Docker daemon and available via the &lt;code&gt;docker logs&lt;/code&gt; command if using the default &lt;a href="https://docs.docker.com/config/containers/logging/configure/"&gt;logging driver&lt;/a&gt;, or sent wherever the daemon is configured otherwise. Handling logging this way has a number of benefits including a unified way to view logs (&lt;code&gt;docker logs&lt;/code&gt;), not bloating the container filesystem with log files, not needing to enter into the container to view logs, and compatibility with configurations that send logs to some variety of centralized aggregation, storage, or&amp;nbsp;analysis.&lt;/p&gt;
&lt;p&gt;Furthermore, the &lt;span class="caps"&gt;STDOUT&lt;/span&gt; and &lt;span class="caps"&gt;STDERR&lt;/span&gt; streams should be logically separated either by level (i.e. error messages to &lt;span class="caps"&gt;STDERR&lt;/span&gt;, normal output or info/debug to &lt;span class="caps"&gt;STDOUT&lt;/span&gt;) or by function (i.e. web server access logs to &lt;span class="caps"&gt;STDOUT&lt;/span&gt; and error logs to&amp;nbsp;&lt;span class="caps"&gt;STDERR&lt;/span&gt;).&lt;/p&gt;
&lt;h2 id="tagging-and-versioning"&gt;&lt;a class="toclink" href="#tagging-and-versioning"&gt;Tagging and&amp;nbsp;Versioning&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Docker image tags determine which one of an unlimited number of variations of a single image is used. On the official Docker Hub images, they&amp;#8217;re used both to specify a version (i.e. &lt;code&gt;python:2.7&lt;/code&gt; or &lt;code&gt;python:3.8.2&lt;/code&gt;) as well as to specify an optional variant with some sort of difference, often the base image use (i.e. &lt;code&gt;python:3.8.6-buster&lt;/code&gt; vs &lt;code&gt;python:3.8.6-alpine3.11&lt;/code&gt;). On most official images, a given image has multiple tags; for example, the current &lt;em&gt;newest&lt;/em&gt; stable Python image, &lt;code&gt;python:latest&lt;/code&gt; (what you get if you omit a tag, and just &lt;code&gt;docker pull python&lt;/code&gt;), is also tagged with &lt;code&gt;3.9.0-buster&lt;/code&gt;, &lt;code&gt;3.9-buster&lt;/code&gt;, &lt;code&gt;3-buster&lt;/code&gt;, and &lt;code&gt;buster&lt;/code&gt;. Similarly, the newest official Alpine Linux-based Python image is tagged with eight (8) tags: &lt;code&gt;3.9.0-alpine3.12&lt;/code&gt;, &lt;code&gt;3.9-alpine3.12&lt;/code&gt;, &lt;code&gt;3-alpine3.12&lt;/code&gt;, &lt;code&gt;alpine3.12&lt;/code&gt;, &lt;code&gt;3.9.0-alpine&lt;/code&gt;, &lt;code&gt;3.9-alpine&lt;/code&gt;, &lt;code&gt;3-alpine&lt;/code&gt;, &lt;code&gt;alpine&lt;/code&gt;. The first, and most specific, of these tags (&lt;code&gt;3.9.0-alpine3.12&lt;/code&gt;) is generally unchanging; there will (usually) only be one &lt;code&gt;python:3.9.0-alpine3.12&lt;/code&gt; image published ever. Running this image should always get you an identical container, without any changes from the last time you pulled and ran it, forever. The less-specific tags, however, change over time to point to the newest relevant image. In this way, image tags can be used like version specifiers in many packaging systems; you can choose to install a very specific, unchanging version of some dependency, or you can choose to install the newest version within some&amp;nbsp;range.&lt;/p&gt;
&lt;p&gt;One possible caveat in this is that I&amp;#8217;m not sure if Docker Hub (for official images) enforces that the most specific tag will &lt;em&gt;never&lt;/em&gt; change. In general, I strongly recommend that every image built have at least one completely unique tag that will never be used on another build of that image. This makes it much easier to refer to one specific, unique image, than having to deal with the image digest hash. Many examples that I&amp;#8217;ve seen build this unique tag based on some combination of source control information and timestamp; at my company, our usual practice is to build images with a tag based on the git branch or &lt;span class="caps"&gt;PR&lt;/span&gt; number, short commit &lt;span class="caps"&gt;SHA&lt;/span&gt; that&amp;#8217;s being built, and the current integer timestamp. If a build succeeds and gets released, we&amp;#8217;ll then re-tag the image with the &lt;a href="https://semver.org/"&gt;semver&lt;/a&gt; version&amp;nbsp;number.&lt;/p&gt;
&lt;p&gt;The key point here is that (in most cases) any image that makes it past the initial image build and testing stage should be tagged multiple or many times, to suit the two different purposes of&amp;nbsp;tags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One completely unique tag, to identify that exact image for all&amp;nbsp;eternity.&lt;/li&gt;
&lt;li&gt;One or more (usually three or more) version tags, to allow specifying a major, major.minor, or major.minor.patch version of the&amp;nbsp;image.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For images that are used solely within an automated build and deploy process, you may choose to completely ignore and never use the &lt;code&gt;latest&lt;/code&gt; tag. For images that at any point will or may be manually pulled by humans, or any public images, the &lt;code&gt;latest&lt;/code&gt; tag should be used and point to the most recent &lt;em&gt;stable&lt;/em&gt;&amp;nbsp;version.&lt;/p&gt;
&lt;h2 id="repeatable-builds"&gt;&lt;a class="toclink" href="#repeatable-builds"&gt;Repeatable&amp;nbsp;Builds&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Especially since the 2020 &lt;a href="https://www.docker.com/blog/scaling-dockers-business-to-serve-millions-more-developers-storage/"&gt;Docker Hub announcement&lt;/a&gt; that images without any activity for six months will be deleted, it is vitally important that Docker image builds be &lt;a href="https://martinfowler.com/bliki/ReproducibleBuild.html"&gt;reproducible&lt;/a&gt;. Even for personal projects or companies with private Docker registries, it is always possible that you&amp;#8217;ll need to revisit an old version, test for a regression, or simply rebuild a system that was happily running an uncommon image for a long time. &lt;strong&gt;Running &lt;code&gt;docker build&lt;/code&gt; on a given Dockerfile, with the same arguments, should produce a functionally identical image on any machine at any point in time.&lt;/strong&gt; As such, all version information for sources (including dependencies) outside of your repository should be either hard-coded explicitly or passed via build-time &lt;a href="https://docs.docker.com/engine/reference/builder/#arg"&gt;&lt;span class="caps"&gt;ARG&lt;/span&gt;&lt;/a&gt; arguments in the Dockerfile. Further, nothing during the build process should ever download un-versioned URLs (i.e. clone from git master, or download the &amp;#8220;latest&amp;#8221; of&amp;nbsp;something).&lt;/p&gt;
&lt;p&gt;Two possible exceptions to this are the base / &lt;span class="caps"&gt;FROM&lt;/span&gt; image, and operating system packages. Ideally the base/&lt;span class="caps"&gt;FROM&lt;/span&gt; image should be defined in the Dockerfile with an immutable tag, but in some cases it&amp;#8217;s desirable to always use the latest image, or to use a less-constrained version tag. In these cases, your build tooling should resolve and record the image used in the &lt;span class="caps"&gt;FROM&lt;/span&gt; tag, and also ideally add this as a label on the final image. Similarly, when dealing with &lt;span class="caps"&gt;OS&lt;/span&gt; packages which may be updated within a given release, it&amp;#8217;s desirable to generate a listing of all installed packages before the build finishes and store this somewhere if needed at a later&amp;nbsp;date.&lt;/p&gt;
&lt;h2 id="no-runtime-downloads"&gt;&lt;a class="toclink" href="#no-runtime-downloads"&gt;No Runtime&amp;nbsp;Downloads&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Dependencies should never be downloaded by a container when it starts up. Doing so breaks repeatability of the image, introduces significant latency to the startup process, and makes possibly-invalid assumptions about network connectivity and available bandwidth. Dependencies that need to be downloaded from the Internet should either be packaged inside the image itself, or downloaded by the user (or some system/automation) and mounted into the&amp;nbsp;container.&lt;/p&gt;
&lt;h2 id="everything-in-source-control-git"&gt;&lt;a class="toclink" href="#everything-in-source-control-git"&gt;Everything in Source Control&amp;nbsp;(Git)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Your Dockerfile, as well as any dependencies for building the image that are not part of another project/artifact/package, should be stored in source control. More often than not these days, that means git. This repository should include the Dockerfile, instructions for building and developing the image, and anything that needs to be &lt;span class="caps"&gt;COPY&lt;/span&gt;&amp;#8217;ed or &lt;span class="caps"&gt;ADD&lt;/span&gt;&amp;#8217;ed into the image. If at all possible, your images should be tagged or labeled with the git commit hash that was used to build them. The repository should have tags (ideally full Releases, if hosting on GitHub or a similar system) at least corresponding to every released image (i.e. &lt;span class="caps"&gt;X.Y.&lt;/span&gt;Z for projects using&amp;nbsp;semver).&lt;/p&gt;
&lt;p&gt;This process has a number of benefits for every image, but especially for public images of open-source&amp;nbsp;projects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It&amp;#8217;s clear how to find the exact source code that was used to build a specific image, so that you or contributors can troubleshoot or modify&amp;nbsp;it.&lt;/li&gt;
&lt;li&gt;It allows easy reproduction and regression of bugs, by running specific versions of the&amp;nbsp;image.&lt;/li&gt;
&lt;li&gt;It enables using automated systems to build the image, such as Docker Hub automated&amp;nbsp;builds.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="labels"&gt;&lt;a class="toclink" href="#labels"&gt;Labels&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Docker images should make use of &lt;a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#label"&gt;LABELs&lt;/a&gt; for storing metadata, passed in as build arguments (&lt;span class="caps"&gt;ARG&lt;/span&gt;). There is a label schema that&amp;#8217;s gaining acceptance at &lt;a href="http://label-schema.org/"&gt;http://label-schema.org/&lt;/a&gt; which provides some very useful suggestions and guidelines. I recommend implementing as many of these as practical. In addition, I often find it useful to include a label with the &lt;span class="caps"&gt;URL&lt;/span&gt; to the automated build that generated the image if possible, as well as to any applicable test results. This can be quite useful when&amp;nbsp;troubleshooting.&lt;/p&gt;
&lt;h2 id="add-a-healthcheck"&gt;&lt;a class="toclink" href="#add-a-healthcheck"&gt;Add a&amp;nbsp;&lt;span class="caps"&gt;HEALTHCHECK&lt;/span&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The Dockerfile &lt;a href="https://docs.docker.com/engine/reference/builder/#healthcheck"&gt;&lt;span class="caps"&gt;HEALTHCHECK&lt;/span&gt;&lt;/a&gt; allows specifying a command to be executed inside running containers at a configurable interval, to check the health of the container. Unless you know for certain that any critical failure in the container will cause it to exit, you should add a health check. This is especially important in any container that uses an init system or runs multiple services. It is generally assumed that, when running Docker containers, they will exit on failure and leave it up to some external system - your service manager, the docker Daemon, etc. - to restart them and track these&amp;nbsp;events.&lt;/p&gt;
&lt;h2 id="testing-built-images"&gt;&lt;a class="toclink" href="#testing-built-images"&gt;Testing Built&amp;nbsp;Images&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It is generally unwise to assume that a &lt;code&gt;docker build&lt;/code&gt; is correct just because all commands during the build succeeded. Many times I&amp;#8217;ve seen otherwise-good Dockerfiles result in broken images because a library version changed, an executable was moved to a different package, some dependency problem exists, or an exit code went unchecked somewhere deep in a script. The Dockerfile &lt;a href="https://docs.docker.com/engine/reference/builder/#healthcheck"&gt;&lt;span class="caps"&gt;HEALTHCHECK&lt;/span&gt;&lt;/a&gt; is very important, but it only applies to running&amp;nbsp;containers.&lt;/p&gt;
&lt;p&gt;At a minimum, a script should be included in the Dockerfile and executed via &lt;code&gt;RUN&lt;/code&gt; that performs a basic sanity/smoke test of the image before the build is complete. This can be as simple as running noop versions of important commands (such as a &lt;code&gt;--version&lt;/code&gt; flag) to ensure that they execute without error, or adding a sanity check command to your&amp;nbsp;service.&lt;/p&gt;
&lt;p&gt;Taken a step further, if at all possible, you should actually run containers from newly-built images before pushing them to a registry. This can be as simple as ensuring that the container starts up correctly, or running some basic network/functional tests against the service running in it. As a next step, you can run something like &lt;a href="https://serverspec.org/"&gt;serverspec&lt;/a&gt; / &lt;a href="https://testinfra.readthedocs.io/en/latest/"&gt;testinfra&lt;/a&gt; / &lt;a href="https://github.com/aelsabbahy/goss"&gt;goss&lt;/a&gt; against the container to verify the state of files, services, processes, listening ports, etc. Ideally, you should also run your application&amp;#8217;s test suite (what I&amp;#8217;d usually call &amp;#8220;acceptance tests&amp;#8221;), or a representative subset of it, against the&amp;nbsp;container.&lt;/p&gt;
&lt;h2 id="updates-rollbacks-issue-reproduction-and-disaster-recovery"&gt;&lt;a class="toclink" href="#updates-rollbacks-issue-reproduction-and-disaster-recovery"&gt;Updates, Rollbacks, Issue Reproduction, and Disaster&amp;nbsp;Recovery&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In general, assuming the service inside an image is designed correctly, deploying an update should be as simple as pulling and running a newer tag of the same image. Ideally, the service inside the container is written to gracefully handle both upgrades and downgrades (if applicable). This allows our deployment/update and rollback plan to be the same: just stop the container that&amp;#8217;s currently running, and start one of the unique tag that we want&lt;sup&gt;&lt;a href="#foot1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;a name="foot1source"&gt;&lt;/a&gt;. Some orchestration is required when running multiple instances of a service, but the overall concept remains the same: aside from the data we store or pass in (i.e. environment variables, volume mounts, and any external stores such as databases), we should be able to completely and identically recreate a previous state by running the previous tag of the&amp;nbsp;image.&lt;/p&gt;
&lt;p&gt;Since a Docker image is an immutable artifact with a unique identifier (tag), we can run a given image on any other system at any time in the future. This has very significant benefits for troubleshooting (issue reproduction) as well as disaster recovery. So long as we capture the state of all external data before changing the running image (i.e. dump databases, back up any filesystems mounted into the container), it should be possible to recreate a functionally identical system and state at any point in the future. Deploy an upgrade to production and find some really hard-to-troubleshoot bug? Just restore your backups (sanitized of any sensitive data, of course) to a test environment, run the same tag of your image with adjusted configuration, and reproduce the bug safely&lt;sup&gt;&lt;a href="#foot2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;a name="foot2source"&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Similarly, in a disaster recovery context, all we need to do is have a record of how our container was started/run (you&amp;#8217;re using some sort of configuration management for this, right?) and a backup of any volumes that it uses. If the machine it&amp;#8217;s running on catches fire, or gets deleted, two years from now&amp;#8230; just restore the backed-up volumes, and pull and run the container the same way you did before. You should end up with an identical&amp;nbsp;system.&lt;/p&gt;
&lt;h2 id="automated-builds"&gt;&lt;a class="toclink" href="#automated-builds"&gt;Automated&amp;nbsp;Builds&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Finally, while some may disagree, I&amp;#8217;m a staunch advocate that &lt;code&gt;docker build&lt;/code&gt; should &lt;em&gt;never&lt;/em&gt; be directly executed by a human. It is virtually impossible to follow the other guidance here reliably - especially when it comes to tags and labels - by building a &lt;code&gt;docker build&lt;/code&gt; command by hand. Ideally, all builds will be handled by an automated system, which could be anything from Docker Hub automated builds to Jenkins or another &lt;span class="caps"&gt;CI&lt;/span&gt; system, to a shell script. At times, I&amp;#8217;ve gone so far as to add a required &lt;code&gt;ARG never_build_manually&lt;/code&gt; to the Dockerfile to make this clear. For local development a &lt;code&gt;local_build.sh&lt;/code&gt; script can be added to the repository, which sets tags and labels appropriately to ensure that if the image is pushed to a registry it&amp;#8217;s clearly identified as a local development&amp;nbsp;build.&lt;/p&gt;
&lt;p&gt;Enforcing that only automated builds are considered &amp;#8220;real&amp;#8221; builds ensures that the above points - especially repeatability, proper tagging and labeling, and full testing - are always in place for each&amp;nbsp;image.&lt;/p&gt;
&lt;h1 id="docker-image-checklist"&gt;&lt;a class="toclink" href="#docker-image-checklist"&gt;Docker Image&amp;nbsp;Checklist&lt;/a&gt;&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Your Dockerfile follows the &lt;a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/"&gt;Best practices for writing Dockerfiles&lt;/a&gt;, and your service is as close to a &lt;a href="https://12factor.net/"&gt;12 factor app&lt;/a&gt; as&amp;nbsp;possible.&lt;/li&gt;
&lt;li&gt;Your image/container &lt;a href="#what-to-put-in-an-image"&gt;only runs one service&lt;/a&gt;, ideally without any sort of init&amp;nbsp;subsystem.&lt;/li&gt;
&lt;li&gt;Your image takes its &lt;a href="#configuration"&gt;configuration&lt;/a&gt; via environment variables, or if need be, via config files mounted into the running container (with sane defaults&amp;nbsp;provided).&lt;/li&gt;
&lt;li&gt;In no circumstances do you build different images for different environments or deployment&amp;nbsp;scenarios.&lt;/li&gt;
&lt;li&gt;The service running in your images &lt;a href="#logging"&gt;logs&lt;/a&gt; to &lt;span class="caps"&gt;STDOUT&lt;/span&gt;/&lt;span class="caps"&gt;STDERR&lt;/span&gt;, to be handled by the Docker daemon, and not to files on disk. Ideally, out and err have some logical&amp;nbsp;separation.&lt;/li&gt;
&lt;li&gt;Your image is &lt;a href="#tagging-and-versioning"&gt;tagged&lt;/a&gt; with both a unique/immutable tag per image as well as relevant version tags (ideally following semver, and allowing use of major or major.minor images). All images should be able to be referenced by a unique tag, for all time to&amp;nbsp;come.&lt;/li&gt;
&lt;li&gt;For released software or open-source projects, the &lt;code&gt;latest&lt;/code&gt; tag points to the most recent stable&amp;nbsp;release.&lt;/li&gt;
&lt;li&gt;Within the constraints of base images, &lt;span class="caps"&gt;OS&lt;/span&gt; packages, etc. any given image is &lt;a href="#repeatable-builds"&gt;repeatable&lt;/a&gt; and can be rebuilt from source control at any point in the&amp;nbsp;future.&lt;/li&gt;
&lt;li&gt;When run as a container, your image does not &lt;a href="#no-runtime-downloads"&gt;download dependencies at runtime&lt;/a&gt;. The image should include everything (except data) required to&amp;nbsp;work.&lt;/li&gt;
&lt;li&gt;Everything needed to build the image (aside from external artifacts) is &lt;a href="#everything-in-source-control-git"&gt;included in source control&lt;/a&gt;, and versioned along with the Dockerfile. It is possible to tie an image to the commit / source state that it was generated from, and to tie a tag/release in source control to the corresponding&amp;nbsp;image.&lt;/li&gt;
&lt;li&gt;Your image makes use of &lt;a href="#labels"&gt;labels&lt;/a&gt; on the image to store metadata about it, its contents, and the build&amp;nbsp;process.&lt;/li&gt;
&lt;li&gt;Your image includes a &lt;a href="#add-a-healthcheck"&gt;healthcheck&lt;/a&gt; so that the Docker daemon can tell if containers are in a healthy, functional&amp;nbsp;state.&lt;/li&gt;
&lt;li&gt;The process for building your image includes running &lt;a href="#testing-built-images"&gt;tests&lt;/a&gt; against it, and ideally also against a running&amp;nbsp;container.&lt;/li&gt;
&lt;li&gt;Data used by your image is isolated in volumes, so that users can &lt;a href="#updates-rollbacks-issue-reproduction-and-disaster-recovery"&gt;roll back and forward, reproduce issues, and perform disaster recovery&lt;/a&gt; via&amp;nbsp;tags.&lt;/li&gt;
&lt;li&gt;The process for building your image is &lt;a href="#automated-builds"&gt;automated&lt;/a&gt;, and manually/locally built images are easily identified as development / non-release&amp;nbsp;artifacts.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="footnotes"&gt;&lt;a class="toclink" href="#footnotes"&gt;Footnotes&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a name="foot1"&gt;1&lt;/a&gt;: This is a gross simplification, describing a lab or desktop environment or the most trivial and unimportant service. For anything else, even in the lowest environments, you&amp;#8217;d most likely have multiple containers running of the same service, and would use a zero-downtime deployment method such as blue/green or progressive traffic shifting. But at an extremely high level, the idea is the same: that you can roll backwards and forwards through container versions. &lt;a href="#foot1source"&gt;back to&amp;nbsp;source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name="foot2"&gt;2&lt;/a&gt;: I&amp;#8217;ll admit that this is rather optimistic, and makes a lot of assumptions. This may end up being &lt;em&gt;much&lt;/em&gt; more complicated than &amp;#8220;just restore your backups and run it in test&amp;#8221;, but it&amp;#8217;s still much simpler than what this process looked like a decade ago. &lt;a href="#foot2source"&gt;back to&amp;nbsp;source&lt;/a&gt;&lt;/p&gt;</content><category term="docker"></category><category term="build"></category><category term="deploy"></category><category term="image"></category><category term="container"></category></entry><entry><title>Galaxy S10 / Android 9 alarm app broken by batteryÂ optimization</title><link href="https://blog.jasonantman.com/2019/04/galaxy-s10--android-9-alarm-app-broken-by-battery-optimization/" rel="alternate"></link><published>2019-04-02T07:46:00-04:00</published><updated>2019-04-02T07:46:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2019-04-02:/2019/04/galaxy-s10--android-9-alarm-app-broken-by-battery-optimization/</id><summary type="html">&lt;p&gt;How to fix the Galaxy S10 / Android 9 &amp;#8220;Pie&amp;#8221; phones from putting alarm apps to&amp;nbsp;sleep.&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few weeks ago I finally replaced my four-year-old Samsung Galaxy S6 with a brand new Galaxy S10. All in all I&amp;#8217;ve been liking it aside from a few differences in the last four years of Android development that annoy me. By far the biggest issue I&amp;#8217;ve had was my alarm clock not going off two morings, and going off seventeen minutes late another morning. At first I thought maybe I was shutting my alarm off, but that doesn&amp;#8217;t seem likely&amp;#8230; I use &lt;a href="https://play.google.com/store/apps/details?id=com.vp.alarmClockPlusDock"&gt;Alarm Clock Plus&lt;/a&gt;, and have been using it for almost ten years, because it allows me to set an alarm that requires correctly solving some algebra to snooze or dismiss it. I tend to be a very heavy sleeper, and the &amp;#8220;math to snooze&amp;#8221; / &amp;#8220;math to dismiss&amp;#8221; requirement ensures that I actually wake up, yet eliminates the harsh &amp;#8220;alarm clock on the other side of the room&amp;#8221;&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;So I was right, I didn&amp;#8217;t suddenly start sleeping so deeply that I could do the algebra and disable my alarm without even remembering it. On the third day of no alarm, I saw the pattern: if I had my phone on the charger, the alarm went off. If my phone wasn&amp;#8217;t on the charger overnight - as I&amp;#8217;d started doing because I now had a phone that lasted &lt;em&gt;two&lt;/em&gt; days on a charge - the alarm wouldn&amp;#8217;t go off. I figured it had to be something with power management or putting apps to&amp;nbsp;sleep.&lt;/p&gt;
&lt;p&gt;Sure enough, this was caused by the new &amp;#8220;&lt;span class="caps"&gt;AI&lt;/span&gt;-based&amp;#8221; battery optimization, which by default limits background usage - not just data, but processor cycles - of apps that it thinks you don&amp;#8217;t use&amp;nbsp;often.&lt;/p&gt;
&lt;p&gt;To solve this on my Samsung Galaxy S10 running Android 9 / OneUI&amp;nbsp;1.1:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Open the Android Settings&amp;nbsp;app.&lt;/li&gt;
&lt;li&gt;Scroll to and tap on&amp;nbsp;&amp;#8220;Apps&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Tap on the app in question (Alarm Clock Plus for&amp;nbsp;me).&lt;/li&gt;
&lt;li&gt;Tap on &amp;#8220;Battery&amp;#8221; in the &amp;#8220;Usage&amp;#8221;&amp;nbsp;menu.&lt;/li&gt;
&lt;li&gt;Ensure the &amp;#8220;Allow background activity&amp;#8221; slider is&amp;nbsp;&lt;span class="caps"&gt;ON&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Tap the &amp;#8220;Optimize battery usage&amp;#8221;&amp;nbsp;button.&lt;/li&gt;
&lt;li&gt;Near the top left, change the dropdown from &amp;#8220;Apps not optimized&amp;#8221; to&amp;nbsp;&amp;#8220;All&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Find the app in question, and tap it to turn the slider&amp;nbsp;&lt;span class="caps"&gt;OFF&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This should let the app use background resources as it desires, such as ensuring that your alarm goes off when&amp;nbsp;scheduled.&lt;/p&gt;</content><category term="android"></category><category term="samsung"></category><category term="s10"></category><category term="galaxy s10"></category><category term="android 9"></category><category term="pie"></category><category term="battery optimization"></category><category term="app"></category></entry><entry><title>Open Source WiFi Site Survey HeatmapÂ Tool</title><link href="https://blog.jasonantman.com/2018/11/open-source-wifi-site-survey-tool/" rel="alternate"></link><published>2018-11-01T18:07:00-04:00</published><updated>2018-11-01T18:07:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-11-01:/2018/11/open-source-wifi-site-survey-tool/</id><summary type="html">&lt;p&gt;A bit about a Python project I wrote to plot floorplan heatmaps of wireless site&amp;nbsp;surveys.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week I finally bought myself a new wireless access point (&lt;span class="caps"&gt;AP&lt;/span&gt;) to replace my current ones, a pair of older Ubiquiti models that have been continually in service without issue for &lt;a href="https://twitter.com/j_antman/status/1029135879695228929"&gt;nine years&lt;/a&gt; and five years, respectively. I bought another Ubiquiti, of course, but wanted to be a bit more methodical and scientific in figuring out the best placement of it in my&amp;nbsp;house.&lt;/p&gt;
&lt;p&gt;Years ago when part of my job was supporting an extremely large wireless network, we used some expensive proprietary Windows software (I&amp;#8217;m pretty sure it was &lt;a href="https://www.ekahau.com/products/ekahau-site-survey/overview/"&gt;Ekahau Site Survey&lt;/a&gt;) for performing site surveys to
determine &lt;span class="caps"&gt;AP&lt;/span&gt; location. Essentially you temporarily rig up a running &lt;span class="caps"&gt;AP&lt;/span&gt; where you propose locating one, load a floorplan of the building into the site survey software, and then walk around the area tapping on the floorplan at your current location. At each tap, the software performs some measurements through the &lt;span class="caps"&gt;AP&lt;/span&gt; (I don&amp;#8217;t remember what the specific software we used did, but generally it&amp;#8217;s some bandwidth measurement like &lt;a href="https://software.es.net/iperf/"&gt;iperf&lt;/a&gt;) and ends up plotting a (predictive, interpolated) heatmap of signal strength or data transfer speeds over the&amp;nbsp;floorplan.&lt;/p&gt;
&lt;p&gt;I wanted to do something similar for my new &lt;span class="caps"&gt;AP&lt;/span&gt;, but was rather surprised that I couldn&amp;#8217;t find any existing F/&lt;span class="caps"&gt;OSS&lt;/span&gt; solution; only a handful of proprietary options costing anywhere from &amp;#8220;more than I&amp;#8217;d pay for a one-time thing&amp;#8221; to astronomical prices, and none of them clearly with Linux support. The closest I was able to find - and I&amp;#8217;m very thankful that I found it - was a &lt;a href="https://github.com/beaugunderson/wifi-heatmap"&gt;GitHub repository from Beau Gunderson&lt;/a&gt; that plots a heatmap superimposed on a floorplan using a &lt;span class="caps"&gt;CSV&lt;/span&gt; file of WiFi signal strength measurements. This was enough to get me started on a similar project to automate the&amp;nbsp;process.&lt;/p&gt;
&lt;p&gt;Over a couple of afternoons I came up with a really rough tool, &lt;a href="https://github.com/jantman/python-wifi-survey-heatmap"&gt;python-wifi-survey-heatmap&lt;/a&gt; to handle this. The full documentation is in the &lt;a href="https://github.com/jantman/python-wifi-survey-heatmap/blob/master/README.rst"&gt;&lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt;, but the gist is that it&amp;#8217;s a Python &lt;span class="caps"&gt;GUI&lt;/span&gt; (wxPython) and &lt;span class="caps"&gt;CLI&lt;/span&gt; application that automates the process. It&amp;#8217;s currently Linux-only because it uses &lt;code&gt;iwlib&lt;/code&gt; (wireless_tools) to pull wireless information and perform scans, but that could be fixed by adding collector classes for other OSes. In short you run an iperf3 server somewhere on your &lt;span class="caps"&gt;LAN&lt;/span&gt;, connect to the &lt;span class="caps"&gt;SSID&lt;/span&gt; you want to test, fire up the &lt;span class="caps"&gt;GUI&lt;/span&gt; passing it the path to an image to use as the floorplan background and the &lt;span class="caps"&gt;IP&lt;/span&gt; or hostname of the iperf3 server, and then walk around clicking the floorplan at your current location. For each click the application will draw a yellow circle and then change it to green when measurement is complete, about a minute&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;For each measurement point (location on the floorplan), the application&amp;nbsp;captures:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Current wireless statistics including quality, signal strength, and noise level (like &lt;code&gt;iwconfig&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;A current scan (like &lt;code&gt;iwlist scan&lt;/code&gt;) of all visible networks and their signal&amp;nbsp;strength/quality.&lt;/li&gt;
&lt;li&gt;Three 10-second iperf3 measurements to the iperf&amp;nbsp;server:&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;TCP&lt;/span&gt; upload (client/application to&amp;nbsp;server)&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;TCP&lt;/span&gt; download (server to&amp;nbsp;client)&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;UDP&lt;/span&gt;&amp;nbsp;upload&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After each measurement is complete all data is saved to a &lt;span class="caps"&gt;JSON&lt;/span&gt; file in the current directory, and the gui application can optionally load an existing &lt;span class="caps"&gt;JSON&lt;/span&gt; output file to continue a previous survey. None of this uses any sort of shell/subprocess/exec hackery; we interface with iwconfig and iwlist information via the python &lt;a href="https://pypi.org/project/iwlib/"&gt;iwlib&lt;/a&gt; package, a cffi Python wrapper around wireless_tools&amp;#8217; iwlib, and with iperf3 via the &lt;a href="https://pypi.org/project/iperf3/"&gt;iperf3&lt;/a&gt; package, a cdll wrapper around&amp;nbsp;libiperf.&lt;/p&gt;
&lt;p&gt;Once you&amp;#8217;ve completed capturing data for your site survey, the &lt;code&gt;wifi-heatmap&lt;/code&gt; &lt;span class="caps"&gt;CLI&lt;/span&gt; entrypoint processes the data and generates some heatmaps as well as channel utilization graphs like&amp;nbsp;these:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/channels24_WAP1.png"&gt;&lt;img alt="example 2.4 GHz channel usage" src="/GFX/channels24_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/channels5_WAP1.png"&gt;&lt;img alt="example 5 GHz channel usage" src="/GFX/channels5_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/jitter_WAP1.png"&gt;&lt;img alt="example jitter heatmap" src="/GFX/jitter_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/quality_WAP1.png"&gt;&lt;img alt="example quality heatmap" src="/GFX/quality_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/rssi_WAP1.png"&gt;&lt;img alt="example rssi heatmap" src="/GFX/rssi_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/tcp_download_Mbps_WAP1.png"&gt;&lt;img alt="example tcp download heatmap" src="/GFX/tcp_download_Mbps_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/tcp_upload_Mbps_WAP1.png"&gt;&lt;img alt="example tcp upload heatmap" src="/GFX/tcp_upload_Mbps_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/udp_Mbps_WAP1.png"&gt;&lt;img alt="example udp upload heatmap" src="/GFX/udp_Mbps_WAP1_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All of the code and some initial documentation is available at &lt;a href="https://github.com/jantman/python-wifi-survey-heatmap"&gt;https://github.com/jantman/python-wifi-survey-heatmap&lt;/a&gt;. It&amp;#8217;s very alpha and rough around the edges, and I doubt I&amp;#8217;ll be actively developing or supporting it once I&amp;#8217;m done installing my new &lt;span class="caps"&gt;AP&lt;/span&gt;, but I very much hope that it might be of use to someone else and maybe someone will even improve it a&amp;nbsp;bit.&lt;/p&gt;</content><category term="wifi"></category><category term="survey"></category><category term="wireless"></category><category term="heatmap"></category><category term="python"></category></entry><entry><title>Better Logging for AppDaemonÂ Apps</title><link href="https://blog.jasonantman.com/2018/07/better-logging-for-appdaemon-apps/" rel="alternate"></link><published>2018-07-15T07:38:00-04:00</published><updated>2018-07-15T07:38:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2018-07-15:/2018/07/better-logging-for-appdaemon-apps/</id><summary type="html">&lt;p&gt;A small Python class I wrote to give AppDaemon apps more Pythonic&amp;nbsp;logging.&lt;/p&gt;</summary><content type="html">&lt;p&gt;As I briefly mentioned in my last post, &lt;a href="/2018/07/ip-camera-home-security-and-automation-update/"&gt;&lt;span class="caps"&gt;IP&lt;/span&gt; Camera, Home Security and Automation Update&lt;/a&gt;, I&amp;#8217;ve begun using the &lt;a href="https://www.home-assistant.io/"&gt;HomeAssistant&lt;/a&gt; project for home automation and also to act as the brain for my &lt;span class="caps"&gt;DIY&lt;/span&gt; alarm system. The logic behind some of this is somewhat complex, so rather than try to use HomeAssistant&amp;#8217;s &lt;span class="caps"&gt;YAML&lt;/span&gt;-based automation configuration for all of it, I&amp;#8217;ve implemented the alarm logic using AppDaemon. &lt;a href="http://appdaemon.readthedocs.io/en/latest/"&gt;AppDaemon&lt;/a&gt; is a Python daemon that integrates with HomeAssistant&amp;#8217;s &lt;span class="caps"&gt;API&lt;/span&gt; and message/event bus, and allows standalone Python classes (&amp;#8220;apps&amp;#8221;) to operate like HomeAssistant automations - be triggered by events or state change, access internal state and attributes, call services, and control anything that HomeAssistant can control. For someone with at least a basic working knowledge of Python, this makes it much easier to write complex conditional logic than attempting to use&amp;nbsp;&lt;span class="caps"&gt;YAML&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;However, when I wrote my first AppDaemon app, I was quite frustrated by the built-in logging system. The &lt;a href="http://appdaemon.readthedocs.io/en/latest/APPGUIDE.html#writing-to-logfiles"&gt;documentation&lt;/a&gt; explains that AppDaemon uses two log files by default, &amp;#8220;general&amp;#8221; and &amp;#8220;error&amp;#8221;, and that each AppDaemon app (subclass of &lt;code&gt;appdaemon.plugins.hass.hassapi.Hass&lt;/code&gt;) can log to them using &lt;code&gt;self.log()&lt;/code&gt; and &lt;code&gt;self.error()&lt;/code&gt; convenience methods. So far this sounds fine. However, looking at the &lt;span class="caps"&gt;API&lt;/span&gt; documentation for these &lt;a href="http://appdaemon.readthedocs.io/en/latest/APIREFERENCE.html#log"&gt;log()&lt;/a&gt; and &lt;a href="http://appdaemon.readthedocs.io/en/latest/APIREFERENCE.html#error"&gt;error()&lt;/a&gt; methods, it becomes apparent that the only arguments they take are a string &lt;code&gt;message&lt;/code&gt; and a log level that defaults to &lt;code&gt;INFO&lt;/code&gt;. Unlike the ubiquitous logging methods of the &lt;a href="https://docs.python.org/3/library/logging.html#logger-objects"&gt;Python standard library&lt;/a&gt;, they don&amp;#8217;t accept a message with percent-formatting placeholders and a list of arguments, meaning that the message string needs to be formatted in the logging call&amp;nbsp;itself.&lt;/p&gt;
&lt;p&gt;Another annoyance is the fixed logging format that includes only the timestamp, log level, app name, and message; when I&amp;#8217;m developing and debugging code I often find it useful to include at least the source module and line number in the log message. At first I tried to alter the logging formatter in use by AppDaemon, but that gave some strange results because it turns out that AppDaemon doesn&amp;#8217;t actually use a logging format, but rather in the &lt;a href="https://github.com/home-assistant/appdaemon/blob/e04820aafafe840fb4be7a8bef1996b70e62506f/appdaemon/utils.py#L143-L160"&gt;appdaemon.utils.log()&lt;/a&gt; function interpolates the timestamp, level and app name directly into the message and passes that to&amp;nbsp;logging.&lt;/p&gt;
&lt;p&gt;Furthermore, and even more bothersome during development, there&amp;#8217;s no way to enable debug-level logging on a per-app basis. Logging level is controlled by a command line flag (&lt;code&gt;-D&lt;/code&gt;) to &lt;code&gt;appdaemon&lt;/code&gt; itself, which means that debug logging is all-or-nothing for both AppDaemon itself and all apps. I found a &lt;a href="https://community.home-assistant.io/t/appdaemon-debug-mode/9703"&gt;forum thread&lt;/a&gt; complaining about this and also a &lt;a href="https://github.com/home-assistant/appdaemon/issues/45"&gt;closed GitHub issue&lt;/a&gt; looking for a better&amp;nbsp;solution.&lt;/p&gt;
&lt;p&gt;So, I came up with my own solution to this in the form of my &lt;a href="https://github.com/jantman/home-automation-configs/blob/9c196f1e552fc9fbdfe15f2e27a7275bca24f167/appdaemon/apps/sane_app_logging.py"&gt;sane_app_logging.py&lt;/a&gt; module and the &lt;a href="https://github.com/jantman/home-automation-configs/blob/9c196f1e552fc9fbdfe15f2e27a7275bca24f167/appdaemon/apps/sane_app_logging.py"&gt;SaneAppLogging&lt;/a&gt; mixin class in it. All I need to do is add &lt;code&gt;SaneAppLogging&lt;/code&gt; to the list of classes my app inherits from and add a call to &lt;code&gt;self._setup_logging(self.__class__.__name__, False)&lt;/code&gt; at the beginning of the &lt;code&gt;initialize()&lt;/code&gt; method. What this gets me&amp;nbsp;is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;self._log.(debug|info|warning|error|critical|log)&lt;/code&gt; methods that pass directly through to the standard library logging methods, including args and kwargs (and therefore support for log messages with percent-formatting of&amp;nbsp;args).&lt;/li&gt;
&lt;li&gt;Log message formatting for all of AppDaemon that includes the filename, line number and function name (&lt;code&gt;"[%(levelname)s %(filename)s:%(lineno)s - %(name)s.%(funcName)s() ] %(message)s"&lt;/code&gt;). A large portion of the code in my &lt;code&gt;sane_app_logging.py&lt;/code&gt; module is dedicated to finding the proper stack frame so that source location is correct even with the wrapper in&amp;nbsp;place.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Runtime&lt;/em&gt; toggling of &amp;#8220;debug-as-info&amp;#8221; logging. To get around AppDaemon&amp;#8217;s global log levels and the requirement of enabling debugging at AppDaemon start and for all running code, apps using &lt;code&gt;SaneAppLogging&lt;/code&gt; listen for a &lt;code&gt;LOGWRAPPER_SET_DEBUG&lt;/code&gt; event from HomeAssistant. When received this event toggles a specific app class to log all &lt;code&gt;.debug()&lt;/code&gt; messages at &lt;span class="caps"&gt;INFO&lt;/span&gt; level instead, allowing me to selectively turn on and off debug logging on a single app at&amp;nbsp;runtime.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The event payloads for debug-as-info toggling are quite simple, a dictionary with two keys: &lt;code&gt;app_class&lt;/code&gt; and &lt;code&gt;debug_value&lt;/code&gt;. &lt;code&gt;app_class&lt;/code&gt; should be set to the name of the class (App) we want to change, and &lt;code&gt;debug_value&lt;/code&gt; a boolean. When True, any messages logged via &lt;code&gt;self._log.debug()&lt;/code&gt; will &lt;a href="https://github.com/jantman/home-automation-configs/blob/9c196f1e552fc9fbdfe15f2e27a7275bca24f167/appdaemon/apps/sane_app_logging.py#L100-L102"&gt;actually be logged&lt;/a&gt; via &lt;code&gt;self._log.info()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So far this seems to be working quite well for me, and allowing me to have a much better experience with developing, debugging and testing AppDaemon apps. Perhaps it will be useful to someone else as&amp;nbsp;well.&lt;/p&gt;</content><category term="AppDaemon"></category><category term="HomeAssistant"></category><category term="automation"></category><category term="python"></category><category term="logging"></category></entry><entry><title>Python script to check xfinity dataÂ usage</title><link href="https://blog.jasonantman.com/2017/04/python-script-to-check-xfinity-data-usage/" rel="alternate"></link><published>2017-04-17T16:11:00-04:00</published><updated>2017-04-17T16:11:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2017-04-17:/2017/04/python-script-to-check-xfinity-data-usage/</id><summary type="html">&lt;p&gt;Python/selenium script to check your Xfinity data&amp;nbsp;usage&lt;/p&gt;</summary><content type="html">&lt;p&gt;Yesterday I got one of those invasive, abusive, utterly awful (and idiotic) &lt;a href="https://www.techdirt.com/articles/20161123/10554936126/comcast-takes-heat-injecting-messages-into-internet-traffic.shtml"&gt;injected popups from Xfinity&lt;/a&gt; that I&amp;#8217;m at 75% of my monthly bandwidth allocation. Nevermind the fact that I have a bunch of automated scripts running on my computer and injected &lt;span class="caps"&gt;HTML&lt;/span&gt; might never be seen by a human, or that I work from home and every once in a while I&amp;#8217;ll find myself pulling and pushing multi-&lt;span class="caps"&gt;GB&lt;/span&gt; Docker images, which completely kills my &lt;span class="caps"&gt;1TB&lt;/span&gt; bandwidth limit. But it&amp;#8217;s only half way through the month and, frankly, I&amp;#8217;m pretty mystified how I could have used so much data this quickly. I went to Xfinity&amp;#8217;s site to check my usage meter - after rummaging around in my password manager to find my credentials - and realized that while it shows a graph of the past three months and a progress bar for the current month, it doesn&amp;#8217;t show me any detailed (i.e. daily or hourly) data that would help me figure out the&amp;nbsp;cause.&lt;/p&gt;
&lt;p&gt;So, I wrote a little &lt;a href="https://github.com/jantman/xfinity-usage"&gt;script&lt;/a&gt; using Python and Selenium to log in to their My Account site and screen-scrape the &lt;a href="http://www.xfinity.com/usagemeter"&gt;usage meter&lt;/a&gt;. Why Comcast would require me to log in to view my usage when I&amp;#8217;m accessing their site from the &lt;span class="caps"&gt;IP&lt;/span&gt; address &lt;em&gt;they&lt;/em&gt; gave me, on &lt;em&gt;their&lt;/em&gt; network, I have no idea&amp;#8230; unless it&amp;#8217;s to provide a disincentive for customers to be aware of their usage. But I wrote the script, and it seems to be working. For the time being, I&amp;#8217;m both pushing the results into Graphite so I can see usage over time, and sending myself a daily email so I can keep on top of&amp;nbsp;usage.&lt;/p&gt;
&lt;p&gt;Apparently Comcast used to have &lt;a href="http://usmapp-qa.comcast.net/"&gt;a desktop app&lt;/a&gt; to track usage but it&amp;#8217;s since been completely shut down, along with the &lt;span class="caps"&gt;API&lt;/span&gt; that backed it (which an enterprising fellow reverse-engineered in &lt;a href="https://github.com/WTFox/comcastUsage"&gt;this script&lt;/a&gt;). I can only assume this is another indication that, though the bandwidth cap was introduced citing &amp;#8220;network performance&amp;#8221;, they really don&amp;#8217;t want people lowering network load (and avoiding&amp;nbsp;fees).&lt;/p&gt;
&lt;p&gt;I don&amp;#8217;t remember anything about screen-scraping in the Xfinity terms of service - and if they&amp;#8217;re f-ing injecting elements into &lt;em&gt;my&lt;/em&gt; web traffic, I sure as hell hope they don&amp;#8217;t complain about me checking my own usage - but use this at your own risk. Also be aware that it&amp;#8217;s screen-scraping, so it may well break with a site redesign or element &lt;span class="caps"&gt;ID&lt;/span&gt;&amp;nbsp;changes.&lt;/p&gt;
&lt;p&gt;If anyone would find this useful, please see &lt;a href="https://github.com/jantman/xfinity-usage"&gt;https://github.com/jantman/xfinity-usage&lt;/a&gt;.&lt;/p&gt;</content><category term="comcast"></category><category term="xfinity"></category><category term="data"></category><category term="usage"></category><category term="bandwidth"></category><category term="cap"></category><category term="python"></category><category term="selenium"></category></entry><entry><title>OpenSSH changing hostnames based onÂ location</title><link href="https://blog.jasonantman.com/2016/08/openssh-changing-hostnames-based-on-location/" rel="alternate"></link><published>2016-08-27T11:22:00-04:00</published><updated>2016-08-27T11:22:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2016-08-27:/2016/08/openssh-changing-hostnames-based-on-location/</id><summary type="html">&lt;p&gt;How to change &lt;span class="caps"&gt;SSH&lt;/span&gt; hostnames based on guessed&amp;nbsp;location&lt;/p&gt;</summary><content type="html">&lt;p&gt;Yesterday I was doing some work on my laptop, SSHed in to my desktop (&amp;#8220;phoenix&amp;#8221;). As
always happens when I&amp;#8217;m using my laptop from home, I kept getting connection errors&amp;#8230;
because my &lt;code&gt;~/.ssh/config&lt;/code&gt; on my laptop is setup with my dynamic &lt;span class="caps"&gt;DNS&lt;/span&gt; hostname and port
to reach my desktop, for any time I&amp;#8217;m out of the house. But those don&amp;#8217;t work while
on the home network, and I got really tired of having to &lt;code&gt;ssh 192.168.0.24&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It turns out that, as long as your&amp;#8217;re using &lt;a href="http://www.openssh.com/txt/release-6.5"&gt;OpenSSH &amp;gt;= 6.5&lt;/a&gt;,
the &lt;code&gt;ssh_config (5)&lt;/code&gt; file (typically &lt;code&gt;~/.ssh/config&lt;/code&gt;) supports a &lt;code&gt;Match&lt;/code&gt; directive
that can execute system commands, and either match or not based on exit&amp;nbsp;code.&lt;/p&gt;
&lt;p&gt;I came up with relatively naive script that tries to determine whether or not I&amp;#8217;m on my
home network based on a combination of &lt;code&gt;resolv.conf&lt;/code&gt; settings, &lt;span class="caps"&gt;IP&lt;/span&gt; address and WiFi&amp;nbsp;&lt;span class="caps"&gt;SSID&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;# test if I&amp;#39;m on my home network,&lt;/span&gt;
&lt;span class="c1"&gt;# for &lt;span class="caps"&gt;SSH&lt;/span&gt; matching. Somewhat naive.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# For use in ~/.ssh/config Match directive;&lt;/span&gt;
&lt;span class="c1"&gt;# exit 0 if I&amp;#39;m at home, exit 1 otherwise&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# To debug, run script directly as `bash -x am_i_am_home.sh`&lt;/span&gt;
&lt;span class="c1"&gt;########&lt;/span&gt;

&lt;span class="c1"&gt;# check that I&amp;#39;ve got the right nameserver and search domain; exit otherwise&lt;/span&gt;
grep -q &lt;span class="s1"&gt;&amp;#39;jasonantman.com&amp;#39;&lt;/span&gt; /etc/resolv.conf &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
grep &lt;span class="s1"&gt;&amp;#39;^nameserver&amp;#39;&lt;/span&gt; /etc/resolv.conf &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s1"&gt;&amp;#39;192.168.0.1&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;

&lt;span class="c1"&gt;# check that I&amp;#39;ve got a 192.168.0. address; exit otherwise&lt;/span&gt;
ip addr &lt;span class="p"&gt;|&lt;/span&gt; grep -q &lt;span class="s1"&gt;&amp;#39;192.168.0.&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;

&lt;span class="c1"&gt;# check that I&amp;#39;m connected to one of my SSIDs; if so, exit 0 (match)&lt;/span&gt;
nmcli -t -f active,ssid dev wifi &lt;span class="p"&gt;|&lt;/span&gt; grep -q &lt;span class="s1"&gt;&amp;#39;^yes:ObiWAN&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
nmcli -t -f active,ssid dev wifi &lt;span class="p"&gt;|&lt;/span&gt; grep -q &lt;span class="s1"&gt;&amp;#39;^yes:&lt;span class="caps"&gt;WAP1&lt;/span&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;

&lt;span class="c1"&gt;# assume not; no match&lt;/span&gt;
&lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This can be used in my &lt;code&gt;~/.ssh/config&lt;/code&gt; to trigger an initial (internal network)
directive if it exits 0, and fall through to the external-network directive otherwise,
as shown below. The &lt;code&gt;originalhost phoenix&lt;/code&gt; portion of the &lt;code&gt;Match&lt;/code&gt; line ensures
that it&amp;#8217;s only executed if I &lt;code&gt;ssh phoenix&lt;/code&gt;, so it doesn&amp;#8217;t conflict with other
host&amp;nbsp;directives.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# phoenix when at home
Match originalhost phoenix exec &amp;quot;/home/jantman/bin/am_i_at_home.sh&amp;quot;
     HostName phoenix
     Port 22

# fall-through - phoenix when abroad
Host phoenix
     HostName my_dynamic_hostname
     Port &amp;lt;something other than 22&amp;gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="openssh"></category><category term="ssh"></category></entry><entry><title>Puppetlabs Beaker SUTs with GUI /Â Non-Headless</title><link href="https://blog.jasonantman.com/2015/09/puppetlabs-beaker-suts-with-gui--non-headless/" rel="alternate"></link><published>2015-09-19T11:09:00-04:00</published><updated>2015-09-19T11:09:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-09-19:/2015/09/puppetlabs-beaker-suts-with-gui--non-headless/</id><summary type="html">&lt;p&gt;How to enable the &lt;span class="caps"&gt;GUI&lt;/span&gt; / disable headless mode on a puppetlabs Beaker&amp;nbsp;&lt;span class="caps"&gt;SUT&lt;/span&gt;.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://github.com/puppetlabs/beaker/"&gt;Beaker&lt;/a&gt; is a puppetlabs tool for automating acceptance testing
of puppet modules; in most common use cases, it uses a &lt;a href="https://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt;/
&lt;a href="https://www.virtualbox.org/"&gt;virtualbox&lt;/a&gt; &lt;span class="caps"&gt;VM&lt;/span&gt; to run the&amp;nbsp;tests.&lt;/p&gt;
&lt;p&gt;This week, I was writing tests for a &lt;a href="https://github.com/jantman/puppet-archlinux-workstation"&gt;module&lt;/a&gt;
that configures my desktop and laptop, including installing and setting up Xorg and &lt;span class="caps"&gt;KDE&lt;/span&gt; and the
&lt;a href="https://github.com/sddm"&gt;&lt;span class="caps"&gt;SDDM&lt;/span&gt;&lt;/a&gt; display manager. I wanted to be able to test that they not only
got installed, but actually ran without dieing - which required a graphincal environment (ideally,
I&amp;#8217;d visually confirm this as&amp;nbsp;well).&lt;/p&gt;
&lt;p&gt;To do this in Vagrant, you&amp;#8217;d just add a &lt;code&gt;gui = true&lt;/code&gt; option to the
&lt;a href="https://docs.vagrantup.com/v2/virtualbox/configuration.html"&gt;virtualbox provider&lt;/a&gt; in your&amp;nbsp;Vagrantfile.&lt;/p&gt;
&lt;p&gt;It isn&amp;#8217;t documented anywhere, but I &lt;a href="https://github.com/jantman/puppet-archlinux-workstation/commit/6ca19a24853681c468eba38735c8d2d7f54cd616"&gt;found&lt;/a&gt;
that Beaker has support for this as well; all you need to do is add &lt;code&gt;vb_gui: true&lt;/code&gt; in your node definition&amp;nbsp;&lt;span class="caps"&gt;YAML&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gd"&gt;--- before.yaml 2015-09-19 11:20:47.772523116 -0400&lt;/span&gt;
&lt;span class="gi"&gt;+++ after.yaml  2015-09-19 11:20:20.768867546 -0400&lt;/span&gt;
&lt;span class="gu"&gt;@@ -1,11 +1,12 @@&lt;/span&gt;
 &lt;span class="caps"&gt;HOSTS&lt;/span&gt;:
   arch-x64:
     roles:
       - master
     platform: archlinux-2015.09.01-amd64
     box: jantman/packer-arch-workstation
     hypervisor: vagrant
&lt;span class="gi"&gt;+    vb_gui: true&lt;/span&gt;

 &lt;span class="caps"&gt;CONFIG&lt;/span&gt;:
   log_level: verbose
   type: foss
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once that&amp;#8217;s done, the VirtualBox &lt;span class="caps"&gt;VM&lt;/span&gt; will run with a graphical display enabled. This is probably only useful on a local
machine or if you&amp;#8217;re running on a remote host have you have access to and have &lt;a href="https://www.virtualbox.org/manual/ch07.html"&gt;vrdp&lt;/a&gt;
enabled, but in some edge cases like my module, it&amp;#8217;s&amp;nbsp;useful.&lt;/p&gt;</content><category term="puppet"></category><category term="beaker"></category><category term="sut"></category><category term="rspec"></category><category term="virtualbox"></category><category term="headless"></category><category term="GUI"></category></entry><entry><title>Visualization of when Iâm working on personal vs workÂ projects</title><link href="https://blog.jasonantman.com/2015/06/visualization-of-when-im-working-on-personal-vs-work-projects/" rel="alternate"></link><published>2015-06-05T21:20:00-04:00</published><updated>2015-06-05T21:20:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-06-05:/2015/06/visualization-of-when-im-working-on-personal-vs-work-projects/</id><summary type="html">&lt;p&gt;A fun python script to visualize the time of day and day of week of your commits to personal vs work&amp;nbsp;repositories.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was thinking the other day - as I was pushing out some final code reviews for work at &lt;span class="caps"&gt;11PM&lt;/span&gt; before taking a day off -
about how much work I do outside of &amp;#8220;work hours&amp;#8221;. And the answer is, I don&amp;#8217;t really know, especially when it comes to
projects that I really enjoy and find interesting. So, I decided to have some fun with &lt;a href="https://github.com/gitpython-developers/GitPython"&gt;GitPython&lt;/a&gt;
and find&amp;nbsp;out.&lt;/p&gt;
&lt;p&gt;The result of this was &lt;a href="https://github.com/jantman/misc-scripts/blob/master/whendoiwork.py"&gt;whendoiwork.py&lt;/a&gt;. It&amp;#8217;s a pretty simple script,
and also makes some pretty big assumptions, but I found the results interesting. Given some local directories which contain git clones
of my work repositories, and some which contain clones of my personal repos, it iterates over all* of the commits in them by me
(going by the git author name) in the last N days (default 365); it counts commits to personal repositories as +1 and to work
repositories as -1, and adds them to buckets per hour of day, per day of week. It then uses &lt;a href="http://matplotlib.org/"&gt;matplotlib&lt;/a&gt;
to build a heatmap, with the maximum commits per hour for work repos in blue and the maximum per hour for personal in&amp;nbsp;red.&lt;/p&gt;
&lt;p&gt;I can&amp;#8217;t vouch that it&amp;#8217;s 100% accurate, but the results were interesting to me; while it seems like I tend to do a fair amount
of work in the evenings, compared to work on personal projects, all of my work for my employer is well contained in my normal
7-3 work&amp;nbsp;day.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s an example of the output of this script, for my own work, run&amp;nbsp;with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./whendoiwork.py -v -a /home/jantman/&lt;span class="caps"&gt;GIT&lt;/span&gt; -b /home/jantman/work/git -b /home/jantman/work/git/ops -d 365 -t &amp;#39;&lt;span class="caps"&gt;US&lt;/span&gt;/Eastern&amp;#39; --repoAlabel personal --repoBlabel work
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that this iterates over every commit in all of the git repos it finds, possibly multiple times. On my own
system (9G of git repos with a few hundred thousand commits), this took about 2&amp;nbsp;minutes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="heatmap of days of week and hours of day when I commit to work vs personal repos" src="https://raw.githubusercontent.com/jantman/misc-scripts/master/whendoiwork.png"&gt;&lt;/p&gt;
&lt;p&gt;If you find any bugs/issues with it, please pass them along by &lt;a href="https://github.com/jantman/misc-scripts/issues"&gt;opening an issue&lt;/a&gt;.&lt;/p&gt;</content><category term="git"></category><category term="commits"></category><category term="python"></category><category term="graphs"></category><category term="visualization"></category></entry><entry><title>Jira to TrelloÂ Script</title><link href="https://blog.jasonantman.com/2015/04/jira-to-trello-script/" rel="alternate"></link><published>2015-04-10T05:58:00-04:00</published><updated>2015-04-10T05:58:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-04-10:/2015/04/jira-to-trello-script/</id><summary type="html">&lt;p&gt;A script to pull time tracking and dependency information for Jira tickets onto Trello&amp;nbsp;cards.&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few weeks ago, I &lt;a href="/2015/03/my-new-found-love-of-trello-and-a-helpful-greasemonkey-script/"&gt;posted about&lt;/a&gt; how I&amp;#8217;ve
started using &lt;a href="https://trello.com/"&gt;Trello&lt;/a&gt; to keep track of my work and keep things flowing smoothly. It&amp;#8217;s been
absolutely wonderful, and I feel more productive and less stressed, and like I have a better idea of what&amp;#8217;s coming
up. The one thing that Trello is missing is time tracking. I don&amp;#8217;t need anything fancy, all I really wanted was to
be able to show a time estimate on my cards. I know I could&amp;#8217;ve just put the estimate right in the title of the cards,
but that seemed like a waste of&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;At the moment we&amp;#8217;re using Jira at work, so I wrote &lt;a href="https://github.com/jantman/misc-scripts/blob/master/jira2trello.py"&gt;jira2trello.py&lt;/a&gt;.
It&amp;#8217;s a pretty simple Python script that uses the &lt;a href="https://pypi.python.org/pypi/trello"&gt;trello&lt;/a&gt; and
&lt;a href="https://pypi.python.org/pypi/jira"&gt;jira&lt;/a&gt; packages from pypi to iterate over all cards on a specified Trello
board, and for each card that matches a configurable regular expression for ticket keys (i.e.
&lt;code&gt;.*((project1|project2|project3)-\d+):.*&lt;/code&gt;), the script&amp;nbsp;will:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Determine if the Jira issue is a subtask, and if so, prefix its title with the issue key of the parent issue,
using the format of &lt;code&gt;PARENT-xxx -&amp;gt; CHILD-xxx&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Look up the &amp;#8220;Original Estimate&amp;#8221; time tracking field in Jira, and if present, prepend it to the title of
the&amp;nbsp;card.&lt;/li&gt;
&lt;li&gt;Regenerate the title of the card, using the current issue summary from&amp;nbsp;Jira.&lt;/li&gt;
&lt;li&gt;Move the card to a specified &amp;#8220;Done&amp;#8221; list if it&amp;#8217;s closed in&amp;nbsp;Jira.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are a few assumptions in the script about how the titles of cards are formed, namely that they follow the
&lt;code&gt;ISSUE-xxx: Summary Here&lt;/code&gt; format used by my &lt;a href="https://github.com/jantman/userscripts#trellocontextmenu"&gt;TrelloContextMenu&lt;/a&gt;
Firefox userscript. But I hope that this might be of use to someone else as well. Please feel free to open issues
or submit pull requests for any improvements that would be helpful, including any assumptions I&amp;#8217;ve made that aren&amp;#8217;t
valid in your environment. The source can be found on GitHub: &lt;a href="https://github.com/jantman/misc-scripts/blob/master/jira2trello.py"&gt;jira2trello.py&lt;/a&gt;.&lt;/p&gt;</content><category term="jira"></category><category term="trello"></category><category term="python"></category><category term="ticket"></category><category term="kanban"></category></entry><entry><title>Some Additional ServerspecÂ Types</title><link href="https://blog.jasonantman.com/2015/03/some-additional-serverspec-types/" rel="alternate"></link><published>2015-03-14T11:58:00-04:00</published><updated>2015-03-14T11:58:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-03-14:/2015/03/some-additional-serverspec-types/</id><summary type="html">&lt;p&gt;Some additional types that I wrote for&amp;nbsp;Serverspec&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://serverspec.org/"&gt;Serverspec&lt;/a&gt; is an rspec-based framework for testing live machines,
and making assertions about things like the output of commands, installed packages, running
services, file content, etc. However, it has a relatively limited and basic set of
&lt;a href="http://serverspec.org/resource_types.html"&gt;Resource Types&lt;/a&gt; that it can test&amp;nbsp;for.&lt;/p&gt;
&lt;p&gt;Before Serverspec completely disabled their GitHub issue tracker (they now seem to have no
issue tracker at all), I&amp;#8217;d suggested some improvements for more advanced resource types,
such as one that can perform an &lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;GET&lt;/span&gt; against an application and check the status code
and/or output. I was told in no uncertain terms that this is a task for application integration
testing, and that it&amp;#8217;s &amp;#8220;not what Serverspec is&amp;nbsp;for.&amp;#8221;&lt;/p&gt;
&lt;p&gt;I humbly disagree. I&amp;#8217;ve begun migrating my &lt;a href="https://www.linode.com/"&gt;Linode&lt;/a&gt; to an &lt;span class="caps"&gt;EC2&lt;/span&gt; machine,
using some technology that I&amp;#8217;ve been using at my day job; specifically, Puppet to configure the
machine and &lt;a href="https://packer.io/"&gt;Packer&lt;/a&gt; to build an &lt;span class="caps"&gt;AMI&lt;/span&gt;. Instead of using &lt;a href="http://aws.amazon.com/cloudformation/"&gt;Cloudformation&lt;/a&gt;
to spin up an entire stack, I just use a Rakefile to spin up a new &lt;span class="caps"&gt;EC2&lt;/span&gt; instance, test it, and
swap an &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html"&gt;Elastic &lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/a&gt;
if all the tests pass. Of course, this requires that I have relatively complete automated testing
of the &lt;span class="caps"&gt;EC2&lt;/span&gt; instance. Stock Serverspec can handle 95% of what I want to test, but there are a few
other, more complex, things that it can&amp;#8217;t. So, I wrote some code to fix&amp;nbsp;that.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ll admit right off the bat that this code doesn&amp;#8217;t really work the way Serverspec is intended to,
but it works and it&amp;#8217;s relatively simple. This largely breaks the abstraction of serverspec using
&lt;a href="https://github.com/serverspec/specinfra"&gt;specinfra&lt;/a&gt; under the hood, but I&amp;#8217;m not sure if that&amp;#8217;s even
a concern (since specinfra seems to be all about testing a running machine via some local command
execution mechanism, and two of the types that I wrote use network &lt;span class="caps"&gt;IO&lt;/span&gt;&amp;nbsp;instead).&lt;/p&gt;
&lt;p&gt;For the time being, I&amp;#8217;ve written three additional &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/#Types"&gt;types&lt;/a&gt;
that solve some specific use cases for&amp;nbsp;me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/#bitlbee"&gt;bitlbee&lt;/a&gt;
type that connects to a &lt;a href="http://www.bitlbee.org/"&gt;Bitlbee&lt;/a&gt; &lt;span class="caps"&gt;IRC&lt;/span&gt; gateway, authenticates,
and checks the running bitlbee version. It has matchers to check whether or not the connection and
authentication was successful, whether or not it timed out, and the bitlbee version. Parameters for
the type include login nick and password, bitlbee port, and whether or not to connect with&amp;nbsp;&lt;span class="caps"&gt;SSL&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;A &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/#http_get"&gt;http_get&lt;/a&gt;
type which connects to the system under test (with a specified port) and issues a
&lt;span class="caps"&gt;HTTP&lt;/span&gt; &lt;span class="caps"&gt;GET&lt;/span&gt; request for a specified path, with a specified &lt;code&gt;Host&lt;/code&gt; header and a timeout (default
10 seconds). Matchers are provided for the response content body (string), response headers
(hash), &lt;span class="caps"&gt;HTTP&lt;/span&gt; status code, and whether or not the request timed out (which also sets a status of&amp;nbsp;0).&lt;/li&gt;
&lt;li&gt;A &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/#virtualenv"&gt;virtualenv&lt;/a&gt; type for testing
python &lt;a href="https://virtualenv.pypa.io/en/latest/"&gt;virtualenv&lt;/a&gt;s. It takes the absolute path to the venv
on the filesystem, and uses serverspec&amp;#8217;s built-in file and command execution features to ensure that
the path &amp;#8220;looks like&amp;#8221; a virtualenv, and has matchers for the pip and python versions used in the venv
as well as the &lt;code&gt;pip freeze&lt;/code&gt; output as a hash of requirements and their&amp;nbsp;versions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hopefully this will be of use to someone else as well. As I continue using serverspec, I plan on
adding to the&amp;nbsp;types.&lt;/p&gt;
&lt;p&gt;The code for serverspec-extended-types is on &lt;a href="https://github.com/jantman/serverspec-extended-types/tree/master"&gt;GitHub&lt;/a&gt;
(pull requests and issues welcome) and it&amp;#8217;s packaged and hosted as a &lt;a href="https://rubygems.org/gems/serverspec-extended-types"&gt;ruby gem&lt;/a&gt;.
&lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/0.0.2#Installation"&gt;Installation&lt;/a&gt; and usage is as simple
as adding it to your Gemfile and &lt;a href="http://www.rubydoc.info/gems/serverspec-extended-types/0.0.2#Usage"&gt;spec_helper&lt;/a&gt;
and then using the types and matchers in your&amp;nbsp;specs.&lt;/p&gt;</content><category term="serverspec"></category><category term="specinfra"></category><category term="testing"></category><category term="beaker"></category><category term="ruby"></category><category term="rspec"></category><category term="gem"></category></entry><entry><title>RSpec Matcher For Hash ItemÂ Value</title><link href="https://blog.jasonantman.com/2015/02/rspec-matcher-for-hash-item-value/" rel="alternate"></link><published>2015-02-21T10:33:00-05:00</published><updated>2015-02-21T10:33:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2015-02-21:/2015/02/rspec-matcher-for-hash-item-value/</id><summary type="html">&lt;p&gt;An RSpec matcher for hash item value&amp;nbsp;regex&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; Well, this is embarassing. &lt;em&gt;After&lt;/em&gt; I posted this, I received a
&lt;a href="http://blog.jasonantman.com/2015/02/rspec-matcher-for-hash-item-value/#comment-1868422853"&gt;comment&lt;/a&gt;
within a few hours from &lt;a href="https://twitter.com/myronmarston"&gt;@myronmarston&lt;/a&gt;. I&amp;#8217;d originally
written this matcher for RSpec2, and then had to convert my project to use
RSpec3. I just blindly converted this matcher over. Myron pointed out that with
RSpec3&amp;#8217;s &lt;a href="http://rspec.info/blog/2014/01/new-in-rspec-3-composable-matchers/"&gt;composable matchers&lt;/a&gt;,
the functionality of this gem is built-in. It can be done as simply&amp;nbsp;as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;its&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:headers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;should&lt;/span&gt; &lt;span class="kp"&gt;include&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;server&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="sr"&gt;/nginx\/1\./&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;As such, I&amp;#8217;ve yanked them gem and am leaving the code and blog post here just for posterity.&lt;/strong&gt;
This should probably not be&amp;nbsp;used.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve been working on a project to move my &lt;a href="http://linode.com"&gt;Linode&lt;/a&gt; &lt;span class="caps"&gt;VM&lt;/span&gt; to an
Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt; instance; the entire instance is a &amp;#8220;baked&amp;#8221; &lt;span class="caps"&gt;AMI&lt;/span&gt; built by Puppet. Since
I&amp;#8217;d like to be able to rebuild this quickly, I&amp;#8217;m using &lt;a href="http://serverspec.org/"&gt;ServerSpec&lt;/a&gt;
(which I have some non-technical issues with, but that&amp;#8217;s a long story) to run full
integration tests of the whole system - check that packages are installed, services
are running, and even make live &lt;span class="caps"&gt;HTTP&lt;/span&gt; requests agsinst&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;One part of this was making live &lt;span class="caps"&gt;HTTP&lt;/span&gt; requests (from inside ServerSpec / &lt;a href="http://rspec.info/"&gt;rspec&lt;/a&gt;)
and checking &lt;span class="caps"&gt;HTTP&lt;/span&gt; response headers. Unfortunately, RSpec doesn&amp;#8217;t have a nice, clean way to make
assertions about a hash&amp;nbsp;item.&lt;/p&gt;
&lt;p&gt;So, I wrote a little Ruby Gem to do this, &lt;a href="https://github.com/jantman/rspec-matcher-hash-item"&gt;rspec-matcher-hash-item&lt;/a&gt;. At the moment it just
has one matcher, &lt;code&gt;have_hash_item_matching&lt;/code&gt;. This operates on a hash, and takes two arguments,
a key and a regex for the value. It allows me to do simple but useful things&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &lt;span class="n"&gt;describe&lt;/span&gt; &lt;span class="n"&gt;http_get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;testapp1.jasonantman.com&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/testapp1234&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="n"&gt;its&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:headers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;should&lt;/span&gt; &lt;span class="n"&gt;have_hash_item_matching&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;server&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sr"&gt;/nginx\/1\./&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(The &lt;code&gt;http_get&lt;/code&gt; serverspec matcher is coming in a future gem and blog&amp;nbsp;post)&lt;/p&gt;
&lt;p&gt;Among other things, it prints diffs on&amp;nbsp;failure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  2) privatepuppet::ec2::vhosts::testapp1 Http_get &amp;quot;&amp;quot; headers should include key &amp;#39;server&amp;#39; matching /badvalue/
     On host `54.149.198.147&amp;#39;
     Failure/Error: its(:headers) { should have_hash_item_matching(&amp;#39;server&amp;#39;, /badvalue/) }
       expected that hash[server] would match /badvalue/
       Diff:
       @@ -1,2 +1,6 @@
       -[&amp;quot;server&amp;quot;, /badvalue/]
       +&amp;quot;connection&amp;quot; =&amp;gt; &amp;quot;close&amp;quot;,
       +&amp;quot;content-type&amp;quot; =&amp;gt; &amp;quot;text/plain&amp;quot;,
       +&amp;quot;date&amp;quot; =&amp;gt; &amp;quot;Sat, 21 Feb 2015 16:07:42 &lt;span class="caps"&gt;GMT&lt;/span&gt;&amp;quot;,
       +&amp;quot;server&amp;quot; =&amp;gt; &amp;quot;nginx/1.6.2&amp;quot;,
       +&amp;quot;transfer-encoding&amp;quot; =&amp;gt; &amp;quot;chunked&amp;quot;,
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using the gem is as simple as including it in your &lt;code&gt;Gemfile&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gem &amp;quot;rspec-matcher-hash-item&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And adding a line to your &lt;code&gt;spec_helper.rb&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;require &amp;#39;rspec_matcher_hash_item&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that the gem is written for&amp;nbsp;RSpec3.&lt;/p&gt;
&lt;p&gt;This is available at &lt;a href="https://rubygems.org/gems/rspec-matcher-hash-item"&gt;rubygems.org&lt;/a&gt; or from
&lt;a href="https://github.com/jantman/rspec-matcher-hash-item"&gt;GitHub&lt;/a&gt;. See GitHub for the&amp;nbsp;documentation.&lt;/p&gt;</content><category term="ruby"></category><category term="rspec"></category><category term="spec"></category><category term="testing"></category></entry><entry><title>Watching Jenkins Jobs and CloudFormation Updates with PushoverÂ Notification</title><link href="https://blog.jasonantman.com/2014/12/watching-jenkins-jobs-and-cloudformation-updates-with-pushover-notification/" rel="alternate"></link><published>2014-12-14T19:22:00-05:00</published><updated>2014-12-14T19:22:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-12-14:/2014/12/watching-jenkins-jobs-and-cloudformation-updates-with-pushover-notification/</id><summary type="html">&lt;p&gt;Some scripts to watch the status of Jenkins jobs and CloudFormation updates, and send Pushover&amp;nbsp;notifications.&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few months ago I &lt;a href="http://blog.jasonantman.com/2014/09/pushover-notifications-for-shell-command-completion-and-status/"&gt;posted&lt;/a&gt;
about a script I wrote to send &lt;a href="https://pushover.net/"&gt;Pushover&lt;/a&gt; notifications for shell command&amp;nbsp;completion.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve been doing quite a bit of work lately both with testing some &lt;a href="http://jenkins-ci.org/"&gt;Jenkins&lt;/a&gt; jobs, and spinning up
&lt;span class="caps"&gt;AWS&lt;/span&gt; stacks using &lt;a href="https://aws.amazon.com/cloudformation/"&gt;CloudFormation&lt;/a&gt;. Last week I wrote two python scripts to aid in&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/jantman/misc-scripts/blob/master/watch_cloudformation.py"&gt;watch_cloudformation.py&lt;/a&gt; uses the popular &lt;a href="https://github.com/boto/boto"&gt;boto&lt;/a&gt;
Python &lt;span class="caps"&gt;AWS&lt;/span&gt; interface to list (and display) the events on a specified CloudFormation stack, and exit 0 or 1 when it finds a (&lt;span class="caps"&gt;CREATE&lt;/span&gt;|&lt;span class="caps"&gt;UPDATE&lt;/span&gt;)_(&lt;span class="caps"&gt;FAILED&lt;/span&gt;|&lt;span class="caps"&gt;COMPLETE&lt;/span&gt;) event.
It also optionally uses &lt;a href="https://pypi.python.org/pypi/python-pushover"&gt;python-pushover&lt;/a&gt; to send the notification to your devices via&amp;nbsp;Pushover.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/jantman/misc-scripts/blob/master/watch_jenkins.py"&gt;watch_jenkins.py&lt;/a&gt; takes the &lt;span class="caps"&gt;URL&lt;/span&gt; to a Jenkins job or build, and uses
&lt;a href="https://pypi.python.org/pypi/python-jenkins"&gt;python-jenkins&lt;/a&gt; to poll the status of the build (or the latest build, if given a Job url)
and display the result when the build finishes, also optionally using python-pushover to send notifications to your&amp;nbsp;device.&lt;/p&gt;
&lt;p&gt;They&amp;#8217;re really quick-and-dirty scripts and might not be suitable for everyone&amp;#8217;s use case, but I took the time to write them,
so hopefully they&amp;#8217;ll be useful to someone&amp;nbsp;else.&lt;/p&gt;</content><category term="script"></category><category term="pushover"></category><category term="jenkins"></category><category term="hudson"></category><category term="aws"></category><category term="cloudformation"></category></entry><entry><title>Idea for a Generic Method to Communicate Repository/ProjectÂ Status</title><link href="https://blog.jasonantman.com/2014/12/idea-for-a-generic-method-to-communicate-repositoryproject-status/" rel="alternate"></link><published>2014-12-07T18:24:00-05:00</published><updated>2014-12-07T18:24:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-12-07:/2014/12/idea-for-a-generic-method-to-communicate-repositoryproject-status/</id><summary type="html">&lt;p&gt;Some ideas for generic methods of communicating the status of a project / source code repository to humans and&amp;nbsp;machines.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Update 2014-12-24: I actually did something with this. See &lt;a href="http://www.repostatus.org"&gt;repostatus.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, something funny, before my possibly-hair-brained&amp;nbsp;scheme:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.commitstrip.com/en/2014/11/25/west-side-project-story/"&gt;&lt;img alt="commitstrip.com &amp;quot;side project&amp;quot; comic strip" src="http://www.commitstrip.com/wp-content/uploads/2014/11/Strip-Side-project-650-finalenglish.jpg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I know I&amp;#8217;m not alone in having a mess of &lt;a href="https://github.com/jantman?tab=repositories"&gt;repositories on GitHub&lt;/a&gt;; I personally have over 90, and they&amp;#8217;re
all in various states of &amp;#8220;doneness.&amp;#8221; Some are working and undergoing active development. Some should be
working, but I no longer use them (and sometimes lack &amp;#8220;things&amp;#8221; needed to use them, especially the case
with projects linked to specific hardware). Some of them were ideas that never took off; some of these
I intend on finishing, and some I never want to touch&amp;nbsp;again.&lt;/p&gt;
&lt;p&gt;While GitHub has a &lt;a href="https://help.github.com/articles/about-releases/"&gt;Releases&lt;/a&gt; feature, at best (where everyone
understands and follows &lt;a href="http://semver.org/"&gt;semantic versioning&lt;/a&gt;), it can only differentiate &amp;#8220;initial development&amp;#8221;
(prior to stable public release) versions from those after them. It may be an indication of the usability or completeness
of the software, but not of its current state of&amp;nbsp;maintenance.&lt;/p&gt;
&lt;p&gt;The questions that I&amp;#8217;d really like to be able to answer about a given project or repository&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the &amp;#8220;completeness&amp;#8221; of the code? Should it be usable, or is it functionally&amp;nbsp;incomplete?&lt;/li&gt;
&lt;li&gt;What is the status of development efforts? Is this actively developed, or supported (even if bugfix-only), or totally&amp;nbsp;abandoned?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;#8217;d like to be able to easily communicate this to people who come across my work, and also
track it for my own needs - I have enough repositories with barely-started concepts that I
occasionally forget about them. I&amp;#8217;d also, of course, like to be able to know this information
about other peoples&amp;#8217; work as&amp;nbsp;well.&lt;/p&gt;
&lt;p&gt;Ideally, I thought that this should be a GitHub feature, exposed via the &lt;span class="caps"&gt;API&lt;/span&gt; and the &lt;span class="caps"&gt;UI&lt;/span&gt;. However,
there are a number of problems with&amp;nbsp;that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It would require GitHub to implement the feature. Quite ironically, GitHub is &lt;a href="https://github.com/isaacs/github/issues/6"&gt;not very open&lt;/a&gt;
about issues and feature requests for their platform itself, and the only good way to suggest something is &lt;a href="https://github.com/isaacs/github"&gt;unofficial&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;It would be tied to GitHub directly. When the next big thing comes along, or for projects using other services (like Gitorious, or even non-git hosting),
it would be rendered&amp;nbsp;useless.&lt;/li&gt;
&lt;li&gt;The status really describes the code/project itself, not the GitHub repository per se, so it should live with the&amp;nbsp;code.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, I&amp;#8217;m brainstorming a straightforward semi-standardized way of communicating this information. Assuming
it&amp;#8217;s not implemented in GitHub itself, but rather becomes part of the repository content, that poses some
interesting questions for both what information is communicated and how to communicate it. What follows is
really my brainstorming and initial ideas. I&amp;#8217;d very much appreciate it if anyone who&amp;#8217;s interested submits
their ideas and comments. I fully intend to start using something like this for my own projects but, not to
be too arrogant, I think it&amp;#8217;s a useful idea and could benefit from some accepted&amp;nbsp;standard.&lt;/p&gt;
&lt;h2 id="what-to-communicate"&gt;&lt;a class="toclink" href="#what-to-communicate"&gt;What to&amp;nbsp;Communicate&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The first question is what data to communicate. Ideally, this would be one of a standardized set of
repository/project status identifiers, along with a textual description that could be provided by
the author, for additional clarity. My humble suggestion (very much a &lt;span class="caps"&gt;WIP&lt;/span&gt;) of the possible statuses,
along with the suggested (canonical) description of their&amp;nbsp;meanings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Concept&lt;/strong&gt; - Minimal or no implementation has been done&amp;nbsp;yet.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;span class="caps"&gt;WIP&lt;/span&gt;&lt;/strong&gt; - Initial development is in progress, but there has not yet been a stable, usable release suitable for the&amp;nbsp;public.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Suspended&lt;/strong&gt; - A &lt;span class="caps"&gt;WIP&lt;/span&gt; project that has had work stopped for the time being; the author(s) intend on resuming&amp;nbsp;work.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Abandoned&lt;/strong&gt; - A &lt;span class="caps"&gt;WIP&lt;/span&gt; project that has been abandoned; the author(s) do not intend on continuing&amp;nbsp;development.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Active&lt;/strong&gt; - The project has reached a stable, usable state and is being actively&amp;nbsp;developed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inactive&lt;/strong&gt; - The project has reached a stable, usable state but is no longer being actively developed; support/maintenance will be provided as time&amp;nbsp;allows.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unsupported&lt;/strong&gt; - The project has reached a stable, usable state but the author(s) have ceased all work on it. A new maintainer may be&amp;nbsp;desired.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I assume that there might be some dissenting opinions on whether this list of statuses is complete, or perhaps too long.
However I feel that it&amp;#8217;s the minimum set required to describe a project along the two axes which I consider important:
usability (is the code here complete enough to &amp;#8220;work&amp;#8221; for something) and support/development status (is it being worked on,
or are there plans to do so in the future). I&amp;#8217;m certainly open to opinions on&amp;nbsp;this.&lt;/p&gt;
&lt;h2 id="how-to-communicate-it"&gt;&lt;a class="toclink" href="#how-to-communicate-it"&gt;How to Communicate&amp;nbsp;It&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I view this as a more complex question technically, as doing this within the repository content (instead of in a GitHub &lt;span class="caps"&gt;API&lt;/span&gt;)
necessarily involves polluting that repository. My main two technical requirements (at least with my own intended use in mind)
are that the status be readable both by human and machine, and that the status should be available in one place within the
repository (i.e. in only one place for both humans and machines, and not requiring any&amp;nbsp;transformation).&lt;/p&gt;
&lt;p&gt;The best I&amp;#8217;ve been able to come up with so far is either including the status in a special file (likely a specially-named dotfile),
or including it in the &lt;span class="caps"&gt;README&lt;/span&gt;. The dotfile method is optimized for machine-reading - it would be a single file, likely named
&amp;#8220;.repostatus.org&amp;#8221;, with a simple specified format. It&amp;#8217;s easy and cheap for a machine to find and parse, and shouldn&amp;#8217;t be too cumbersome
to add. But it pollutes the repository with another file, and worse, it would be quite unlikely to be found by a human who isn&amp;#8217;t
familiar with this practice, so it loses a lot in terms of human readability and&amp;nbsp;intuitiveness.&lt;/p&gt;
&lt;p&gt;On the other hand, adding something special to the &lt;span class="caps"&gt;README&lt;/span&gt; file is much more human-centric. The &amp;#8220;something&amp;#8221; could be a simple
string or link, or even better, a &lt;a href="http://shields.io/"&gt;badge&lt;/a&gt;. It would appear clearly when rendered on GitHub, and should also appear anywhere
else the readme is rendered (i.e. in online documentation or in packages of the project). However, this poses a few&amp;nbsp;challenges:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It wouldn&amp;#8217;t necessarily be possible to have a status that&amp;#8217;s machine-readable but not rendered to the human observer. Sure, this
sort of goes against half of the purpose of this idea, but some people probably wouldn&amp;#8217;t want this extra piece of information
cluttering up their &lt;span class="caps"&gt;README&lt;/span&gt;. It&amp;#8217;s possible to put comments in &lt;a href="http://docutils.sourceforge.net/docs/ref/rst/restructuredtext.html#comments"&gt;rST&lt;/a&gt;,
but &lt;a href="http://stackoverflow.com/questions/4823468/store-comments-in-markdown-syntax"&gt;markdown support&lt;/a&gt; isn&amp;#8217;t nearly as reliable,
being a bit of a&amp;nbsp;hack.&lt;/li&gt;
&lt;li&gt;This is optimized for human readers. In order to be detected by machine, the repository would need to be searched for
a readme file (even assuming the convention of &amp;#8220;^&lt;span class="caps"&gt;README&lt;/span&gt;*&amp;#8221;, there&amp;#8217;s a myriad of possible file extensions that could be used),
which isn&amp;#8217;t necessarily a cheap operation (especially since it would require access to the file listing within the&amp;nbsp;repository).&lt;/li&gt;
&lt;li&gt;Furthermore, machine detection would need to be able to either parse the markup (if any), or do string search on the file
contents. Once again, a more expensive&amp;nbsp;operation.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="current-theory"&gt;&lt;a class="toclink" href="#current-theory"&gt;Current&amp;nbsp;Theory&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At the moment, I&amp;#8217;m leaning towards this theory of&amp;nbsp;implementation:&lt;/p&gt;
&lt;p&gt;Badges are placed in the project&amp;#8217;s &lt;span class="caps"&gt;README&lt;/span&gt; indicating the status. The badges would be sourced from specified URLs, served
by &lt;a href="http://repostatus.org"&gt;repostatus.org&lt;/a&gt; and linked to specified URLs describing the status (likely of the form
http://repostatus.org/1.0/#active). Machine determination of status would be made by a string match for one of
the specified status URLs - nothing more is needed. It would be simple enough to simply specify that, for machine
determination, the first file in the repository (sorted in lexicographical order) beginning with &amp;#8220;readme&amp;#8221; (case-insensitive) and containing
a matching &lt;span class="caps"&gt;URL&lt;/span&gt; determines the status. For human users, the badge image could be combined with descriptive alt-text, and
possibly followed by a more descriptive explanation, if the author chose so. This would eliminate the need for a fixed
set of possible readme file names, and the need for machine identification to be able to parse all possible&amp;nbsp;markups.&lt;/p&gt;
&lt;p&gt;The visual impact to the readme document (assuming it&amp;#8217;s rendered) would be minimal. Here are some quick takes on
a first set of badges, along with the alt text set on them (which could be changed by the user, or also included
in plain text next to the&amp;nbsp;badge).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;img alt="Repo Status: Concept - Minimal or no implementation has been done yet." src="http://img.shields.io/badge/repo%20status-Concept-ffffff.svg"&gt; Repo Status: Concept - Minimal or no implementation has been done&amp;nbsp;yet.&lt;/li&gt;
&lt;li&gt;&lt;img alt="Repo Status: WIP - Initial development is in progress, but there has not yet been a stable, usable release suitable for the public." src="http://img.shields.io/badge/repo%20status-WIP-yellow.svg"&gt; Repo Status: &lt;span class="caps"&gt;WIP&lt;/span&gt; - Initial development is in progress, but there has not yet been a stable, usable release suitable for the&amp;nbsp;public.&lt;/li&gt;
&lt;li&gt;&lt;img alt="Repo Status: Suspended - A WIP project that has had work stopped for the time being; the author(s) intend on resuming work." src="http://img.shields.io/badge/repo%20status-Suspended-orange.svg"&gt; Repo Status: Suspended - A &lt;span class="caps"&gt;WIP&lt;/span&gt; project that has had work stopped for the time being; the author(s) intend on resuming&amp;nbsp;work.&lt;/li&gt;
&lt;li&gt;&lt;img alt="Repo Status: Abandoned - A WIP project that has been abandoned; the author(s) do not intend on continuing development." src="http://img.shields.io/badge/repo%20status-Abandoned-000000.svg"&gt; Repo Status: Abandoned - A &lt;span class="caps"&gt;WIP&lt;/span&gt; project that has been abandoned; the author(s) do not intend on continuing&amp;nbsp;development.&lt;/li&gt;
&lt;li&gt;&lt;img alt="Repo Status: Active - The project has reached a stable, usable state and is being actively developed." src="http://img.shields.io/badge/repo%20status-Active-brightgreen.svg"&gt; Repo Status: Active - The project has reached a stable, usable state and is being actively&amp;nbsp;developed.&lt;/li&gt;
&lt;li&gt;&lt;img alt="Repo Status: Inactive - The project has reached a stable, usable state and is no longer being actively developed; support/maintenance will be done as time allows." src="http://img.shields.io/badge/repo%20status-Inactive-yellowgreen.svg"&gt; Repo Status: Inactive - The project has reached a stable, usable state and is no longer being actively developed; support/maintenance will be done as time&amp;nbsp;allows.&lt;/li&gt;
&lt;li&gt;&lt;img alt="Repo Status: Unsupported - The project has reached a stable, usable state but the author(s) have ceased all work on it. A new maintainer may be desired." src="http://img.shields.io/badge/repo%20status-Unsupported-lightgrey.svg"&gt; Repo Status: Unsupported - The project has reached a stable, usable state but the author(s) have ceased all work on it. A new maintainer may be&amp;nbsp;desired.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the readme is (for some strange reason) primarily intended for a non-rendered view, it would be acceptable to
include just the &lt;span class="caps"&gt;URL&lt;/span&gt; to the status description, optionally with some human-readable&amp;nbsp;text.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ll probably start using something like this for my personal projects. I intend on even writing up a spec
for the &lt;span class="caps"&gt;README&lt;/span&gt;-based variant, along with some formatting and parsing/machine identification rules. Any and
all comments are welcome. This is the result of a few hours&amp;#8217; sporadic thought one afternoon, so I&amp;#8217;m sure there
are some major issues I haven&amp;#8217;t realized yet. Please pass them along, or tell me if this is of any interest to&amp;nbsp;you.&lt;/p&gt;</content><category term="repository"></category><category term="project"></category><category term="git"></category><category term="github"></category></entry><entry><title>Pushover Notifications for Shell Command Completion andÂ Status</title><link href="https://blog.jasonantman.com/2014/09/pushover-notifications-for-shell-command-completion-and-status/" rel="alternate"></link><published>2014-09-27T21:20:00-04:00</published><updated>2014-09-27T21:20:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-09-27:/2014/09/pushover-notifications-for-shell-command-completion-and-status/</id><summary type="html">&lt;p&gt;How to get pushover notifications of shell command completion and&amp;nbsp;status&lt;/p&gt;</summary><content type="html">&lt;p&gt;Lately I&amp;#8217;ve been doing a bunch of work with &lt;a href="http://www.packer.io/"&gt;packer&lt;/a&gt; building &lt;a href="http://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt;
machine images, and using &lt;a href="http://serverspec.org/"&gt;serverspec&lt;/a&gt; to run automated acceptance tests on the images. Unfortunately,
this ends up being a ~40-minute cycle time for the full image to provision and test. So, lots of watching text slowly scroll
down a screen, and finding something else to do. It&amp;#8217;s the weekend; I want to get this project finished, but I&amp;#8217;ve got other
things to&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;So, I wrote a little bash wrapper around &lt;a href="https://github.com/jnwatts"&gt;jnwatts&amp;#8217;&lt;/a&gt;
&lt;a href="https://raw.githubusercontent.com/jnwatts/pushover.sh/master/pushover.sh"&gt;pushover.sh&lt;/a&gt;. Assuming wherever you put this
is in your path, simply prefix any command with &lt;code&gt;pushover&lt;/code&gt;, and you&amp;#8217;ll get a handy &lt;a href="https://pushover.net/"&gt;Pushover&lt;/a&gt;
notification when it completes, along with the exit status and some other useful&amp;nbsp;information.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Notify command completion and exit status via pushover&lt;/span&gt;
&lt;span class="c1"&gt;# uses pushover.sh from https://raw.githubusercontent.com/jnwatts/pushover.sh/master/pushover.sh&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;APIKEY&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Your Pushover &lt;span class="caps"&gt;API&lt;/span&gt; Key Here&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;USERKEY&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Your Pushover User Key Here&amp;quot;&lt;/span&gt;

&lt;span class="nv"&gt;stime&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;date &lt;span class="s1"&gt;&amp;#39;+%s&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;$@&lt;/span&gt;
&lt;span class="nv"&gt;exitcode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$?&lt;/span&gt;
&lt;span class="c1"&gt;# timer&lt;/span&gt;
&lt;span class="nv"&gt;etime&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;date &lt;span class="s1"&gt;&amp;#39;+%s&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;etime &lt;span class="o"&gt;-&lt;/span&gt; stime&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;ds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;dt &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="m"&gt;60&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;dm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;dt &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="m"&gt;60&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="m"&gt;60&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;dh&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;dt &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="m"&gt;3600&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;times&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;printf&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;%d:%02d:%02d&amp;#39;&lt;/span&gt; &lt;span class="nv"&gt;$dh&lt;/span&gt; &lt;span class="nv"&gt;$dm&lt;/span&gt; &lt;span class="nv"&gt;$ds&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# end timer&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$exitcode&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; -eq &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    pushover.sh -p &lt;span class="m"&gt;0&lt;/span&gt; -t &lt;span class="s2"&gt;&amp;quot;Command Succeeded&amp;quot;&lt;/span&gt; -T &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;APIKEY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; -U &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;USERKEY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;succeeded in &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;times&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; on &lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;hostname&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="nv"&gt;$@&lt;/span&gt;&lt;span class="s2"&gt; (in &lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;(sent pushover success notification)&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
    pushover.sh -p &lt;span class="m"&gt;0&lt;/span&gt; -s falling -t &lt;span class="s2"&gt;&amp;quot;Command Failed&amp;quot;&lt;/span&gt; -T &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;APIKEY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; -U &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;USERKEY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;failed in &lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;times&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; (exit &lt;/span&gt;&lt;span class="nv"&gt;$exitcode&lt;/span&gt;&lt;span class="s2"&gt;) on &lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;hostname&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="nv"&gt;$@&lt;/span&gt;&lt;span class="s2"&gt; (in &lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;(sent pushover failure notification)&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So, for example, a failing spec&amp;nbsp;test:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;jantman@phoenix:pts/4:~/&lt;span class="caps"&gt;CMG&lt;/span&gt;/git/puppet-cm (&lt;span class="caps"&gt;AUTO&lt;/span&gt;-415=)$ pushover bundle exec rake spec
&amp;lt;lots of failing spec output that exits non-0 after 1 minute 10 seconds&amp;gt;
(sent pushover failure notification)
jantman@phoenix:pts/4:~/&lt;span class="caps"&gt;CMG&lt;/span&gt;/git/puppet-cm (&lt;span class="caps"&gt;AUTO&lt;/span&gt;-415=)$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Would send me a handy pushover message when it&amp;nbsp;finishes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Command Failed
failed in 0:01:10 (exit 1) on phoenix: bundle exec rake spec (in /home/jantman/&lt;span class="caps"&gt;CMG&lt;/span&gt;/git/puppet-cm)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hopefully this is useful to someone else as&amp;nbsp;well&amp;#8230;&lt;/p&gt;</content><category term="pushover"></category><category term="shell"></category><category term="notifications"></category></entry><entry><title>Session Save and Restore with Bash and GNUÂ Screen</title><link href="https://blog.jasonantman.com/2014/07/session-save-and-restore-with-bash-and-gnu-screen/" rel="alternate"></link><published>2014-07-25T10:09:00-04:00</published><updated>2014-07-25T10:09:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-07-25:/2014/07/session-save-and-restore-with-bash-and-gnu-screen/</id><summary type="html">&lt;p&gt;How to automatically save and restore &lt;span class="caps"&gt;GNU&lt;/span&gt; screen sessions including windows, pwd and&amp;nbsp;history&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been using &lt;a href="http://www.gnu.org/software/screen/"&gt;&lt;span class="caps"&gt;GNU&lt;/span&gt; Screen&lt;/a&gt; for a very long time; I pretty much do &lt;em&gt;all&lt;/em&gt; of my
daily work in it. I have long-lived screen sessions pretty much everywhere; at any given time, I&amp;#8217;ve got a session running
on my desktop (that probably has 19 windows open and active) and a few on various remote hosts. I also have a really
bad habit of using screen windows to hold work in progress, things that I need to revisit, and what I want to do
next. This isn&amp;#8217;t as big of a deal on boxes in a datacenter that rarely go down, but my home desktop ends up getting
rebooted every few weeks (and not always at planned&amp;nbsp;times).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt; - what I&amp;#8217;m about to describe is, really, a fragile and somewhat ugly hack. I&amp;#8217;m pretty sure that if I took
the time to learn and switch to zsh (or another, more modern shell) and tmux, I could probably do this easier. But my
shell environment is something I&amp;#8217;m pretty stuck in. So, if this is useful to anyone else, cool. But caveat&amp;nbsp;emptor.&lt;/p&gt;
&lt;p&gt;screen 4.2.0 introduced some extensions to the &lt;code&gt;-Q&lt;/code&gt; remote querying capabilities, including the ability to retrieve a
list of current windows and their titles via &lt;code&gt;screen -Q windows&lt;/code&gt;. A few months ago, I wrapped a python script around
this that reads the currently open windows along with their title and window number, and writes out &lt;code&gt;~/.screenrc.save&lt;/code&gt;
that&amp;#8217;s &lt;code&gt;~/.screenrc&lt;/code&gt; with &lt;code&gt;screen -t&lt;/code&gt; lines to recreate my currently open windows with their titles. After a system
crash or reboot, I could &lt;code&gt;screen -c ~/.screenrc.save&lt;/code&gt; and get all of my windows and their titles back. So, that&amp;#8217;s
a slightly better reminder of what I was working on assuming I keep my titles relevant. But each window just dumped
me into &lt;code&gt;~/&lt;/code&gt; like usual, so I&amp;#8217;d just have the window title to remind me what I was working&amp;nbsp;on. &lt;/p&gt;
&lt;p&gt;I ran this script for a few months; you can see the original version &lt;a href="https://github.com/jantman/misc-scripts/blob/ab6a14774d5dd6250aac98f804c33d3dc26a32eb/savescreen.py"&gt;here&lt;/a&gt;.
However, this still really isn&amp;#8217;t what I&amp;#8217;d call &amp;#8220;session restore&amp;#8221;. I had window titles as &amp;#8220;hints&amp;#8221; to what I was doing,
but everything else was left to my&amp;nbsp;memory.&lt;/p&gt;
&lt;p&gt;Enter some awful &lt;code&gt;bashrc&lt;/code&gt; hackery. Please note that my bashrc is a bit complicated, mainly due to git completion
and getting a proper prompt for python virtualenvs, but here&amp;#8217;s the magic&amp;nbsp;portion:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# git prompt - make it work everywhere&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -e /usr/share/git/completion/git-prompt.sh &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;source&lt;/span&gt; /usr/share/git/completion/git-prompt.sh
&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -e /usr/share/git-core/contrib/completion/git-prompt.sh &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;source&lt;/span&gt; /usr/share/git-core/contrib/completion/git-prompt.sh
&lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -e ~/bin/git-prompt.sh &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;source&lt;/span&gt; ~/bin/git-prompt.sh
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="c1"&gt;#set the &lt;span class="caps"&gt;PROMPT&lt;/span&gt;&lt;/span&gt;
&lt;span class="nv"&gt;cur_tty&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nv"&gt;temp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;tty&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;temp&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;5&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="c1"&gt;# git prompt configutation&lt;/span&gt;
&lt;span class="nv"&gt;GIT_PS1_SHOWDIRTYSTATE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="nv"&gt;GIT_PS1_SHOWUNTRACKEDFILES&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="nv"&gt;GIT_PS1_SHOWUPSTREAM&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;auto&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;GIT_PS1_SHOWCOLORHINTS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;

&lt;span class="c1"&gt;# for screen session-saving hack, set per-window history file if in screen&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;STY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;&lt;span class="caps"&gt;HISTFILE&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;readlink -f ~/.screenhist/&lt;span class="nv"&gt;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;shopt&lt;/span&gt; -s histappend

&lt;span class="c1"&gt;# make sure our screen session-saving hack directories exist&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt; -d ~/.screenhist &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; mkdir ~/.screenhist
&lt;span class="o"&gt;[[&lt;/span&gt; -d ~/.screendirs &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; mkdir ~/.screendirs

__wrap_git_ps1 &lt;span class="o"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;# commands here now get executed every time bash constructs a prompt&lt;/span&gt;
    &lt;span class="c1"&gt;# for screen pwd saving&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;STY&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
    &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="nv"&gt;&lt;span class="caps"&gt;SCREENLINKDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;readlink -f ~/.screendirs&lt;span class="k"&gt;)&lt;/span&gt;
        rm -f &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SCREENLINKDIR&lt;/span&gt;&lt;/span&gt;/&lt;span class="nv"&gt;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&lt;/span&gt;
        ln -sf &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;/ &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SCREENLINKDIR&lt;/span&gt;&lt;/span&gt;/&lt;span class="nv"&gt;$&lt;span class="caps"&gt;WINDOW&lt;/span&gt;&lt;/span&gt;
    &lt;span class="k"&gt;fi&lt;/span&gt;
    &lt;span class="c1"&gt;# virtualenv stuff for prompt&lt;/span&gt;
    &lt;span class="nv"&gt;venv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class="o"&gt;[[&lt;/span&gt; &lt;span class="nv"&gt;$VIRTUAL_ENV&lt;/span&gt; !&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nv"&gt;venv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;\[\033[31m\](&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VIRTUAL_ENV&lt;/span&gt;&lt;span class="p"&gt;##*/&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;)\e[0m&amp;quot;&lt;/span&gt;
    __git_ps1 &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$venv&lt;/span&gt;&lt;span class="s2"&gt;\u@\h:&lt;/span&gt;&lt;span class="nv"&gt;$cur_tty&lt;/span&gt;&lt;span class="s2"&gt;:\w&amp;quot;&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;\\\$ &amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;history&lt;/span&gt; -a
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="nv"&gt;PROMPT_COMMAND&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;__wrap_git_ps1&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;&lt;span class="caps"&gt;PS2&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;gt; &amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So&amp;#8230; the hack. First we source the git prompt scripts that come with git (trying the
locations they should be at on all of the machines I commonly use, and if it can&amp;#8217;t find
any of them, falling back to a copy in my homedir) and set some configuration variables
for them (as well as capturing the current tty). We then (conditionally on being inside
a screen window) set our history file to a per-screen-window path, and have history append.
At this point we also make sure some directories we&amp;#8217;ll use&amp;nbsp;exist.&lt;/p&gt;
&lt;p&gt;Now the real fun. &lt;code&gt;PROMPT_COMMAND&lt;/code&gt; specifies a function for bash to execute to build the
prompt string; this is called every time bash needs to display the prompt (so, effectively,
every time a command completes in the shell). We set it to &lt;code&gt;__wrap_git_ps1&lt;/code&gt;, a function we
just defined. The magic happens in this function. Screen sets some environment variables
inside each window, including &lt;code&gt;STY&lt;/code&gt; (the name of the screen session you&amp;#8217;re in) and
&lt;code&gt;WINDOW&lt;/code&gt;, the current window number. If both of these are set, we symlink our current
&lt;code&gt;pwd&lt;/code&gt; to &lt;code&gt;~/.screendirs/$WINDOW&lt;/code&gt; (note some hackery, explicitly removing the link if it
already exists, to get this to work correctly). We then throw in some python virtualenv-specific
prompt settings, and pass on the strings we&amp;#8217;ve constructed to &lt;code&gt;__git_ps1&lt;/code&gt; which adds the
git-specific information, and then sets &lt;code&gt;PS1&lt;/code&gt; correctly. Finally, we explicitly append to
current history, to make sure the history on disk is always accurate and&amp;nbsp;up-to-date.&lt;/p&gt;
&lt;p&gt;This works in combination with the &lt;a href="https://github.com/jantman/misc-scripts/blob/master/savescreen.py"&gt;latest version&lt;/a&gt;
of savescreen.py, which has some minor changes. The line to create each window,&amp;nbsp;formerly:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;fh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;screen -t &lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt;{name}&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt; {num}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;windows&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;becomes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;fh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;screen -t &lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt;{name}&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt; {num} sh -c &lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt;cd $(readlink -fn {dirpath}/{num}); bash&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;windows&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dirpath&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dirpath&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When each window is created at startup, we &lt;code&gt;cd&lt;/code&gt; into the previous &lt;code&gt;pwd&lt;/code&gt; (the path
that the &lt;code&gt;~/.screendirs/$WINDOW&lt;/code&gt; symlink, created by bashrc, points to) and then
call our shell. When this is combined with the &lt;code&gt;HISTFILE&lt;/code&gt; change, the effect is that
&lt;code&gt;screen -c ~/.screenrc.save&lt;/code&gt; brings us back into a screen session that has not only
all of our previous windows and their titles, but also a shell in each window&amp;#8217;s previous
working directory, and that window&amp;#8217;s&amp;nbsp;history.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Limitations&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I should&amp;#8217;ve also used &lt;code&gt;$STY&lt;/code&gt; in each of the paths, so this would be multi-session-safe.
   I didn&amp;#8217;t, so this has undefined behavior if more than one screen session is running as
   your&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;A lot of this is lost, obviously, if you &lt;code&gt;sudo su&lt;/code&gt; or &lt;code&gt;ssh&lt;/code&gt;, or in any other way end up
   as a different&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;I&amp;#8217;m thinking about rolling in some method of automatic &lt;code&gt;virtualenv&lt;/code&gt; activation (since it,
   unfortunately, doesn&amp;#8217;t have anything like &lt;code&gt;.rvmrc&lt;/code&gt;). Maybe in the next&amp;nbsp;version.&lt;/li&gt;
&lt;/ol&gt;</content><category term="bash"></category><category term="screen"></category><category term="restore"></category><category term="bashrc"></category></entry><entry><title>How Yum and RPM CompareÂ Versions</title><link href="https://blog.jasonantman.com/2014/07/how-yum-and-rpm-compare-versions/" rel="alternate"></link><published>2014-07-11T23:31:00-04:00</published><updated>2014-07-11T23:31:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-07-11:/2014/07/how-yum-and-rpm-compare-versions/</id><summary type="html">&lt;p&gt;A description of the algorithms used by Yum and &lt;span class="caps"&gt;RPM&lt;/span&gt; to compare package&amp;nbsp;versions.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was recently tripped up by a bug in Puppet, &lt;a href="https://tickets.puppetlabs.com/browse/PUP-1244"&gt;&lt;span class="caps"&gt;PUP&lt;/span&gt;-1244&lt;/a&gt;,
dealing with how it compares package versions. All of Puppet&amp;#8217;s Package types assumed
&lt;a href="http://semver.org/"&gt;semantic versioning&lt;/a&gt;, and that&amp;#8217;s far from the case for RPMs and therefore Yum. This
manifested itself in how Puppet validates package installations - if a version was explicitly specified
and Yum/&lt;span class="caps"&gt;RPM&lt;/span&gt; could install it, puppet would shell out to them and install the package, but then report
a failure in its post-install validation, as the &lt;em&gt;exact&lt;/em&gt; version string specified isn&amp;#8217;t present.
For example, many RedHat/CentOS packages (such as those from &lt;span class="caps"&gt;EPEL&lt;/span&gt;) include a release string with the major
version of the distribution they were packged for - i.e. &amp;#8220;.el5&amp;#8221; or &amp;#8220;.el6&amp;#8221;. If Puppet was instructed to
install package &amp;#8220;foo&amp;#8221; version &amp;#8220;1.2.3&amp;#8221;, but the actual package in the repositories was &amp;#8220;foo-1.2.3-el5&amp;#8221;,
Puppet would cause the package to be installed, but then report&amp;nbsp;failure.&lt;/p&gt;
&lt;p&gt;I cut a &lt;a href="https://github.com/puppetlabs/puppet/pull/2866"&gt;pull request&lt;/a&gt; against the Puppet4 branch to
fix these issues, essentially re-implementing yum and rpm&amp;#8217;s version comparison logic in Ruby. It took
me a few days of research and sorting through source code (and in the process I found that &lt;code&gt;yum&lt;/code&gt;, despite
its use in so many distributions, has no unit tests at all) but I finally got it finished. In the process,
I found out exactly how&amp;#8230; weird&amp;#8230; &lt;span class="caps"&gt;RPM&lt;/span&gt;&amp;#8217;s version comparison rules&amp;nbsp;are.&lt;/p&gt;
&lt;h3 id="package-naming-and-parsing"&gt;&lt;a class="toclink" href="#package-naming-and-parsing"&gt;Package Naming and&amp;nbsp;Parsing&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt; package names are made up of five parts; the package name, epoch, version, release, and architecture.
This format is commonly referred to as the acronym &lt;span class="caps"&gt;NEVRA&lt;/span&gt;. The epoch is not always included; it is assumed
to be zero (0) on any packages that lack it explicitly. The format for the whole string is &lt;code&gt;n-e:v-r.a&lt;/code&gt;.
For my purposes, I was only really concerned with comparing the &lt;span class="caps"&gt;EVR&lt;/span&gt; portion; Puppet knows about package names
and the bug herein was with what Puppet calls the &amp;#8220;version&amp;#8221; (&lt;span class="caps"&gt;EVR&lt;/span&gt; in yum/rpm parlance). Parsing is pretty&amp;nbsp;simple:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If there is a &lt;code&gt;:&lt;/code&gt; in the string, everything before it is the epoch. If not, the epoch is&amp;nbsp;zero.&lt;/li&gt;
&lt;li&gt;If there is a &lt;code&gt;-&lt;/code&gt; in the &lt;em&gt;remaining&lt;/em&gt; string, everything before the first &lt;code&gt;-&lt;/code&gt; is the version,
  and everything after it is the release. If there isn&amp;#8217;t one, the release is considered&amp;nbsp;null/nill/None/whatever.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="how-yum-compares-evr"&gt;&lt;a class="toclink" href="#how-yum-compares-evr"&gt;How Yum Compares&amp;nbsp;&lt;span class="caps"&gt;EVR&lt;/span&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once the package string is parsed into its &lt;span class="caps"&gt;EVR&lt;/span&gt; components, yum calls &lt;code&gt;rpmUtils.miscutils.compareEVR()&lt;/code&gt;,
which does some data type massaging for the inputs, and then calls out to &lt;code&gt;rpm.labelCompare()&lt;/code&gt;
(found in &lt;code&gt;rpm.git/python/header-py.c&lt;/code&gt;). &lt;code&gt;labelCompare()&lt;/code&gt; sets each epoch
to &amp;#8220;0&amp;#8221; if it was null/Nonem, and then uses &lt;code&gt;compare_values()&lt;/code&gt; to compare each &lt;span class="caps"&gt;EVR&lt;/span&gt; portion, which in turn falls through
to a function called &lt;code&gt;rpmvercmp()&lt;/code&gt; (see below). The algorithm for &lt;code&gt;labelCompare()&lt;/code&gt; is as&amp;nbsp;follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Set each epoch value to 0 if it&amp;#8217;s&amp;nbsp;null/None.&lt;/li&gt;
&lt;li&gt;Compare the epoch values using &lt;code&gt;compare_values()&lt;/code&gt;. If they&amp;#8217;re not equal, return that result, else
   move on to the next portion (version). The logic within &lt;code&gt;compare_values()&lt;/code&gt; is that if one is empty/null
   and the other is not, the non-empty one is greater, and that ends the comparison. If neither of
   them is empty/not present, compare them using &lt;code&gt;rpmvercmp()&lt;/code&gt; and follow the same logic; if one
   is &amp;#8220;greater&amp;#8221; (newer) than the other, that&amp;#8217;s the end result of the comparison. Otherwise, move
   on to the next component&amp;nbsp;(version).&lt;/li&gt;
&lt;li&gt;Compare the versions using the same&amp;nbsp;logic.&lt;/li&gt;
&lt;li&gt;Compare the releases using the same&amp;nbsp;logic.&lt;/li&gt;
&lt;li&gt;If all of the components are &amp;#8220;equal&amp;#8221;, the packages are the&amp;nbsp;same.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The real magic, obviously, happens in &lt;code&gt;rpmvercmp()&lt;/code&gt;, the rpm library function to compare two
versions (or epochs, or releases). That&amp;#8217;s also where the madness&amp;nbsp;happens.&lt;/p&gt;
&lt;h3 id="how-rpm-compares-version-parts"&gt;&lt;a class="toclink" href="#how-rpm-compares-version-parts"&gt;How &lt;span class="caps"&gt;RPM&lt;/span&gt; Compares Version&amp;nbsp;Parts&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt; is written in C. Converting all of the buffer and pointer processing for these strings
over to Ruby was quite a pain. That being said, I didn&amp;#8217;t make this up, this is actually the
algorithm that &lt;code&gt;rpmvercmp()&lt;/code&gt; (&lt;code&gt;lib/rpmvercmp.c&lt;/code&gt;) uses to compare version &amp;#8220;parts&amp;#8221;
(epoch, version, release). This function returns 0 if the strings are equal, 1 if &lt;code&gt;a&lt;/code&gt; (the
first string argument) is newer than &lt;code&gt;b&lt;/code&gt; (the second string argument), or -1 if
&lt;code&gt;a&lt;/code&gt; is older than &lt;code&gt;b&lt;/code&gt;. Also keep in mind that this uses pointers in C, so it works by removing
a sequence of 0 or more characters from the front of each string, comparing them, and then repeating
for the remaining characters in each string until something is unequal, or a string reaches its&amp;nbsp;end.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If the strings are binary equal (&lt;code&gt;a == b&lt;/code&gt;), they&amp;#8217;re equal, return&amp;nbsp;0.&lt;/li&gt;
&lt;li&gt;Loop over the strings, left-to-right.&lt;ol&gt;
&lt;li&gt;Trim anything that&amp;#8217;s not &lt;code&gt;[A-Za-z0-9]&lt;/code&gt; or tilde (&lt;code&gt;~&lt;/code&gt;) from the front of both&amp;nbsp;strings.&lt;/li&gt;
&lt;li&gt;If both strings start with a tilde, discard it and move on to the next&amp;nbsp;character.&lt;/li&gt;
&lt;li&gt;If string &lt;code&gt;a&lt;/code&gt; starts with a tilde and string &lt;code&gt;b&lt;/code&gt; does not, return -1 (string &lt;code&gt;a&lt;/code&gt; is older);
   and the inverse if string &lt;code&gt;b&lt;/code&gt; starts with a tilde and string &lt;code&gt;a&lt;/code&gt; does&amp;nbsp;not.&lt;/li&gt;
&lt;li&gt;End the loop if either string has reached zero&amp;nbsp;length.&lt;/li&gt;
&lt;li&gt;If the first character of &lt;code&gt;a&lt;/code&gt; is a digit, pop the leading chunk of continuous digits from
   each string (which may be &amp;#8221; for &lt;code&gt;b&lt;/code&gt; if only one &lt;code&gt;a&lt;/code&gt; starts with digits). If &lt;code&gt;a&lt;/code&gt; begins
   with a letter, do the same for leading&amp;nbsp;letters.&lt;/li&gt;
&lt;li&gt;If the segement from &lt;code&gt;b&lt;/code&gt; had 0 length, return 1 if the segment from &lt;code&gt;a&lt;/code&gt; was numeric, or
   -1 if it was alphabetic. The logical result of this is that if &lt;code&gt;a&lt;/code&gt; begins with numbers
   and &lt;code&gt;b&lt;/code&gt; does not, &lt;code&gt;a&lt;/code&gt; is newer (return 1). If &lt;code&gt;a&lt;/code&gt; begins with letters and &lt;code&gt;b&lt;/code&gt; does not,
   then &lt;code&gt;a&lt;/code&gt; is older (return -1). If the leading character(s) from &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; were both
   numbers or both letters, continue&amp;nbsp;on.&lt;/li&gt;
&lt;li&gt;If the leading segments were both numeric, discard any leading zeros and &lt;em&gt;whichever one is longer
   wins&lt;/em&gt;. If &lt;code&gt;a&lt;/code&gt; is longer than &lt;code&gt;b&lt;/code&gt; (without leading zeroes), return 1, and vice-versa. If
   they&amp;#8217;re of the same length, continue&amp;nbsp;on.&lt;/li&gt;
&lt;li&gt;Compare the leading segments with &lt;code&gt;strcmp()&lt;/code&gt; (or &lt;code&gt;&amp;lt;=&amp;gt;&lt;/code&gt; in Ruby). If that returns a non-zero
   value, then return that value. Else continue to the next iteration of the&amp;nbsp;loop.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;If the loop ended (nothing has been returned yet, either both strings are totally the same or they&amp;#8217;re
   the same up to the end of one of them, like with &amp;#8220;1.2.3&amp;#8221; and &amp;#8220;1.2.3b&amp;#8221;), then the longest wins -
   if what&amp;#8217;s left of &lt;code&gt;a&lt;/code&gt; is longer than what&amp;#8217;s left of &lt;code&gt;b&lt;/code&gt;, return 1. Vice-versa for if what&amp;#8217;s
   left of &lt;code&gt;b&lt;/code&gt; is longer than what&amp;#8217;s left of &lt;code&gt;a&lt;/code&gt;. And finally, if what&amp;#8217;s left of them is the same
   length, return&amp;nbsp;0.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Well there you have it. Quite convoluted. And full of things like the &amp;#8220;~&amp;#8221; magic character (&amp;#8220;~1&amp;#8221; is always
older than&amp;nbsp;&amp;#8220;9999zzzz&amp;#8221;).&lt;/p&gt;</content><category term="rpm"></category><category term="yum"></category><category term="puppet"></category><category term="versions"></category></entry><entry><title>bashrc Vagrant / VirtualBoxÂ reminder</title><link href="https://blog.jasonantman.com/2014/07/bashrc-vagrant-virtualbox-reminder/" rel="alternate"></link><published>2014-07-10T06:45:00-04:00</published><updated>2014-07-10T06:45:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-07-10:/2014/07/bashrc-vagrant-virtualbox-reminder/</id><summary type="html">&lt;p&gt;Add a little reminder about Vagrant/VirtualBox running machines in your&amp;nbsp;profile/bashrc.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Lately I&amp;#8217;ve been using VirtualBox VMs, both managed by Vagrant and otherwise, quite a lot.
I&amp;#8217;ve also been doing a bunch of development work with them. And inevitably, I close a screen
window and fo on with my work and end up with a few &amp;#8220;orphaned&amp;#8221; virtualbox VMs running that
I&amp;#8217;ve forgotten&amp;nbsp;about.&lt;/p&gt;
&lt;p&gt;Below is the snippet I&amp;#8217;ve added to my &lt;code&gt;~/.bashrc&lt;/code&gt; to keep me aware of this situation. Unfortunately
the &lt;code&gt;vagrant global-status&lt;/code&gt; command is relatively slow, so this adds (on my machine) about
1.5 seconds of wall-clock time to my &lt;code&gt;.bashrc&lt;/code&gt; (hence the process check&amp;nbsp;first).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Vagrant/VirtualBox reminder&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; pgrep VBoxHeadless &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&amp;gt;/dev/null&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nv"&gt;vblist&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;VBoxManage list runningvms&lt;span class="k"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;[&lt;/span&gt; -n &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;vblist&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; -e &lt;span class="s2"&gt;&amp;quot;\e[1;31mRunning VirtualBox VMs:\e[0m\n&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;vblist&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;\n&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; which vagrant &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&amp;gt; /dev/null &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; vagrant &lt;span class="nb"&gt;help&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; grep -q global-status&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="nv"&gt;vagrantstatus&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;vagrant global-status &lt;span class="p"&gt;|&lt;/span&gt; sed &lt;span class="s1"&gt;&amp;#39;/^\s*$/q&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
        &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$vagrantstatus&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; grep -q running &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; -e &lt;span class="s2"&gt;&amp;quot;\e[1;31mRunning Vagrant Machines:\e[0m&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$vagrantstatus&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; head -2&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$vagrantstatus&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; grep running&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="vagrant"></category><category term="bashrc"></category><category term="profile"></category><category term="virtualbox"></category></entry><entry><title>Remotely-controlled deck.js slideÂ presentations</title><link href="https://blog.jasonantman.com/2014/05/remotely-controlled-deckjs-slide-presentations/" rel="alternate"></link><published>2014-05-12T09:34:00-04:00</published><updated>2014-05-12T09:34:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-05-12:/2014/05/remotely-controlled-deckjs-slide-presentations/</id><summary type="html">&lt;p&gt;A wonderful GitHub project by chrisjaure to remotely control deck.js slide&amp;nbsp;presentations.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been struggling to find a good, cross-platform remote meeting solution. We&amp;#8217;re using &lt;a href="http://www.imeet.com"&gt;iMeet&lt;/a&gt;
at work at the moment, but there&amp;#8217;s no way to present or screen share from a Linux machine. For most of our ops and
automation team daily and weekly meetings, we use &lt;a href="http://www.teamspeak.com/"&gt;TeamSpeak&lt;/a&gt; - sure it&amp;#8217;s not open source,
but it&amp;#8217;s simple, supports all OSes that matter to us (Mac, Linux, Windows, Android and iOS), can be self-hosted,
and has the holy grail, functional push-to-talk. But it&amp;#8217;s audio&amp;nbsp;only.&lt;/p&gt;
&lt;p&gt;On Friday I was running two short elaboration meetings, and had quick little slide decks done up in &lt;a href="http://imakewebthings.com/deck.js/"&gt;deck.js&lt;/a&gt;
to keep us on track. I couldn&amp;#8217;t help but think, gee, it sure would be nice if instead of switching to Mac or a &lt;span class="caps"&gt;VM&lt;/span&gt; and sharing my screen,
we could just use the audio communication mediums that we already do, and I could simply control the slides in a&amp;nbsp;browser.&lt;/p&gt;
&lt;p&gt;Well this morning I stumbled on &lt;a href="http://cleverchris.com/"&gt;Chris Jaure&lt;/a&gt;&amp;#8216;s &lt;a href="https://github.com/chrisjaure/deckjs-remote"&gt;deckjs-remote&lt;/a&gt;
project that does exactly that. It&amp;#8217;s a nodejs npm module that runs a websocket server, and allows people to join a session and follow
along as the presenter changes&amp;nbsp;slides.&lt;/p&gt;
&lt;p&gt;I did have a few hiccups getting it working - mainly some issues with &lt;span class="caps"&gt;CORS&lt;/span&gt;. The &lt;span class="caps"&gt;README&lt;/span&gt;.md has a large block of markup to be added to
the slide deck html to support &amp;#8220;older browsers that don&amp;#8217;t support &lt;span class="caps"&gt;CORS&lt;/span&gt;.&amp;#8221; I&amp;#8217;m running Firefox 28.0 (Firefox has supported &lt;span class="caps"&gt;CORS&lt;/span&gt; since
3.0, quite a few years back) and still needed to add this to get everything working. I also needed to manually add a script tag
for socket.io coming from the nodejs server in order to get everything&amp;nbsp;working.&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s a bit of a delay for the socket connection to come up after initially loading the page, but once that&amp;#8217;s done, the presenter
(&amp;#8220;master&amp;#8221; session) should get the password prompt, and any guests should get a prompt asking if they want to join the current
session. Perhaps the best part is that the nodejs server interally stores each deck by &lt;span class="caps"&gt;URL&lt;/span&gt;, so it seems to work perfectly fine
when running one instance for N presenters (i.e. a single instance running persistently on a shared&amp;nbsp;server).&lt;/p&gt;</content><category term="slide"></category><category term="presentation"></category><category term="deck.js"></category><category term="deckjs"></category><category term="javascript"></category></entry><entry><title>dashsnap.py - A Script to Snapshot a GraphiteÂ Dashboard</title><link href="https://blog.jasonantman.com/2014/05/dashsnap-a-script-to-snapshot-a-graphite-dashboard/" rel="alternate"></link><published>2014-05-07T21:58:00-04:00</published><updated>2014-05-07T21:58:00-04:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-05-07:/2014/05/dashsnap-a-script-to-snapshot-a-graphite-dashboard/</id><summary type="html">&lt;p&gt;dashsnap.py, a script to snapshot a Graphite dashboard at various&amp;nbsp;intervals&lt;/p&gt;</summary><content type="html">&lt;p&gt;As we push more and more and more metrics into &lt;a href="http://graphite.wikidot.com/"&gt;Graphite&lt;/a&gt;
at work, we&amp;#8217;ve found the need to preserve data from an incident or outage to be quite
important. Especially now that we&amp;#8217;re feeding a &lt;em&gt;lot&lt;/em&gt; of our data at 10-second intervals,
and our storage schemas generally start aggregating that past 24 hours (God only knows
how many spikes are gone if you look a week later), it&amp;#8217;s important to capture as much
data as we think we&amp;#8217;ll need as soon after the incident as&amp;nbsp;possible.&lt;/p&gt;
&lt;p&gt;To this end, a few days (and nights) into a relatively major crisis, I wrote a little
python script, &lt;a href="https://github.com/jantman/misc-scripts/blob/master/dashsnap.py"&gt;dashsnap.py&lt;/a&gt;.
It&amp;#8217;s horribly simple; pass it the hostname to your graphite server (if &amp;#8220;graphite&amp;#8221; doesn&amp;#8217;t
resolve to what you want), the name of a dashboard, optionally a height and width for images
(the default is currently 1024x768), and either a from and to date/time or a list of graphite
&lt;span class="caps"&gt;URL&lt;/span&gt;-style intervals (the default is a ginormous &amp;#8220;-10minutes,-30minutes,-1hours,-2hours,-4hours,-6hours,-12hours,-24hours,-36hours&amp;#8221;).
It will find all graphs on your dashboard, and locally save (in a horribly named directory)
both PNGs of all the graphs, as well as the &lt;em&gt;raw &lt;span class="caps"&gt;JSON&lt;/span&gt; data&lt;/em&gt; for them. It&amp;#8217;ll also write
(2 &lt;span class="caps"&gt;AM&lt;/span&gt;-simple) &lt;span class="caps"&gt;HTML&lt;/span&gt; index files to all of the intervals and graphs within&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a view of the index page using the default&amp;nbsp;intervals:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/dashsnap_index.png"&gt;&lt;img alt="screenshot of rendered index page" src="/GFX/dashsnap_index_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And here&amp;#8217;s the page showing graphs and &lt;span class="caps"&gt;JSON&lt;/span&gt; links for an individual dashboard for one&amp;nbsp;interval:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/dashsnap_page.png"&gt;&lt;img alt="screenshot of one interval page" src="/GFX/dashsnap_page_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ll quickly admit right now that this is alpha software, if you can even call it that.
I guess in reality it&amp;#8217;s a late-night fix to a problem that deserves more. But, if it can
save someone else a few hours late at night, it&amp;#8217;s worth mentioning. PRs are welcome, as
are issues and suggestions on GitHub for bugs, or for where I should take this; I like
the handy little &lt;span class="caps"&gt;CLI&lt;/span&gt; script (though the output could use quite a bit of visual work),
but I&amp;#8217;m also toying around with the idea of creating a service to take the snapshots
and store them, mostly thinking about it being part of something like
&lt;a href="https://github.com/etsy/morgue"&gt;Etsy&amp;#8217;s Morgue&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The latest version of the source for dashsnap will (within the forseeable future)
be available&amp;nbsp;at:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/jantman/misc-scripts/blob/master/dashsnap.py"&gt;https://github.com/jantman/misc-scripts/blob/master/dashsnap.py&lt;/a&gt;&lt;/p&gt;</content><category term="graphite"></category><category term="monitoring"></category></entry><entry><title>Python script to backup DisqusÂ comments</title><link href="https://blog.jasonantman.com/2014/03/python-script-to-backup-disqus-comments/" rel="alternate"></link><published>2014-03-01T19:01:00-05:00</published><updated>2014-03-01T19:01:00-05:00</updated><author><name>Jason Antman</name></author><id>tag:blog.jasonantman.com,2014-03-01:/2014/03/python-script-to-backup-disqus-comments/</id><summary type="html">&lt;p&gt;Quick Python script to backup Disqus comments for a&amp;nbsp;forum&lt;/p&gt;</summary><content type="html">&lt;p&gt;Since I just &lt;a href="/2014/03/wordpress-to-pelican-with-disqus-comments"&gt;switched this blog to using Disqus for commenting&lt;/a&gt;,
I wanted a way to back up comments in case something goes wrong (like,
Disqus going the way of del.icio.us&amp;nbsp;bookmarking).&lt;/p&gt;
&lt;p&gt;I whipped up a quick &lt;a href="https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py"&gt;Python script&lt;/a&gt;
using the official &lt;a href="https://github.com/disqus/disqus-python"&gt;Disqus Python &lt;span class="caps"&gt;API&lt;/span&gt; client&lt;/a&gt;. It grabs the forum details,
threads list and posts (comments) list, and writes them out to a &lt;span class="caps"&gt;JSON&lt;/span&gt;&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;It doesn&amp;#8217;t have any restore feature, but it captures all of the&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;My first test made it look like there &lt;em&gt;may&lt;/em&gt; be some posts and theads missing (my import from
wordpress showed 56 threads and 146 comments, but this script only grabbed 52 and 125 respectively),
so exercise some caution until I verify what the problem is. If you happen to figure it out,
please submit a&amp;nbsp;&lt;span class="caps"&gt;PR&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The script is available on GitHub at &lt;a href="https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py"&gt;https://github.com/jantman/misc-scripts/blob/master/disqus_backup.py&lt;/a&gt;.&lt;/p&gt;</content><category term="pelican"></category><category term="disqus"></category><category term="python"></category></entry><entry><title>Testing GPG KeyÂ Passphrases</title><link href="https://blog.jasonantman.com/2013/08/testing-gpg-key-passphrases/" rel="alternate"></link><published>2013-08-26T06:00:00-04:00</published><updated>2013-08-26T06:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-08-26:/2013/08/testing-gpg-key-passphrases/</id><summary type="html">&lt;p&gt;So hypothetically, you have a &lt;span class="caps"&gt;GPG&lt;/span&gt; public/private keypair (from a backup
or old computer), but you don&amp;#8217;t remember the passphrase. Here&amp;#8217;s a
relatively simple way to find it from a number of possible options. This
&lt;em&gt;requires&lt;/em&gt; that you have a computer secure enough to store the possible â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;So hypothetically, you have a &lt;span class="caps"&gt;GPG&lt;/span&gt; public/private keypair (from a backup
or old computer), but you don&amp;#8217;t remember the passphrase. Here&amp;#8217;s a
relatively simple way to find it from a number of possible options. This
&lt;em&gt;requires&lt;/em&gt; that you have a computer secure enough to store the possible
options in a text file. I&amp;#8217;d recommend storing that file on a
ramdisk/tmpfs, and using a temporary &lt;span class="caps"&gt;VM&lt;/span&gt; for this, which you&amp;#8217;ll wipe away
when you&amp;#8217;re&amp;nbsp;done.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preparation:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You have an appropriately secure place to do this with &lt;span class="caps"&gt;GPG&lt;/span&gt;
    installed, and a safe place to store a text file of sample
    passphrases (i.e. a&amp;nbsp;ramdisk).&lt;/li&gt;
&lt;li&gt;Copy your backed up public and private keys to &lt;code&gt;~/.gnupg&lt;/code&gt; on that
    host. Let&amp;#8217;s assume they&amp;#8217;re called &lt;code&gt;TestUser_public.key&lt;/code&gt; and
    &lt;code&gt;TestUser_private.key&lt;/code&gt;. We&amp;#8217;re assuming that you &lt;span class="caps"&gt;KNOW&lt;/span&gt;, &lt;span class="caps"&gt;BEYOND&lt;/span&gt; A &lt;span class="caps"&gt;DOUBT&lt;/span&gt;
    that these are your keys (i.e. you got them from a secure offline
    backup medium, you&amp;#8217;ve verified against a printed key fingerprint,
    you&amp;#8217;ve verified the fingerprints against a
    &lt;a href="http://pgp.mit.edu/"&gt;keyserver&lt;/a&gt; that you know is authoritative for
    your keys,&amp;nbsp;etc.).&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;First, we import the public and private keys to&amp;nbsp;&lt;span class="caps"&gt;GPG&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;testuser:~$&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; .gnupg
&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --import TestUser_public.key 
&lt;span class="go"&gt;gpg: keyring `/home/testuser/.gnupg/secring.gpg` created&lt;/span&gt;
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: public key &amp;quot;Test User (Test User) &amp;quot; imported&lt;/span&gt;
&lt;span class="go"&gt;gpg: Total number processed: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:               imported: 1  (&lt;span class="caps"&gt;RSA&lt;/span&gt;: 1)&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --allow-secret-key-import --import TestUser_secret.key 
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: secret key imported&lt;/span&gt;
&lt;span class="go"&gt;gpg: key &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;: &amp;quot;Test User (Test User) &amp;quot; not changed&lt;/span&gt;
&lt;span class="go"&gt;gpg: Total number processed: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:              unchanged: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:       secret keys read: 1&lt;/span&gt;
&lt;span class="go"&gt;gpg:   secret keys imported: 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check that the keys are&amp;nbsp;there:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --list-keys
&lt;span class="go"&gt;/home/testuser/.gnupg/pubring.gpg&lt;/span&gt;
&lt;span class="go"&gt;--------------------------------&lt;/span&gt;
&lt;span class="go"&gt;pub   2048R/&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; 2013-08-24&lt;/span&gt;
&lt;span class="go"&gt;uid                  Test User (Test User) &lt;/span&gt;
&lt;span class="go"&gt;sub   2048R/&lt;span class="caps"&gt;40D9F35E&lt;/span&gt; 2013-08-24&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; gpg --list-secret-keys
&lt;span class="go"&gt;/home/testuser/.gnupg/secring.gpg&lt;/span&gt;
&lt;span class="go"&gt;--------------------------------&lt;/span&gt;
&lt;span class="go"&gt;sec   2048R/&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; 2013-08-24&lt;/span&gt;
&lt;span class="go"&gt;uid                  Test User (Test User) &lt;/span&gt;
&lt;span class="go"&gt;ssb   2048R/&lt;span class="caps"&gt;40D9F35E&lt;/span&gt; 2013-08-24&lt;/span&gt;

&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Note the fingerprint of the key which is, in this case, &lt;code&gt;17AD8D3D&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Testing&amp;nbsp;Passphrases:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Now that we have the keys imported, we&amp;#8217;re ready to test some
    passphrases. Enter your passphrases, one per line, in a text file.
    We&amp;#8217;re assuming that we&amp;#8217;re working on a totally secured host
    (ideally, a &lt;span class="caps"&gt;VM&lt;/span&gt; running on a standalone, non-networked machine) that
    will be destroyed when we&amp;#8217;re done. For added security, I&amp;#8217;d put this
    file on a ramdisk. In this example, the actual passphrase for the
    key is &amp;#8220;test&amp;#8221;. Here&amp;#8217;s our text&amp;nbsp;file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; cat /tmp/passphrases 
&lt;span class="go"&gt;bad&lt;/span&gt;
&lt;span class="go"&gt;notgood&lt;/span&gt;
&lt;span class="go"&gt;notright&lt;/span&gt;
&lt;span class="go"&gt;test&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next, create a test data file to try to&amp;nbsp;sign/encrypt:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;test input&amp;quot;&lt;/span&gt; &amp;gt; /tmp/test.in
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now we run the actual test (see below for more&amp;nbsp;information&amp;#8230;)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; p in &lt;span class="sb"&gt;`&lt;/span&gt;cat /tmp/passphrases&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$p&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; gpg -q --sign --local-user &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; --passphrase-fd &lt;span class="m"&gt;0&lt;/span&gt; --output /dev/null --yes /tmp/test.in &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: &lt;/span&gt;&lt;span class="nv"&gt;$p&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;break&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0&lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0&lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0&lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;gpg: skipped &amp;quot;&lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;&amp;quot;: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;gpg: signing failed: bad passphrase&lt;/span&gt;
&lt;span class="go"&gt;Reading passphrase from file descriptor 0&lt;/span&gt;

&lt;span class="go"&gt;You need a passphrase to unlock the secret key for&lt;/span&gt;
&lt;span class="go"&gt;user: &amp;quot;Test User (Test User) &amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;2048-bit &lt;span class="caps"&gt;RSA&lt;/span&gt; key, &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt;, created 2013-08-24&lt;/span&gt;

&lt;span class="go"&gt;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: test&lt;/span&gt;
&lt;span class="gp"&gt;testuser:~/.gnupg$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And there we have it, the working passphrase. I&amp;#8217;m sure there&amp;#8217;s a
    more efficient way to do this, and probably a more secure way, but
    I&amp;#8217;m not trying to brute-force someone&amp;#8217;s &lt;span class="caps"&gt;GPG&lt;/span&gt; key, I&amp;#8217;m trying to
    remember which one of my (many, many) passwords I used for a &lt;span class="caps"&gt;GPG&lt;/span&gt; key
    that I generated a decade&amp;nbsp;ago.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The actual command that we ran, rewritten with some linebreaks for
legibility,&amp;nbsp;is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; p in &lt;span class="sb"&gt;`&lt;/span&gt;cat /tmp/passphrases&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$p&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; gpg -q --sign --local-user &lt;span class="caps"&gt;17AD8D3D&lt;/span&gt; --passphrase-fd &lt;span class="m"&gt;0&lt;/span&gt; --output /dev/null --yes /tmp/test.in &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;CORRECT&lt;/span&gt; passphrase: &lt;/span&gt;&lt;span class="nv"&gt;$p&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;break&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This loops over each line in the passphrases file (each passphrase that
we want to try), and for each one, echoes the password and pipes it to
&lt;span class="caps"&gt;STDIN&lt;/span&gt; of &lt;code&gt;gpg&lt;/code&gt;, which tries to sign /tmp/test.in (sending the output
to /dev/null) using the key with &lt;span class="caps"&gt;ID&lt;/span&gt; &lt;code&gt;17AD8D3D&lt;/code&gt; (from #5 in the
Preparation steps above) and a password provided on &lt;span class="caps"&gt;STDIN&lt;/span&gt;. If the &lt;span class="caps"&gt;GPG&lt;/span&gt;
command succeeds, we echo the passphrase and stop looping through the
passphrases&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;I hope I wouldn&amp;#8217;t have to say this for anyone who&amp;#8217;s reading my blog, but
this information (as easy as it is to be figured out), is not to be used
for unethical&amp;nbsp;purposes.&lt;/p&gt;</content><category term="encryption"></category><category term="gnupg"></category><category term="gpg"></category><category term="key"></category><category term="passphrase"></category><category term="pgp"></category></entry><entry><title>Quick Tip: Timestamping bashÂ history</title><link href="https://blog.jasonantman.com/2013/06/quick-tip-timestamping-bash-history/" rel="alternate"></link><published>2013-06-11T07:09:00-04:00</published><updated>2013-06-11T07:09:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-06-11:/2013/06/quick-tip-timestamping-bash-history/</id><summary type="html">&lt;p&gt;Here&amp;#8217;s a tiny little snippet that I have in my &lt;code&gt;.bashrc&lt;/code&gt; which really
comes in handy when trying to figure out what I did on a system when.
One of the first things I do when (eek) building out or working on a
one-off machine (or setting up a â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here&amp;#8217;s a tiny little snippet that I have in my &lt;code&gt;.bashrc&lt;/code&gt; which really
comes in handy when trying to figure out what I did on a system when.
One of the first things I do when (eek) building out or working on a
one-off machine (or setting up a new laptop/desktop, as I am right now)
is set this in bashrc for my user and root, so I can go back and
document the setup process with a little more ease and sanity. Just add
this (it&amp;#8217;s just a &lt;a href="http://linux.die.net/man/3/strftime"&gt;strftime (3)&lt;/a&gt;
format string &lt;a href="http://www.gnu.org/software/bash/manual/bashref.html#index-HISTTIMEFORMAT"&gt;according to the
docs&lt;/a&gt;,
so adjust as desired) to &lt;code&gt;.bashrc&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;&lt;span class="caps"&gt;HISTTIMEFORMAT&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;%F %T &amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and bash will store commented-out integer timestamps before each line in
&lt;code&gt;.bash_history&lt;/code&gt; like&amp;nbsp;so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt;&lt;span class="m"&gt;1370950005&lt;/span&gt;
&lt;span class="go"&gt;less .bashrc&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;&lt;span class="m"&gt;1370950017&lt;/span&gt;
&lt;span class="go"&gt;history &lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;&lt;span class="m"&gt;1370950279&lt;/span&gt;
&lt;span class="go"&gt;tail -30 .bash_history &lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;&lt;span class="m"&gt;1370950293&lt;/span&gt;
&lt;span class="go"&gt;exit&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;the output of &lt;code&gt;history&lt;/code&gt; now uses the specified time&amp;nbsp;format:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 997  2013-06-11 07:26:45 less .bashrc
 998  2013-06-11 07:26:57 history 
 999  2013-06-11 07:31:19 tail -30 .bash_history 
1000  2013-06-11 07:31:33 exit
&lt;/pre&gt;&lt;/div&gt;</content><category term="bash"></category><category term="history"></category><category term="shell"></category><category term="timestamp"></category></entry><entry><title>Python script to check a list of URLs for return code, and final return code ifÂ redirected</title><link href="https://blog.jasonantman.com/2013/06/python-script-to-check-a-list-of-urls-for-return-code-and-final-return-code-if-redirected/" rel="alternate"></link><published>2013-06-10T06:00:00-04:00</published><updated>2013-06-10T06:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-06-10:/2013/06/python-script-to-check-a-list-of-urls-for-return-code-and-final-return-code-if-redirected/</id><summary type="html">&lt;p&gt;Every once in a while I need to add a bunch of redirects in Apache.
Here&amp;#8217;s a handy, dead simple Python script which takes a list of URLs on
&lt;span class="caps"&gt;STDIN&lt;/span&gt;, and for each one prints out either the response code, or, if the
response is a redirect, the response â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Every once in a while I need to add a bunch of redirects in Apache.
Here&amp;#8217;s a handy, dead simple Python script which takes a list of URLs on
&lt;span class="caps"&gt;STDIN&lt;/span&gt;, and for each one prints out either the response code, or, if the
response is a redirect, the response code of what is redirected to.
Pretty useful when you&amp;#8217;ve just added a bunch of redirects and want to
make sure none of them&amp;nbsp;404.&lt;/p&gt;
&lt;p&gt;The latest source of this script lives at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/check_url_list.py"&gt;https://github.com/jantman/misc-scripts/blob/master/check_url_list.py&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Script to check a list of URLs (passed on stdin) for response code, and for response code of the final path in a series of redirects.&lt;/span&gt;
&lt;span class="sd"&gt;Outputs (to stdout) a list of count of a given &lt;span class="caps"&gt;URL&lt;/span&gt;, response code, and if redirected, the final &lt;span class="caps"&gt;URL&lt;/span&gt; and its response code&lt;/span&gt;

&lt;span class="sd"&gt;Optionally, with verbose flag, report on all &lt;span class="caps"&gt;URL&lt;/span&gt; checks on &lt;span class="caps"&gt;STDERR&lt;/span&gt;&lt;/span&gt;

&lt;span class="sd"&gt;Copyright 2013 Jason Antman  all rights reserved&lt;/span&gt;
&lt;span class="sd"&gt;This script is distributed under the terms of the GPLv3, as per the&lt;/span&gt;
&lt;span class="sd"&gt;&lt;span class="caps"&gt;LICENSE&lt;/span&gt; file in this repository.&lt;/span&gt;

&lt;span class="sd"&gt;The canonical version of this script can be found at:&lt;/span&gt;

&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_url_nofollow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;code&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcode&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;urllib2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTTPError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;+ checking &lt;span class="caps"&gt;URL&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;get_url_nofollow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;++ &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;code&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="http"></category><category term="python"></category><category term="redirect"></category><category term="urllib"></category></entry><entry><title>Modern (0.10.x+) NodeJS RPMs on CentOS/REHL 5 andÂ 6</title><link href="https://blog.jasonantman.com/2013/06/modern-0-10-x-nodejs-rpms-on-centosrehl-5-and-6/" rel="alternate"></link><published>2013-06-06T20:47:00-04:00</published><updated>2013-06-06T20:47:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-06-06:/2013/06/modern-0-10-x-nodejs-rpms-on-centosrehl-5-and-6/</id><summary type="html">&lt;p&gt;I posted back in January about &lt;a href="/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt; Spec Files for nodejs 0.9.5 and v8
on CentOS
6&lt;/a&gt;. In
that post I also said that I was unable to get recent NodeJS to build on
CentOS 5 because of a long chain of dependencies including node-gyp, v8,
http-parser, glibc â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I posted back in January about &lt;a href="/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt; Spec Files for nodejs 0.9.5 and v8
on CentOS
6&lt;/a&gt;. In
that post I also said that I was unable to get recent NodeJS to build on
CentOS 5 because of a long chain of dependencies including node-gyp, v8,
http-parser, glibc, etc. I said I couldn&amp;#8217;t get it to build. Well, I have
good news for both distro&amp;nbsp;versions.&lt;/p&gt;
&lt;p&gt;On the CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; 6 side, thanks to a lot of work by &lt;span class="caps"&gt;T. C.
&lt;/span&gt;Hollingsworth and others, NodeJS 0.10.5 is currently in the official
&lt;a href="http://fedoraproject.org/wiki/EPEL"&gt;&lt;span class="caps"&gt;EPEL&lt;/span&gt;&lt;/a&gt; repositories. They seem to be
keeping the packages pretty current, but if you need newer, you can
always grab the SRPMs from &lt;span class="caps"&gt;EPEL&lt;/span&gt; and build the newer versions. This is
great, because it means I no longer need to maintain the spec files and
do my own builds. I don&amp;#8217;t think I really did anything to help get this
package in &lt;span class="caps"&gt;EPEL&lt;/span&gt;, other than ping a few people and comment on a few&amp;nbsp;tickets.&lt;/p&gt;
&lt;p&gt;For CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; 5, I finally have packages, but they&amp;#8217;re not exactly
pretty. The dependency solving issues still stand; they&amp;#8217;re rooted at the
dependency of node-gyp which requires the v8 C++ JavaScript library, and
is required to compile shared object addons. The best solution that I
(and a few others) could find is simply not to build node-gyp, and not
to have support for addons or package any addons; we just have the
binaries that NodeJS&amp;#8217;s Makefile creates, and everything else is
interpreted. A &lt;a href="https://twitter.com/toxigenicpoem"&gt;coworker&lt;/a&gt; found
&lt;a href="https://github.com/kazuhisya/nodejs-rpm"&gt;https://github.com/kazuhisya/nodejs-rpm&lt;/a&gt;
which contains a configure patch and specfile for a dead-simple CentOS
5/6 &lt;span class="caps"&gt;RPM&lt;/span&gt; of NodeJS 0.10.9, which essentially just uses &lt;span class="caps"&gt;EPEL&lt;/span&gt;&amp;#8217;s python26
packages to power the NodeJS build process, configures and uses the
Makefile&amp;#8217;s &lt;code&gt;make binary&lt;/code&gt; command to spit out a NodeJS binary tarball,
and then packages that. That whole process way out of line from the
&lt;a href="http://fedoraproject.org/wiki/Packaging:Guidelines"&gt;Fedora Packaging
Guidelines&lt;/a&gt;, and
also only dumps out nodejs, nodejs-binary and nodejs-debuginfo packages,
so I also can&amp;#8217;t just substitute in a different package name in my puppet
manifests (which install nodejs, nodejs-devel and npm packages). So I
&lt;a href="https://github.com/jantman/nodejs-rpm-centos5"&gt;forked that repository&lt;/a&gt;
and made some changes to the specfile: I gave the package name a prefix
(&amp;#8220;cmgd_&amp;#8221;, since that&amp;#8217;s where I work these days) and some warnings in
the description, to make it abundantly clear that these packages are
very far from what you find in &lt;span class="caps"&gt;EPEL&lt;/span&gt; and other repositories, and broke
npm and the devel files out into their own subpackages. Hopefully this
spec file will be of use to someone else who also has the unfortunate
need of supporting recent NodeJS on CentOS 5. If there&amp;#8217;s enough
interest, I&amp;#8217;ll consider building the packages and putting them in a
repository&amp;nbsp;somewhere.&lt;/p&gt;
&lt;p&gt;You can see the NodeJS 0.10.9 on CentOS 5 spec file, a patch, and the
READMEs at
&lt;a href="https://github.com/jantman/nodejs-rpm-centos5"&gt;https://github.com/jantman/nodejs-rpm-centos5&lt;/a&gt;.
Patches and/or pull requests are greatly appreciated, especially from
anyone who wants to make the spec file more Fedora guidelines&amp;nbsp;compliant.&lt;/p&gt;</content><category term="build"></category><category term="centos"></category><category term="EPEL"></category><category term="node"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="redhat"></category><category term="RHEL"></category><category term="rpm"></category><category term="specfile"></category></entry><entry><title>Script to easily rebuild aÂ SRPM</title><link href="https://blog.jasonantman.com/2013/05/script-to-easily-rebuild-a-srpm/" rel="alternate"></link><published>2013-05-28T10:26:00-04:00</published><updated>2013-05-28T10:26:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-28:/2013/05/script-to-easily-rebuild-a-srpm/</id><summary type="html">&lt;p&gt;Between &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 5 and 6 the default &lt;span class="caps"&gt;RPM&lt;/span&gt; compression format was
changed to xz. As such, trying to build a recent Fedora or Cent6 &lt;span class="caps"&gt;SRPM&lt;/span&gt; on
Cent5 will error out with a message like
&lt;code&gt;error: unpacking of archive failed on file foo;51a4c2a5: cpio: MD5 sum mismatch&lt;/code&gt;
because tar â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Between &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 5 and 6 the default &lt;span class="caps"&gt;RPM&lt;/span&gt; compression format was
changed to xz. As such, trying to build a recent Fedora or Cent6 &lt;span class="caps"&gt;SRPM&lt;/span&gt; on
Cent5 will error out with a message like
&lt;code&gt;error: unpacking of archive failed on file foo;51a4c2a5: cpio: MD5 sum mismatch&lt;/code&gt;
because tar on CentOS 5 doesn&amp;#8217;t support&amp;nbsp;xz.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a quick and dirty little script to use &lt;code&gt;rpm2cpio&lt;/code&gt; to rebuild a
&lt;span class="caps"&gt;SRPM&lt;/span&gt; using the host&amp;#8217;s native &lt;span class="caps"&gt;RPM&lt;/span&gt; compression. The latest version will
live at
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/rebuild_srpm.sh"&gt;https://github.com/jantman/misc-scripts/blob/master/rebuild_srpm.sh&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Script to rebuild a &lt;span class="caps"&gt;SRPM&lt;/span&gt; 1:1, useful when you want to build a &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 6&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;span class="caps"&gt;SRPM&lt;/span&gt; on a &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS 5 system that doesn&amp;#39;t support newer compression (cpio: &lt;span class="caps"&gt;MD5&lt;/span&gt; sum mismatch)&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# by Jason Antman &lt;/span&gt;
&lt;span class="c1"&gt;# The latest version of this script will always live at:&lt;/span&gt;
&lt;span class="c1"&gt;# &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-h&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--help&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: rebuild_srpm.sh  &amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nv"&gt;&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="nv"&gt;&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[[&lt;/span&gt; ! -e &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: &lt;span class="caps"&gt;SRPM&lt;/span&gt; file not found: &lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; ! which rpmbuild &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&amp;gt; /dev/null
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rpmbuild could not be found. please install. (sudo yum install rpm-build)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; ! which rpm2cpio &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&amp;gt; /dev/null
&lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rpm2cpio could not be found. please install. (sudo yum install rpm)&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;dirname &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;basename &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;mktemp -d&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nv"&gt;&lt;span class="caps"&gt;STARTPWD&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Rebuilding &lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;...&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# copy srpm into tempdir&lt;/span&gt;
cp &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;

&lt;span class="nb"&gt;pushd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt; &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&amp;gt;/dev/null

&lt;span class="c1"&gt;# setup local build dir structure&lt;/span&gt;
mkdir -p rpm rpm/&lt;span class="caps"&gt;BUILD&lt;/span&gt; rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt; rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt; rpm/&lt;span class="caps"&gt;SPECS&lt;/span&gt; rpm/&lt;span class="caps"&gt;SRPMS&lt;/span&gt; rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/athlon rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/i&lt;span class="se"&gt;\[&lt;/span&gt;&lt;span class="m"&gt;3456&lt;/span&gt;&lt;span class="se"&gt;\]&lt;/span&gt;&lt;span class="m"&gt;86&lt;/span&gt; rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/i386 rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/noarch rpm/&lt;span class="caps"&gt;RPMS&lt;/span&gt;/x86_64

&lt;span class="c1"&gt;# setup rpmmacros file&lt;/span&gt;
cat /dev/null &amp;gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/.rpmmacros
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%_topdir        &lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;/rpm&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.rpmmacros

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Extracting &lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;pushd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt;/ &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&amp;gt;/dev/null
rpm2cpio &lt;span class="nv"&gt;$&lt;span class="caps"&gt;SRPM&lt;/span&gt;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; cpio -idmv &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&amp;gt;/dev/null
&lt;span class="nb"&gt;popd&lt;/span&gt; &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&amp;gt;/dev/null

&lt;span class="c1"&gt;# build the &lt;span class="caps"&gt;SRPM&lt;/span&gt; from the spec and sources&lt;/span&gt;
&lt;span class="c1"&gt;# we&amp;#39;re just building a &lt;span class="caps"&gt;SRPM&lt;/span&gt; so we can ignore dependencies&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Rebuilding &lt;span class="caps"&gt;SRPM&lt;/span&gt;...&amp;quot;&lt;/span&gt;
&lt;span class="nv"&gt;NEW_SRPM&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;rpmbuild -bs --nodeps --macros&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/.rpmmacros &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;/rpm/&lt;span class="caps"&gt;SOURCES&lt;/span&gt;/*.spec &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;^Wrote: &amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Copying to &lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
cp &lt;span class="nv"&gt;$NEW_SRPM&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;/

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Wrote file to &lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;OUTDIR&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;/`basename &lt;/span&gt;&lt;span class="nv"&gt;$NEW_SRPM&lt;/span&gt;&lt;span class="s2"&gt;`&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# cleanup&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$&lt;span class="caps"&gt;STARTPWD&lt;/span&gt;&lt;/span&gt;
rm -Rf &lt;span class="nv"&gt;$&lt;span class="caps"&gt;TEMPDIR&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="lzma"></category><category term="packaging"></category><category term="rpm"></category><category term="rpm2cpio"></category><category term="rpmbuild"></category><category term="srpm"></category><category term="xz"></category></entry><entry><title>Search for a small-scale but automated RPM buildÂ system</title><link href="https://blog.jasonantman.com/2013/05/search-for-a-small-scale-but-automated-rpm-build-system/" rel="alternate"></link><published>2013-05-13T05:00:00-04:00</published><updated>2013-05-13T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-13:/2013/05/search-for-a-small-scale-but-automated-rpm-build-system/</id><summary type="html">&lt;p&gt;&lt;strong&gt;This post is part of a series of older draft posts from a few months
ago that I&amp;#8217;m just getting around to publishing. Unfortunately, I have
yet to find a build system that meets my requirements (see the last&amp;nbsp;paragraph).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At work, we have a handful - currently a really â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;This post is part of a series of older draft posts from a few months
ago that I&amp;#8217;m just getting around to publishing. Unfortunately, I have
yet to find a build system that meets my requirements (see the last&amp;nbsp;paragraph).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At work, we have a handful - currently a really small number - of &lt;span class="caps"&gt;RPM&lt;/span&gt;
packages that we need to build and deploy internally for our CentOS
server infrastructure. A number of them are just pulled down from
specific third-party repositories and rebuilt to have the vendor set as
us, and some are internally patched or developed software. We run
websites, and on the product side, we&amp;#8217;re a
Python/&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; shop (in fact, probably
one of the largest Django apps out there). We don&amp;#8217;t deploy our Django
apps via &lt;span class="caps"&gt;RPM&lt;/span&gt;, so building and distributing RPMs is definitely not one of
our core competencies. In fact, we really only want to do it when we&amp;#8217;re
testing/deploying a new distro, or when an upstream package is&amp;nbsp;updated.&lt;/p&gt;
&lt;p&gt;Last week I pulled a ticket to deploy &lt;a href="http://nodejs.org/"&gt;node.js&lt;/a&gt; to
one of our build hosts, and we&amp;#8217;ve got a few things in the pipeline that
also rely on it. I found the
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module on Github that&amp;#8217;s supposed to install it on &lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS, but it
pulls packages from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;,
and the newest version of nodejs there is 0.6.18, which is quite old. I
can&amp;#8217;t find any actively maintained sources of newer nodejs packages for
&lt;span class="caps"&gt;RHEL&lt;/span&gt;/CentOS (yeah, I know, that&amp;#8217;s one down side to the
distributions&amp;#8230;). However, I did find that nodejs 0.9.5 is being &lt;a href="http://koji.fedoraproject.org/koji/packageinfo?packageID=15154"&gt;built
for Fedora 18/19 in the Fedora build
system&lt;/a&gt;,
is already in the Fedora 18 Testing and Fedora Rawhide repos, but is
failing its &lt;span class="caps"&gt;EL6&lt;/span&gt; builds in their system. The decision I&amp;#8217;ve come to is to
use the puppetlabs-nodejs module to install it, but try and rebuild the
Fedora 18 RPMs under CentOS 5 and&amp;nbsp;6.&lt;/p&gt;
&lt;p&gt;So that&amp;#8217;s the background. Now, my current task: to search for an &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system for my current job. My core requirements, in no specific
order,&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Be relatively easy and quick to use for people who have a specfile
    or &lt;span class="caps"&gt;SRPM&lt;/span&gt; and want to be able to &amp;#8220;ensure =&gt; present&amp;#8221; the finished &lt;span class="caps"&gt;RPM&lt;/span&gt;
    on a system. i.e., require as little per-package configuration as&amp;nbsp;possible.&lt;/li&gt;
&lt;li&gt;Be able to handle rebuilding &amp;#8220;all&amp;#8221; of our RPMs when we roll out a
    new distro version. Doesn&amp;#8217;t necessarily need to be automatic, but
    should be relatively&amp;nbsp;simple.&lt;/li&gt;
&lt;li&gt;Ideally, not need to be running constantly - i.e. something that
    will cope well with build hosts being VMs that are shut down when
    they&amp;#8217;re not&amp;nbsp;needed.&lt;/li&gt;
&lt;li&gt;Handle automatically putting successfully built packages into a
    repository, ideally with some sort of (manual) promotion process
    from staging to&amp;nbsp;stable.&lt;/li&gt;
&lt;li&gt;Have minimal external (infrastructure) dependencies that we can&amp;#8217;t
    satisfy with existing&amp;nbsp;systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, the first step was to research existing &lt;span class="caps"&gt;RPM&lt;/span&gt; build systems and how
others do this. Here&amp;#8217;s a list of what I could find online, though most
of these are from distributions and software vendors/projects, not
end-user companies that are only building for internal&amp;nbsp;use.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://fedorahosted.org/koji/wiki"&gt;Koji&lt;/a&gt; is the build system used
    by &lt;a href="http://fedoraproject.org/wiki/Koji"&gt;Fedora&lt;/a&gt; and RedHat. It&amp;#8217;s
    about as full-featured as any can be, and I&amp;#8217;m familiar with it from
    my time at &lt;a href="http://koji.rutgers.edu/koji/"&gt;Rutgers University&lt;/a&gt;, as
    it&amp;#8217;s used to maintain their CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; packages. It&amp;#8217;s based largely
    on Mock. However, &lt;a href="http://fedoraproject.org/wiki/Koji/ServerHowTo"&gt;setting up the build
    server&lt;/a&gt; is no
    trivial task; there are few installations outside of Fedora/RedHat,
    and it relies on either Kerberos or an &lt;span class="caps"&gt;SSL&lt;/span&gt; &lt;span class="caps"&gt;CA&lt;/span&gt; infrastructure to
    authenticate machines and clients. So, it&amp;#8217;s designed for too large a
    scale and too much infrastructure for&amp;nbsp;me.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux has a &lt;a href="https://www.pld-linux.org/developingpld/builderscript"&gt;builder
    script&lt;/a&gt; that
    seems to automate &lt;code&gt;rpmbuild&lt;/code&gt; as well as fetching sources and
    resolving/building dependencies. I haven&amp;#8217;t looked at the script yet,
    but apparently it&amp;#8217;s in &lt;span class="caps"&gt;PLD&lt;/span&gt;&amp;#8217;s &amp;#8220;rpm-build-tools&amp;#8221;&amp;nbsp;package.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;PLD&lt;/span&gt; Linux also has a &lt;span class="caps"&gt;CVS&lt;/span&gt; repository for something called
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new"&gt;pld-builder.new&lt;/a&gt;.
    The
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/README?rev=1.5"&gt;&lt;span class="caps"&gt;README&lt;/span&gt;&lt;/a&gt;
    and
    &lt;a href="http://cvs.pld-linux.org/cgi-bin/cvsweb/pld-builder.new/doc/ARCHITECTURE?rev=1.6"&gt;&lt;span class="caps"&gt;ARCHITECTURE&lt;/span&gt;&lt;/a&gt;
    files make it sound like a relatively simple mainly-Python system
    that builds &lt;span class="caps"&gt;SRPMS&lt;/span&gt; and binary packages when requested, and most
    importantly, seems like a simple system that uses little more than
    shared filesystem access for communication and&amp;nbsp;coordination.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;ALT&lt;/span&gt; Linux has &lt;a href="http://en.altlinux.org/Sisyphus"&gt;Sisyphus&lt;/a&gt;, which
    combines repository management and web interface tools, package
    building and testing tools, and&amp;nbsp;more.&lt;/li&gt;
&lt;li&gt;The Dries &lt;span class="caps"&gt;RPM&lt;/span&gt; repository uses (or at least used&amp;#8230; my reference is
    quite old) &lt;a href="http://dries.ulyssis.org/rpm/pydar2/index.html"&gt;pydar2&lt;/a&gt;,
    &amp;#8220;a distributed client/server program which allows you to build
    multiple spec files on multiple distribution/architecture
    combinations automatically.&amp;#8221; That sounds like it could be what I
    need, but the last update says that it isn&amp;#8217;t finished yet, and that
    was in &lt;strong&gt;2005&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Mandriva Linux has pretty extensive information on their build
    system &lt;a href="http://wiki.mandriva.com/en/Category:Build_System"&gt;on their
    wiki&lt;/a&gt; and a
    &lt;a href="http://wiki.mandriva.com/en/Development/Packaging/BuildSystem/Theory"&gt;build system theory
    page&lt;/a&gt;,
    but it seems to be largely a hodgepodge of shell scripts and
    cronjobs, and is likely not a candidate for use by anyone other than
    its&amp;nbsp;designers.&lt;/li&gt;
&lt;li&gt;Argeo provides the &lt;a href="https://www.argeo.org/wiki/SLC"&gt;&lt;span class="caps"&gt;SLC&lt;/span&gt; framework&lt;/a&gt;
    which has a &amp;#8220;&lt;span class="caps"&gt;RPM&lt;/span&gt; Factory&amp;#8221; component, but I can&amp;#8217;t seem to find much
    more than a wiki page, and can&amp;#8217;t tell if it&amp;#8217;s a build automation
    system or just handles mocking packages and putting them in a repo
    on a single&amp;nbsp;host.&lt;/li&gt;
&lt;li&gt;Dag Wieers&amp;#8217; repositories use (or used) a set of python scripts
    called &lt;a href="http://dag.wieers.com/home-made/dar/"&gt;&lt;span class="caps"&gt;DAR&lt;/span&gt;, &amp;#8220;Dynamic Apt Repository
    builder&amp;#8221;&lt;/a&gt;. They&amp;#8217;re on
    &lt;a href="https://github.com/dagwieers/dar"&gt;github&lt;/a&gt; but are listed as &amp;#8220;old&amp;#8221;
    and haven&amp;#8217;t been updated in at least 2 years. The features sound
    quite interesting, and though it&amp;#8217;s based on the Apt repo format, it
    might provide some good ideas for implementing a similar&amp;nbsp;system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Update four months later:&lt;/strong&gt; I&amp;#8217;ve yet to find a build system that meets
my requirements above. For the moment I&amp;#8217;m only managing \~20 packages,
so my &amp;#8220;build system&amp;#8221; is a single shell script that reads in some
environment variables and runs through using
&lt;a href="http://fedoraproject.org/wiki/Projects/Mock"&gt;mock&lt;/a&gt; to build them in the
correct order (including pushing the finished RPMs back into the local
repository that mock reads from) and then pushing the finished packages
to our internal repository. Maybe when I have some spare time, I&amp;#8217;ll
consider a project to either make a slightly better (but simple) &lt;span class="caps"&gt;RPM&lt;/span&gt;
build system based on Python, or get our
&lt;a href="http://jenkins-ci.org/"&gt;Jenkins&lt;/a&gt; install to handle this for&amp;nbsp;me.&lt;/p&gt;</content><category term="build"></category><category term="linux"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="repository"></category><category term="rpm"></category><category term="rpmbuild"></category><category term="software"></category><category term="sysadmin"></category><category term="yum"></category></entry><entry><title>Environment Variable Substitution in Apache httpdÂ Configs</title><link href="https://blog.jasonantman.com/2013/05/environment-variable-substitution-in-apache-httpd-configs/" rel="alternate"></link><published>2013-05-11T12:01:00-04:00</published><updated>2013-05-11T12:01:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-05-11:/2013/05/environment-variable-substitution-in-apache-httpd-configs/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been configuring Apache httpd for over a decade, from a single
personal web server to web farms running thousands of vhosts. In most of
the &amp;#8220;real&amp;#8221; environments I&amp;#8217;ve worked in, we&amp;#8217;ve had some variation of
production, stage/test/&lt;span class="caps"&gt;QA&lt;/span&gt; and development hosts; and usually some method â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been configuring Apache httpd for over a decade, from a single
personal web server to web farms running thousands of vhosts. In most of
the &amp;#8220;real&amp;#8221; environments I&amp;#8217;ve worked in, we&amp;#8217;ve had some variation of
production, stage/test/&lt;span class="caps"&gt;QA&lt;/span&gt; and development hosts; and usually some method
of managing configurations between them, whether it&amp;#8217;s source control or
generating them from template. And in all of these environments, there
has invariably been drift between the configurations in the various
environments, whether it&amp;#8217;s because of poor tools to maintain a unified
configuration or many of those emergency redirect requests that make it
into production but are never backported. This is made all the worse
because everywhere I&amp;#8217;ve worked, the real difference between what
production and other environments &lt;em&gt;should&lt;/em&gt; be is really just a string
replacement in Apache configurations - &lt;code&gt;/prod/&lt;/code&gt; to &lt;code&gt;/test/&lt;/code&gt; or
&lt;code&gt;www.example.com&lt;/code&gt; to &lt;code&gt;www.dev.example.com&lt;/code&gt; or something along those&amp;nbsp;lines.&lt;/p&gt;
&lt;p&gt;Well a few days ago I was having a discussion with some co-workers that
dovetailed into this topic, and when I started some research, I found
(&lt;em&gt;finally after using httpd for years&lt;/em&gt;) that the &lt;a href="http://httpd.apache.org/docs/2.2/configuring.html#syntax"&gt;Apache httpd 2.2
configuration file syntax
documentation&lt;/a&gt;
states that httpd supports environment variable interpolation anywhere
in the config files (and &lt;a href="http://httpd.apache.org/docs/2.4/configuring.html#syntax"&gt;httpd
2.4&lt;/a&gt; supports
it with Defines as&amp;nbsp;well).&lt;/p&gt;
&lt;p&gt;Yup, that&amp;#8217;s right. All those different Apache configs I&amp;#8217;ve worked with
for years that define separate vhosts, document roots, rewrite targets,
ServerAliases, etc. for &lt;code&gt;www.example.com&lt;/code&gt; and &lt;code&gt;www.qa.example.com&lt;/code&gt; and
&lt;code&gt;www.dev.example.com&lt;/code&gt; really only had to be
&lt;code&gt;www.${ENV_URL_PART}example.com&lt;/code&gt;, and set &lt;code&gt;ENV_URL_PART&lt;/code&gt; in the init
script or sysconfig file. (Of course this all assumes that you have your
different environments served by different httpd instances, which you
do, of&amp;nbsp;course&amp;#8230;)&lt;/p&gt;
&lt;p&gt;For me, this is a very big deal. It means that finally, instead of
maintaining separate sets of configs for different environments which
are (theoretically, except for those emergencies) kept identical by
hand, or updating templates and then re-generating each environment&amp;#8217;s
configs, we can finally follow the same
commit/merge/promotion-between-environments workflow that we use for
other production code and Puppet configuration. It also means that those
pesky little rewrites and other minor tweaks will make it all the way
back to development&amp;nbsp;environments.&lt;/p&gt;
&lt;p&gt;So, here&amp;#8217;s a little example of how this would work in reality. Let&amp;#8217;s
assume that we have 3 main environments, &lt;code&gt;prod&lt;/code&gt;, &lt;code&gt;qa&lt;/code&gt; and &lt;code&gt;dev&lt;/code&gt; (though
this should work for N environments) and that domains are prefixed with
&amp;#8220;qa.&amp;#8221; or &amp;#8220;dev.&amp;#8221; for the respective internal environments. We set
environment variables before httpd is started, on a per-host basis,
depending on what environment that host is in. On RedHat based systems,
we&amp;#8217;d add the variables to &lt;code&gt;/etc/sysconfig/httpd&lt;/code&gt; for&amp;nbsp;production:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;HTTPD_ENV_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;prod&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;HTTPD_ENV_URL_PART&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;or for&amp;nbsp;&lt;span class="caps"&gt;QA&lt;/span&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;HTTPD_ENV_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;qa&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;HTTPD_ENV_URL_PART&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;qa.&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Those variables will now be available to httpd within the configurations
(and also to any applications or scripts that have access to the web
server&amp;#8217;s environment&amp;nbsp;variables).&lt;/p&gt;
&lt;p&gt;Now let&amp;#8217;s look at an example vhost configuration file that uses the
environment&amp;nbsp;variables:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;ServerName&lt;/span&gt; example.com
&lt;span class="nb"&gt;ServerAlias&lt;/span&gt; www.example.com
&lt;span class="c"&gt;# Aliases including proper environment name&lt;/span&gt;
&lt;span class="nb"&gt;ServerAlias&lt;/span&gt; www.${HTTPD_ENV_NAME}.example.com ${HTTPD_ENV_NAME}.example.com

&lt;span class="nb"&gt;ErrorLog&lt;/span&gt; &lt;span class="sx"&gt;/var/log/httpd/example.com-error_log&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; &lt;span class="sx"&gt;/var/log/httpd/example.com-access_log&lt;/span&gt; combined

&lt;span class="nb"&gt;DocumentRoot&lt;/span&gt; &lt;span class="sx"&gt;/sites/example.com/&lt;/span&gt;${HTTPD_ENV_NAME}/

&lt;span class="c"&gt;# Environment-specific configuration, if we absolutely need it:&lt;/span&gt;
&lt;span class="nb"&gt;Include&lt;/span&gt; &lt;span class="sx"&gt;/etc/httpd/sites/&lt;/span&gt;${HTTPD_ENV_NAME}/env.conf


&lt;span class="nb"&gt;RewriteEngine&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt;
&lt;span class="nb"&gt;RewriteRule&lt;/span&gt; &lt;span class="sx"&gt;/foobar/.&lt;/span&gt;* http://www.${HTTPD_ENV_URL_PART}example.com/baz/ [R=302,L]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Every instance of &lt;code&gt;${HTTPD_ENV_NAME}&lt;/code&gt; will be replaced with the value
set in the sysconfig file, and likewise with every instance of
&lt;code&gt;${HTTPD_ENV_URL_PART}&lt;/code&gt;. This way, we can have one set of configurations
and use our normal source control branch/promotion process to both test
and promote changes through the environments along with application
code, and ensure that any straight-to-production emergency changes
(everyone has customer-ordered rewrites like that, right?) make it back
to development and&amp;nbsp;qa.&lt;/p&gt;
&lt;p&gt;One caveat is that, if the environment variable is not defined, the
&lt;code&gt;${VAR_NAME}&lt;/code&gt; will be left as a literal string in the configuration
file. There doesn&amp;#8217;t seem to be any way to protect against this in httpd
2.2, other than making sure the variables are set before the server
starts (and maybe setting logical default values, like an empty string,
in your init script which should be overridden by the sysconfig&amp;nbsp;file).&lt;/p&gt;
&lt;p&gt;If you&amp;#8217;re running httpd 2.4+, you can turn on
&lt;a href="http://httpd.apache.org/docs/2.4/mod/mod_info.html"&gt;mod_info&lt;/a&gt; and
browse to &lt;code&gt;http://servername/server-info?config&lt;/code&gt; to dump the current
configuration, which will show the variable&amp;nbsp;substitution.&lt;/p&gt;</content><category term="apache"></category><category term="environment"></category><category term="httpd"></category><category term="variable"></category></entry><entry><title>RPM Spec Files for nodejs 0.9.5 and v8 on CentOSÂ 6</title><link href="https://blog.jasonantman.com/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/" rel="alternate"></link><published>2013-01-31T14:13:00-05:00</published><updated>2013-01-31T14:13:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-01-31:/2013/01/rpm-spec-files-for-nodejs-0-9-5-and-v8-on-centos-5/</id><summary type="html">&lt;p&gt;The latest version of nodejs that I could find as an &lt;span class="caps"&gt;RPM&lt;/span&gt; for CentOS was
0.6.16, from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;.
That&amp;#8217;s the one that puppetlabs currently uses in their
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module. There is, however, a nodejs 0.9.5 &lt;span class="caps"&gt;RPM&lt;/span&gt; in the Fedora Rawhide â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The latest version of nodejs that I could find as an &lt;span class="caps"&gt;RPM&lt;/span&gt; for CentOS was
0.6.16, from
&lt;a href="http://patches.fedorapeople.org/oldnode/stable/"&gt;http://patches.fedorapeople.org/oldnode/stable/&lt;/a&gt;.
That&amp;#8217;s the one that puppetlabs currently uses in their
&lt;a href="https://github.com/puppetlabs/puppetlabs-nodejs"&gt;puppetlabs-nodejs&lt;/a&gt;
module. There is, however, a nodejs 0.9.5 &lt;span class="caps"&gt;RPM&lt;/span&gt; in the Fedora Rawhide (19)
repository. Below are some patches to that specfile, and the specfile
for its v8 dependency, to get them to build on CentOS 6. You can also
find the full specfiles on my &lt;a href="https://github.com/jantman/specfiles"&gt;github specfile
repository&lt;/a&gt;. I had originally
wanted to get them built on CentOS 5 as well, but after following the
dependency tree from nodejs to http-parser to gyp, and then finding
issues in the gyp source that are incompatible with CentOS 5&amp;#8217;s python
2.4, I gave up on that&amp;nbsp;target.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nodejs.spec&lt;/strong&gt;, diff from Fedora Rawhide nodejs-0.9.5-9.fc18.src.rpm,
buildID=377755 (&lt;a href="https://raw.github.com/jantman/specfiles/master/nodejs.spec"&gt;full
specfile&lt;/a&gt;)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gh"&gt;diff --git a/nodejs.spec b/nodejs.spec&lt;/span&gt;
&lt;span class="gh"&gt;index 050ed86..86c0f4b 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/nodejs.spec&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/nodejs.spec&lt;/span&gt;
&lt;span class="gu"&gt;@@ -1,6 +1,6 @@&lt;/span&gt;
 Name: nodejs
 Version: 0.9.5
&lt;span class="gd"&gt;-Release: 9%{?dist}&lt;/span&gt;
&lt;span class="gi"&gt;+Release: 10%{?dist}&lt;/span&gt;
 Summary: JavaScript runtime
 License: &lt;span class="caps"&gt;MIT&lt;/span&gt; and &lt;span class="caps"&gt;ASL&lt;/span&gt; 2.0 and &lt;span class="caps"&gt;ISC&lt;/span&gt; and &lt;span class="caps"&gt;BSD&lt;/span&gt;
 Group: Development/Languages
&lt;span class="gu"&gt;@@ -25,7 +25,7 @@ Source6: nodejs-fixdep&lt;/span&gt;
 BuildRequires: v8-devel &amp;gt;= %{v8_ge}
 BuildRequires: http-parser-devel &amp;gt;= 2.0
 BuildRequires: libuv-devel
&lt;span class="gd"&gt;-BuildRequires: c-ares-devel&lt;/span&gt;
&lt;span class="gi"&gt;+BuildRequires: c-ares-devel &amp;gt;= 1.9.0&lt;/span&gt;
 BuildRequires: zlib-devel
 # Node.js requires some features from openssl 1.0.1 for &lt;span class="caps"&gt;SPDY&lt;/span&gt; support
 BuildRequires: openssl-devel &amp;gt;= 1:1.0.1
&lt;span class="gu"&gt;@@ -165,9 +165,13 @@ cp -p common.gypi %{buildroot}%{_datadir}/node&lt;/span&gt;

 %files docs
 %{_defaultdocdir}/%{name}-docs-%{version}
&lt;span class="gd"&gt;-%doc &lt;span class="caps"&gt;LICENSE&lt;/span&gt;&lt;/span&gt;

 %changelog
&lt;span class="gi"&gt;+* Thu Jan 31 2013 Jason Antman  - 0.9.5-10&lt;/span&gt;
&lt;span class="gi"&gt;+- specify build requirement of c-ares-devel &amp;gt;= 1.9.0&lt;/span&gt;
&lt;span class="gi"&gt;+- specify build requirement of libuv-devel 0.9.4&lt;/span&gt;
&lt;span class="gi"&gt;+- remove duplicate %doc &lt;span class="caps"&gt;LICENSE&lt;/span&gt; that was causing cpio &amp;#39;Bad magic&amp;#39; error on CentOS6&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
 * Sat Jan 12 2013 &lt;span class="caps"&gt;T.C.&lt;/span&gt; Hollingsworth  - 0.9.5-9
 - fix brown paper bag bug in requires generation script
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;v8.spec&lt;/strong&gt;, diff from Fedora Rawhide 3.13.7.5-2 (&lt;a href="https://raw.github.com/jantman/specfiles/master/v8.spec"&gt;full
specfile&lt;/a&gt;)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gd"&gt;--- v8.spec.orig       2013-01-26 16:03:18.000000000 -0500&lt;/span&gt;
&lt;span class="gi"&gt;+++ v8.spec     2013-01-31 09:04:51.068029459 -0500&lt;/span&gt;
&lt;span class="gu"&gt;@@ -21,9 +21,11 @@&lt;/span&gt;

 # %%global svnver 20110721svn8716

&lt;span class="gi"&gt;+%{!?python_sitelib: %define python_sitelib %(%{__python} -c &amp;quot;import distutils.sysconfig as d; print d.get_python_lib()&amp;quot;)}&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
 Name:          v8
 Version:       %{somajor}.%{sominor}.%{sobuild}.%{sotiny}
&lt;span class="gd"&gt;-Release:       2%{?dist}&lt;/span&gt;
&lt;span class="gi"&gt;+Release:       5%{?dist}&lt;/span&gt;
 Epoch:         1
 Summary:       JavaScript Engine
 Group:         System Environment/Libraries
&lt;span class="gu"&gt;@@ -32,7 +34,7 @@&lt;/span&gt;
 Source0:       http://commondatastorage.googleapis.com/chromium-browser-official/v8-%{version}.tar.bz2
 BuildRoot:     %{_tmppath}/%{name}-%{version}-%{release}-root-%(%{__id_u} -n)
 ExclusiveArch: %{ix86} x86_64 %{arm}
&lt;span class="gd"&gt;-BuildRequires: scons, readline-devel, libicu-devel&lt;/span&gt;
&lt;span class="gi"&gt;+BuildRequires: scons, readline-devel, libicu-devel, ncurses-devel&lt;/span&gt;

 %description
 V8 is Google&amp;#39;s open source JavaScript engine. V8 is written in C++ and is used 
&lt;span class="gu"&gt;@@ -51,8 +53,13 @@&lt;/span&gt;
 %setup -q -n %{name}-%{version}

 # -fno-strict-aliasing is needed with gcc 4.4 to get past some ugly code
&lt;span class="gd"&gt;-PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -Wno-error=strict-overflow -Wno-error=unused-local-typedefs -Wno-unused-but-set-variable\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
&lt;span class="gi"&gt;+%if 0%{?el5}&lt;/span&gt;
&lt;span class="gi"&gt;+PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -lncurses\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
&lt;span class="gi"&gt;+sed -i &amp;quot;s|&amp;#39;-O3&amp;#39;,|$PARSED_OPT_FLAGS,|g&amp;quot; SConstruct&lt;/span&gt;
&lt;span class="gi"&gt;+%else&lt;/span&gt;
&lt;span class="gi"&gt;+PARSED_OPT_FLAGS=`echo \&amp;#39;$RPM_OPT_FLAGS -fPIC -fno-strict-aliasing -Wno-unused-parameter -Wno-error=strict-overflow -Wno-unused-but-set-variable\&amp;#39;| sed &amp;quot;s/ /&amp;#39;,/g&amp;quot; | sed &amp;quot;s/&amp;#39;,/&amp;#39;, &amp;#39;/g&amp;quot;`&lt;/span&gt;
 sed -i &amp;quot;s|&amp;#39;-O3&amp;#39;,|$PARSED_OPT_FLAGS,|g&amp;quot; SConstruct
&lt;span class="gi"&gt;+%endif&lt;/span&gt;

 # clear spurious executable bits
 find . \( -name \*.cc -o -name \*.h -o -name \*.py \) -a -executable   
&lt;span class="gu"&gt;@@ -198,6 +205,17 @@&lt;/span&gt;
 %{python_sitelib}/j*.py*

 %changelog
&lt;span class="gi"&gt;+* Thu Jan 31 2013 Jason Antman  - 1:3.13.7.5-5&lt;/span&gt;
&lt;span class="gi"&gt;+- remove -Werror=unused-local-typedefs on cent6&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+* Wed Jan 30 2013 Jason Antman  - 1:3.13.7.5-4&lt;/span&gt;
&lt;span class="gi"&gt;+- define python_sitelib if it isn&amp;#39;t already (CentOS 5)&lt;/span&gt;
&lt;span class="gi"&gt;+&lt;/span&gt;
&lt;span class="gi"&gt;+* Wed Jan 30 2013 Jason Antman  - 1:3.13.7.5-3&lt;/span&gt;
&lt;span class="gi"&gt;+- pull 3.13.7.5-2 &lt;span class="caps"&gt;SRPM&lt;/span&gt; from Fedora 19 Koji most recent build&lt;/span&gt;
&lt;span class="gi"&gt;+- add ncurses-devel BuildRequires&lt;/span&gt;
&lt;span class="gi"&gt;+- modify PARSED_OPT_FLAGS to work with g++ 4.1.2 on CentOS 5&lt;/span&gt;
&lt;span class="gi"&gt;+ &lt;/span&gt;
 * Sat Jan 26 2013 &lt;span class="caps"&gt;T.C.&lt;/span&gt; Hollingsworth  - 1:3.13.7.5-2
 - rebuild for icu-50
 - ignore new &lt;span class="caps"&gt;GCC&lt;/span&gt; 4.8 warning
&lt;/pre&gt;&lt;/div&gt;</content><category term="build"></category><category term="centos"></category><category term="node"></category><category term="nodejs"></category><category term="package"></category><category term="packaging"></category><category term="redhat"></category><category term="RHEL"></category><category term="rpm"></category><category term="specfile"></category></entry><entry><title>Fedora Init Script SpecificationÂ Summary</title><link href="https://blog.jasonantman.com/2013/01/fedora-init-script-specification-summary/" rel="alternate"></link><published>2013-01-03T11:30:00-05:00</published><updated>2013-01-03T11:30:00-05:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2013-01-03:/2013/01/fedora-init-script-specification-summary/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; 2014-12-16: I&amp;#8217;m leaving this here for historical reasons, and since
some older &lt;span class="caps"&gt;OS&lt;/span&gt; versions still need properly-written init scripts. Since starting
to use &lt;a href="https://www.archlinux.org/"&gt;Arch Linux&lt;/a&gt; on my laptop, I&amp;#8217;ve become a
convert to the &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/"&gt;systemd&lt;/a&gt;
world. I know this is a &lt;a href="http://en.wikipedia.org/wiki/Systemd#Criticism"&gt;hot topic&lt;/a&gt;
and has sparked a â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; 2014-12-16: I&amp;#8217;m leaving this here for historical reasons, and since
some older &lt;span class="caps"&gt;OS&lt;/span&gt; versions still need properly-written init scripts. Since starting
to use &lt;a href="https://www.archlinux.org/"&gt;Arch Linux&lt;/a&gt; on my laptop, I&amp;#8217;ve become a
convert to the &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/"&gt;systemd&lt;/a&gt;
world. I know this is a &lt;a href="http://en.wikipedia.org/wiki/Systemd#Criticism"&gt;hot topic&lt;/a&gt;
and has sparked a lot of controversy. While I agree with some of the arguments
in principal, I strongly feel that systemd provides the interface that
Linux needs in modern times, and provides a unified solution to many problems
that were previously solved in myriad ways inside init scripts. In short,
if your distro supports systemd, I&amp;#8217;d recommend to skip past this page
and go ahead and write a &lt;a href="http://www.freedesktop.org/software/systemd/man/systemd.unit.html"&gt;unit file&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve been deploying some new software lately (specifically
&lt;a href="https://github.com/marisaseal/selenesse"&gt;selenesse&lt;/a&gt;, which combines
&lt;a href="http://seleniumhq.org/"&gt;Selenium&lt;/a&gt; and &lt;a href="http://fitnesse.org/"&gt;fitnesse&lt;/a&gt;,
&lt;a href="http://en.wikipedia.org/wiki/Xvfb"&gt;xvfb&lt;/a&gt;). None of these seem to come
with init scripts to run as daemons, and the quality of the few
Fedora/RedHat/CentOS init scripts I was able to find was quite poor. The
Fedora project has a &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript"&gt;Specification for SysV-style Init Scripts in their
Packaging wiki&lt;/a&gt;,
which specifies what a Fedora/RedHat/CentOS init script should look
like, in excruciating detail. What follows is an overview of the more
important points, which I&amp;#8217;m using to develop or modify the scripts I&amp;#8217;m
currently working&amp;nbsp;on.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scripts must be put in &lt;code&gt;/etc/rc.d/init.d&lt;/code&gt;, not in the &lt;code&gt;/etc/init.d&lt;/code&gt;
    symlink. They should have 0755&amp;nbsp;permissions.&lt;/li&gt;
&lt;li&gt;Scripts must have a Fedora-style &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Chkconfig_Header"&gt;chkconfig
    header&lt;/a&gt;
    (&amp;#8220;chkconfig:&amp;#8221;, &amp;#8220;description:&amp;#8221; lines), and may have an &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#LSB_Header"&gt;&lt;span class="caps"&gt;LSB&lt;/span&gt;-style
    header&lt;/a&gt;
    (&lt;span class="caps"&gt;BEGIN&lt;/span&gt; &lt;span class="caps"&gt;INIT&lt;/span&gt; &lt;span class="caps"&gt;INFO&lt;/span&gt;/&lt;span class="caps"&gt;END&lt;/span&gt; &lt;span class="caps"&gt;INIT&lt;/span&gt; &lt;span class="caps"&gt;INFO&lt;/span&gt;). See &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Initscript_template"&gt;Initscript
    template&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Scripts &lt;strong&gt;must&lt;/strong&gt; make use of a lockfile in &lt;code&gt;/var/lock/subsys/&lt;/code&gt;, and
    the name of the lockfile must be the same as the name of the init
    script. (There is a technical reason for this relating to how sysv
    init terminates daemons at shutdown). The lockfile should be touched
    when the daemon successfully starts, and removed when it
    successfully&amp;nbsp;stops.&lt;/li&gt;
&lt;li&gt;Init scripts should not depend on any environment variables set
    outside the script. They should operate gracefully with an
    empty/uninitialized environment (or only &lt;span class="caps"&gt;LANG&lt;/span&gt; and &lt;span class="caps"&gt;TERM&lt;/span&gt; set and a &lt;span class="caps"&gt;CWD&lt;/span&gt;
    of &lt;code&gt;/&lt;/code&gt;, as enforced by &lt;code&gt;service(8)&lt;/code&gt;, or with a full environment if
    they are called directly by a&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Required_Actions"&gt;Required&amp;nbsp;actions&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;all of the following actions are required, and have specific&amp;nbsp;definitions:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;start&lt;/strong&gt;: starts the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;stop&lt;/strong&gt;: stops the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;restart&lt;/strong&gt;: stop and restart the service if the service is
    already running, otherwise just start the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;condrestart (and try-restart)&lt;/strong&gt;: restart the service if the
    service is already running, if not, do&amp;nbsp;nothing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;reload&lt;/strong&gt;: reload the configuration of the service without
    actually stopping and restarting the service (if the service
    does not support this, do&amp;nbsp;nothing)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;force-reload&lt;/strong&gt;: reload the configuration of the service and
    restart it so that it takes&amp;nbsp;effect&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;status&lt;/strong&gt;: print the current status of the&amp;nbsp;service&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;usage&lt;/strong&gt;: by default, if the initscript is run without any
    action, it should list a &amp;#8220;usage message&amp;#8221; that has all actions
    (intended for&amp;nbsp;use)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are specified exit codes for &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Exit_Codes_for_the_Status_Action"&gt;status
    actions&lt;/a&gt;
    and &lt;a href="http://fedoraproject.org/wiki/Packaging:SysVInitScript#Exit_Codes_for_non-Status_Actions"&gt;non-status
    actions&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;They must &amp;#8220;behave sensibly&amp;#8221;. I&amp;#8217;ve found this to be one of the
    biggest problems with homegrown init scripts. If &lt;code&gt;servicename start&lt;/code&gt;
    is called while the service is already running, it should simply
    exit 0. Likewise if the service is already stopped. Init scripts
    &lt;strong&gt;must not kill unrelated processes&lt;/strong&gt;. I don&amp;#8217;t know how many times
    I&amp;#8217;ve seen scripts that kill every java or python process on a&amp;nbsp;machine.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I intend to use this as a quick checklist when developing or evaluating
init scripts for RedHat/Fedora based systems. In my experience, the
biggest problems with most init scripts revolve around poor handling of
&lt;span class="caps"&gt;PID&lt;/span&gt; files and lockfiles,&amp;nbsp;mainly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Killing processes other than the one that the script started (i.e.
    killing all java or python processes), usually because the &lt;span class="caps"&gt;PID&lt;/span&gt; isn&amp;#8217;t
    tracked at&amp;nbsp;start&lt;/li&gt;
&lt;li&gt;Starting a second instance of the subsystem because lockfiles aren&amp;#8217;t
    used, or the status function is&amp;nbsp;broken.&lt;/li&gt;
&lt;li&gt;improper exit&amp;nbsp;codes&lt;/li&gt;
&lt;li&gt;either explicitly relying on environment variables (and therefore
    breaking when called through &lt;code&gt;service(8)&lt;/code&gt;), or conversely, not
    cleaning/resetting environment variables that are used by dependent
    code or&amp;nbsp;processes.&lt;/li&gt;
&lt;/ul&gt;</content><category term="centos"></category><category term="fedora"></category><category term="init"></category><category term="redhat"></category><category term="startup"></category></entry><entry><title>Readable Nagios LogÂ Timestamps</title><link href="https://blog.jasonantman.com/2012/10/readable-nagios-log-timestamps/" rel="alternate"></link><published>2012-10-17T05:00:00-04:00</published><updated>2012-10-17T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-10-17:/2012/10/readable-nagios-log-timestamps/</id><summary type="html">&lt;p&gt;If you&amp;#8217;re like me and most humans, the Nagios logfile timestamp (a unix
timestamp) isn&amp;#8217;t terribly useful when trying to grep through the logs
and correlate&amp;nbsp;events:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; head -2 nagios.log
&lt;span class="go"&gt;[1350360000] &lt;span class="caps"&gt;LOG&lt;/span&gt; &lt;span class="caps"&gt;ROTATION&lt;/span&gt;: &lt;span class="caps"&gt;DAILY&lt;/span&gt;&lt;/span&gt;
&lt;span class="go"&gt;[1350360000] &lt;span class="caps"&gt;LOG&lt;/span&gt; &lt;span class="caps"&gt;VERSION&lt;/span&gt;: 2.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here&amp;#8217;s a nifty Perl one-liner that you â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you&amp;#8217;re like me and most humans, the Nagios logfile timestamp (a unix
timestamp) isn&amp;#8217;t terribly useful when trying to grep through the logs
and correlate&amp;nbsp;events:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; head -2 nagios.log
&lt;span class="go"&gt;[1350360000] &lt;span class="caps"&gt;LOG&lt;/span&gt; &lt;span class="caps"&gt;ROTATION&lt;/span&gt;: &lt;span class="caps"&gt;DAILY&lt;/span&gt;&lt;/span&gt;
&lt;span class="go"&gt;[1350360000] &lt;span class="caps"&gt;LOG&lt;/span&gt; &lt;span class="caps"&gt;VERSION&lt;/span&gt;: 2.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here&amp;#8217;s a nifty Perl one-liner that you can pipe your logs&amp;nbsp;through:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;perl&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;pe&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;s/(\\d+)/localtime($1)/e&amp;#39;&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to get nicer output&amp;nbsp;like:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# head -2 nagios.log&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Tue&lt;/span&gt; &lt;span class="n"&gt;Oct&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;LOG&lt;/span&gt;&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;ROTATION&lt;/span&gt;:&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;DAILY&lt;/span&gt;&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Tue&lt;/span&gt; &lt;span class="n"&gt;Oct&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;LOG&lt;/span&gt;&lt;/span&gt; &lt;span class="n"&gt;&lt;span class="caps"&gt;VERSION&lt;/span&gt;:&lt;/span&gt; &lt;span class="mf"&gt;2.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="icinga"></category><category term="Nagios"></category><category term="perl"></category><category term="timestamp"></category></entry><entry><title>Dumping all Macros from an RPM SpecÂ File</title><link href="https://blog.jasonantman.com/2012/09/dumping-all-macros-from-an-rpm-spec-file/" rel="alternate"></link><published>2012-09-10T10:00:00-04:00</published><updated>2012-09-10T10:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-10:/2012/09/dumping-all-macros-from-an-rpm-spec-file/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been doing a lot of &lt;span class="caps"&gt;RPM&lt;/span&gt; packaging lately, and on different (and
very old) distros and versions. Sometimes I lose track of all of the
macros used in specfiles (&lt;code&gt;_bindir _sbindir dist _localstatedir&lt;/code&gt;, etc).
There&amp;#8217;s no terribly easy way to dump a list of all of the â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been doing a lot of &lt;span class="caps"&gt;RPM&lt;/span&gt; packaging lately, and on different (and
very old) distros and versions. Sometimes I lose track of all of the
macros used in specfiles (&lt;code&gt;_bindir _sbindir dist _localstatedir&lt;/code&gt;, etc).
There&amp;#8217;s no terribly easy way to dump a list of all of the available
macros. There is, however, a bit of a kludge. Insert the following code
in your specfile before the &lt;code&gt;%prep&lt;/code&gt; or &lt;code&gt;%setup&lt;/code&gt; lines:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;%dump
exit 1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;%dump&lt;/code&gt; macro will dump all defined macros to &lt;span class="caps"&gt;STDERR&lt;/span&gt;. The &lt;code&gt;exit 1&lt;/code&gt;
will prevent rpmbuild from going on and trying to build the package. If
you want to view the output nicely, you can pipe it through a pager like
less: &lt;code&gt;rpmbuild -ba filename.spec 2&amp;gt;&amp;amp;1 | less&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Just make sure to remove those two lines when you want to actually build
the&amp;nbsp;package.&lt;/p&gt;</content><category term="packaging"></category><category term="rpm"></category><category term="rpmbuild"></category></entry><entry><title>Getting oVirt up andÂ running</title><link href="https://blog.jasonantman.com/2012/09/getting-ovirt-up-and-running/" rel="alternate"></link><published>2012-09-07T05:00:00-04:00</published><updated>2012-09-07T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-07:/2012/09/getting-ovirt-up-and-running/</id><summary type="html">&lt;p&gt;The bulk of this post was written way back in April 2012. If you&amp;#8217;re just
coming here, and looking to setup oVirt, you should probably &lt;a href="#postscript"&gt;skip down
to the postscript&lt;/a&gt; for an update, and ignore most of the
content here (as it&amp;#8217;s applicable to an older oVirt&amp;nbsp;version â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;The bulk of this post was written way back in April 2012. If you&amp;#8217;re just
coming here, and looking to setup oVirt, you should probably &lt;a href="#postscript"&gt;skip down
to the postscript&lt;/a&gt; for an update, and ignore most of the
content here (as it&amp;#8217;s applicable to an older oVirt&amp;nbsp;version).&lt;/p&gt;
&lt;p&gt;I recently started setting up &lt;a href="http://www.ovirt.org"&gt;oVirt&lt;/a&gt;, the
community version of Red Hat Enterprise Virtualization, at work for some
testing (mainly a &amp;#8220;sandbox&amp;#8221; &lt;span class="caps"&gt;VM&lt;/span&gt; environment, and because
&lt;a href="http://theforeman.org/"&gt;Foreman&lt;/a&gt;
&lt;a href="http://blog.theforeman.org/2012/03/vnc-support-built-in-foreman.html"&gt;supports&lt;/a&gt;
it). To start with, I had two nodes, each with two dual-core Xeon
processors (&lt;span class="caps"&gt;VT&lt;/span&gt;-x capable) with &lt;span class="caps"&gt;20GB&lt;/span&gt; &lt;span class="caps"&gt;RAM&lt;/span&gt;, one with &lt;span class="caps"&gt;600GB&lt;/span&gt; internal storage
and one with &lt;span class="caps"&gt;140GB&lt;/span&gt; internal. While oVirt&amp;#8217;s documentation isn&amp;#8217;t exactly
wonderful, I found a blgo post by Jason Brooks, &lt;a href="http://blog.jebpages.com/archives/how-to-get-up-and-running-with-ovirt/"&gt;How to Get Up and
Running with
oVirt&lt;/a&gt;,
which gives a great walkthrough of getting the oVirt Engine setup on a
machine, and also setting up that same machine as a &lt;span class="caps"&gt;VM&lt;/span&gt; host. As oVirt is
still fairly young, this is all done on Fedora. I performed my
installation via Cobbler, though I&amp;#8217;m afraid to admit it was an entirely
manual, interactive&amp;nbsp;install.&lt;/p&gt;
&lt;p&gt;I did run into a few bumps during Jason&amp;#8217;s tutorial. In step 15, adding
the data &lt;span class="caps"&gt;NFS&lt;/span&gt; export as a Storage Domain, I was unable to add the &lt;span class="caps"&gt;NFS&lt;/span&gt;
export. I found the &lt;a href="http://www.ovirt.org/wiki/Troubleshooting_NFS_Storage_Issues"&gt;Troubleshooting &lt;span class="caps"&gt;NFS&lt;/span&gt; Storage Issues page on the
oVirt
wiki&lt;/a&gt;,
ensured that SELinux was disabled and that the export had the correct
permissions, confirmed that &lt;code&gt;/etc/nfsmount.conf&lt;/code&gt; specified &lt;code&gt;Nfsvers=3&lt;/code&gt;,
rebooted, and then ran the &lt;code&gt;nfs-check.py&lt;/code&gt; script. At this point, I was
able to add the other storage domains in steps 15 and&amp;nbsp;16.&lt;/p&gt;
&lt;p&gt;My second issue was that even on Fedora 16, I simply can&amp;#8217;t get the spice
client (through the &lt;code&gt;spice-xpi&lt;/code&gt; browser plugin) to work. As far as I can
tell from the logs, it looks like &lt;code&gt;spicec&lt;/code&gt; is being sent a value of
&amp;#8220;None&amp;#8221; for the secured port parameter, instead of the correct port
number. I assume this is a bug in oVirt, but I&amp;#8217;ll revisit this problem
when I have time. In the mean time, I changed my test &lt;span class="caps"&gt;VM&lt;/span&gt; to use &lt;span class="caps"&gt;VNC&lt;/span&gt;,
which is launched by installing the &lt;code&gt;ovirt-engine-cli&lt;/code&gt; package (see
below) on your client computer, connecting to the oVirt &lt;span class="caps"&gt;API&lt;/span&gt; with&amp;nbsp;ovirt-shell:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;ovirt-shell --connect --url=https://ovirt-engine.example.com:8443/api --user=admin@internal --password adminpassword&lt;/code&gt;&lt;br&gt;
and then running &lt;code&gt;console vm_name&lt;/code&gt;. This launches the &lt;code&gt;vncviewer&lt;/code&gt;
binary, which is in the &amp;#8220;tigervnc&amp;#8221; package on&amp;nbsp;Fedora.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing&amp;nbsp;ovirt-engine-cli&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To run &lt;code&gt;ovirt-shell&lt;/code&gt; on your workstation (Fedora 16, of course&amp;#8230;)
you&amp;#8217;ll need the ovirt-engine-cli and ovirt-engine-sdk packages. I
manually downloaded them from
&lt;a href="http://www.ovirt.org/releases/nightly/fedora/16/"&gt;http://www.ovirt.org/releases/nightly/fedora/16/&lt;/a&gt;,
versions 2.1.3 and 1.6.2, respecitively. The &lt;span class="caps"&gt;SDK&lt;/span&gt; and &lt;span class="caps"&gt;CLI&lt;/span&gt; are python
based, so there are a few Python dependencies, all of which were
automatically solved by yum. I know there are &lt;span class="caps"&gt;SDK&lt;/span&gt; and &lt;span class="caps"&gt;CLI&lt;/span&gt; packages out
there for other distros, but haven&amp;#8217;t tried them&amp;nbsp;yet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing Linux&amp;nbsp;Guests&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Installing a CentOS 6.2 x86_64 guest was relatively straightforward,
and my usual kickstart infrastructure worked fine. The only catch was
the VirtIO storage interface, which shows up as &lt;code&gt;/dev/vdx&lt;/code&gt; instead of
&lt;code&gt;/dev/sdx&lt;/code&gt;; I just added another kickstart metadata option in Cobbler
that allows me to use &lt;code&gt;sdx&lt;/code&gt; by specifying &amp;#8220;virtual=yes&amp;#8221; (for our VMWare
hosts), or &lt;code&gt;vdx&lt;/code&gt; by specifying&amp;nbsp;&amp;#8220;virtual=ovirt&amp;#8221;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setting up&amp;nbsp;Authentication&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As installed, oVirt only has one user, &amp;#8220;admin@internal&amp;#8221;; it requires an
external directory service for user authentication. Currently, it
supports &lt;span class="caps"&gt;IPA&lt;/span&gt;, Red Hat&amp;#8217;s Enterprise Identity Management tool (combines
&lt;span class="caps"&gt;RHEL&lt;/span&gt;, oVirt Directory Server, Kerberos and &lt;span class="caps"&gt;NTP&lt;/span&gt;; perhaps
&lt;a href="http://freeipa.org"&gt;FreeIPA&lt;/a&gt; would work as well?) and Microsoft Active
Directory. As much as I&amp;#8217;d like to give &lt;span class="caps"&gt;IPA&lt;/span&gt; or FreeIPA a try, my company
already has an &lt;span class="caps"&gt;AD&lt;/span&gt; infrastructure, so I opted to go that route.
Documentation is given in the &lt;a href="http://www.ovirt.org/wiki/File:OVirt-3.0-Installation_Guide-en-US.pdf"&gt;oVirt 3.0 Installation
Guide&lt;/a&gt;,
starting on page 96. Unfortunately, I was never about to get &lt;span class="caps"&gt;AD&lt;/span&gt; auth
working correctly, so I just worked with the one admin&amp;nbsp;user.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adding a&amp;nbsp;Node&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The biggest issue I had was adding the second node to oVirt. I attempted
to use the &lt;span class="caps"&gt;DVD&lt;/span&gt; Import feature of Cobbler on the &lt;a href="http://www.ovirt.org/get-ovirt/"&gt;oVirt Node Image
&lt;span class="caps"&gt;ISO&lt;/span&gt;&lt;/a&gt;, but that failed. I then found the
image&amp;#8217;s &lt;code&gt;LiveOS/livecd-iso-to-pxeboot&lt;/code&gt; script and used that to make a
kernerl and initrd, and kernel parameters, for Cobbler. &lt;span class="caps"&gt;PXE&lt;/span&gt; works&amp;nbsp;fine.&lt;/p&gt;
&lt;p&gt;&lt;a name="postscript"&gt;&lt;/a&gt;&lt;strong&gt;Postscript:&lt;/strong&gt; I ended up blowing away my
oVirt installation in favor of testing other things. At some point, the
engine install got corrupted in a way that I just couldn&amp;#8217;t fix; even
though I spent all day one Saturday working on it, it took more time
than I could allocate to a personal project. So this post is really
semi-complete at best. However, there is some good news. Jason Brooks&amp;#8217;
original post, &lt;a href="http://blog.jebpages.com/archives/how-to-get-up-and-running-with-ovirt/"&gt;How to Get Up and Running with
oVirt&lt;/a&gt;,
was written for oVirt 3.0, as was this post. Since then, there has been
a new release, &lt;a href="http://wiki.ovirt.org/wiki/OVirt_3.1_release_notes"&gt;oVirt
3.1&lt;/a&gt;, which
apparently has a better &lt;span class="caps"&gt;UI&lt;/span&gt; and a better installer. Jason Brooks has a
new post, &lt;a href="http://blog.jebpages.com/archives/up-and-running-with-ovirt-3-1-edition/"&gt;Up and Running with oVirt, 3.1
Edition&lt;/a&gt;,
which covers installation and configuration of both an all-in-one
machine and a separate node. If you&amp;#8217;re looking to try oVirt, I&amp;#8217;d
recommend you give that a shot. Unfortunately (and strangely, given that
this is supposed to be the &amp;#8220;upstream&amp;#8221; of RedHat&amp;#8217;s proprietary &lt;span class="caps"&gt;RHEV&lt;/span&gt;) it&amp;#8217;s
still all based on&amp;nbsp;Fedora.&lt;/p&gt;</content><category term="fedora"></category><category term="kvm"></category><category term="ovirt"></category><category term="qemu"></category><category term="redhat"></category><category term="rhev"></category><category term="spice"></category><category term="virtualization"></category></entry><entry><title>Project - Storing and Analyzing Apache httpd Logs from ManyÂ Hosts</title><link href="https://blog.jasonantman.com/2012/09/project-storing-and-analyzing-apache-httpd-logs-from-many-hosts/" rel="alternate"></link><published>2012-09-06T05:00:00-04:00</published><updated>2012-09-06T05:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-06:/2012/09/project-storing-and-analyzing-apache-httpd-logs-from-many-hosts/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve recently started casual work on a side-project to collect, store,
and analyze apache logs from a bunch of servers - for the initial
implementation, I&amp;#8217;m looking to handle about 15M access_log lines per
day (that works out to 173 lines/second assuming an even distribution,
which there certainly â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve recently started casual work on a side-project to collect, store,
and analyze apache logs from a bunch of servers - for the initial
implementation, I&amp;#8217;m looking to handle about 15M access_log lines per
day (that works out to 173 lines/second assuming an even distribution,
which there certainly isn&amp;#8217;t). Here is a selection of links that I&amp;#8217;ve
been using for ideas and inspiration, both for the technical side (data
collection, transport, storage and analysis) and&amp;nbsp;visualization:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://oss.oetiker.ch/rrdtool/gallery/index.en.html"&gt;RRDtool - RRDtool
    Gallery&lt;/a&gt; - I&amp;#8217;m
    starting a graphing/log analysis project, and looked here for some
    inspiration for my proof-of-concept&amp;nbsp;code&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aplawrence.com/Girish/gv-rrdtool.html"&gt;Creating pretty graphs with
    &lt;span class="caps"&gt;RRDTOOL&lt;/span&gt;&lt;/a&gt; from &lt;a href=""&gt;Girish
    Venkatachalam&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;There&amp;#8217;s some good information on RRDtool&amp;#8217;s &amp;#8220;Abberant Behavior
    Detection&amp;#8221; (Holt-Winters prediction, deviation and failure
    detection) on the
    &lt;a href="http://oss.oetiker.ch/rrdtool/doc/rrdtool.en.html"&gt;rrdtool&lt;/a&gt;,
    &lt;a href="http://oss.oetiker.ch/rrdtool/doc/rrdgraph_examples.en.html"&gt;rrdgraph_examples&lt;/a&gt;
    and &lt;a href="http://oss.oetiker.ch/rrdtool/doc/rrdcreate.en.html"&gt;rrdcreate&lt;/a&gt;
    documentation pages, but unfortunately no anchors to link directly&amp;nbsp;to.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://square.github.com/cube/"&gt;Cube&lt;/a&gt; - &amp;#8220;Cube is a system for
    collecting timestamped events and deriving metrics. By collecting
    events rather than metrics, Cube lets you compute aggregate
    statistics post hoc. It also enables richer analysis, such as
    quantiles and histograms of arbitrary event sets. Cube is built on
    MongoDB and available under the Apache License on&amp;nbsp;GitHub.&amp;#8221;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://square.github.com/cubism/"&gt;Cubism.js&lt;/a&gt; - &amp;#8220;Cubism.js is a D3
    plugin for visualizing time series. Use Cubism to construct better
    realtime dashboards, pulling data from Graphite, Cube and other
    sources. Cubism is available under the Apache License on GitHub.&amp;#8221;
    The demo on that page looks pretty&amp;nbsp;cool.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.highcharts.com/demo/"&gt;Highcharts Demo Gallery&lt;/a&gt; - &lt;span class="caps"&gt;JS&lt;/span&gt;
    chart/graph library. It requires a paid license for commercial use
    (though it&amp;#8217;s a bit unclear to me whether an internal ops dashboard
    would fall under this license provision) so I probably wouldn&amp;#8217;t go
    with this one. They have some cool charts, including a &lt;a href="http://www.highcharts.com/demo/dynamic-update/gray"&gt;dynamic line
    chart updating every
    second&lt;/a&gt;, a
    &lt;a href="http://www.highcharts.com/demo/scatter/gray"&gt;scatter plot&lt;/a&gt; and a
    nice &lt;a href="http://www.highcharts.com/demo/line-time-series/gray"&gt;zoomable time-series
    graph&lt;/a&gt;, though
    &lt;span class="caps"&gt;IMHO&lt;/span&gt; it&amp;#8217;s not as nice as the Google Chart Tools (formerly Google
    Visualization) &lt;a href="https://developers.google.com/chart/interactive/docs/gallery/annotatedtimeline"&gt;annotated
    timeline&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://forums.cacti.net/viewtopic.php?t=29963"&gt;[ &lt;span class="caps"&gt;HOWTO&lt;/span&gt; ] Graphing Holt-Winters Predictive
    Analysis&lt;/a&gt; - Cacti&amp;nbsp;forums&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dygraphs.com/"&gt;dygraphs&lt;/a&gt; - an impressive permissive-license
    &lt;span class="caps"&gt;JS&lt;/span&gt; chart library dedicated to visualizing dense time-series data.
    Developed by Google and now used by them (Google Correlate, Google
    Latitude) as well as &lt;span class="caps"&gt;NASA&lt;/span&gt;, 10gen and others. There are some very
    cool demos on that main page, and also on the &lt;a href="http://dygraphs.com/tests/"&gt;tests
    page&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.planetdevops.net/?p=12289"&gt;Graphite, JMXTrans, Ganglia, Logster, Collectd, say what ? Â« Planet&amp;nbsp;DevOps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://auxesis.github.com/visage/"&gt;Visage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kgorman/mongo_graph"&gt;kgorman/mongo_graph&lt;/a&gt; - a
    tool to pull data from MongoDB and put it in &lt;span class="caps"&gt;RRD&lt;/span&gt;&amp;nbsp;files&lt;/li&gt;
&lt;li&gt;&lt;a href="http://web.taranis.org/drraw/"&gt;drraw&lt;/a&gt; - a perl-based graphing
    frontend (web &lt;span class="caps"&gt;UI&lt;/span&gt;) for&amp;nbsp;RRDtool&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/etsy/logster"&gt;etsy/logster Â· GitHub&lt;/a&gt; - Etsy&amp;#8217;s
    Python tool to maintain a pointer on a log file, and parse at a
    regular rate feeding the data into a tool like Graphite or&amp;nbsp;Ganglia.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cebailey59/charcoal"&gt;cebailey59/charcoal&lt;/a&gt; - a
    Sinatra app that allows creation of dashboards from Graphite,
    collectd, or any other service that creates images from &lt;span class="caps"&gt;URL&lt;/span&gt;&amp;nbsp;calls.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/etsy/dashboard"&gt;etsy/dashboard&lt;/a&gt; - some examples
    of how Etsy builds monitoring&amp;nbsp;dashboards.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.devco.net/archives/2011/10/08/gdash-graphite-dashboard.php"&gt;GDash â Graphite Dashboard |
    &lt;span class="caps"&gt;R.I.&lt;/span&gt;Pienaar&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;a Sinatra dashboard app for Graphite, using Twitter bootstrap for&amp;nbsp;visualization.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/paperlesspost/graphiti"&gt;paperlesspost/graphiti&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;a Ruby and JavaScript front-end for&amp;nbsp;Graphite.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://graphite.wikidot.com/screen-shots"&gt;Graphite Screenshots&lt;/a&gt; -
    just two, but they get the idea across pretty&amp;nbsp;well.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://graylog2.org/"&gt;Graylog2&lt;/a&gt; - a centralized log management
    application with a powerful web interface. Stores logs in
    &lt;a href="http://www.elasticsearch.org/"&gt;ElasticSearch&lt;/a&gt; (which is built on
    Lucene, a Java-based index and search server) and statistics/graphs
    in MongoDB. It does analytics, alerting, monitoring/graphing and
    searching all through a web interface, and accepts log data via
    syslog, &lt;span class="caps"&gt;AMQP&lt;/span&gt; and &lt;span class="caps"&gt;GELF&lt;/span&gt; (its own log format). Java server and Ruby on
    Rails web&amp;nbsp;&lt;span class="caps"&gt;UI&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://logstash.net/"&gt;Logstash&lt;/a&gt; - another centralized log project
    that stores and indexes logs, with search via a web &lt;span class="caps"&gt;UI&lt;/span&gt;. &amp;#8220;Ship any
    event to anywhere over any protocol.&amp;#8221; Takes many inputs including
    files, syslog, &lt;span class="caps"&gt;AMQP&lt;/span&gt;, Flume, &lt;span class="caps"&gt;STOMP&lt;/span&gt;, &lt;span class="caps"&gt;HTTP&lt;/span&gt; and even twitter, performs a
    number of filters including timestamp checks, parsing, dropping,
    joins, etc, and then sends logs back on an output including &lt;span class="caps"&gt;AMQP&lt;/span&gt;,
    Graylog2 &lt;span class="caps"&gt;GELF&lt;/span&gt;, &lt;span class="caps"&gt;STOMP&lt;/span&gt;, MongoDB, ElasticSearch, syslog, WebSockets and
    to Nagios. One particularly cool feature is its &amp;#8220;file&amp;#8221; input, which
    continuously tails a file and claims to be log rotation safe. Just&amp;nbsp;cool.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.google.com/present/view?id=dcmwwd94_16dfdxgpw8"&gt;jordansissel&amp;#8217;s Logstash intro
    slides&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rashidkpc.github.com/Kibana/"&gt;Kibana&lt;/a&gt; - an alternative
    interface for Logstash and
    &lt;a href="http://www.elasticsearch.org/"&gt;ElasticSearch&lt;/a&gt; that allows
    searching, graphing and analysis of log data stored in&amp;nbsp;Logstash.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pivotallabs.com/talks/139-metrics-metrics-everywhere"&gt;Pivotal Labs: Talks - Metrics Metrics
    Everywhere&lt;/a&gt;
    (Coda&amp;nbsp;Hale)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aq.iriscouch.com/swinger/_design/swinger/index.html#/preso/aq-mdd/display/1"&gt;PaperlessPost - @quirkey&amp;#8217;s talk on
    metrics&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;very good high level stuff, but slides&amp;nbsp;only&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/paperlesspost/graphiti"&gt;paperlesspost/graphiti&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;graphiti, a &lt;span class="caps"&gt;JS&lt;/span&gt;/Ruby frontend for Graphite that does graphs,
dashboards, and point-in-time snapshots of graphs. Lots of&amp;nbsp;functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://redis.io/"&gt;Redis&lt;/a&gt; - a distributed key/value store that&amp;#8217;s
    really popular with the cool kids. &lt;a href="http://nosql.mypopescu.com/post/8652869828/another-redis-use-case-centralized-logging"&gt;Another Redis Use Case:
    Centralized Logging â¢&amp;nbsp;myNoSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cebailey59/charcoal"&gt;Charcoal&lt;/a&gt; - a
    &lt;a href="http://www.sinatrarb.com/"&gt;Sinatra&lt;/a&gt; (Ruby) dashboard app (ready for
    use on &lt;a href="http://www.heroku.com/"&gt;Heroku&lt;/a&gt; but usable anywhere).
    Graphite-oriented but will work with any tool that generates images
    from&amp;nbsp;URLs.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/etsy/logster"&gt;etsy/logster&lt;/a&gt; - etsy&amp;#8217;s Logster
    tool, which keeps a tail on log files, parses them, and ships
    metrics to Graphite or&amp;nbsp;Ganglia.&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>RVM and Ruby 1.9 to test logstash grok patterns onÂ Fedora/CentOS</title><link href="https://blog.jasonantman.com/2012/09/rvm-and-ruby-1-9-to-test-logstash-grok-patterns-on-fedoracentos/" rel="alternate"></link><published>2012-09-03T08:37:00-04:00</published><updated>2012-09-03T08:37:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-09-03:/2012/09/rvm-and-ruby-1-9-to-test-logstash-grok-patterns-on-fedoracentos/</id><summary type="html">&lt;p&gt;I&amp;#8217;ve been working on a personal project with
&lt;a href="http://logstash.net/"&gt;Logstash&lt;/a&gt; lately, and it relies relatively
heavily on &lt;a href="https://github.com/jordansissel/grok"&gt;grok&lt;/a&gt; filters for
matching text and extracting matched parts. Today, I&amp;#8217;ve been parsing
syslog from &lt;a href="http://puppetlabs.com/puppet/puppet-open-source/"&gt;Puppet&lt;/a&gt;
to extract various metrics and timings, which will then be passed on
from Logstash to &lt;a href="https://github.com/etsy/statsd"&gt;Etsy â¦&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been working on a personal project with
&lt;a href="http://logstash.net/"&gt;Logstash&lt;/a&gt; lately, and it relies relatively
heavily on &lt;a href="https://github.com/jordansissel/grok"&gt;grok&lt;/a&gt; filters for
matching text and extracting matched parts. Today, I&amp;#8217;ve been parsing
syslog from &lt;a href="http://puppetlabs.com/puppet/puppet-open-source/"&gt;Puppet&lt;/a&gt;
to extract various metrics and timings, which will then be passed on
from Logstash to &lt;a href="https://github.com/etsy/statsd"&gt;Etsy&amp;#8217;s statsd&lt;/a&gt; and
then to &lt;a href="http://graphite.wikidot.com/"&gt;graphite&lt;/a&gt; for display.
Unfortunately, a few of my patterns are showing the &amp;#8220;_grokparsefailure&amp;#8221;
tag and I just can&amp;#8217;t seem to find the&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;The logstash wiki provides a page on &lt;a href="https://github.com/logstash/logstash/wiki/Testing-your-Grok-patterns-(--logstash-1.1.0-and-above-)"&gt;Testing your Grok
patterns&lt;/a&gt;,
as does Sean Laurent on his blog: &lt;a href="http://blog.bealetech.com/content/testing-logstash-grok-filters"&gt;Testing Logstash grok
filters&lt;/a&gt;.
Unfortunately, I work in a CentOS/&lt;span class="caps"&gt;RHEL&lt;/span&gt; shop, and we&amp;#8217;re decidedly &lt;em&gt;not&lt;/em&gt; a
Ruby shop. Our Logstash install is using the monolithic/standalone Java
&lt;span class="caps"&gt;JAR&lt;/span&gt;. We run Puppet, which is currently under ruby 1.8.7, and the
&lt;a href="http://rubygems.org/gems/jls-grok"&gt;jls-grok rubygem&lt;/a&gt; requires ruby 1.9.
There&amp;#8217;s no way I&amp;#8217;d feel safe installing 1.9 on any of our machines, as
they all run (and require) Puppet. So, I found out about
&lt;a href="https://rvm.io/"&gt;&lt;span class="caps"&gt;RVM&lt;/span&gt;&lt;/a&gt;, the Ruby Version Manager, which allows you to
run and switch between multiple ruby versions, and all of it is
installed on a per-user basis. So, I created a new user on my Fedora 16
desktop called &amp;#8220;rvmtest&amp;#8221; and went about the process of setting up what&amp;#8217;s
needed to test grok patterns in the user&amp;#8217;s local environment. I imagine
this would work similarly under CentOS or &lt;span class="caps"&gt;RHEL&lt;/span&gt;, but the following is
only tested on Fedora 16. If you have any issues, you should probably
refer back to the &lt;span class="caps"&gt;RVM&lt;/span&gt;&amp;nbsp;documentation.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create the isolated user, just to be extra careful. Login as that&amp;nbsp;user.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As per &lt;a href="https://rvm.io/rvm/install/"&gt;Installing &lt;span class="caps"&gt;RVM&lt;/span&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl https://raw.github.com/wayneeseguin/rvm/master/binscripts/rvm-installer | bash -s stable
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;edit your &lt;code&gt;~/.bashrc&lt;/code&gt; and&amp;nbsp;add:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[[&lt;/span&gt; -s &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;HOME&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;/.rvm/scripts/rvm&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; . &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;HOME&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;/.rvm/scripts/rvm&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt; -r &lt;span class="nv"&gt;$rvm_path&lt;/span&gt;/scripts/completion &lt;span class="o"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; . &lt;span class="nv"&gt;$rvm_path&lt;/span&gt;/scripts/completion
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first line sets up &lt;span class="caps"&gt;RVM&lt;/span&gt; for your sessions, and the second sources
in tab-completion for the &lt;code&gt;rvm&lt;/code&gt; command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;source .bashrc&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;If you&amp;#8217;re interested, you can see a list of all known rubies with:
    &lt;code&gt;rvm list known&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install Ruby (&lt;span class="caps"&gt;MRI&lt;/span&gt;) 1.9.2: &lt;code&gt;rvm install 1.9.2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;switch&amp;#8221; to that ruby: &lt;code&gt;rvm use 1.9.2&lt;/code&gt; and confirm it by running
    &lt;code&gt;ruby -v&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Make it the default ruby for us: &lt;code&gt;rvm use 1.9.2 --default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create a &amp;#8220;gemset&amp;#8221; (set of rubygems for our environment):
    &lt;code&gt;rvm gemset create groktest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use it, and set it as default: &lt;code&gt;rvm use 1.9.2@groktest --default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;for grok testing, &lt;code&gt;gem install jls-grok&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;check that it&amp;#8217;s there: &lt;code&gt;gem list&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Download Logstash&amp;#8217;s default grok patterns &lt;a href="https://raw.github.com/logstash/logstash/master/patterns/grok-patterns"&gt;from&amp;nbsp;github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;You should now be ready to test some grok&amp;nbsp;patterns.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While the two howto&amp;#8217;s linked above use &lt;code&gt;irb&lt;/code&gt; to interactively test the
patterns, I prefer something easier to move to production, more
reliable, and more repeatable. The following quick little ruby script
takes test to match against on &lt;span class="caps"&gt;STDIN&lt;/span&gt; (log files, messages, etc.) and
prints the matches to &lt;span class="caps"&gt;STDOUT&lt;/span&gt;. The script is based on
&lt;a href="https://github.com/jordansissel/ruby-grok/blob/master/examples/test.rb"&gt;test.rb&lt;/a&gt;
from &lt;a href="https://github.com/jordansissel/ruby-grok"&gt;jordansissel&amp;#8217;s
ruby-grok&lt;/a&gt;. Note one
important thing here, I couldn&amp;#8217;t get the shebang (&lt;code&gt;#!&lt;/code&gt;) to work with
anything other than the explicit path to my &lt;span class="caps"&gt;RVM&lt;/span&gt; ruby install
(&lt;code&gt;which ruby&lt;/code&gt;) so you&amp;#8217;ll need to manually update this&amp;nbsp;yourself.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!.rvm/rubies/ruby-1.9.2-320bin/ruby&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;rubygems&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;grok-pure&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;pp&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;grok&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;
&lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_patterns_from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;grok-patterns&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;your_grok_pattern_here&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;PATTERN&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;gets&lt;/span&gt;
  &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;IN&lt;/span&gt;: &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grok&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;
    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;pp&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;captures&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;No Match.&amp;quot;&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here&amp;#8217;s an example using a pattern to capture information from custom
syslog messages triggered by updating puppet configs. Here&amp;#8217;s some sample&amp;nbsp;messages:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;[rvmtest@jantmanwork ~]$&lt;/span&gt; cat puppet.log
&lt;span class="go"&gt;Updated 2 files in puppet svn (environment prod) to revision 754&lt;/span&gt;
&lt;span class="go"&gt;Updated 3 files in puppet svn (environment prod) to revision 756&lt;/span&gt;
&lt;span class="go"&gt;Updated 1 files in puppet svn (environment prod) to revision 757&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the pattern that I&amp;nbsp;use:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Updated%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files}%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}files%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}in%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}puppet%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}svn%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}\(environment%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env}\)%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}to%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}revision%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the output of the&amp;nbsp;script:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;[rvmtest@jantmanwork ~]$&lt;/span&gt; cat puppet.log &lt;span class="p"&gt;|&lt;/span&gt; ./puppet-update-test.rb 
&lt;span class="go"&gt;&lt;span class="caps"&gt;PATTERN&lt;/span&gt;: Updated%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files}%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}files%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}in%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}puppet%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}svn%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}\(environment%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env}\)%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}to%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}revision%{&lt;span class="caps"&gt;SPACE&lt;/span&gt;}%{&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 2 files in puppet svn (environment prod) to revision 754&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;2&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;2&amp;quot;, &amp;quot;754&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;754&amp;quot;]}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 3 files in puppet svn (environment prod) to revision 756&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;3&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;3&amp;quot;, &amp;quot;756&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;756&amp;quot;]}&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;IN&lt;/span&gt;: Updated 1 files in puppet svn (environment prod) to revision 757&lt;/span&gt;
&lt;span class="go"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt;:&lt;/span&gt;
&lt;span class="go"&gt;{&amp;quot;&lt;span class="caps"&gt;SPACE&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;, &amp;quot; &amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_num_files&amp;quot;=&amp;gt;[&amp;quot;1&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;BASE10NUM&lt;/span&gt;&amp;quot;=&amp;gt;[&amp;quot;1&amp;quot;, &amp;quot;757&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;WORD&lt;/span&gt;:puppet_svn_env&amp;quot;=&amp;gt;[&amp;quot;prod&amp;quot;],&lt;/span&gt;
&lt;span class="go"&gt; &amp;quot;&lt;span class="caps"&gt;NUMBER&lt;/span&gt;:puppet_svn_revision&amp;quot;=&amp;gt;[&amp;quot;757&amp;quot;]}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hopefully this will make the process a bit simpler for someone&amp;nbsp;else&amp;#8230;&lt;/p&gt;</content><category term="grok"></category><category term="grokparsefailure"></category><category term="jruby"></category><category term="kibana"></category><category term="logstash"></category><category term="ruby"></category><category term="rvm"></category></entry><entry><title>Puppet facter facts for syslog daemon type and version, symantecÂ netbackup</title><link href="https://blog.jasonantman.com/2012/08/puppet-facter-facts-for-syslog-daemon-type-and-version-symantec-netbackup/" rel="alternate"></link><published>2012-08-25T11:33:00-04:00</published><updated>2012-08-25T11:33:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-25:/2012/08/puppet-facter-facts-for-syslog-daemon-type-and-version-symantec-netbackup/</id><summary type="html">&lt;p&gt;I have a few more custom facts that I&amp;#8217;ve added to my
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;puppet-facter-facts&lt;/a&gt;
github&amp;nbsp;repository:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_bin.rb"&gt;syslog_bin&lt;/a&gt;,
    &lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_type.rb"&gt;syslog_type&lt;/a&gt;,
    and
    &lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_version.rb"&gt;syslog_version&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;tell the absolute path to the &lt;em&gt;running&lt;/em&gt; syslog binary, its short
name (basename), and its version as a string. Currently only know
about &lt;code&gt;/sbin/syslogd&lt;/code&gt; and &lt;code&gt;/sbin/rsyslogd&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/has_netbackup.rb"&gt;has_netbackup&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;tests â¦&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;I have a few more custom facts that I&amp;#8217;ve added to my
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;puppet-facter-facts&lt;/a&gt;
github&amp;nbsp;repository:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_bin.rb"&gt;syslog_bin&lt;/a&gt;,
    &lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_type.rb"&gt;syslog_type&lt;/a&gt;,
    and
    &lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/syslog_version.rb"&gt;syslog_version&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;tell the absolute path to the &lt;em&gt;running&lt;/em&gt; syslog binary, its short
name (basename), and its version as a string. Currently only know
about &lt;code&gt;/sbin/syslogd&lt;/code&gt; and &lt;code&gt;/sbin/rsyslogd&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jantman/puppet-facter-facts/blob/master/has_netbackup.rb"&gt;has_netbackup&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;tests for presence of the &lt;code&gt;/usr/openv/netbackup/bin&lt;/code&gt; directory,
created by installation of &lt;a href="http://www.symantec.com/netbackup"&gt;Symantec
Netbackup&lt;/a&gt;. Useful for making
generation of include/exclude files conditional on having NetBackup&amp;nbsp;installed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hopefully some of these will be of use to someone else as&amp;nbsp;well.&lt;/p&gt;</content><category term="facter"></category><category term="nbu"></category><category term="netbackup"></category><category term="puppet"></category><category term="rsyslog"></category><category term="syslog"></category></entry><entry><title>Puppet facter fact for all applied classes, returned as a CSVÂ list</title><link href="https://blog.jasonantman.com/2012/08/puppet-facter-fact-for-all-applied-classes-returned-as-a-csv-list/" rel="alternate"></link><published>2012-08-22T07:05:00-04:00</published><updated>2012-08-22T07:05:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-22:/2012/08/puppet-facter-fact-for-all-applied-classes-returned-as-a-csv-list/</id><summary type="html">&lt;p&gt;I&amp;#8217;m unfortunatey stuck, at least for the time being, using flat-file
manifests to configure my puppet nodes. Without an &lt;span class="caps"&gt;ENC&lt;/span&gt;, it&amp;#8217;s pretty
difficult to get a good ovewview of what classes are used on each node,
and what nodes use a given class. I know I could write â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;m unfortunatey stuck, at least for the time being, using flat-file
manifests to configure my puppet nodes. Without an &lt;span class="caps"&gt;ENC&lt;/span&gt;, it&amp;#8217;s pretty
difficult to get a good ovewview of what classes are used on each node,
and what nodes use a given class. I know I could write up a simple web
tool to do this (unfortunately, given my limited Ruby knowledge, it
would have to be in &lt;span class="caps"&gt;PHP&lt;/span&gt; or Perl, not a real modification to Dashboard in
Ruby). But where to get the data&amp;nbsp;from?&lt;/p&gt;
&lt;p&gt;After some research, I found a &lt;a href="http://sjoeboo.github.com/blog/2012/07/31/updated-puppet-facts-for-puppet-classes/"&gt;puppet fact for puppet
classes&lt;/a&gt;
on &lt;a href="http://sjoeboo.github.com/"&gt;Matthew Nicholson&amp;#8217;s Coffee &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; Beer blog&lt;/a&gt;.
It parses &lt;code&gt;/var/lib/puppet/classes.txt&lt;/code&gt; and returns the list of classes
found as a &lt;span class="caps"&gt;JSON&lt;/span&gt; array. Great base, but I wanted something easier, that
would be more easily parsed from its direct storage in MySQL. My
modification to his code is onlty a few characters; I dropped out the
&lt;span class="caps"&gt;JSON&lt;/span&gt; require, and return the classes as a &lt;span class="caps"&gt;CSV&lt;/span&gt; list. This lets me to easy
&lt;code&gt;LIKE '%,classname,%'&lt;/code&gt; SELECTs in MySQL, and also gives me the fact
value stored in the puppet &lt;span class="caps"&gt;DB&lt;/span&gt;, so I can build a separate tool around
that data. Thanks,&amp;nbsp;Matt.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# facter fact for puppet classes on node, pulled from /var/lib/puppet/classes.txt&lt;/span&gt;
&lt;span class="c1"&gt;# from &lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;facter&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;begin&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hostname&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt;
&lt;span class="k"&gt;rescue&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loadfacts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="n"&gt;hostname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hostname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fqdn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fqdn&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;classes_txt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/var/lib/puppet/classes.txt&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;classes_txt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;classes_txt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;Array&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readlines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;each&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;chomp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_s&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;push&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;settings&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;hostname&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;puppet_classes_csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                &lt;span class="n"&gt;setcode&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                        &lt;span class="n"&gt;classes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All of my facts are now available in a GitHub repository:
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;https://github.com/jantman/puppet-facter-facts&lt;/a&gt;.&lt;/p&gt;</content><category term="classes"></category><category term="csv"></category><category term="fact"></category><category term="facter"></category><category term="node"></category><category term="puppet"></category></entry><entry><title>Puppet facter fact for last applied configurationÂ version</title><link href="https://blog.jasonantman.com/2012/08/puppet-facter-fact-for-last-applied-configuration-version/" rel="alternate"></link><published>2012-08-21T08:55:00-04:00</published><updated>2012-08-21T08:55:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-21:/2012/08/puppet-facter-fact-for-last-applied-configuration-version/</id><summary type="html">&lt;p&gt;For anyone else who sets the Puppet &lt;code&gt;config_version&lt;/code&gt; paramater to return
the current &lt;span class="caps"&gt;SVN&lt;/span&gt; or Git version of your configuration, here&amp;#8217;s a fact that
grabs that version (by parsing the cached &lt;span class="caps"&gt;YAML&lt;/span&gt; catalog) and sets it as a
fact called &amp;#8220;catalog_config_version&amp;#8221;. It can then be used for
sanity-checking your â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;For anyone else who sets the Puppet &lt;code&gt;config_version&lt;/code&gt; paramater to return
the current &lt;span class="caps"&gt;SVN&lt;/span&gt; or Git version of your configuration, here&amp;#8217;s a fact that
grabs that version (by parsing the cached &lt;span class="caps"&gt;YAML&lt;/span&gt; catalog) and sets it as a
fact called &amp;#8220;catalog_config_version&amp;#8221;. It can then be used for
sanity-checking your nodes, looking up via the Inventory Service, or you
can display it in the Dashboard using my patch: &lt;a href="http://blog.jasonantman.com/2012/08/patch-to-puppet-dashboard-1-2-10-to-show-arbitrary-facts-in-the-main-node-table/"&gt;Patch to Puppet
Dashboard 1.2.10 to show arbitrary facts in the main node
table&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# facter fact for last applied config version, skeleton from /var/lib/puppet/client_yaml/catalog/fqdn.yaml&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;puppet&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;yaml&amp;#39;&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;facter&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;localconfig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;&lt;span class="caps"&gt;ARGV&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="no"&gt;Puppet&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;:clientyamldir&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/catalog/&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt; &lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.yaml&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;unless&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exist?&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;localconfig&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;puts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Can&amp;#39;t find &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt; &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fqdn&lt;/span&gt; &lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.yaml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;lc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;File&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;localconfig&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;begin&lt;/span&gt;
  &lt;span class="n"&gt;pup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Marshal&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;TypeError&lt;/span&gt;
  &lt;span class="n"&gt;pup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;&lt;span class="caps"&gt;YAML&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;rescue&lt;/span&gt; &lt;span class="no"&gt;Exception&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
  &lt;span class="k"&gt;raise&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;pup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="no"&gt;Puppet&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Resource&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="no"&gt;Catalog&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;catalog_config_version&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                &lt;span class="n"&gt;setcode&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                        &lt;span class="n"&gt;pup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;
                &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
        &lt;span class="no"&gt;Facter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;catalog_config_version&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                &lt;span class="n"&gt;setcode&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
                        &lt;span class="s2"&gt;&amp;quot;unknown&amp;quot;&lt;/span&gt;
                &lt;span class="k"&gt;end&lt;/span&gt;
        &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All of my facts are now available in a GitHub repository:
&lt;a href="https://github.com/jantman/puppet-facter-facts"&gt;https://github.com/jantman/puppet-facter-facts&lt;/a&gt;.&lt;/p&gt;</content><category term="config_version"></category><category term="fact"></category><category term="facter"></category><category term="puppet"></category></entry><entry><title>Setting emacs zone-mode based onÂ path</title><link href="https://blog.jasonantman.com/2012/08/setting-emacs-zone-mode-based-on-path/" rel="alternate"></link><published>2012-08-15T08:00:00-04:00</published><updated>2012-08-15T08:00:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-15:/2012/08/setting-emacs-zone-mode-based-on-path/</id><summary type="html">&lt;p&gt;At work, we do a fair amount of &lt;span class="caps"&gt;DNS&lt;/span&gt; updates. Our zone files are stored
in subversion, and are named according to the domain (with no .zone
extension). It&amp;#8217;s a real pain when updating a few (or a few dozen) zones
in Emacs, since I have to remember to â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;At work, we do a fair amount of &lt;span class="caps"&gt;DNS&lt;/span&gt; updates. Our zone files are stored
in subversion, and are named according to the domain (with no .zone
extension). It&amp;#8217;s a real pain when updating a few (or a few dozen) zones
in Emacs, since I have to remember to &amp;#8220;M-x zone-mode&amp;#8221; so the serial gets
automatically updated. Here&amp;#8217;s a lisp snippet to put in your &lt;code&gt;.emacs&lt;/code&gt;
file that will set zone-mode for all files in any path matching the
regex &lt;code&gt;svn/named/zones-internal&lt;/code&gt;. I deliberately made it a relative path
(or, really, any path containing that) so it would work for all of my
team&amp;#8217;s workstations, no matter where we have the svn repo checked&amp;nbsp;out:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;add-to-list&lt;/span&gt; &lt;span class="ss"&gt;&amp;#39;auto-mode-alist&lt;/span&gt; &lt;span class="o"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;svn/named/zones-internal/&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="nv"&gt;zone-mode&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Many thanks to &lt;code&gt;taylanub&lt;/code&gt; on #emacs on irc.freenode.net for helping
with&amp;nbsp;this.&lt;/p&gt;</content><category term="bind"></category><category term="emacs"></category><category term="lisp"></category><category term="named"></category><category term="zone-mode"></category></entry><entry><title>Patch to Puppet Dashboard 1.2.10 to show arbitrary facts in the main nodeÂ table</title><link href="https://blog.jasonantman.com/2012/08/patch-to-puppet-dashboard-1-2-10-to-show-arbitrary-facts-in-the-main-node-table/" rel="alternate"></link><published>2012-08-11T10:34:00-04:00</published><updated>2012-08-11T10:34:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-08-11:/2012/08/patch-to-puppet-dashboard-1-2-10-to-show-arbitrary-facts-in-the-main-node-table/</id><summary type="html">&lt;p&gt;We use &lt;a href="http://puppetlabs.com/puppet/related-projects/dashboard/"&gt;Puppet
Dashboard&lt;/a&gt; at
work to view the status of our puppet nodes. While it&amp;#8217;s very handy,
there&amp;#8217;s one feature I really wanted: the ability to show the value of
arbitrary puppet facts in the main node table on the home page.
Specifically, the facts we use â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;We use &lt;a href="http://puppetlabs.com/puppet/related-projects/dashboard/"&gt;Puppet
Dashboard&lt;/a&gt; at
work to view the status of our puppet nodes. While it&amp;#8217;s very handy,
there&amp;#8217;s one feature I really wanted: the ability to show the value of
arbitrary puppet facts in the main node table on the home page.
Specifically, the facts we use for environment (we have eng/dev, qa,
prod, and test puppet environments), zone (physical location) and last
applied configuration version. I&amp;#8217;m not terribly experience with Ruby,
but I managed to muddle my way through a working patch to do this, along
with options in the settings file to enable it and configure the facts.
You&amp;#8217;ll need to restart dashboard (or your web server) to change the
facts, of course. The commit is currently &lt;a href="https://github.com/jantman/puppet-dashboard/commit/5364e2b0188d18ae62c355279e58c7ce6d7db654"&gt;available on
github&lt;/a&gt;,
but it doesn&amp;#8217;t strictly follow the &lt;a href="https://github.com/puppetlabs/puppet-dashboard/blob/master/CONTRIBUTING.md"&gt;puppet-dashboard contributing
checklist&lt;/a&gt;
so I may have to redo&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s a&amp;nbsp;screenshot:&lt;/p&gt;
&lt;p&gt;&lt;a href="/GFX/dashboard_after_patch.png"&gt;&lt;img alt="Dashboard screenshot after
patch" src="/GFX/dashboard_after_patch_sm.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And here&amp;#8217;s that the configuration section added to settings.yml looks&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Enables display of arbitrary node facts in &amp;quot;home&amp;quot; page node table, between node name and latest report time&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;enable_home_facts&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;true&lt;/span&gt;

&lt;span class="c1"&gt;# If enable_home_facts is true, the fact names and column headings to display. Simply repeat the following two line pairs&lt;/span&gt;
&lt;span class="c1"&gt;# as needed:&lt;/span&gt;
&lt;span class="c1"&gt;#- name: &amp;#39;factname&amp;#39;&lt;/span&gt;
&lt;span class="c1"&gt;#  heading: &amp;#39;heading text&amp;#39;&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;home_facts&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; 
&lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;environment&amp;#39;&lt;/span&gt;
  &lt;span class="l l-Scalar l-Scalar-Plain"&gt;heading&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Env&amp;#39;&lt;/span&gt;
&lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;zone&amp;#39;&lt;/span&gt;
  &lt;span class="l l-Scalar l-Scalar-Plain"&gt;heading&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Zone&amp;#39;&lt;/span&gt;
&lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;catalog_config_version&amp;#39;&lt;/span&gt;
  &lt;span class="l l-Scalar l-Scalar-Plain"&gt;heading&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Cfg&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;Ver&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If I feel really adventurous, I&amp;#8217;d like to implement my other big wish,
some sort of pop-up list of links, based on arbitrary facts (mainly
hostname and fqdn) for each node - something where I can mouse over the
node name/table cell, and see links (static URLs with node
name/fqdn/other facts plugged in) to things like Nagios/Icinga, our
backup system,&amp;nbsp;etc.&lt;/p&gt;</content><category term="dashboard"></category><category term="facts"></category><category term="puppet"></category><category term="ruby"></category><category term="sysadmin"></category></entry><entry><title>Logging OpenSSH SFTPÂ Transactions</title><link href="https://blog.jasonantman.com/2012/07/logging-openssh-sftp-transactions/" rel="alternate"></link><published>2012-07-16T08:47:00-04:00</published><updated>2012-07-16T08:47:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-07-16:/2012/07/logging-openssh-sftp-transactions/</id><summary type="html">&lt;p&gt;I just came across a really handy post on &lt;a href="https://plus.google.com/117561367404774597588/posts"&gt;David
Busby&lt;/a&gt;&amp;#8216;s blog:
&lt;a href="http://blog.oneiroi.co.uk/linux/enable-logging-in-the-sftp-subsystem/"&gt;Enable logging in the &lt;span class="caps"&gt;SFTP&lt;/span&gt; subsystem -
Oneiroi&lt;/a&gt;.
From OpenSSH 4.4 on, you can pass arguments to Subsystem calls, and the
sftp subsystem supports logging to an aribtrary syslog facility and
priority. Simply adding a line&amp;nbsp;like â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I just came across a really handy post on &lt;a href="https://plus.google.com/117561367404774597588/posts"&gt;David
Busby&lt;/a&gt;&amp;#8216;s blog:
&lt;a href="http://blog.oneiroi.co.uk/linux/enable-logging-in-the-sftp-subsystem/"&gt;Enable logging in the &lt;span class="caps"&gt;SFTP&lt;/span&gt; subsystem -
Oneiroi&lt;/a&gt;.
From OpenSSH 4.4 on, you can pass arguments to Subsystem calls, and the
sftp subsystem supports logging to an aribtrary syslog facility and
priority. Simply adding a line&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Subsystem       sftp    /usr/libexec/openssh/sftp-server -f &lt;span class="caps"&gt;LOCAL5&lt;/span&gt; -l &lt;span class="caps"&gt;INFO&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and the appropriate lines to your syslog config will give you a handy
transfer log&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Jul 16 09:22:25 hostname sftp-server[2058]: session opened for local user jantman from [&lt;span class="caps"&gt;A.B.C.&lt;/span&gt;D]
Jul 16 09:22:26 hostname sftp-server[2058]: open &amp;quot;/home/jantman/temp/sftp_test&amp;quot; flags &lt;span class="caps"&gt;WRITE&lt;/span&gt;,&lt;span class="caps"&gt;CREATE&lt;/span&gt;,&lt;span class="caps"&gt;TRUNCATE&lt;/span&gt; mode 0666
Jul 16 09:22:45 hostname sftp-server[2058]: close &amp;quot;/home/jantman/temp/sftp_test&amp;quot; bytes read 0 written 1464813
Jul 16 09:23:08 hostname sftp-server[2058]: session closed for local user jantman from [&lt;span class="caps"&gt;A.B.C.&lt;/span&gt;D]
Jul 16 09:27:50 hostname sftp-server[2309]: session opened for local user jantman from [&lt;span class="caps"&gt;A.B.C.&lt;/span&gt;D]
Jul 16 09:27:50 hostname sftp-server[2309]: open &amp;quot;/home/jantman/temp/sftp_test&amp;quot; flags &lt;span class="caps"&gt;READ&lt;/span&gt; mode 0666
Jul 16 09:27:54 hostname sftp-server[2309]: close &amp;quot;/home/jantman/temp/sftp_test&amp;quot; bytes read 1464813 written 0
Jul 16 09:27:54 hostname sftp-server[2309]: session closed for local user jantman from [&lt;span class="caps"&gt;A.B.C.&lt;/span&gt;D]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you have syslog write these logs to their own file, remember to setup
log rotation for&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;Unfortunately, I&amp;#8217;m not aware of any way to log &lt;span class="caps"&gt;SCP&lt;/span&gt; file&amp;nbsp;transfers.&lt;/p&gt;</content><category term="logging"></category><category term="openssh"></category><category term="sftp"></category><category term="ssh"></category></entry><entry><title>Nagios Check Plugin for RsnapshotÂ Backups</title><link href="https://blog.jasonantman.com/2012/07/nagios-check-plugin-for-rsnapshot-backups/" rel="alternate"></link><published>2012-07-07T06:34:00-04:00</published><updated>2012-07-07T06:34:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-07-07:/2012/07/nagios-check-plugin-for-rsnapshot-backups/</id><summary type="html">&lt;p&gt;In a previous post, I described how I do &lt;a href="/2012/01/secure-rsnapshot-backups-over-the-wan-via-ssh/"&gt;Secure rsnapshot backups over
the &lt;span class="caps"&gt;WAN&lt;/span&gt; via
&lt;span class="caps"&gt;SSH&lt;/span&gt;&lt;/a&gt;. While my
layout of rsnapshot configuration files, data, and log files is a bit
esoteric, I monitor all this with a Nagios check plugin that runs on my
backup host. It Assumes that â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In a previous post, I described how I do &lt;a href="/2012/01/secure-rsnapshot-backups-over-the-wan-via-ssh/"&gt;Secure rsnapshot backups over
the &lt;span class="caps"&gt;WAN&lt;/span&gt; via
&lt;span class="caps"&gt;SSH&lt;/span&gt;&lt;/a&gt;. While my
layout of rsnapshot configuration files, data, and log files is a bit
esoteric, I monitor all this with a Nagios check plugin that runs on my
backup host. It Assumes that the output of
&lt;a href="http://rsnapshot.org/"&gt;rsnapshot&lt;/a&gt; is written to a text log file, one
file per host, at a path that matches
&lt;code&gt;/path_to_log_directory/log_HOSTNAME_YYYYMMDD-HHMMSS.log&lt;/code&gt; where
&lt;code&gt;HOSTNAME&lt;/code&gt; is the name of the host, and &lt;code&gt;YYYYMMDD-HHMMSS&lt;/code&gt; is a datestamp
(actually, the script just finds the newest file matching
&lt;code&gt;log_HOSTNAME_*.log&lt;/code&gt; in that directory). In order to obtain correct
timing of the runs, which rsnapshot doesn&amp;#8217;t offer, it assumes that you
trigger rsnapshot through a wrapper script, which runs it once per host
(inside a loop?) with per-host log files and some logging information
added,&amp;nbsp;like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; h in 
&lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="nv"&gt;&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/mnt/backup/rsnapshot/logs/log_&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;h&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;_`date +%Y%m%d-%H%M%S`.txt&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;# Starting backup at `date` (`date +%s`)&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
    /usr/bin/rsnapshot -c /etc/rsnapshot-&lt;span class="nv"&gt;$h&lt;/span&gt;.conf daily &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&amp;gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;# Finished backup at `date` (`date +%s`)&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$&lt;span class="caps"&gt;LOGFILE&lt;/span&gt;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;check_rsnapshot.pl&lt;/code&gt; plugin uses &lt;code&gt;utils.pm&lt;/code&gt; from Nagios, as well as
&lt;a href="http://search.cpan.org/~jv/Getopt-Long-2.38/lib/Getopt/Long.pm"&gt;Getopt::Long&lt;/a&gt;,
&lt;a href="http://search.cpan.org/~makoto/File-Stat-0.01/Stat.pm"&gt;File::stat&lt;/a&gt;,
&lt;a href="http://search.cpan.org/~flora/perl-5.14.2/lib/File/Basename.pm"&gt;File::Basename&lt;/a&gt;,
&lt;a href="http://search.cpan.org/~smueller/PathTools-3.33/lib/File/Spec.pm"&gt;File::Spec&lt;/a&gt;
and
&lt;a href="http://search.cpan.org/~ferreira/Number-Bytes-Human-0.07/Human.pm"&gt;Number::Bytes::Human&lt;/a&gt;.
This was one of my first Perl plugins, but seems to be rather
acceptable. It makes the following checks based on the rsnapshot&amp;nbsp;log:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Backup run in the last X seconds (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;li&gt;Maximum time from start to finish (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;li&gt;Minimum size of backup (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;li&gt;Minimum number of files in backup (warning and crit&amp;nbsp;thresholds)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In addition to &lt;code&gt;check_file_age&lt;/code&gt; checks on a number of files that are
included in backups and I know are modified before each backup run, this
seems to handle monitoring quite well for me. I certainly preferred
running &lt;a href="http://www.bacula.org/"&gt;Bacula&lt;/a&gt; and using my MySQL-based
&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/check_bacula_job.php"&gt;check_bacula_job.php&lt;/a&gt;,
but as I&amp;#8217;m now backing up 4 machines to my desktop, I no longer have a
need for Bacula (or&amp;nbsp;tapes).&lt;/p&gt;
&lt;p&gt;The script itself can be found at
&lt;a href="https://github.com/jantman/nagios-scripts/blob/master/check_rsnapshot.pl"&gt;github&lt;/a&gt;.&lt;/p&gt;</content><category term="backups"></category><category term="monitoring"></category><category term="Nagios"></category><category term="rsnapshot"></category><category term="rsync"></category></entry><entry><title>Tools for watching apache httpd andÂ memcached</title><link href="https://blog.jasonantman.com/2012/06/tools-for-watching-apache-httpd-and-memcached/" rel="alternate"></link><published>2012-06-26T13:46:00-04:00</published><updated>2012-06-26T13:46:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-06-26:/2012/06/tools-for-watching-apache-httpd-and-memcached/</id><summary type="html">&lt;p&gt;Recently I was working on a code release on a site running &lt;span class="caps"&gt;PHP&lt;/span&gt; on
&lt;a href="http://httpd.apache.org/"&gt;Apache httpd&lt;/a&gt;, and using
&lt;a href="http://memcached.org/"&gt;memcached&lt;/a&gt;. Without getting into specifics, we
had a number of issues that were both Apache and memcached problems, and
little visibility into them as it was running on an older server without â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently I was working on a code release on a site running &lt;span class="caps"&gt;PHP&lt;/span&gt; on
&lt;a href="http://httpd.apache.org/"&gt;Apache httpd&lt;/a&gt;, and using
&lt;a href="http://memcached.org/"&gt;memcached&lt;/a&gt;. Without getting into specifics, we
had a number of issues that were both Apache and memcached problems, and
little visibility into them as it was running on an older server without
much monitoring in place. I started looking around for simple tools that
could provide a bit more insight, without many dependencies (as the
machine is a relatively minimalist install). Here are some of the
options I&amp;nbsp;found:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://code.google.com/p/memcache-top/"&gt;memcache-top&lt;/a&gt; - A top-like
    script that pulls stats from memcached instances and can show both
    per-instance, total and average usage %, hit rate, number of
    connections, time to run the stats query, evictions, gets, sets, and
    read and write amounts. Best of all, it&amp;#8217;s a very small perl script
    that requires only &lt;span class="caps"&gt;IO&lt;/span&gt;::Socket and Time::HiRes. Here&amp;#8217;s a small
    example of the&amp;nbsp;output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;memcache-top v0.6       (default port: 11211, color: on, refresh: 3 seconds)

&lt;span class="caps"&gt;INSTANCE&lt;/span&gt;                &lt;span class="caps"&gt;USAGE&lt;/span&gt;   &lt;span class="caps"&gt;HIT&lt;/span&gt; %   &lt;span class="caps"&gt;CONN&lt;/span&gt;    &lt;span class="caps"&gt;TIME&lt;/span&gt;    &lt;span class="caps"&gt;EVICT&lt;/span&gt;   &lt;span class="caps"&gt;GETS&lt;/span&gt;    &lt;span class="caps"&gt;SETS&lt;/span&gt;    &lt;span class="caps"&gt;READ&lt;/span&gt;    &lt;span class="caps"&gt;WRITE&lt;/span&gt;
127.0.0.1:11211         86.6%   99.4%   115     0.6ms   0.0     4114    1669    1.3M    24.2M
127.0.0.1:11212         85.5%   59.9%   2       0.4ms   0.0     0       0       90      8055

&lt;span class="caps"&gt;AVERAGE&lt;/span&gt;:                86.0%   79.6%   58      0.5ms   0.0     2057    834     682.4K  12.1M

&lt;span class="caps"&gt;TOTAL&lt;/span&gt;:          0.&lt;span class="caps"&gt;9GB&lt;/span&gt;/  1.&lt;span class="caps"&gt;0GB&lt;/span&gt;           117     1.0ms   0.0     4114    1669    1.3M    24.2M
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/dormando/damemtop"&gt;damemtop&lt;/a&gt; is also a nice
    top-like memcached tool. On the positive side, you can specify any
    column from &amp;#8220;stats&amp;#8221;, &amp;#8220;stats items&amp;#8221; or &amp;#8220;stats slabs&amp;#8221; in the
    configuration file, and can choose between average or one-second
    snapshots for each column. On the down side, it requires the &lt;span class="caps"&gt;YAML&lt;/span&gt;
    and AnyEvent Perl modules, so it has some uncommon&amp;nbsp;dependencies.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;damemtop: Tue Jun 26 14:02:24 2012 [sort: hostname asc] [delay: 3s]
hostname           all_version  all_fill_rate  hit_rate  evictions  curr_items  curr_connections   cmd_get  cmd_set  bytes_written  bytes_read  get_hits  get_misses  
&lt;span class="caps"&gt;TOTAL&lt;/span&gt;:             
&lt;span class="caps"&gt;NA&lt;/span&gt;                 &lt;span class="caps"&gt;NA&lt;/span&gt;           &lt;span class="caps"&gt;NA&lt;/span&gt;             &lt;span class="caps"&gt;NA&lt;/span&gt;        &lt;span class="caps"&gt;NA&lt;/span&gt;         &lt;span class="caps"&gt;NA&lt;/span&gt;          &lt;span class="caps"&gt;NA&lt;/span&gt;                 87       32       491,735        30,894      86        1           
&lt;span class="caps"&gt;AVERAGE&lt;/span&gt;:           
&lt;span class="caps"&gt;NA&lt;/span&gt;                 &lt;span class="caps"&gt;NA&lt;/span&gt;           86.00%         99.00%    &lt;span class="caps"&gt;NA&lt;/span&gt;         &lt;span class="caps"&gt;NA&lt;/span&gt;          &lt;span class="caps"&gt;NA&lt;/span&gt;                 43       16       122,933        7,723       43        1           
10.200.1.78:11211  1.2.6        86.63%         98.04%    0          0           -1.00204024880524  51       19       386,492        21,613      50        1           
10.200.1.78:11212  1.2.6        85.46%         &lt;span class="caps"&gt;NA&lt;/span&gt;        0          0           0                  0        0        11,373         31          0         0           
10.200.1.79:11211  1.2.6        87.31%         100.00%   0          0           -1.00204024880524  36       13       82,479         9,219       36        0           
10.200.1.79:11212  1.2.6        85.08%         &lt;span class="caps"&gt;NA&lt;/span&gt;        0          0           0                  0        0        11,389         31          0         0           
loop took: 0.305617094039917
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;#8217;m still looking around for something for apache that uses mod_status
and isn&amp;#8217;t too verbose; ideally I&amp;#8217;d like to be able to watch memcached,
apache response codes/times, and apache mod_status all in the same
terminal&amp;nbsp;window.&lt;/p&gt;</content><category term="apache"></category><category term="memcached"></category><category term="perl"></category><category term="top"></category><category term="troubleshooting"></category></entry><entry><title>Script to Chart Intervals Between Problem and Recovery from Nagios/Icinga LogÂ Files</title><link href="https://blog.jasonantman.com/2012/05/script-to-chart-intervals-between-problem-and-recovery-from-nagiosicinga-log-files/" rel="alternate"></link><published>2012-05-31T13:54:00-04:00</published><updated>2012-05-31T13:54:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-05-31:/2012/05/script-to-chart-intervals-between-problem-and-recovery-from-nagiosicinga-log-files/</id><summary type="html">&lt;p&gt;At work, we use &lt;a href="http://www.icinga.org"&gt;Icinga&lt;/a&gt; (a fork of
&lt;a href="http://nagios.org/"&gt;Nagios&lt;/a&gt;) for monitoring. We have a few services
which are restarted or otherwise poked by event handlers, but the
recovery takes a while - so we often get paged for problems which
recover in a few minutes. I wrote a small perl script â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;At work, we use &lt;a href="http://www.icinga.org"&gt;Icinga&lt;/a&gt; (a fork of
&lt;a href="http://nagios.org/"&gt;Nagios&lt;/a&gt;) for monitoring. We have a few services
which are restarted or otherwise poked by event handlers, but the
recovery takes a while - so we often get paged for problems which
recover in a few minutes. I wrote a small perl script that greps through
the archived log files for a given regex (service and/or host name) and
then calculates the time from problem to recovery and graphs those&amp;nbsp;times.&lt;/p&gt;
&lt;p&gt;The script is called &lt;code&gt;nagios_log_problem_interval.pl&lt;/code&gt; and can be
downloaded from &lt;a href="https://github.com/jantman/nagios-scripts/blob/master/nagios_log_problem_interval.pl"&gt;my
github&lt;/a&gt;.
Below is some sample output, the number of minutes from problem to
recovery are along the Y axis and the count is along the X&amp;nbsp;axis:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt; nagios_log_problem_interval.pl --archivedir&lt;span class="o"&gt;=&lt;/span&gt;/var/icinga/archive --match&lt;span class="o"&gt;=&lt;/span&gt;myhost --backtrack&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt; myhost&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="caps"&gt;HTTP&lt;/span&gt;
&lt;span class="go"&gt;Count&lt;/span&gt;
&lt;span class="go"&gt;1:########(8)&lt;/span&gt;
&lt;span class="go"&gt;2:##(2)&lt;/span&gt;
&lt;span class="go"&gt;3:#(1)&lt;/span&gt;
&lt;span class="go"&gt;4:##(2)&lt;/span&gt;
&lt;span class="go"&gt;5:#######(7)&lt;/span&gt;
&lt;span class="go"&gt;6:(0)&lt;/span&gt;
&lt;span class="go"&gt;7:(0)&lt;/span&gt;
&lt;span class="go"&gt;8:#(1)&lt;/span&gt;
&lt;span class="go"&gt;9:(0)&lt;/span&gt;
&lt;span class="go"&gt;10:(0)&lt;/span&gt;
&lt;span class="go"&gt;11:#(1)&lt;/span&gt;
&lt;span class="go"&gt;12:(0)&lt;/span&gt;
&lt;span class="go"&gt;13:#(1)&lt;/span&gt;
&lt;span class="go"&gt;14:(0)&lt;/span&gt;
&lt;span class="go"&gt;15:(0)&lt;/span&gt;
&lt;span class="go"&gt;16-29:(0)&lt;/span&gt;
&lt;span class="go"&gt;30-59:(0)&lt;/span&gt;
&lt;span class="go"&gt;60+:(0)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="chart"></category><category term="icinga"></category><category term="monitoring"></category><category term="Nagios"></category><category term="perl"></category></entry><entry><title>Apache httpd - logging for sites with and without loadÂ balancing</title><link href="https://blog.jasonantman.com/2012/05/apache-httpd-logging-for-sites-with-and-without-load-balancing/" rel="alternate"></link><published>2012-05-30T09:46:00-04:00</published><updated>2012-05-30T09:46:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-05-30:/2012/05/apache-httpd-logging-for-sites-with-and-without-load-balancing/</id><summary type="html">&lt;p&gt;There are a few unfortunate places where I have an Apache httpd server
serving multiple vhosts, some behind a F5 BigIp load balancer and some
with direct traffic. For sites behind the &lt;span class="caps"&gt;LB&lt;/span&gt;, the remote &lt;span class="caps"&gt;IP&lt;/span&gt;/host will
always show up as the &lt;span class="caps"&gt;LB&lt;/span&gt;&amp;#8217;s &lt;span class="caps"&gt;IP&lt;/span&gt;/host, not that of â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are a few unfortunate places where I have an Apache httpd server
serving multiple vhosts, some behind a F5 BigIp load balancer and some
with direct traffic. For sites behind the &lt;span class="caps"&gt;LB&lt;/span&gt;, the remote &lt;span class="caps"&gt;IP&lt;/span&gt;/host will
always show up as the &lt;span class="caps"&gt;LB&lt;/span&gt;&amp;#8217;s &lt;span class="caps"&gt;IP&lt;/span&gt;/host, not that of the actual client. Using
the default configuration with LogFormat directives in &lt;code&gt;httpd.conf&lt;/code&gt;,
this means that either we need to define log formats per-vhost or lose
the client &lt;span class="caps"&gt;IP&lt;/span&gt; in one of our scenarios (&lt;span class="caps"&gt;LB&lt;/span&gt; or no&amp;nbsp;&lt;span class="caps"&gt;LB&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;I came by a simple solution to this on &lt;a href="http://www.maretmanu.org/homepage/inform/apache-forwarded.php"&gt;Emmanuel
ChantrÃ©au&lt;/a&gt;&amp;#8216;s
blog, and here is my condensed version of it. It sets an environment
variable (&amp;#8220;bigip-request&amp;#8221;) if the BIOrigClientAddr request header is set
(this header holds the client&amp;#8217;s &lt;span class="caps"&gt;IP&lt;/span&gt;; it&amp;#8217;s the BigIp proprietary version
of the X-Forwarded-For header. You could easily substitute that more
standard header in the following snippet) and then sets the &amp;#8220;combined&amp;#8221;
LogFormat based on that variable - a version using BIOrigClientAddr if
it is set, and a version using the normal &amp;#8220;%h&amp;#8221; remote host&amp;nbsp;otherwise.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;httpd.conf:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# set the &amp;quot;bigip-request&amp;quot; env variable to &amp;quot;1&amp;quot; if there is a BIOrigClientAddr header in the request                                                                                                   &lt;/span&gt;
&lt;span class="nb"&gt;SetEnvIf&lt;/span&gt; BIOrigClientAddr . bigip-request
&lt;span class="c"&gt;# we&amp;#39;ll use this following LogFormat (BIOrigClientAddr in place of remote host) as &amp;quot;combined&amp;quot; &lt;span class="caps"&gt;IF&lt;/span&gt; the bigip-request env variable is set                                                                     &lt;/span&gt;
&lt;span class="nb"&gt;LogFormat&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%{BIOrigClientAddr}i %l %u %t %v \&amp;quot;%r\&amp;quot; %&amp;gt;s %b \&amp;quot;%{Referer}i\&amp;quot; \&amp;quot;%{User-Agent}i\&amp;quot;&amp;quot;&lt;/span&gt; combined_lb
&lt;span class="c"&gt;# else we&amp;#39;ll use this one (remote host &lt;span class="caps"&gt;IP&lt;/span&gt; address) as &amp;quot;combined&amp;quot; &lt;span class="caps"&gt;IF&lt;/span&gt; the bigip-request env variable is &lt;span class="caps"&gt;NOT&lt;/span&gt; set                                                                                   &lt;/span&gt;
&lt;span class="nb"&gt;LogFormat&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%h %l %u %t %v \&amp;quot;%r\&amp;quot; %&amp;gt;s %b \&amp;quot;%{Referer}i\&amp;quot; \&amp;quot;%{User-Agent}i\&amp;quot;&amp;quot;&lt;/span&gt; combined
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then in our vhost&amp;nbsp;configuration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# use this log format if we&amp;#39;re behind an &lt;span class="caps"&gt;LB&lt;/span&gt;&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; logs/&amp;lt;%= domain %&amp;gt;_access_log combined env=!bigip-request
&lt;span class="c"&gt;# or this format if we&amp;#39;re not&lt;/span&gt;
&lt;span class="nb"&gt;CustomLog&lt;/span&gt; logs/&amp;lt;%= domain %&amp;gt;_access_log combined_lb env=bigip-request
&lt;/pre&gt;&lt;/div&gt;</content><category term="apache"></category><category term="bigip"></category><category term="f5"></category><category term="httpd"></category><category term="load balancer"></category><category term="logging"></category></entry><entry><title>Creating RPMs from Perl CPANÂ Modules</title><link href="https://blog.jasonantman.com/2012/05/creating-rpms-from-perl-cpan-modules/" rel="alternate"></link><published>2012-05-15T15:01:00-04:00</published><updated>2012-05-15T15:01:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-05-15:/2012/05/creating-rpms-from-perl-cpan-modules/</id><summary type="html">&lt;p&gt;I try my absolute best to always install software on my Linux boxes as
&lt;a href="http://en.wikipedia.org/wiki/RPM_Package_Manager"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt;&lt;/a&gt;s, installed
through &lt;a href="http://yum.baseurl.org/"&gt;Yum&lt;/a&gt; (yes, I use
&lt;a href="http://www.centos.org"&gt;CentOS&lt;/a&gt; on servers and
&lt;a href="http://fedoraproject.org/"&gt;Fedora&lt;/a&gt; on my desktops/laptops). Not only is
this more-or-less required to sanely manage configuration through
Puppet, but it also lets me recreate a â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I try my absolute best to always install software on my Linux boxes as
&lt;a href="http://en.wikipedia.org/wiki/RPM_Package_Manager"&gt;&lt;span class="caps"&gt;RPM&lt;/span&gt;&lt;/a&gt;s, installed
through &lt;a href="http://yum.baseurl.org/"&gt;Yum&lt;/a&gt; (yes, I use
&lt;a href="http://www.centos.org"&gt;CentOS&lt;/a&gt; on servers and
&lt;a href="http://fedoraproject.org/"&gt;Fedora&lt;/a&gt; on my desktops/laptops). Not only is
this more-or-less required to sanely manage configuration through
Puppet, but it also lets me recreate a machine, or install dependencies
for something, in one simple command line. Unfortunately, I run quite a
bit of Perl code, and there are a lot of &lt;a href="http://www.cpan.org/"&gt;&lt;span class="caps"&gt;CPAN&lt;/span&gt;&lt;/a&gt;
Perl modules that aren&amp;#8217;t in any of the usual CentOS/Fedora&amp;nbsp;repositories.&lt;/p&gt;
&lt;p&gt;Enter cpan2rpm: a Perl script that, in its simplest invocation,
downloads a specified &lt;span class="caps"&gt;CPAN&lt;/span&gt; module and automatically builds RPMs and
SRPMs for it. The &lt;a href="http://perl.arix.com/cpan2rpm/"&gt;original version&lt;/a&gt; by
&lt;a href="http://www.arix.com/ec/"&gt;Erick Calder&lt;/a&gt; hasn&amp;#8217;t been touched since 2005,
but there&amp;#8217;s &lt;a href="http://www.mediaburst.co.uk/blog/creating-perl-module-rpms/"&gt;a newer version from
Mediaburst&lt;/a&gt;,
&lt;a href="http://www2.mbstatic.co.uk/wp-content/uploads/2009/09/cpan2rpmmb"&gt;cpan2rpmmb&lt;/a&gt;,
that seems to incorporate some nice improvements and worked quite well
for&amp;nbsp;me.&lt;/p&gt;</content><category term="cpan"></category><category term="cpan2rpm"></category><category term="perl"></category><category term="rpm"></category><category term="yum"></category></entry><entry><title>Adjusting the VirtualBox F12 BIOS Boot PromptÂ Timeout</title><link href="https://blog.jasonantman.com/2012/04/adjusting-the-virtualbox-f12-bios-boot-prompt-timeout/" rel="alternate"></link><published>2012-04-09T13:52:00-04:00</published><updated>2012-04-09T13:52:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-09:/2012/04/adjusting-the-virtualbox-f12-bios-boot-prompt-timeout/</id><summary type="html">&lt;p&gt;I&amp;#8217;m working from home today, connected by &lt;span class="caps"&gt;VPN&lt;/span&gt;. I&amp;#8217;m in the process of
testing a bunch of Puppet stuff, and needed to re-image a bunch of
&lt;a href="https://www.virtualbox.org/"&gt;VirtualBox&lt;/a&gt; VMs on my desktop at work,
using &lt;span class="caps"&gt;PXE&lt;/span&gt; boot to &lt;a href="https://fedorahosted.org/cobbler/"&gt;Cobbler&lt;/a&gt;. I&amp;#8217;m only
connected to the desktop by &lt;span class="caps"&gt;SSH&lt;/span&gt;, and â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;m working from home today, connected by &lt;span class="caps"&gt;VPN&lt;/span&gt;. I&amp;#8217;m in the process of
testing a bunch of Puppet stuff, and needed to re-image a bunch of
&lt;a href="https://www.virtualbox.org/"&gt;VirtualBox&lt;/a&gt; VMs on my desktop at work,
using &lt;span class="caps"&gt;PXE&lt;/span&gt; boot to &lt;a href="https://fedorahosted.org/cobbler/"&gt;Cobbler&lt;/a&gt;. I&amp;#8217;m only
connected to the desktop by &lt;span class="caps"&gt;SSH&lt;/span&gt;, and running the VMs with &lt;code&gt;VBoxHeadless&lt;/code&gt;
and connecting to them via &lt;span class="caps"&gt;RDP&lt;/span&gt; (well, &lt;span class="caps"&gt;VRDP&lt;/span&gt;). The problem with this is
that if I start a &lt;span class="caps"&gt;VM&lt;/span&gt; on my console window, then switch to my &lt;span class="caps"&gt;RDP&lt;/span&gt; client
and connect, by the time the &lt;span class="caps"&gt;VM&lt;/span&gt; gets keyboard focus, it&amp;#8217;s already past
the VBox &amp;#8220;Press F12 to select boot device&amp;#8221; prompt and booting from disk.
I could modify the boot order on the &lt;span class="caps"&gt;VM&lt;/span&gt;, but then that becomes a pain
when it reboots after the&amp;nbsp;install.&lt;/p&gt;
&lt;p&gt;Thanks to some of the guys on the &lt;a href="https://www.virtualbox.org/wiki/IRC"&gt;VirtualBox &lt;span class="caps"&gt;IRC&lt;/span&gt;
channel&lt;/a&gt;, I found out about the
&lt;code&gt;--bioslogodisplaytime&lt;/code&gt; option for VMs, which controls the length of
time (in milliseconds) that the boot splash screen is shown (the default
value seems to be 0). It&amp;#8217;s included in the &lt;a href="http://www.virtualbox.org/manual/ch08.html#vboxmanage-modifyvm"&gt;reference guide to
VBoxManage&lt;/a&gt;
in the modifyvm section. Setting this to a value of 10 seconds or so, as
shown below, is more than enough for me to start the &lt;span class="caps"&gt;VM&lt;/span&gt;, Alt-Tab to my
&lt;span class="caps"&gt;RDP&lt;/span&gt; client, connect to the &lt;span class="caps"&gt;VM&lt;/span&gt;, and hit &amp;#8216;F12&amp;#8217; to select a one-time
network&amp;nbsp;boot:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;VBoxManage modifyvm &lt;span class="caps"&gt;VMNAME&lt;/span&gt; --bioslogodisplaytime 10000
&lt;/pre&gt;&lt;/div&gt;</content><category term="provisioning"></category><category term="pxe"></category><category term="rdp"></category><category term="sysadmin"></category><category term="vbox"></category><category term="virtualbox"></category><category term="virtualization"></category><category term="vm"></category></entry><entry><title>Rsync on an AndroidÂ phone</title><link href="https://blog.jasonantman.com/2012/04/rsync-on-an-android-phone/" rel="alternate"></link><published>2012-04-04T20:40:00-04:00</published><updated>2012-04-04T20:40:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-04-04:/2012/04/rsync-on-an-android-phone/</id><summary type="html">&lt;p&gt;Every once in a while, there are some files that I want kept in sync
between my Android-based phone and one of my Linux (or Mac, or any Unix,
or maybe Windows too, but I use Linux&amp;#8230;) boxes. Yeah, I can copy them
over manually via &lt;span class="caps"&gt;USB&lt;/span&gt; or even something â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Every once in a while, there are some files that I want kept in sync
between my Android-based phone and one of my Linux (or Mac, or any Unix,
or maybe Windows too, but I use Linux&amp;#8230;) boxes. Yeah, I can copy them
over manually via &lt;span class="caps"&gt;USB&lt;/span&gt; or even something a bit simpler like
&lt;a href="https://market.android.com/details?id=lysesoft.andftp"&gt;AndFTP&lt;/a&gt;
(assuming you can &lt;span class="caps"&gt;SCP&lt;/span&gt; to the target machine). But that&amp;#8217;s a real pain for
anything like my &lt;a href="http://keepass.info/"&gt;KeePass&lt;/a&gt; (well, actually
&lt;a href="http://www.keepassx.org/"&gt;KeePassX&lt;/a&gt; and
&lt;a href="https://market.android.com/details?id=com.android.keepass"&gt;KeePassDroid&lt;/a&gt;)
password database, that I might add something to at any time and forget
to sync. I also try to occasionally (waiting in line?) backup &lt;span class="caps"&gt;SMS&lt;/span&gt;, call
logs, etc. on my phone, and like to have those synced back to the
desktop&amp;nbsp;automatically.&lt;/p&gt;
&lt;p&gt;Enter the solution: &lt;a href="https://market.android.com/details?id=eu.kowalczuk.rsync4android"&gt;rsync backup for
Android&lt;/a&gt;,
a &lt;a href="http://rsync.samba.org/"&gt;rsync&lt;/a&gt; client for Android that includes
Tasker plugins (there are a few things about the app that I don&amp;#8217;t like,
but it seems to be the only option at the moment), and
&lt;a href="https://market.android.com/details?id=net.dinglisch.android.taskerm"&gt;Tasker&lt;/a&gt;,
an automation framework for Android.Tasker is one of the few Android
apps that I&amp;#8217;ve actually bought (i.e. not free/no-cost), and is currently
selling for $6.49. It&amp;#8217;s an incredibly capable task automator, very much
akin to &lt;a href="http://www.twofortyfouram.com/"&gt;Locale&lt;/a&gt; on steroids. On the
down side, Tasker can eat up battery life if you don&amp;#8217;t configure it
intelligently, and it&amp;#8217;s not &lt;em&gt;always&lt;/em&gt; 100% reliable when interacting with
the system. On the positive side, Tasker can identify practically any
combination of states in the android system (from hardware and software
events to &lt;span class="caps"&gt;GPS&lt;/span&gt; location, time, signal status, etc.) and perform almost
any task on the system based on this information. Sure, this specific
problem could be solved with a cron replacement (which Android lacks, of
course), but Tasker can do things like play specific audio files when
you get an &lt;span class="caps"&gt;SMS&lt;/span&gt; from a specific number, mute audio at certain &lt;span class="caps"&gt;GPS&lt;/span&gt;
locations, or turn WiFi on when I get home and off when I leave the
house. It also has a plugin architecture, and rsync backup for Android
happens to have a plugin that works with&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;So, our goal is to have a daily, bi-directional, newest-file-wins sync
between a directory on our Android phone and a directory on a computer.
I&amp;#8217;m not going to go into a lot of the computer-side stuff, mainly
because that varies quite a bit between operating systems, and also
because my personal setup is a bit paranoid in terms of security. For
the computer side, we&amp;#8217;ll need a machine that can be SSHed to from the
Internet (either a static &lt;span class="caps"&gt;IP&lt;/span&gt; or a known hostname/dynamic &lt;span class="caps"&gt;DNS&lt;/span&gt;), a user
that can run rsync over &lt;span class="caps"&gt;SSH&lt;/span&gt;, and a directory that&amp;#8217;s writable&amp;nbsp;(obviously).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Buy and install the
    &lt;a href="https://play.google.com/store/apps/details?id=net.dinglisch.android.taskerm"&gt;Tasker&lt;/a&gt;&amp;nbsp;app.&lt;/li&gt;
&lt;li&gt;Install the &lt;a href="https://play.google.com/store/apps/details?id=eu.kowalczuk.rsync4android"&gt;rsync backup for
    Android&lt;/a&gt;&amp;nbsp;app.&lt;/li&gt;
&lt;li&gt;Configure the rsync stuff on the computer. In the simplest form,
    we&amp;#8217;ll just need a user that can login and run rsync, and a directory
    to sync from/to &lt;em&gt;(note: this should be a directory used only for
    syncing the&amp;nbsp;phone&amp;#8230;).&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Open the rsync backup for Android app. Use Menu -&gt; Generate Keys to
    generate a new pair of &lt;span class="caps"&gt;SSH&lt;/span&gt; keys, and then get the public key setup
    on the target computer. See &lt;a href="http://android.kowalczuk.eu/rsync4android/"&gt;the developer&amp;#8217;s web
    site&lt;/a&gt; for&amp;nbsp;instructions.&lt;/li&gt;
&lt;li&gt;Once keys are setup, create a new profile called &amp;#8220;&lt;span class="caps"&gt;PC&lt;/span&gt;-droid&amp;#8221;. Set the
    local directory to a new empty directory (I used &lt;code&gt;/sdcard/sync&lt;/code&gt;),
    enter the remote host address, port, username, and remote directory,
    and select the private &lt;span class="caps"&gt;SSH&lt;/span&gt; key that you created. Check off &amp;#8220;rsync on
    reverse direction&amp;#8221;. As this program is just a &lt;span class="caps"&gt;GUI&lt;/span&gt; wrapper around
    normal rsync binaries, you can specify additional options to the
    rsync command; my string ended up being
    &lt;code&gt;-vHrltDuO --chmod=Du+rwx,go-rwx,Fu+rw,go-rw --no-perms&lt;/code&gt;. If it
    helps, at the bottom of the screen you can see the actual rsync
    command line that will be run. Save when&amp;nbsp;done.&lt;/li&gt;
&lt;li&gt;Save the profile, then long-press it and select &amp;#8220;Duplicate&amp;#8221;. Change
    the name to &amp;#8220;droid-&lt;span class="caps"&gt;PC&lt;/span&gt;&amp;#8221;, uncheck &amp;#8220;rsync in reverse direction&amp;#8221;, and
    change your additional options as needed (mine became
    &lt;code&gt;-vHrltDu --chmod=Dug+rwx,o-rwx,Fug+rw,o-rw --no-perms&lt;/code&gt;). Save when&amp;nbsp;done.&lt;/li&gt;
&lt;li&gt;Create a test file in the sync directory on the &lt;span class="caps"&gt;PC&lt;/span&gt;, and a different
    one in the sync directory on the&amp;nbsp;droid.&lt;/li&gt;
&lt;li&gt;One at a time, in the rsync backup app, tap on the profile names. If
    all goes well, the syncs should run, and both files will now be in
    both places. If there are any problems, the output should help; the
    most likely issues are probably permissions, rsync command options,
    or &lt;span class="caps"&gt;SSH&lt;/span&gt;&amp;nbsp;keys.&lt;/li&gt;
&lt;li&gt;Long-press each profile, select &amp;#8220;Edit&amp;#8221;, and check off &amp;#8220;Close log
    window after job is done&amp;#8221;. Save&amp;nbsp;profile.&lt;/li&gt;
&lt;li&gt;Now fire up Tasker. Click the &amp;#8220;+&amp;#8221; at the bottom of the screen to
    create a new profile, call it &amp;#8220;sync&amp;#8221;, and click the check&amp;nbsp;mark.&lt;/li&gt;
&lt;li&gt;On the First Context panel, tap Time, and select when you want the
    jobs to run; I chose 03:01. Tap the check&amp;nbsp;mark.&lt;/li&gt;
&lt;li&gt;On the Task Selection panel, tap New Task. Give it a name, like&amp;nbsp;&amp;#8220;sync2&amp;#8221;.&lt;/li&gt;
&lt;li&gt;On the Task Edit panel, tap the &amp;#8220;+&amp;#8221; button at the bottom left, tap
    Plugin, tap &amp;#8220;rsync backup for Android&amp;#8221;, click the &amp;#8220;Edit&amp;#8221; button on
    the Configuration line, and select the &lt;span class="caps"&gt;PC&lt;/span&gt;-droid rsync profile. Tap
    the check mark in the lower left to&amp;nbsp;save.&lt;/li&gt;
&lt;li&gt;Repeat the last step for the droid-&lt;span class="caps"&gt;PC&lt;/span&gt; rsync&amp;nbsp;profile.&lt;/li&gt;
&lt;li&gt;Tap the check box in the lower left. This saves the&amp;nbsp;profile.&lt;/li&gt;
&lt;li&gt;In the main Tasker screen, make sure there&amp;#8217;s a green check to the
    right of the profile you just added, and that the button at the
    bottom right of the screen is set to&amp;nbsp;&amp;#8220;On&amp;#8221;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Assuming this all went well, the next time the time you specified rolls
around, your sync should run. If you gave the task a name in step 12,
you can setup additional profiles to run it at other times (or use the
repeat logic&amp;nbsp;builtin).&lt;/p&gt;</content><category term="android"></category><category term="rsync"></category><category term="tasker"></category></entry><entry><title>Python script to find dependency cycles in GraphViz dotÂ files</title><link href="https://blog.jasonantman.com/2012/03/python-script-to-find-dependency-cycles-in-graphviz-dot-files/" rel="alternate"></link><published>2012-03-28T22:05:00-04:00</published><updated>2012-03-28T22:05:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-28:/2012/03/python-script-to-find-dependency-cycles-in-graphviz-dot-files/</id><summary type="html">&lt;p&gt;Using &lt;a href="http://www.graphviz.org/"&gt;GraphViz&lt;/a&gt; to describe configurations is
relatively popular in the software and systems architecture world; the
simple text-based format makes it quiet simple, and the directed graph
(dot file) is a simple method to store a graph of information flow or
component relationships. &lt;a href="http://puppetlabs.com"&gt;Puppet&lt;/a&gt; includes
builtin support for &lt;a href="http://docs.puppetlabs.com/guides/faq.html#how-do-i-use-puppets-graphing-support"&gt;generating dot â¦&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Using &lt;a href="http://www.graphviz.org/"&gt;GraphViz&lt;/a&gt; to describe configurations is
relatively popular in the software and systems architecture world; the
simple text-based format makes it quiet simple, and the directed graph
(dot file) is a simple method to store a graph of information flow or
component relationships. &lt;a href="http://puppetlabs.com"&gt;Puppet&lt;/a&gt; includes
builtin support for &lt;a href="http://docs.puppetlabs.com/guides/faq.html#how-do-i-use-puppets-graphing-support"&gt;generating dot
graphs&lt;/a&gt;
of its configuration resources and relationships (both those specified
by the user, and all relationships including ones generated by Puppet&amp;nbsp;itself).&lt;/p&gt;
&lt;p&gt;One of the common uses for puppet&amp;#8217;s graphs is to identify dependency
cycles, as cyclic dependencies cause an error condition. However,
Puppet&amp;#8217;s own
&lt;a href="http://docs.puppetlabs.com/guides/faq.html#how-do-i-use-puppets-graphing-support"&gt;&lt;span class="caps"&gt;FAQ&lt;/span&gt;&lt;/a&gt;
only mentions using the &lt;code&gt;dot&lt;/code&gt; command to generate a &lt;span class="caps"&gt;PNG&lt;/span&gt; graphical
representation of the the graph. When debugging a recent problem with
puppet, I ended up with a message&amp;nbsp;like:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Could not apply complete catalog: Found dependency cycles in the following relationships: Service[puppet] =&amp;gt; File[/var/lib/puppet/yaml/foreman], File[/var/lib/puppet/yaml] =&amp;gt; File[/var/lib/puppet/yaml/foreman], Service[puppet] =&amp;gt; File[/etc/puppet/node.rb], File[fileserver.conf] =&amp;gt; Service[apache], File[namespaceauth.conf] =&amp;gt; Service[apache], File[puppet.conf] =&amp;gt; Service[apache], File[puppet.conf] =&amp;gt; Service[puppet], Service[puppet] =&amp;gt; File[foreman-report.rb], File[/var/lib/puppet/yaml/foreman] =&amp;gt; Package[puppet-server], Service[foreman-proxy] =&amp;gt; Package[puppet-server], File[foreman-proxy-settings.yml] =&amp;gt; Package[puppet-server], Package[foreman-proxy] =&amp;gt; Package[puppet-server], User[foreman-proxy] =&amp;gt; Package[puppet-server], File[/var/lib/puppet/yaml] =&amp;gt; Package[puppet-server], File[foreman-report.rb] =&amp;gt; Package[puppet-server], File[/etc/puppet/node.rb] =&amp;gt; Package[puppet-server], File[/var/lib/puppet/yaml/foreman] =&amp;gt; Exec[create_puppetmaster_certs], Service[foreman-proxy] =&amp;gt; Exec[create_puppetmaster_certs], File[foreman-proxy-settings.yml] =&amp;gt; Exec[create_puppetmaster_certs], Package[foreman-proxy] =&amp;gt; Exec[create_puppetmaster_certs], User[foreman-proxy] =&amp;gt; Exec[create_puppetmaster_certs], File[/var/lib/puppet/yaml] =&amp;gt; Exec[create_puppetmaster_certs], File[foreman-report.rb] =&amp;gt; Exec[create_puppetmaster_certs], File[/etc/puppet/node.rb] =&amp;gt; Exec[create_puppetmaster_certs], File[/var/lib/puppet/yaml/foreman] =&amp;gt; File[/etc/puppet/environments], Service[foreman-proxy] =&amp;gt; File[/etc/puppet/environments], File[foreman-proxy-settings.yml] =&amp;gt; File[/etc/puppet/environments], Package[foreman-proxy] =&amp;gt; File[/etc/puppet/environments], User[foreman-proxy] =&amp;gt; File[/etc/puppet/environments], File[/var/lib/puppet/yaml] =&amp;gt; File[/etc/puppet/environments], File[foreman-report.rb] =&amp;gt; File[/etc/puppet/environments], File[/etc/puppet/node.rb] =&amp;gt; File[/etc/puppet/environments], File[foreman-proxy-settings.yml] =&amp;gt; Service[foreman-proxy], Package[foreman-proxy] =&amp;gt; Service[foreman-proxy], Service[puppet]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Not exactly easy to follow, or to pull much meaning out of, even if I
did some slight reformatting by putting in some newlines. I then
generated the png as described in the Puppet FAQs, but even scrolling
back and forth on this for 20 minutes didn&amp;#8217;t help: &lt;em&gt;(note: link is to
the original 14405x665px png)&lt;/em&gt;&lt;br&gt;
&lt;a href="/GFX/relationships.dot.png"&gt;&lt;img alt="dot file
png" src="/GFX/relationships.dot.small.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With a little research, I managed to find the
&lt;a href="http://networkx.lanl.gov"&gt;NetworkX&lt;/a&gt; package for Python; according to
their site, &amp;#8220;NetworkX is a Python language software package for the
creation, manipulation, and study of the structure, dynamics, and
functions of complex networks.&amp;#8221; Among its features are the ability to
&lt;a href="http://networkx.lanl.gov/reference/drawing.html#module-networkx.drawing.nx_pydot"&gt;read dot
files&lt;/a&gt;
using the &lt;a href="http://code.google.com/p/pydot/"&gt;pydot&lt;/a&gt; library, and the
ability to &lt;a href="http://networkx.lanl.gov/reference/generated/networkx.algorithms.cycles.simple_cycles.html#networkx.algorithms.cycles.simple_cycles"&gt;find simple
cycles&lt;/a&gt;
within a graph. In about 20 minutes, I hacked together the dead-simple
script&amp;nbsp;below.&lt;/p&gt;
&lt;p&gt;Given a dot file (of the type generated, for example, by Puppet), this
will output all of the cycles found within the graph. I ran this script
on the &lt;code&gt;expanded_relationships.dot&lt;/code&gt; file from Puppet, which had 99 nodes
(nodes on the graph, not puppet clients), and got the following&amp;nbsp;output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[&amp;#39;File[foreman-report.rb]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-report.rb]&amp;#39;]
[&amp;#39;File[foreman-report.rb]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-report.rb]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;Package[puppet-server]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/var/lib/puppet/yaml/foreman]&amp;#39;, &amp;#39;Package[puppet-server]&amp;#39;]
[&amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;]
[&amp;#39;File[/etc/puppet/node.rb]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;File[/etc/puppet/node.rb]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;Package[foreman-proxy]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[/var/lib/puppet/yaml/foreman]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;Service[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;File[foreman-proxy-settings.yml]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
[&amp;#39;File[puppet.conf]&amp;#39;, &amp;#39;Service[puppet]&amp;#39;, &amp;#39;User[foreman-proxy]&amp;#39;, &amp;#39;File[puppet.conf]&amp;#39;]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It probably would have taken me hours to come up with that by hand, let
alone realize that &lt;code&gt;Service[puppet]&lt;/code&gt; is the common item in all of them,
and hence the problem. With that little tidbit of information, I managed
to track down an extraneous &amp;#8220;require puppet&amp;#8221; that this all originated
from. I sincerely hope that this script will save someone else at least
as much time as it took me to write (I know it will for&amp;nbsp;me&amp;#8230;).&lt;/p&gt;
&lt;p&gt;You can always obtain the latest version of this script from
&lt;a href="https://github.com/jantman/misc-scripts/blob/master/dot_find_cycles.py"&gt;my github repository&lt;/a&gt;
It&amp;#8217;s free for use
and distribution, provided that you leave my copyright/attribution and
source &lt;span class="caps"&gt;URL&lt;/span&gt; notice intact, update the changelog, and send any
features/fixes back to me. The script is written in Python, and depends
on the python-networkx, graphviz-python, and pydot packages (all of
which are available as packages in the default repos of Fedora and
CentOS at least). For Puppet purposes, I&amp;#8217;d recommend running this on
&lt;code&gt;expanded_relationships.dot&lt;/code&gt; to get the full&amp;nbsp;information.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;dot_find_cycles.py - uses Pydot and NetworkX to find cycles in a dot file directed graph.&lt;/span&gt;

&lt;span class="sd"&gt;Very helpful for &lt;/span&gt;

&lt;span class="sd"&gt;By Jason Antman  2012.&lt;/span&gt;

&lt;span class="sd"&gt;Free for all use, provided that you send any changes you make back to me, update the changelog, and keep this comment intact.&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;REQUIREMENTS&lt;/span&gt;:&lt;/span&gt;
&lt;span class="sd"&gt;Python&lt;/span&gt;
&lt;span class="sd"&gt;python-networkx - &lt;/span&gt;
&lt;span class="sd"&gt;graphviz-python - &lt;/span&gt;
&lt;span class="sd"&gt;pydot - &lt;/span&gt;
&lt;span class="sd"&gt;(all of these are available as native packages at least on CentOS)&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;USAGE&lt;/span&gt;:&lt;/span&gt;
&lt;span class="sd"&gt;dot_find_cycles.py /path/to/file.dot&lt;/span&gt;

&lt;span class="sd"&gt;The canonical source of this script can always be found from:&lt;/span&gt;


&lt;span class="sd"&gt;$HeadURL: http://svn.jasonantman.com/misc-scripts/dot_find_cycles.py $&lt;/span&gt;
&lt;span class="sd"&gt;$LastChangedRevision: 33 $&lt;/span&gt;

&lt;span class="sd"&gt;&lt;span class="caps"&gt;CHANGELOG&lt;/span&gt;:&lt;/span&gt;
&lt;span class="sd"&gt;    Wednesday 2012-03-28 Jason Antman :&lt;/span&gt;
&lt;span class="sd"&gt;        - initial script creation&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;access&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;R_OK&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;networkx&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;nx&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dot_find_cycles.py by Jason Antman &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;  finds cycles in dot file graphs, such as those from Puppet&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;USAGE&lt;/span&gt;: dot_find_cycles.py /path/to/file.dot&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;fh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;IOError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stderr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;span class="caps"&gt;ERROR&lt;/span&gt;: could not read file &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;usage&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# read in the specified file, create a networkx DiGraph&lt;/span&gt;
    &lt;span class="n"&gt;G&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DiGraph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;simple_cycles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;G&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;

&lt;span class="c1"&gt;# Run&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="dot"></category><category term="graph"></category><category term="graphviz"></category><category term="puppet"></category><category term="python"></category></entry><entry><title>Github as a repository inÂ Redmine</title><link href="https://blog.jasonantman.com/2012/03/github-as-a-repository-in-redmine/" rel="alternate"></link><published>2012-03-27T21:36:00-04:00</published><updated>2012-03-27T21:36:00-04:00</updated><author><name>admin</name></author><id>tag:blog.jasonantman.com,2012-03-27:/2012/03/github-as-a-repository-in-redmine/</id><summary type="html">&lt;p&gt;As a follow-up to my &lt;a href="/2012/03/cvs-to-svn-to-git/"&gt;&lt;span class="caps"&gt;CVS&lt;/span&gt; to &lt;span class="caps"&gt;SVN&lt;/span&gt; to Git&lt;/a&gt;
post, I have the &lt;a href="http://www.php-ems-tools.com"&gt;&lt;span class="caps"&gt;PHP&lt;/span&gt; &lt;span class="caps"&gt;EMS&lt;/span&gt; Tools&lt;/a&gt;
repository migrated from my &lt;span class="caps"&gt;SVN&lt;/span&gt; to
&lt;a href="https://github.com/jantman/php-ems-tools"&gt;github&lt;/a&gt;. Since I&amp;#8217;m moving the
website and all development to a &lt;a href="http://www.redmine.org/"&gt;Redmine&lt;/a&gt;
instance, the next step is setting up Github to work as a revision
control â¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;As a follow-up to my &lt;a href="/2012/03/cvs-to-svn-to-git/"&gt;&lt;span class="caps"&gt;CVS&lt;/span&gt; to &lt;span class="caps"&gt;SVN&lt;/span&gt; to Git&lt;/a&gt;
post, I have the &lt;a href="http://www.php-ems-tools.com"&gt;&lt;span class="caps"&gt;PHP&lt;/span&gt; &lt;span class="caps"&gt;EMS&lt;/span&gt; Tools&lt;/a&gt;
repository migrated from my &lt;span class="caps"&gt;SVN&lt;/span&gt; to
&lt;a href="https://github.com/jantman/php-ems-tools"&gt;github&lt;/a&gt;. Since I&amp;#8217;m moving the
website and all development to a &lt;a href="http://www.redmine.org/"&gt;Redmine&lt;/a&gt;
instance, the next step is setting up Github to work as a revision
control repository in redmine. Well, it&amp;#8217;s dead simple. I just followed
the instructions for the &lt;a href="http://mentalized.net/journal/2009/08/03/redmine_plugin_github_hook/"&gt;Redmine plugin: Github
hook&lt;/a&gt;
, with the exception that I followed the &lt;a href="http://www.redmine.org/projects/redmine/wiki/HowTo_keep_in_sync_your_git_repository_for_redmine"&gt;redmine instructions for
setting up the repository
clone&lt;/a&gt;
instead of Step #2 in the plugin instructions. All worked well, though
I&amp;#8217;ll admit I only tried it talking to redmine over plain &lt;span class="caps"&gt;HTTP&lt;/span&gt;, not&amp;nbsp;&lt;span class="caps"&gt;HTTPS&lt;/span&gt;.&lt;/p&gt;</content><category term="git"></category><category term="github"></category><category term="redmine"></category></entry></feed>